{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Vissim_env_class import environment\n",
    "from Actor_critic_class import ACAgent\n",
    "from MasterAC_Agent import MasterAC_Agent\n",
    "from MasterDQN_Agent import MasterDQN_Agent\n",
    "\n",
    "# Network Specific Libraries\n",
    "from Balance_Functions import balance_dictionary\n",
    "\n",
    "# General Libraries\n",
    "import numpy as np \n",
    "import pylab as plt\n",
    "import os\n",
    "import shutil\n",
    "import csv\n",
    "import pandas as pd\n",
    "import json\n",
    "import sqlite3\n",
    "\n",
    "%load_ext sql\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balance RL DQN Integrated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session ID: Balance_integrated_default_actions_100_10800_DuelingDDQN_delay\n"
     ]
    }
   ],
   "source": [
    "model_name  = 'Balance_integrated'\n",
    "vissim_working_directory = 'C:\\\\Users\\\\acabrejasegea\\\\OneDrive - The Alan Turing Institute\\\\Desktop\\\\ATI\\\\0_TMF\\\\MLforFlowOptimisation\\\\Vissim\\\\'\n",
    "#vissim_working_directory = \"E:\\\\OneDrive - University of Warwick\\\\Desktop\\\\ATI\\\\0_TMF\\\\MLforFlowOptimisation\\\\Vissim\"\n",
    "\n",
    "# State the internal IDs of the intersections used during training, according to topology\n",
    "intersection_ids = [\"1_2_4\", \"1_2_4\", \"3\", \"1_2_4\", \"5\", \"6\", \"7\",\\\n",
    "                    \"8\", \"9\", \"10\", \"11_12\", \"11_12\", \"13\", \"14\"]\n",
    "\n",
    "## Simulation Parameters\n",
    "Random_Seed = 44\n",
    "sim_length = 10801\n",
    "agent_type = \"DuelingDDQN\"\n",
    "actions = 'default_actions'     # 'default_actions' or 'all_actions'\n",
    "\n",
    "## DQN Hyperaramenters\n",
    "episodes = 100\n",
    "copy_weights_frequency = 10\n",
    "timesteps_per_second = 1\n",
    "PER_activated = True\n",
    "memory_size = 5000\n",
    "batch_size = 256\n",
    "batches_per_episode = 10\n",
    "\n",
    "alpha = 0.001\n",
    "gamma = 0.95\n",
    "\n",
    "# Load balance dictionary\n",
    "Balance_dictionary = balance_dictionary(agent_type)\n",
    "\n",
    "# State session ID\n",
    "Session_ID = model_name + \"_\" + actions + \"_\" + str(episodes) + \"_\" + str(sim_length-1) + \"_\" + agent_type + \"_delay\"\n",
    "print(\"Session ID: {}\".format(Session_ID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x324 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Exploration Schedule (\"linear\" or \"geometric\")\n",
    "exploration_schedule = \"geometric\"\n",
    "epsilon_start = 0.2\n",
    "epsilon_end   = 0.01\n",
    "epsilon_min   = 0.01\n",
    "\n",
    "def choose_schedule(exploration_schedule, espilon_start, epsilon_end, epsilon_min, episodes):\n",
    "    if exploration_schedule == \"linear\":\n",
    "        epsilon_decay = 1.2*(epsilon_end - epsilon_start)/(episodes-1)\n",
    "        epsilon_sequence = [epsilon_start + epsilon_decay * entry for entry in range(episodes+1)]\n",
    "        epsilon_sequence = [epsilon_min if entry < epsilon_min else entry for entry in epsilon_sequence]\n",
    "    elif exploration_schedule == \"geometric\":\n",
    "        epsilon_decay = np.power(epsilon_end/epsilon_start, 1./(episodes-1)) # Geometric decay\n",
    "        epsilon_sequence = [epsilon_start * epsilon_decay ** entry for entry in range(episodes+1)]\n",
    "        epsilon_sequence = [epsilon_min if entry < epsilon_min else entry for entry in epsilon_sequence]\n",
    "    elif exploration_schedule == \"entropy\":\n",
    "        pass\n",
    "    else:\n",
    "        print(\"ERROR: Unrecognized choice of exploration schedule.\")\n",
    "        \n",
    "    # Plotting exploration schedule\n",
    "    plt.figure(figsize=(8,4.5))\n",
    "    x_series = np.array(range(1,episodes+1))\n",
    "    y_series = epsilon_sequence[0:episodes]\n",
    "    plt.plot(x_series, y_series, '-b')\n",
    "    plt.xlabel('Episodes')\n",
    "    plt.ylabel('Ratio of random exploration')\n",
    "    plt.title('Exploration schedule')\n",
    "    plt.show()\n",
    "    return(epsilon_sequence)\n",
    "\n",
    "epsilon_sequence = choose_schedule(exploration_schedule, epsilon_start, epsilon_end, epsilon_min, episodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent 0\n",
      "Copying files...\n",
      "Agent 1\n",
      "Copying files...\n",
      "Agent 2\n",
      "Copying files...\n",
      "Agent 3\n",
      "Copying files...\n",
      "Agent 4\n",
      "Copying files...\n",
      "Agent 5\n",
      "Copying files...\n",
      "Agent 6\n",
      "Copying files...\n",
      "Agent 7\n",
      "Copying files...\n",
      "Agent 8\n",
      "Copying files...\n",
      "Agent 9\n",
      "Copying files...\n",
      "Agent 10\n",
      "Copying files...\n",
      "Agent 11\n",
      "Copying files...\n",
      "Agent 12\n",
      "Copying files...\n",
      "Agent 13\n",
      "Copying files...\n",
      "All Files Successfully Copied.\n"
     ]
    }
   ],
   "source": [
    "## Gather files from pretrained Balance_intX Runs\n",
    "\n",
    "# Re-create the Intersection IDs used during training\n",
    "single_intersection_agent_ids = ['Balance_int'+ int_id for int_id in intersection_ids]\n",
    "# Re-create the Session IDs used during training\n",
    "single_intersection_session_ids = [ agent_id + \"_\" + actions + \"_\" + str(episodes) + \"_\" + str(sim_length-1) + \"_\" + agent_type + \"_delay\"\n",
    " for agent_id in single_intersection_agent_ids]\n",
    "\n",
    "# Use the two previous set of strings to point to the location of the agent files\n",
    "agents_sources_origin = [os.path.join(vissim_working_directory, single_intersection_agent_ids[idx],\\\n",
    "                                   \"Agents_Results\", agent_type, session_id) for idx, session_id in enumerate(single_intersection_session_ids)]\n",
    "\n",
    "# Set the destination path into the new model\n",
    "# Intersections that trained together are now split into individual forlders\n",
    "agents_sources_destination = [os.path.join(vissim_working_directory, \"Balance_Integrated\", \"Agents_source\",\\\n",
    "                                         agent_type, Session_ID,\"Agent{}\".format(idx)) for idx, session_id in enumerate(single_intersection_session_ids)]\n",
    "\n",
    "# Check if output folders exist, if they do not, then create them\n",
    "for folder in agents_sources_destination:\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "\n",
    "# Copy all training files from their origin to the Balance_integrated archive\n",
    "for idx, (origin, destination) in enumerate(zip(agents_sources_origin, agents_sources_destination)):\n",
    "    print(\"Agent {}\".format(idx))\n",
    "    #print(\"Listing files in:\", origin)\n",
    "    \n",
    "    # List all files in origin folder\n",
    "    files_in_folder = os.listdir(origin)\n",
    "    print(\"Copying files...\")\n",
    "    \n",
    "    # Copy them one by one\n",
    "    for file in files_in_folder:\n",
    "        shutil.copy(os.path.join(origin,file), destination)\n",
    "print(\"All Files Successfully Copied.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTERSECTION 0: SETTING UP AGENT\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 24)           216         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 24)           600         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 24)           600         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 24)           600         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            25          dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 3)            75          dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "policy (Lambda)                 (None, 3)            0           dense_5[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,116\n",
      "Trainable params: 2,116\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Deployed instance of Dueling Double Deep Q Learning Agent(s) at Intersection 0\n",
      "\n",
      "INTERSECTION 1: SETTING UP AGENT\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 24)           216         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 24)           600         dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 24)           600         dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 24)           600         dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 1)            25          dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 3)            75          dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "policy (Lambda)                 (None, 3)            0           dense_17[0][0]                   \n",
      "                                                                 dense_15[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 2,116\n",
      "Trainable params: 2,116\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Deployed instance of Dueling Double Deep Q Learning Agent(s) at Intersection 1\n",
      "\n",
      "INTERSECTION 2: SETTING UP AGENT\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 14)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 24)           360         input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 24)           600         dense_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 24)           600         dense_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 24)           600         dense_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 1)            25          dense_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 4)            100         dense_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "policy (Lambda)                 (None, 4)            0           dense_29[0][0]                   \n",
      "                                                                 dense_27[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 2,285\n",
      "Trainable params: 2,285\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Deployed instance of Dueling Double Deep Q Learning Agent(s) at Intersection 2\n",
      "\n",
      "INTERSECTION 3: SETTING UP AGENT\n",
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_36 (Dense)                (None, 24)           216         input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_37 (Dense)                (None, 24)           600         dense_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_40 (Dense)                (None, 24)           600         dense_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_38 (Dense)                (None, 24)           600         dense_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_41 (Dense)                (None, 1)            25          dense_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_39 (Dense)                (None, 3)            75          dense_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "policy (Lambda)                 (None, 3)            0           dense_41[0][0]                   \n",
      "                                                                 dense_39[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 2,116\n",
      "Trainable params: 2,116\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Deployed instance of Dueling Double Deep Q Learning Agent(s) at Intersection 3\n",
      "\n",
      "INTERSECTION 4: SETTING UP AGENT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_48 (Dense)                (None, 24)           168         input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_49 (Dense)                (None, 24)           600         dense_48[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_52 (Dense)                (None, 24)           600         dense_49[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_50 (Dense)                (None, 24)           600         dense_49[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_53 (Dense)                (None, 1)            25          dense_52[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_51 (Dense)                (None, 3)            75          dense_50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "policy (Lambda)                 (None, 3)            0           dense_53[0][0]                   \n",
      "                                                                 dense_51[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 2,068\n",
      "Trainable params: 2,068\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Deployed instance of Dueling Double Deep Q Learning Agent(s) at Intersection 4\n",
      "\n",
      "INTERSECTION 5: SETTING UP AGENT\n",
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           [(None, 3)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_60 (Dense)                (None, 24)           96          input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_61 (Dense)                (None, 24)           600         dense_60[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_64 (Dense)                (None, 24)           600         dense_61[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_62 (Dense)                (None, 24)           600         dense_61[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_65 (Dense)                (None, 1)            25          dense_64[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_63 (Dense)                (None, 2)            50          dense_62[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "policy (Lambda)                 (None, 2)            0           dense_65[0][0]                   \n",
      "                                                                 dense_63[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,971\n",
      "Trainable params: 1,971\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Deployed instance of Dueling Double Deep Q Learning Agent(s) at Intersection 5\n",
      "\n",
      "INTERSECTION 6: SETTING UP AGENT\n",
      "Model: \"model_12\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_13 (InputLayer)           [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_72 (Dense)                (None, 24)           168         input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_73 (Dense)                (None, 24)           600         dense_72[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_76 (Dense)                (None, 24)           600         dense_73[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_74 (Dense)                (None, 24)           600         dense_73[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_77 (Dense)                (None, 1)            25          dense_76[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_75 (Dense)                (None, 2)            50          dense_74[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "policy (Lambda)                 (None, 2)            0           dense_77[0][0]                   \n",
      "                                                                 dense_75[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 2,043\n",
      "Trainable params: 2,043\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Deployed instance of Dueling Double Deep Q Learning Agent(s) at Intersection 6\n",
      "\n",
      "INTERSECTION 7: SETTING UP AGENT\n",
      "Model: \"model_14\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_15 (InputLayer)           [(None, 7)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_84 (Dense)                (None, 24)           192         input_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_85 (Dense)                (None, 24)           600         dense_84[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_88 (Dense)                (None, 24)           600         dense_85[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_86 (Dense)                (None, 24)           600         dense_85[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_89 (Dense)                (None, 1)            25          dense_88[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_87 (Dense)                (None, 3)            75          dense_86[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "policy (Lambda)                 (None, 3)            0           dense_89[0][0]                   \n",
      "                                                                 dense_87[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 2,092\n",
      "Trainable params: 2,092\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Deployed instance of Dueling Double Deep Q Learning Agent(s) at Intersection 7\n",
      "\n",
      "INTERSECTION 8: SETTING UP AGENT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_16\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_17 (InputLayer)           [(None, 3)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_96 (Dense)                (None, 24)           96          input_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_97 (Dense)                (None, 24)           600         dense_96[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_100 (Dense)               (None, 24)           600         dense_97[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_98 (Dense)                (None, 24)           600         dense_97[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_101 (Dense)               (None, 1)            25          dense_100[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_99 (Dense)                (None, 2)            50          dense_98[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "policy (Lambda)                 (None, 2)            0           dense_101[0][0]                  \n",
      "                                                                 dense_99[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,971\n",
      "Trainable params: 1,971\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Deployed instance of Dueling Double Deep Q Learning Agent(s) at Intersection 8\n",
      "\n",
      "INTERSECTION 9: SETTING UP AGENT\n",
      "Model: \"model_18\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_19 (InputLayer)           [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_108 (Dense)               (None, 24)           120         input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_109 (Dense)               (None, 24)           600         dense_108[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_112 (Dense)               (None, 24)           600         dense_109[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_110 (Dense)               (None, 24)           600         dense_109[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_113 (Dense)               (None, 1)            25          dense_112[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_111 (Dense)               (None, 2)            50          dense_110[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "policy (Lambda)                 (None, 2)            0           dense_113[0][0]                  \n",
      "                                                                 dense_111[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,995\n",
      "Trainable params: 1,995\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Deployed instance of Dueling Double Deep Q Learning Agent(s) at Intersection 9\n",
      "\n",
      "INTERSECTION 10: SETTING UP AGENT\n",
      "Model: \"model_20\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_21 (InputLayer)           [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_120 (Dense)               (None, 24)           120         input_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_121 (Dense)               (None, 24)           600         dense_120[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_124 (Dense)               (None, 24)           600         dense_121[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_122 (Dense)               (None, 24)           600         dense_121[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_125 (Dense)               (None, 1)            25          dense_124[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_123 (Dense)               (None, 2)            50          dense_122[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "policy (Lambda)                 (None, 2)            0           dense_125[0][0]                  \n",
      "                                                                 dense_123[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,995\n",
      "Trainable params: 1,995\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Deployed instance of Dueling Double Deep Q Learning Agent(s) at Intersection 10\n",
      "\n",
      "INTERSECTION 11: SETTING UP AGENT\n",
      "Model: \"model_22\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_23 (InputLayer)           [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_132 (Dense)               (None, 24)           120         input_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_133 (Dense)               (None, 24)           600         dense_132[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_136 (Dense)               (None, 24)           600         dense_133[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_134 (Dense)               (None, 24)           600         dense_133[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_137 (Dense)               (None, 1)            25          dense_136[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_135 (Dense)               (None, 2)            50          dense_134[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "policy (Lambda)                 (None, 2)            0           dense_137[0][0]                  \n",
      "                                                                 dense_135[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,995\n",
      "Trainable params: 1,995\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Deployed instance of Dueling Double Deep Q Learning Agent(s) at Intersection 11\n",
      "\n",
      "INTERSECTION 12: SETTING UP AGENT\n",
      "Model: \"model_24\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_25 (InputLayer)           [(None, 7)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_144 (Dense)               (None, 24)           192         input_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_145 (Dense)               (None, 24)           600         dense_144[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_148 (Dense)               (None, 24)           600         dense_145[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_146 (Dense)               (None, 24)           600         dense_145[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_149 (Dense)               (None, 1)            25          dense_148[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_147 (Dense)               (None, 4)            100         dense_146[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "policy (Lambda)                 (None, 4)            0           dense_149[0][0]                  \n",
      "                                                                 dense_147[0][0]                  \n",
      "==================================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 2,117\n",
      "Trainable params: 2,117\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Deployed instance of Dueling Double Deep Q Learning Agent(s) at Intersection 12\n",
      "\n",
      "INTERSECTION 13: SETTING UP AGENT\n",
      "Model: \"model_26\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_27 (InputLayer)           [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_156 (Dense)               (None, 24)           168         input_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_157 (Dense)               (None, 24)           600         dense_156[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_160 (Dense)               (None, 24)           600         dense_157[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_158 (Dense)               (None, 24)           600         dense_157[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_161 (Dense)               (None, 1)            25          dense_160[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_159 (Dense)               (None, 3)            75          dense_158[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "policy (Lambda)                 (None, 3)            0           dense_161[0][0]                  \n",
      "                                                                 dense_159[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,068\n",
      "Trainable params: 2,068\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Deployed instance of Dueling Double Deep Q Learning Agent(s) at Intersection 13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Balance_integrated_MultiDQN_Agents = MasterDQN_Agent(model_name, vissim_working_directory, sim_length, Balance_dictionary, actions,\\\n",
    "                gamma, alpha, agent_type, memory_size, PER_activated, batch_size, batches_per_episode, copy_weights_frequency, epsilon_sequence,\\\n",
    "                Random_Seed, timesteps_per_second, Session_ID, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Agents....\n",
      "Independently Pre-Trained Agent 0, Architecture, Optimizer and Memory.\n",
      "Success.\n",
      "Independently Pre-Trained Agent 1, Architecture, Optimizer and Memory.\n",
      "Success.\n",
      "Independently Pre-Trained Agent 2, Architecture, Optimizer and Memory.\n",
      "Success.\n",
      "Independently Pre-Trained Agent 3, Architecture, Optimizer and Memory.\n",
      "Success.\n",
      "Independently Pre-Trained Agent 4, Architecture, Optimizer and Memory.\n",
      "Success.\n",
      "Independently Pre-Trained Agent 5, Architecture, Optimizer and Memory.\n",
      "Success.\n",
      "Independently Pre-Trained Agent 6, Architecture, Optimizer and Memory.\n",
      "Success.\n",
      "Independently Pre-Trained Agent 7, Architecture, Optimizer and Memory.\n",
      "Success.\n",
      "Independently Pre-Trained Agent 8, Architecture, Optimizer and Memory.\n",
      "Success.\n",
      "Independently Pre-Trained Agent 9, Architecture, Optimizer and Memory.\n",
      "Success.\n",
      "Independently Pre-Trained Agent 10, Architecture, Optimizer and Memory.\n",
      "Success.\n",
      "Independently Pre-Trained Agent 11, Architecture, Optimizer and Memory.\n",
      "Success.\n",
      "Independently Pre-Trained Agent 12, Architecture, Optimizer and Memory.\n",
      "Success.\n",
      "Independently Pre-Trained Agent 13, Architecture, Optimizer and Memory.\n",
      "Success.\n",
      "All Agents successfully loaded. Elapsed time 9.23 seconds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Balance_integrated_MultiDQN_Agents.load_isolated(100, best = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working Directory set to: C:\\Users\\acabrejasegea\\OneDrive - The Alan Turing Institute\\Desktop\\ATI\\0_TMF\\MLforFlowOptimisation\\Vissim\\\n",
      "Generating Cache...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of tensorflow.python.keras.layers.core failed: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\acabrejasegea\\AppData\\Local\\Continuum\\anaconda3\\envs\\vissim\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"C:\\Users\\acabrejasegea\\AppData\\Local\\Continuum\\anaconda3\\envs\\vissim\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 434, in superreload\n",
      "    module = reload(module)\n",
      "  File \"C:\\Users\\acabrejasegea\\AppData\\Local\\Continuum\\anaconda3\\envs\\vissim\\lib\\imp.py\", line 314, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"C:\\Users\\acabrejasegea\\AppData\\Local\\Continuum\\anaconda3\\envs\\vissim\\lib\\importlib\\__init__.py\", line 148, in reload\n",
      "    raise ImportError(msg.format(name), name=name)\n",
      "ImportError: module DQNAgents not in sys.modules\n",
      "]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache generated.\n",
      "\n",
      "****************************\n",
      "*   COM Server dispatched  *\n",
      "****************************\n",
      "\n",
      "Attempting to load Model File: Balance_integrated.inpx ...\n",
      "Model File load process successful.\n",
      "Simulation length set to 10801 seconds.\n",
      "Results from Previous Simulations: Deleted. Fresh Start Available.\n",
      "Fetched and containerized Network Object \n",
      "\n",
      "*******************************************************\n",
      "*                                                     *\n",
      "*                COM SETUP COMPLETE                   *\n",
      "*                                                     *\n",
      "*******************************************************\n",
      "\n",
      "Random seed set in simulator. Random Seed = 44\n",
      "Deploying Network Parser...\n",
      "Successful Network Crawl: Identified SignalControllers, Links, Lanes and Vehicle Inputs.\n",
      "\n",
      "Setting Simulation mode to: demo\n",
      "Starting Deployments of Signal Control Units...\n",
      "SCUs successfully deployed. Elapsed time 7.67 seconds.\n",
      "\n"
     ]
    },
    {
     "ename": "com_error",
     "evalue": "(-2147352567, 'Exception occurred.', (0, None, None, None, 0, -2147467259), None)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mcom_error\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-4d1d5676d2dc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mBalance_integrated_MultiDQN_Agents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdemo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\OneDrive - The Alan Turing Institute\\Desktop\\ATI\\0_TMF\\MLforFlowOptimisation\\Vissim\\MasterDQN_Agent.py\u001b[0m in \u001b[0;36mdemo\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    250\u001b[0m                 \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdone\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m                         \u001b[0mSARSDs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_required\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - The Alan Turing Institute\\Desktop\\ATI\\0_TMF\\MLforFlowOptimisation\\Vissim\\Vissim_env_class.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, actions, green_time)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimesteps_per_second\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVissim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSimulation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRunSingleStep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m                 \u001b[1;31m# increase the update counter by one each step (until reach simulation length)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_counter\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\vissim\\lib\\site-packages\\win32com\\client\\dynamic.py\u001b[0m in \u001b[0;36mRunSingleStep\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[1;31mcom_error\u001b[0m: (-2147352567, 'Exception occurred.', (0, None, None, None, 0, -2147467259), None)"
     ]
    }
   ],
   "source": [
    "Balance_integrated_MultiDQN_Agents.demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Balance_integrated_MultiDQN_Agents.save_integrated(episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## AGENT TRAINING RESULTS\n",
    "# Path to results folder\n",
    "\n",
    "# Loop over each agent\n",
    "for idx , agent in Balance_integrated_MultiDQN_Agents.Agents.items():\n",
    "    results_path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", agent_type,\\\n",
    "                                Session_ID, \"Agent{}\".format(idx))\n",
    "\n",
    "    intersection_number_in_vissim = Balance_integrated_MultiDQN_Agents.Agents[0].signal_id + 1\n",
    "    print(\"Intersection \"+str(intersection_number_in_vissim))\n",
    "    \n",
    "    ## SAVE TRAINING DATA TO JSON.\n",
    "    json_filename = \"Agent{}_Loss_average_reward.json\".format(intersection_number_in_vissim)\n",
    "    Loss_reward = dict()   \n",
    "    # Loss dictionary\n",
    "    for epoch, loss in enumerate(agent.loss):\n",
    "        loss_dict = { epoch : loss }\n",
    "    Loss_reward['Agent{} loss'.format(intersection_number_in_vissim)] = loss_dict\n",
    "    # Reward dictionary            \n",
    "    episode = [i for i in range(len(agent.reward_storage))]\n",
    "    Loss_reward['Agent{} Average_Reward'.format(intersection_number_in_vissim)] = agent.reward_storage\n",
    "    # Store as JSON\n",
    "    with open(results_path + \"/\" + json_filename, 'w') as f:\n",
    "        json.dump(Loss_reward, f)\n",
    "    print(\"Agent {}: Training Loss and Average Reward during training successfuly saved to file:\".format(intersection_number_in_vissim))\n",
    "    print(results_path + \"/\" + json_filename)\n",
    "    \n",
    "    ## LOADING DATA FROM JSON\n",
    "    #results_path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", agent_type, Session_ID)\n",
    "    #dictionary_filename = \"Agent{}_Loss_average_reward.json\".format(intersection_number_in_vissim)\n",
    "    #with open(results_path + \"/\" + json_filename, 'r') as fp:\n",
    "    #    data = json.load(fp)\n",
    "    #print(data)\n",
    "    \n",
    "    ## TRAINING PLOTS\n",
    "    loss_plot_filename  = \"Agent{}_Loss.png\".format(intersection_number_in_vissim)\n",
    "    reward_plot_filename  = \"Agent{}_average_reward.png\".format(intersection_number_in_vissim) \n",
    "    \n",
    "    ## Loss Plot\n",
    "    plt.figure('LossAgent'+str(idx),figsize=(16,9))\n",
    "    plt.plot(agent.loss)\n",
    "    plt.xlabel('Training Epoch',fontsize=18)\n",
    "    plt.ylabel('Loss',fontsize=18)\n",
    "    plt.title('Agent {} Loss over training'.format(idx+1),fontsize=18)\n",
    "    plt.savefig(results_path + \"/\" + loss_plot_filename)\n",
    "\n",
    "    ## Average Reward Plot\n",
    "    plt.figure('RewardAgent'+str(idx),figsize=(16,9))\n",
    "    plt.plot(agent.reward_storage)\n",
    "    plt.xlabel('Training Episode',fontsize=18)\n",
    "    plt.ylabel('Average reward',fontsize=18)\n",
    "    plt.title('Agent {} average reward over training'.format(idx+1),fontsize=18)\n",
    "    plt.savefig(results_path + \"/\" + reward_plot_filename)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Balance_integrated_MultiDQN_Agents.load(500, best = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Balance_integrated_MultiDQN_Agents.demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Balance_integrated_MultiDQN_Agents.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define results path, check if it exists, create it if it doesn't\n",
    "results_path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\",\\\n",
    "                            agent_type, Session_ID, \"Plots\")\n",
    "if not os.path.exists(results_path):\n",
    "    os.makedirs(results_path)\n",
    "\n",
    "time = [t for t in range(len(Balance_integrated_MultiDQN_Agents.Cumulative_Totale_network_stop_delay))]\n",
    "\n",
    "\n",
    "########################################\n",
    "## Queues over time for each junction ##\n",
    "########################################\n",
    "for idx, queues in Balance_integrated_MultiDQN_Agents.Episode_Queues.items():\n",
    "\n",
    "    # Identify Junction ID in map\n",
    "    intersection_number_in_vissim = idx\n",
    "    \n",
    "    queues = np.array(queues)\n",
    "    queues = queues.T\n",
    "    number_queues = np.size(queues,0)\n",
    "    \n",
    "    plt.figure('1'+str(idx),figsize=(16, 9))\n",
    "    \n",
    "    Queues = dict()\n",
    "    Queues['Time'] = time\n",
    "    Queues_legend = []\n",
    "    \n",
    "    for i, queue in enumerate(queues):\n",
    "        plt.plot(queue, label = \"Queue\"+str(i))\n",
    "        Queues[str(i)] = queue.tolist()\n",
    "        Queues_legend.append(\"Queue\"+str(i))\n",
    "    \n",
    "    ## Plot the queues\n",
    "    plt.xlabel('Time [s]',fontsize=18)\n",
    "    plt.ylabel('Queue Length [m]',fontsize=18)\n",
    "    plt.title('Agent {} Queue length'.format(intersection_number_in_vissim),fontsize=18)\n",
    "    plt.gca().legend(Queues_legend)\n",
    "    \n",
    "    filename = \"Agent{}_Queues.png\".format(intersection_number_in_vissim)           \n",
    "    plt.savefig(results_path + \"\\\\\" + filename)\n",
    "    \n",
    "    # Store as JSON\n",
    "    json_filename = \"Agent{}_Queues.json\".format(intersection_number_in_vissim)        \n",
    "    with open(results_path + \"/\" + json_filename, 'w') as f:\n",
    "        json.dump(Queues, f)\n",
    "        \n",
    "    ### LOADING DATA FROM JSON\n",
    "    #results_path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", agent_type, Session_ID)\n",
    "    #json_filename = \"Junction{}_Queues.json\".format(intersection_number_in_vissim)\n",
    "    #with open(results_path + \"/\" + json_filename, 'r') as fp:\n",
    "    #    data = json.load(fp)\n",
    "    #print(data)\n",
    "        \n",
    "    # Success Message\n",
    "    print(\"Agent {}: Queues during Test successfuly saved to file:\".format(intersection_number_in_vissim))\n",
    "    print(results_path + \"/\" + json_filename)\n",
    "       \n",
    "        \n",
    "###################################################        \n",
    "## Accumulated delay over time for each junction ##\n",
    "###################################################\n",
    "for idx, delay in Balance_integrated_MultiDQN_Agents.Cumulative_Episode_Delays.items():\n",
    "    \n",
    "    # Identify Junction ID in map\n",
    "    intersection_number_in_vissim = Balance_integrated_MultiDQN_Agents.Agents[idx].signal_id\n",
    "\n",
    "    # Extract and process delay data\n",
    "    Delay = dict()   \n",
    "    Delay['Time'] = time\n",
    "    Delay['Agent {} delay'.format(intersection_number_in_vissim)] = delay\n",
    "    \n",
    "    # Store as JSON\n",
    "    json_filename = \"Agent{}_Cumulative_Delay.json\".format(intersection_number_in_vissim)        \n",
    "    with open(results_path + \"/\" + json_filename, 'w') as f:\n",
    "        json.dump(Delay, f)\n",
    "        \n",
    "    # Success Message\n",
    "    print(\"Agent {}: Test Cumulative Delay successfuly saved to file:\".format(intersection_number_in_vissim))\n",
    "    print(results_path + \"/\" + json_filename)\n",
    "    \n",
    "    ### Loading data from JSON\n",
    "    #results_path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", agent_type, Session_ID)\n",
    "    #dictionary_filename = \"Junction{}_Cumulative_Delay.json\".format(intersection_number_in_vissim)\n",
    "    #with open(results_path + \"/\" + json_filename, 'r') as fp:\n",
    "    #    data = json.load(fp)\n",
    "    #print(data)\n",
    "\n",
    "    # Plot the cumulative delay\n",
    "    plt.figure('2'+str(idx),figsize=(16, 9))\n",
    "    plt.plot(delay)\n",
    "    plt.xlabel('Time [s]',fontsize=18)\n",
    "    plt.ylabel('Accumulated Delay [s]',fontsize=18)\n",
    "    plt.title('Agent {} Delay'.format(intersection_number_in_vissim),fontsize=18)\n",
    "    \n",
    "    filename = \"Agent{}_Cumulative_Delay.png\".format(intersection_number_in_vissim)\n",
    "    plt.savefig(results_path + \"/\" + filename)\n",
    "    \n",
    "    \n",
    "    \n",
    "########################################################    \n",
    "## Accumulated stop delay over time for each junction ##\n",
    "########################################################\n",
    "for idx, stop_delay in Balance_integrated_MultiDQN_Agents.Cumulative_Episode_stop_Delays.items():\n",
    "    \n",
    "    # Identify Junction ID in map\n",
    "    intersection_number_in_vissim = Balance_integrated_MultiDQN_Agents.Agents[idx].signal_id    \n",
    "    \n",
    "    # Extract and process stop delay data\n",
    "    Stop_delay = dict()   \n",
    "    Stop_delay['Time'] = time\n",
    "    Stop_delay['Agent {} stop delay'.format(intersection_number_in_vissim)] = stop_delay\n",
    "    \n",
    "    # Store as JSON\n",
    "    json_filename = \"Agent{}_Cumulative_Stop_Delay.json\".format(intersection_number_in_vissim)        \n",
    "    with open(results_path + \"/\" + json_filename, 'w') as f:\n",
    "        json.dump(Stop_delay, f)\n",
    "    \n",
    "    # Success Message\n",
    "    print(\"Agent {}: Test Cumulative Stop Delay successfuly saved to file:\".format(intersection_number_in_vissim))\n",
    "    print(results_path + \"/\" + json_filename)\n",
    "        \n",
    "    ### Loading data from JSON\n",
    "    #results_path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", agent_type, Session_ID)\n",
    "    #dictionary_filename = \"Junction{}_Cumulative_Stop_Delay.json\".format(intersection_number_in_vissim)\n",
    "    #with open(results_path + \"/\" + json_filename, 'r') as fp:\n",
    "    #    data = json.load(fp)\n",
    "    #print(data)\n",
    "    \n",
    "    # Plot the cumulative stop delay\n",
    "    plt.figure('3'+str(idx),figsize=(16, 9))\n",
    "    plt.plot(stop_delay)\n",
    "    plt.xlabel('Time [s]',fontsize=18)\n",
    "    plt.ylabel('Accumulated Stop Delay [s]',fontsize=18)\n",
    "    plt.title('Agent {} Stop Delay'.format(intersection_number_in_vissim),fontsize=18)\n",
    "    \n",
    "    filename = \"Agent{}_Cumulative_Stop_Delay.png\".format(intersection_number_in_vissim)\n",
    "    plt.savefig(results_path + \"/\" + filename)\n",
    "\n",
    "    \n",
    "    \n",
    "###############################################\n",
    "## ONLY IF THERE IS MORE THAN ONE CONTROLLER ##\n",
    "##    These are the global network plots     ##\n",
    "###############################################\n",
    "\n",
    "if len(Balance_integrated_MultiDQN_Agents.Agents) > 1:\n",
    "    print(\"DINGDINGDINGDING\")\n",
    "    ########################################    \n",
    "    ## Global Accumulated delay over time ##\n",
    "    ########################################\n",
    "    \n",
    "    # Process global delay data\n",
    "    Global_delay = dict()   \n",
    "    Global_delay['Time'] = time\n",
    "    Global_delay['Global accumulated Delay'] = Balance_integrated_MultiDQN_Agents.Cumulative_Totale_network_delay\n",
    "    \n",
    "    # Store as JSON\n",
    "    json_filename = \"Global_Cumulative_Delay.json\"\n",
    "    with open(results_path + \"/\" + json_filename, 'w') as f:\n",
    "        json.dump(Global_delay, f)\n",
    "    \n",
    "    # Success Message\n",
    "    print(\"Test Cumulative Global Delay successfuly saved to file:\")\n",
    "    print(results_path + \"/\" + json_filename)\n",
    "        \n",
    "    ### Loading data from JSON\n",
    "    #results_path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", agent_type, Session_ID)\n",
    "    #dictionary_filename = \"Global_Cumulative_Delay.json\"\n",
    "    #with open(results_path + \"/\" + json_filename, 'r') as fp:\n",
    "    #    data = json.load(fp)\n",
    "    #print(data)\n",
    "\n",
    "    \n",
    "    # Plot the global delay\n",
    "    plt.figure('4',figsize=(16,9))\n",
    "    plt.plot(Global_delay['Global accumulated Delay'])\n",
    "    plt.xlabel('Time [s]',fontsize=18)\n",
    "    plt.ylabel('Global Cumulative Delay [s]',fontsize=18)\n",
    "    plt.title('Global Cumulative Delay',fontsize=18)\n",
    "\n",
    "    filename = \"Global_Cumulative_Delay.png\".format(intersection_number_in_vissim)\n",
    "    plt.savefig(results_path + \"/\" + filename)\n",
    "\n",
    "\n",
    "    #############################################\n",
    "    ## Global Accumulated stop delay over time ##\n",
    "    #############################################\n",
    "    \n",
    "    # Process global stop delay data\n",
    "    Global_stop_delay = dict()   \n",
    "    Global_stop_delay['Time'] = time\n",
    "    Global_stop_delay['Global Cumulative Stop Delay'] = Balance_integrated_MultiDQN_Agents.Cumulative_Totale_network_stop_delay\n",
    "    \n",
    "    # Store as JSON\n",
    "    json_filename = \"Global_Cumulative_Stop_Delay.json\"\n",
    "    with open(results_path + \"/\" + json_filename, 'w') as f:\n",
    "        json.dump(Global_stop_delay, f)\n",
    "    \n",
    "    # Success Message\n",
    "    print(\"Test Cumulative Global Stop Delay successfuly saved to file:\")\n",
    "    print(results_path + \"/\" + json_filename)\n",
    "        \n",
    "    ### Loading data from JSON\n",
    "    #results_path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", agent_type, Session_ID)\n",
    "    #dictionary_filename = \"Global_Cumulative_Stop_Delay.json\"\n",
    "    #with open(results_path + \"/\" + json_filename, 'r') as fp:\n",
    "    #    data = json.load(fp)\n",
    "    #print(data)\n",
    "\n",
    "    # Plot the global stop delay\n",
    "    plt.figure('5'+str(idx),figsize=(16, 9))\n",
    "    plt.plot(Global_stop_delay['Global Cumulative Stop Delay'])\n",
    "    plt.xlabel('Time [s]',fontsize=18)\n",
    "    plt.ylabel('Global Cumulative Stop Delay [s]',fontsize=18)\n",
    "    plt.title('Global Cumulative Stop Delay',fontsize=18)\n",
    "    plt.gca().legend('Global Cumulative stop Delay')\n",
    "    \n",
    "    filename = \"Global_Cumulative_Stop_Delay.png\".format(intersection_number_in_vissim)\n",
    "    plt.savefig(results_path + \"/\" + filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading Global Cumulative Delay data from JSON\n",
    "results_path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", agent_type, Session_ID, \"Plots\")\n",
    "dictionary_filename = \"Global_Cumulative_Delay.json\"\n",
    "with open(results_path + \"/\" + dictionary_filename, 'r') as fp:\n",
    "    global_cumulative_delay = json.load(fp)\n",
    "\n",
    "\n",
    "### Loading Global Cumulative Stop data from JSON\n",
    "results_path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", agent_type, Session_ID, \"Plots\")\n",
    "dictionary_filename = \"Global_Cumulative_Stop_Delay.json\"\n",
    "with open(results_path + \"/\" + dictionary_filename, 'r') as fp:\n",
    "    global_cumulative_stop_delay = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(global_cumulative_stop_delay.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Balance (Original) SQL Database loading\n",
    "database_name = 24\n",
    "\n",
    "# Define database path\n",
    "DBPATH = os.path.join(vissim_working_directory, \"Balance_VISSIM_original\",\\\n",
    "                      \"PTV Balance PTV Epics Vision Suite Workflow.results\", str(database_name) + \".db\")\n",
    "# Connect to database\n",
    "conn = sqlite3.connect(DBPATH)\n",
    "\n",
    "# Query for the cumulative delay and the cumulative stop delay\n",
    "df = pd.read_sql_query('SELECT \\\n",
    "                        CAST(ARG_TIMEINTERVAL AS BIGINT) AS Time, \\\n",
    "                        sum(DELAYSTOPTOT) OVER (ORDER BY CAST(ARG_TIMEINTERVAL AS BIGINT)) as CumStopDelay, \\\n",
    "                        sum(DELAYTOT) OVER (ORDER BY CAST(ARG_TIMEINTERVAL AS BIGINT)) as CumDelay \\\n",
    "                        FROM VEHICLENETWORKPERFORMANCEMEASUREMENT_EvaluationTimeIntervalClass' ,conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 9))\n",
    "\n",
    "# Plot RLAgents\n",
    "plt.plot(global_cumulative_stop_delay['Time'],\\\n",
    "         global_cumulative_stop_delay['Global Cumulative Stop Delay'],\\\n",
    "         label = 'StopDelay RL' )\n",
    "plt.plot(global_cumulative_delay['Time'],\\\n",
    "         global_cumulative_delay['Global accumulated Delay'],\\\n",
    "         label = 'Delay RL' )\n",
    "# Plot BALANCE\n",
    "plt.plot(df['Time']*300, df['CumStopDelay'], label = 'StopDelay VISSIM' )\n",
    "plt.plot(df['Time']*300, df['CumDelay'], label = 'Delay VISSIM')\n",
    "\n",
    "plt.xlabel('Time [s]',fontsize=18)\n",
    "plt.ylabel('Delay [s]',fontsize=18)\n",
    "plt.title('Delay over Free Flow Time',fontsize=18)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "filename = \"Delay_Comparison_with_Balance.png\"\n",
    "plt.savefig(results_path + \"/\" + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Balance_integrated_MultiDQN_Agents.global_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Argument here neeeds to be episodes_pretrained + desired amount\n",
    "Balance_integrated_MultiDQN_Agents.train(130)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
