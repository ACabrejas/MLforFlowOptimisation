{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Vissim_env_class.py, line 131)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[0;32m\"C:\\Users\\acabrejasegea\\AppData\\Local\\Continuum\\anaconda3\\envs\\vissim\\lib\\site-packages\\IPython\\core\\interactiveshell.py\"\u001b[0m, line \u001b[0;32m2961\u001b[0m, in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-31-c5b69e19c55c>\"\u001b[1;36m, line \u001b[1;32m1\u001b[1;36m, in \u001b[1;35m<module>\u001b[1;36m\u001b[0m\n\u001b[1;33m    from Vissim_env_class import env\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\acabrejasegea\\OneDrive - The Alan Turing Institute\\Desktop\\ATI\\0_TMF\\MLforFlowOptimisation\\Vissim\\Vissim_env_class.py\"\u001b[1;36m, line \u001b[1;32m131\u001b[0m\n\u001b[1;33m    def step_to_next_action(self.actions):\u001b[0m\n\u001b[1;37m                                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from Vissim_env_class import env\n",
    "from Agent_class import ACAgent\n",
    "import numpy as np \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name  = 'Balance'\n",
    "vissim_working_directory =  'C:\\\\Users\\\\Rzhang\\\\Desktop\\\\MLforFlowOptimisationOrigine\\\\Vissim\\\\'\n",
    "sim_length = 3601\n",
    "\n",
    "# all controller actions\n",
    "Balance_dictionnary =\\\n",
    "{\\\n",
    "    # Controller Number 2 \n",
    "    0 : {'compatible_actions' : {   0 : [1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0],\n",
    "                                    1 : [0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1],\n",
    "                                    2 : [0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0] },\n",
    "         \n",
    "         'link' : [2, 40, 7, 38],\n",
    "         'lane' : ['2-1', '2-2', '2-3', '40-1', '7-1', '7-2', '7-3', '38-1'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'green_time' : 6,\n",
    "         'redamber_time' : 1,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 1,\n",
    "         'state_size' : [8],\n",
    "         'state_type' : 'Queues',\n",
    "         'reward_type' : 'Queues'\n",
    "         \n",
    "         \n",
    "        },\n",
    "    # Controller Number 3\n",
    "    1 : {'compatible_actions' : {   0 : [0, 1, 0, 0, 1, 0, 1, 1],\n",
    "                                    1 : [1, 0, 0, 1, 0, 0, 0, 0],\n",
    "                                    2 : [0, 0, 1, 0, 0, 1, 0, 0] },\n",
    "         \n",
    "         'link' : [5, 48, 70, 46],\n",
    "         'lane' : ['5-1', '5-2', '5-3', '48-1', '70-1', '70-2', '70-3', '46-1'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'green_time' : 6,\n",
    "         'redamber_time' : 1,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 1,\n",
    "         'state_size' : [8],\n",
    "         'state_type' : 'Queues',\n",
    "         'reward_type' : 'Queues'\n",
    "        },\n",
    "    # Controller Number 4\n",
    "    2 : {'compatible_actions' : {   0 : [0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                                    1 : [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                                    2 : [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                                    3 : [0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]},\n",
    "         \n",
    "         'link' : [73, 100, 84, 95],\n",
    "         'lane' : ['73-1', '73-2', '73-3', '100-1', '100-2', '100-3', '100-4',\\\n",
    "                  '84-1', '84-2', '84-3', '95-1', '95-2', '95-3', '95-4'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'green_time' : 6,\n",
    "         'redamber_time' : 1,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 1,\n",
    "         'state_size' : [14],\n",
    "         'state_type' : 'Queues',\n",
    "         'reward_type' : 'Queues'\n",
    "        },\n",
    "    # Controller Number 5\n",
    "    3 : {'compatible_actions' : {   0 : [0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0],\n",
    "                                    1 : [1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0],\n",
    "                                    2 : [0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1]},\n",
    "         \n",
    "         'link' : [87, 36, 10, 34],\n",
    "         'lane' : ['87-1', '87-2', '87-3', '36-1', '10-1', '10-2', '10-3', '34-1'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'green_time' : 6,\n",
    "         'redamber_time' : 1,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 1,\n",
    "         'state_size' : [8],\n",
    "         'state_type' : 'Queues',\n",
    "         'reward_type' : 'Queues'\n",
    "        },\n",
    "    # Controller Number 6 \n",
    "    4 : {'compatible_actions' : {   0 : [0, 1, 1, 0, 0],\n",
    "                                    1 : [1, 1, 0, 0, 0],\n",
    "                                    2 : [0, 0, 0, 1, 0]},\n",
    "         'link' : [8, 24, 13],\n",
    "         'lane' : ['8-1', '8-2', '24-1', '13-1', '13-2', '13-3'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'green_time' : 6,\n",
    "         'redamber_time' : 1,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 1,\n",
    "         'state_size' : [6],\n",
    "         'state_type' : 'Queues',\n",
    "         'reward_type' : 'Queues'\n",
    "        },\n",
    "    # Controller Number 8\n",
    "    5 : {'compatible_actions' : {   0 : [1, 0, 1, 0, 1, 0],\n",
    "                                    1 : [0, 1, 0, 1, 0, 1]},\n",
    "         'link' : [26, 23, 35],\n",
    "         'lane' : ['26-1', '23-1', '35-1'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'green_time' : 6,\n",
    "         'redamber_time' : 1,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 1,\n",
    "         'state_size' : [3],\n",
    "         'state_type' : 'Queues',\n",
    "         'reward_type' : 'Queues'\n",
    "         \n",
    "        },\n",
    "    # Controller Number 9\n",
    "    6 : {'compatible_actions' : {   0 : [0, 1, 0, 1, 1, 1],\n",
    "                                    1 : [1, 0, 1, 0, 0, 0]},\n",
    "         'link' : [51, 92, 64, 19],\n",
    "         'lane' : ['51-1', '92-1', '92-2', '64-1', '19-1', '19-2'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'green_time' : 6,\n",
    "         'redamber_time' : 1,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 1,\n",
    "         'state_size' : [6],\n",
    "         'state_type' : 'Queues',\n",
    "         'reward_type' : 'Queues'\n",
    "        },\n",
    "    # Contoller Number 10\n",
    "    7 : {'compatible_actions' : {   0 : [0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "                                    1 : [0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "                                    2 : [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]},\n",
    "         'link' : [18, 66, 16],\n",
    "         'lane' : ['18-1', '18-2', '18-3', '66-1', '16-1', '16-2', '16-3'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'green_time' : 5,\n",
    "         'redamber_time' : 1,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 1,\n",
    "         'state_size' : [7],\n",
    "         'state_type' : 'Queues',\n",
    "         'reward_type' : 'Queues'\n",
    "        },\n",
    "    # Controller Number 12\n",
    "    8 : {'compatible_actions' : {   0 : [1, 0, 1, 0, 0, 0, 0],\n",
    "                                    1 : [0, 1, 0, 0, 0, 0, 0]},\n",
    "         'link' : [62, 45, 44],\n",
    "         'lane' : ['62-1', '45-1', '44-1'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'green_time' : 6,\n",
    "         'redamber_time' : 1,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 1,\n",
    "         'state_size' : [3],\n",
    "         'state_type' : 'Queues',\n",
    "         'reward_type' : 'Queues'\n",
    "        },\n",
    "    # Controller Number 13\n",
    "    9 : {'compatible_actions' : {   0 : [0, 1, 0, 1, 1, 0, 1, 0],\n",
    "                                    1 : [1, 0, 1, 0, 0, 1, 0, 1]},\n",
    "         'link' : [60, 43, 55, 58],\n",
    "         'lane' : ['60-1', '43-1', '55-1', '58-1'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'green_time' : 6,\n",
    "         'redamber_time' : 1,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 1,\n",
    "         'state_size' : [4],\n",
    "         'state_type' : 'Queues',\n",
    "         'reward_type' : 'Queues'\n",
    "            \n",
    "        },\n",
    "    # Controller 15\n",
    "    10 : {'compatible_actions' : {  0 : [1, 0, 1, 0, 0, 1, 0, 1],\n",
    "                                    1 : [0, 1, 0, 1, 1, 0, 1, 0]},\n",
    "         'link' : [32, 42, 30, 39],\n",
    "         'lane' : ['32-1', '42-1', '30-1', '39-1'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'green_time' : 4,\n",
    "         'redamber_time' : 1,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 1,\n",
    "         'state_size' : [4],\n",
    "         'state_type' : 'Queues',\n",
    "         'reward_type' : 'Queues'\n",
    "        },\n",
    "    # Controller 16\n",
    "    11 : {'compatible_actions' :  { 0 : [1, 0, 1, 0, 0, 1, 0, 1],\n",
    "                                    1 : [0, 1, 0, 1, 1, 0, 1, 0]},\n",
    "         'link' : [29, 50, 28, 47],\n",
    "         'lane' : ['29-1', '50-1', '28-1', '47-1'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'green_time' : 8,\n",
    "         'redamber_time' : 1,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 1,\n",
    "         'state_size' : [4],\n",
    "         'state_type' : 'Queues',\n",
    "         'reward_type' : 'Queues'\n",
    "        },\n",
    "    # Controller 17\n",
    "    12 : {'compatible_actions' :  { 0 : [1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1],\n",
    "                                    1 : [0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1],\n",
    "                                    2 : [0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0],\n",
    "                                    3 : [0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0]},\n",
    "         'link' : [27, 22, 25, 77],\n",
    "         'lane' : ['27-1', '22-1', '22-2', '22-3', '25-1', '77-1', '77-2'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'green_time' : 7,\n",
    "         'redamber_time' : 1,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 1,\n",
    "         'state_size' : [7],\n",
    "         'state_type' : 'Queues',\n",
    "         'reward_type' : 'Queues'\n",
    "            \n",
    "        },\n",
    "    # Controller 33 \n",
    "    13 : {'compatible_actions' :  { 0 : [1, 0, 0, 1, 0, 0, 1, 0, 0],\n",
    "                                    1 : [0, 0, 1, 1, 0, 1, 0, 0, 0],\n",
    "                                    2 : [0, 1, 0, 0, 1, 1, 0, 1, 1]},\n",
    "         'link' : [68, 71, 75],\n",
    "         'lane' : ['68-1', '68-2', '68-3', '71-1', '71-2', '75-1'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'green_time' : 6,\n",
    "         'redamber_time' : 1,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 1,\n",
    "         'state_size' : [6],\n",
    "         'state_type' : 'Queues',\n",
    "         'reward_type' : 'Queues'\n",
    "        }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working Directory set to: C:\\Users\\Rzhang\\Desktop\\MLforFlowOptimisationOrigine\\Vissim\\\n",
      "Generating Cache...\n",
      "Cache generated.\n",
      "\n",
      "****************************\n",
      "*   COM Server dispatched  *\n",
      "****************************\n",
      "\n",
      "Attempting to load Model File: Balance.inpx ...\n",
      "Failed load attempt 1/5. Re-attempting.\n",
      "Working Directory set to: C:\\Users\\Rzhang\\Desktop\\MLforFlowOptimisationOrigine\\Vissim\\\n",
      "Generating Cache...\n",
      "Cache generated.\n",
      "\n",
      "****************************\n",
      "*   COM Server dispatched  *\n",
      "****************************\n",
      "\n",
      "Attempting to load Model File: Balance.inpx ...\n",
      "Load process successful\n",
      "Simulation length set to 3601 seconds.\n",
      "Results from Previous Simulations: Deleted. Fresh Start Available.\n",
      "Fetched and containerized Simulation Object\n",
      "Fetched and containerized Network Object \n",
      "\n",
      "*******************************************************\n",
      "*                                                     *\n",
      "*                 SETUP COMPLETE                      *\n",
      "*                                                     *\n",
      "*******************************************************\n",
      "\n",
      "1.0778706073760986\n"
     ]
    }
   ],
   "source": [
    "env = env(model_name, vissim_working_directory, sim_length, Balance_dictionnary,\\\n",
    "            timesteps_per_second = 1, mode = 'training', delete_results = True, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: <Vissim_SCU_class.Signal_Control_Unit at 0x17767ec6be0>,\n",
       " 1: <Vissim_SCU_class.Signal_Control_Unit at 0x17767ec6e48>,\n",
       " 2: <Vissim_SCU_class.Signal_Control_Unit at 0x17767ed6978>,\n",
       " 3: <Vissim_SCU_class.Signal_Control_Unit at 0x17767ee4470>,\n",
       " 4: <Vissim_SCU_class.Signal_Control_Unit at 0x17767eec7b8>,\n",
       " 5: <Vissim_SCU_class.Signal_Control_Unit at 0x17767eec6d8>,\n",
       " 6: <Vissim_SCU_class.Signal_Control_Unit at 0x17767efab38>,\n",
       " 7: <Vissim_SCU_class.Signal_Control_Unit at 0x17767efa278>,\n",
       " 8: <Vissim_SCU_class.Signal_Control_Unit at 0x17767f07a20>,\n",
       " 9: <Vissim_SCU_class.Signal_Control_Unit at 0x17767f070b8>,\n",
       " 10: <Vissim_SCU_class.Signal_Control_Unit at 0x17767f14a20>,\n",
       " 11: <Vissim_SCU_class.Signal_Control_Unit at 0x17767f14518>,\n",
       " 12: <Vissim_SCU_class.Signal_Control_Unit at 0x17767f1b860>,\n",
       " 13: <Vissim_SCU_class.Signal_Control_Unit at 0x17767f1bef0>}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.SCUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.SCUs[0].state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0}\n"
     ]
    }
   ],
   "source": [
    "actions = dict()\n",
    "for i in range(len(env.SCUs)):\n",
    "    actions[i]=0\n",
    "    \n",
    "print(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cyclic_Control():\n",
    "    def __init__(self,size):\n",
    "        self.action = 0\n",
    "        self.size = size\n",
    "        \n",
    "    def choose_action(self,state=None):\n",
    "        self.action = (self.action + 1) % self.size\n",
    "        return self.action\n",
    "CC = [] \n",
    "\n",
    "for idx, info in Balance_dictionnary.items():\n",
    "        cycle_size = len(info['compatible_actions'])\n",
    "        CC.append(Cyclic_Control(cycle_size))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Training loop / simulation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "com_error",
     "evalue": "(-2147352567, 'Une exception s’est produite.', (0, 'VISSIM.Vissim.1100', 'AttValue failed: Object 1 - 3: SG2: Attribute Signal state is no subject to changes.', None, 0, -2147352567), None)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mcom_error\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-18307391b7aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0maction_required\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSARSDs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maction_required\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mactions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\MLforFlowOptimisationOrigine\\Vissim\\Vissim_env_class.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, actions)\u001b[0m\n\u001b[0;32m    106\u001b[0m                 \u001b[1;33m[\u001b[0m\u001b[0mscu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscu\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSCUs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mscu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_required\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m                 \u001b[1;33m[\u001b[0m\u001b[0mscu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscu\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSCUs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m                 \u001b[1;31m# not a nice way of doing this creatung the dictionnary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\MLforFlowOptimisationOrigine\\Vissim\\Vissim_env_class.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    106\u001b[0m                 \u001b[1;33m[\u001b[0m\u001b[0mscu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscu\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSCUs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mscu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_required\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m                 \u001b[1;33m[\u001b[0m\u001b[0mscu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscu\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSCUs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m                 \u001b[1;31m# not a nice way of doing this creatung the dictionnary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\MLforFlowOptimisationOrigine\\Vissim\\Vissim_SCU_class.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    374\u001b[0m                                         \u001b[1;31m#print('_color_changer')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m                                         \u001b[1;31m#tic = t.time()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 376\u001b[1;33m                                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_color_changer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    377\u001b[0m                                         \u001b[1;31m#tac = t.time()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m                                         \u001b[1;31m#print(tac-tic)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\MLforFlowOptimisationOrigine\\Vissim\\Vissim_SCU_class.py\u001b[0m in \u001b[0;36m_color_changer\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    248\u001b[0m                                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mredamber_time\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m \t\t\t\t\t[self.signal_groups[idx].SetAttValue(\"SigState\", \"REDAMBER\") \\\n\u001b[1;32m--> 250\u001b[1;33m \t\t\t\t\t\t\t\t\tfor idx,value in enumerate(self.change_vector) if value == 1]\n\u001b[0m\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m                                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_counter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mredamber_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\MLforFlowOptimisationOrigine\\Vissim\\Vissim_SCU_class.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    248\u001b[0m                                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mredamber_time\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m \t\t\t\t\t[self.signal_groups[idx].SetAttValue(\"SigState\", \"REDAMBER\") \\\n\u001b[1;32m--> 250\u001b[1;33m \t\t\t\t\t\t\t\t\tfor idx,value in enumerate(self.change_vector) if value == 1]\n\u001b[0m\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m                                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_counter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mredamber_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2\\lib\\site-packages\\win32com\\client\\dynamic.py\u001b[0m in \u001b[0;36mSetAttValue\u001b[1;34m(self, Attribut, arg1)\u001b[0m\n",
      "\u001b[1;31mcom_error\u001b[0m: (-2147352567, 'Une exception s’est produite.', (0, 'VISSIM.Vissim.1100', 'AttValue failed: Object 1 - 3: SG2: Attribute Signal state is no subject to changes.', None, 0, -2147352567), None)"
     ]
    }
   ],
   "source": [
    "start_state = env.get_state()\n",
    "for idx, s in start_state.items():\n",
    "    actions[idx] = CC[idx].choose_action(s)\n",
    "    \n",
    "for _ in range(10000):\n",
    "    action_required, SARSDs = env.step(actions)\n",
    "    if action_required : \n",
    "        actions = dict()\n",
    "        for idx , sarsd in SARSDs.items():\n",
    "            s,a,r,ns,d = sarsd\n",
    "            #print(sarsd)\n",
    "            \n",
    "            # in order to find the next action you need to evaluate the \"next_state\" because it is the current state of the simulator\n",
    "            actions[idx] = CC[idx].choose_action(ns)\n",
    "        \n",
    "    if env.done :\n",
    "        env.reset()\n",
    "        for idx, s in start_state.items():\n",
    "            actions[idx] = CC[idx].choose_action(ns)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for i in range(14):\n",
    "    print(len(env.SCUs[i].compatible_actions))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single_Cross_Straight\n",
    "\n",
    "---> The lack of speed comes from the size of the model (particularly the change of color of the heads). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name  = 'Single_Cross_Straight'\n",
    "vissim_working_directory =  'C:\\\\Users\\\\Rzhang\\\\Desktop\\\\MLforFlowOptimisationOrigine\\\\Vissim\\\\'\n",
    "sim_length = 3601\n",
    "\n",
    "# all controller actions\n",
    "Single_Cross_Straight_dictionary =\\\n",
    "{\\\n",
    "    # Controller Number 0 \n",
    "    0 : {'compatible_actions' : {     0 : [1, 0, 1, 0],\n",
    "                                     1 : [0, 1, 0, 1]\n",
    "        },\n",
    " \n",
    "         'link' : [1, 3, 5, 7],\n",
    "         'lane' : ['1-1', '3-1', '5-1', '7-1'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'green_time' : 6,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [4],\n",
    "         'state_type' : 'Queues',\n",
    "         'reward_type' : 'Queues' \n",
    "}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working Directory set to: C:\\Users\\Rzhang\\Desktop\\MLforFlowOptimisationOrigine\\Vissim\\\n",
      "Generating Cache...\n",
      "Cache generated.\n",
      "\n",
      "****************************\n",
      "*   COM Server dispatched  *\n",
      "****************************\n",
      "\n",
      "Attempting to load Model File: Single_Cross_Straight.inpx ...\n",
      "Failed load attempt 1/5. Re-attempting.\n",
      "Working Directory set to: C:\\Users\\Rzhang\\Desktop\\MLforFlowOptimisationOrigine\\Vissim\\\n",
      "Generating Cache...\n",
      "Cache generated.\n",
      "\n",
      "****************************\n",
      "*   COM Server dispatched  *\n",
      "****************************\n",
      "\n",
      "Attempting to load Model File: Single_Cross_Straight.inpx ...\n",
      "Load process successful\n",
      "Simulation length set to 3601 seconds.\n",
      "Results from Previous Simulations: Deleted. Fresh Start Available.\n",
      "Fetched and containerized Simulation Object\n",
      "Fetched and containerized Network Object \n",
      "\n",
      "*******************************************************\n",
      "*                                                     *\n",
      "*                 SETUP COMPLETE                      *\n",
      "*                                                     *\n",
      "*******************************************************\n",
      "\n",
      "0.10934805870056152\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: <Vissim_SCU_class.Signal_Control_Unit at 0x2af8117f7f0>}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = env(model_name, vissim_working_directory, sim_length, Single_Cross_Straight_dictionary,\\\n",
    "            timesteps_per_second = 1, mode = 'training', delete_results = True, verbose = True)\n",
    "\n",
    "env.SCUs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying instance of Actor_Critic Agent(s) !!! TENSORFLOW 2 IS NEEDED !!! \n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                multiple                  210       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  210       \n",
      "_________________________________________________________________\n",
      "value (Dense)                multiple                  43        \n",
      "_________________________________________________________________\n",
      "policy_logits (Dense)        multiple                  86        \n",
      "_________________________________________________________________\n",
      "probability_distribution (Pr multiple                  0         \n",
      "=================================================================\n",
      "Total params: 549\n",
      "Trainable params: 549\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "To be corrected\n"
     ]
    }
   ],
   "source": [
    "gamma = 0.85\n",
    "alpha = 0.00005\n",
    "ID = 0\n",
    "value = 25\n",
    "entropy = 0.01\n",
    "n_step_size = 16\n",
    "state_size = [4]\n",
    "\n",
    "\n",
    "# for the monitoring\n",
    "horizon = 100\n",
    "n_sample = 10\n",
    "\n",
    "Agents = []\n",
    "\n",
    "for idx, info in Single_Cross_Straight_dictionary.items():\n",
    "        acts = info['compatible_actions']\n",
    "        Agent = ACAgent(state_size, len(acts), ID, n_step_size, gamma, alpha, entropy, value)\n",
    "        Agents.append(Agent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent 0 : Predicted Values and True Return : \n",
      " [-3.0, -5.0, -0.0, -1.0, -5.0, -5.0, -0.0, -3.0, -0.0, -5.0] \n",
      " [-445.0, -527.0, -45.0, -94.0, -527.0, -527.0, -20.0, -388.0, -18.0, -527.0]\n",
      "Agent 0 : Proba distribution on those states : \n",
      " [[0.0, 1.0], [0.0, 1.0], [0.21, 0.79], [0.14, 0.86], [0.0, 1.0], [0.0, 1.0], [0.39, 0.61], [0.0, 1.0], [0.39, 0.61], [0.0, 1.0]]\n",
      "Agent 0 : Proba distribution on the 0 state : \n",
      " [0.5 0.5]\n",
      "Agent 0 : Predicted Values and True Return : \n",
      " [-0.0, -2.0, -0.0, -5.0, -0.0, -0.0, -4.0, -7.0, -0.0, -0.0] \n",
      " [-22.0, -18.0, -527.0, -26.0, -19.0, -527.0, -25.0, -15.0, -156.0, -527.0]\n",
      "Agent 0 : Proba distribution on those states : \n",
      " [[0.54, 0.46], [0.63, 0.37], [0.4, 0.6], [0.9, 0.1], [0.54, 0.46], [0.13, 0.87], [0.83, 0.17], [0.93, 0.07], [0.37, 0.63], [0.37, 0.63]]\n",
      "Agent 0 : Proba distribution on the 0 state : \n",
      " [0.51 0.49]\n",
      "Agent 0 : Predicted Values and True Return : \n",
      " [-0.0, -1.0, -0.0, -0.0, -1.0, -0.0, -1.0, -0.0, -1.0, -1.0] \n",
      " [-18.0, -40.0, -17.0, -369.0, -527.0, -527.0, -325.0, -23.0, -13.0, -527.0]\n",
      "Agent 0 : Proba distribution on those states : \n",
      " [[0.25, 0.75], [0.58, 0.42], [0.33, 0.67], [0.5, 0.5], [0.63, 0.37], [0.25, 0.75], [0.5, 0.5], [0.33, 0.67], [0.65, 0.35], [0.64, 0.36]]\n",
      "Agent 0 : Proba distribution on the 0 state : \n",
      " [0.5 0.5]\n",
      "Agent 0 : Predicted Values and True Return : \n",
      " [-0.0, -1.0, -0.0, -1.0, -0.0, -1.0, -1.0, -2.0, -1.0, -1.0] \n",
      " [-20.0, -28.0, -19.0, -31.0, -15.0, -28.0, -90.0, -27.0, -47.0, -16.0]\n",
      "Agent 0 : Proba distribution on those states : \n",
      " [[0.48, 0.52], [0.27, 0.73], [0.48, 0.52], [0.08, 0.92], [0.48, 0.52], [0.62, 0.38], [0.71, 0.29], [0.74, 0.26], [0.27, 0.73], [0.71, 0.29]]\n",
      "Agent 0 : Proba distribution on the 0 state : \n",
      " [0.48 0.52]\n",
      "Agent 0 : Predicted Values and True Return : \n",
      " [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0] \n",
      " [-527.0, -18.0, -84.0, -20.0, -25.0, -25.0, -26.0, -205.0, -18.0, -527.0]\n",
      "Agent 0 : Proba distribution on those states : \n",
      " [[0.67, 0.33], [0.67, 0.33], [0.47, 0.53], [0.67, 0.33], [0.21, 0.79], [0.21, 0.79], [0.09, 0.91], [0.09, 0.91], [0.47, 0.53], [0.21, 0.79]]\n",
      "Agent 0 : Proba distribution on the 0 state : \n",
      " [0.47 0.53]\n",
      "Agent 0 : Predicted Values and True Return : \n",
      " [-1.0, -1.0, -1.0, -1.0, -1.0, -2.0, -5.0, -1.0, -1.0, -3.0] \n",
      " [-49.0, -50.0, -87.0, -383.0, -527.0, -84.0, -13.0, -15.0, -18.0, -14.0]\n",
      "Agent 0 : Proba distribution on those states : \n",
      " [[0.44, 0.56], [0.44, 0.56], [0.71, 0.29], [0.71, 0.29], [0.44, 0.56], [0.47, 0.53], [0.02, 0.98], [0.44, 0.56], [0.44, 0.56], [0.02, 0.98]]\n",
      "Agent 0 : Proba distribution on the 0 state : \n",
      " [0.44 0.56]\n",
      "Agent 0 : Predicted Values and True Return : \n",
      " [-2.0, -4.0, -2.0, -5.0, -2.0, -1.0, -2.0, -1.0, -3.0, -4.0] \n",
      " [-30.0, -26.0, -15.0, -26.0, -308.0, -15.0, -26.0, -527.0, -205.0, -16.0]\n",
      "Agent 0 : Proba distribution on those states : \n",
      " [[0.02, 0.98], [0.0, 1.0], [0.26, 0.74], [0.98, 0.02], [0.76, 0.24], [0.42, 0.58], [0.02, 0.98], [0.1, 0.9], [0.88, 0.12], [0.95, 0.05]]\n",
      "Agent 0 : Proba distribution on the 0 state : \n",
      " [0.42 0.58]\n",
      "Agent 0 : Predicted Values and True Return : \n",
      " [-1.0, -1.0, -5.0, -3.0, -1.0, -3.0, -2.0, -5.0, -3.0, -1.0] \n",
      " [-99.0, -10.0, -265.0, -526.0, -81.0, -25.0, -17.0, -265.0, -24.0, -22.0]\n",
      "Agent 0 : Proba distribution on those states : \n",
      " [[0.4, 0.6], [0.4, 0.6], [0.99, 0.01], [0.93, 0.07], [0.4, 0.6], [0.86, 0.14], [0.81, 0.19], [0.99, 0.01], [0.0, 1.0], [0.06, 0.94]]\n",
      "Agent 0 : Proba distribution on the 0 state : \n",
      " [0.4 0.6]\n",
      "Agent 0 : Predicted Values and True Return : \n",
      " [-3.0, -2.0, -4.0, -2.0, -1.0, -2.0, -1.0, -1.0, -7.0, -4.0] \n",
      " [-26.0, -393.0, -331.0, -254.0, -81.0, -441.0, -433.0, -19.0, -210.0, -49.0]\n",
      "Agent 0 : Proba distribution on those states : \n",
      " [[0.4, 0.6], [0.03, 0.97], [0.96, 0.04], [0.79, 0.21], [0.39, 0.61], [0.79, 0.21], [0.39, 0.61], [0.39, 0.61], [1.0, 0.0], [0.92, 0.08]]\n",
      "Agent 0 : Proba distribution on the 0 state : \n",
      " [0.39 0.61]\n",
      "Agent 0 : Predicted Values and True Return : \n",
      " [-4.0, -2.0, -1.0, -3.0, -2.0, -2.0, -2.0, -8.0, -1.0, -3.0] \n",
      " [-25.0, -20.0, -527.0, -111.0, -300.0, -430.0, -24.0, -26.0, -45.0, -25.0]\n",
      "Agent 0 : Proba distribution on those states : \n",
      " [[0.15, 0.85], [0.02, 0.98], [0.36, 0.64], [0.84, 0.16], [0.02, 0.98], [0.02, 0.98], [0.02, 0.98], [1.0, 0.0], [0.36, 0.64], [0.89, 0.11]]\n",
      "Agent 0 : Proba distribution on the 0 state : \n",
      " [0.36 0.64]\n",
      "Agent 0 : Predicted Values and True Return : \n",
      " [-3.0, -3.0, -4.0, -7.0, -5.0, -4.0, -4.0, -2.0, -2.0, -2.0] \n",
      " [-485.0, -28.0, -18.0, -18.0, -12.0, -26.0, -369.0, -16.0, -84.0, -15.0]\n",
      "Agent 0 : Proba distribution on those states : \n",
      " [[0.01, 0.99], [0.01, 0.99], [0.0, 1.0], [0.0, 1.0], [0.99, 0.01], [0.92, 0.08], [0.0, 1.0], [0.33, 0.67], [0.33, 0.67], [0.33, 0.67]]\n",
      "Agent 0 : Proba distribution on the 0 state : \n",
      " [0.33 0.67]\n",
      "Agent 0 : Predicted Values and True Return : \n",
      " [-3.0, -10.0, -4.0, -5.0, -3.0, -5.0, -6.0, -3.0, -2.0, -7.0] \n",
      " [-527.0, -441.0, -26.0, -92.0, -198.0, -527.0, -26.0, -29.0, -14.0, -22.0]\n",
      "Agent 0 : Proba distribution on those states : \n",
      " [[0.0, 1.0], [0.0, 1.0], [0.95, 0.05], [0.0, 1.0], [0.0, 1.0], [0.0, 1.0], [1.0, 0.0], [0.0, 1.0], [0.29, 0.71], [0.85, 0.15]]\n",
      "Agent 0 : Proba distribution on the 0 state : \n",
      " [0.29 0.71]\n",
      "Agent 0 : Predicted Values and True Return : \n",
      " [-8.0, -6.0, -5.0, -2.0, -10.0, -3.0, -3.0, -6.0, -2.0, -5.0] \n",
      " [-235.0, -16.0, -14.0, -376.0, -527.0, -43.0, -181.0, -254.0, -450.0, -26.0]\n",
      "Agent 0 : Proba distribution on those states : \n",
      " [[0.0, 1.0], [0.0, 1.0], [0.0, 1.0], [0.26, 0.74], [0.08, 0.92], [0.0, 1.0], [0.0, 1.0], [0.0, 1.0], [0.26, 0.74], [0.0, 1.0]]\n",
      "Agent 0 : Proba distribution on the 0 state : \n",
      " [0.26 0.74]\n",
      "Agent 0 : Predicted Values and True Return : \n",
      " [-6.0, -11.0, -5.0, -8.0, -2.0, -4.0, -9.0, -6.0, -15.0, -5.0] \n",
      " [-16.0, -410.0, -20.0, -18.0, -14.0, -22.0, -160.0, -244.0, -26.0, -221.0]\n",
      "Agent 0 : Proba distribution on those states : \n",
      " [[0.0, 1.0], [0.0, 1.0], [0.98, 0.02], [1.0, 0.0], [0.22, 0.78], [0.0, 1.0], [0.91, 0.09], [0.0, 1.0], [0.82, 0.18], [0.0, 1.0]]\n",
      "Agent 0 : Proba distribution on the 0 state : \n",
      " [0.22 0.78]\n",
      "Agent 0 : Predicted Values and True Return : \n",
      " [-6.0, -6.0, -12.0, -3.0, -12.0, -3.0, -8.0, -8.0, -6.0, -3.0] \n",
      " [-325.0, -16.0, -14.0, -27.0, -14.0, -28.0, -45.0, -181.0, -127.0, -415.0]\n",
      "Agent 0 : Proba distribution on those states : \n",
      " [[0.0, 1.0], [0.99, 0.01], [1.0, 0.0], [0.18, 0.82], [1.0, 0.0], [0.18, 0.82], [1.0, 0.0], [1.0, 0.0], [0.99, 0.01], [0.18, 0.82]]\n",
      "Agent 0 : Proba distribution on the 0 state : \n",
      " [0.18 0.82]\n",
      "Agent 0 : Predicted Values and True Return : \n",
      " [-3.0, -3.0, -3.0, -17.0, -7.0, -3.0, -11.0, -9.0, -6.0, -12.0] \n",
      " [-34.0, -16.0, -265.0, -26.0, -19.0, -527.0, -25.0, -12.0, -26.0, -17.0]\n",
      "Agent 0 : Proba distribution on those states : \n",
      " [[0.15, 0.85], [0.15, 0.85], [0.15, 0.85], [1.0, 0.0], [0.99, 0.01], [0.15, 0.85], [0.0, 1.0], [1.0, 0.0], [0.99, 0.01], [1.0, 0.0]]\n",
      "Agent 0 : Proba distribution on the 0 state : \n",
      " [0.15 0.85]\n",
      "Agent 0 : Predicted Values and True Return : \n",
      " [-7.0, -6.0, -11.0, -7.0, -3.0, -6.0, -6.0, -3.0, -3.0, -7.0] \n",
      " [-383.0, -49.0, -524.0, -27.0, -362.0, -331.0, -331.0, -18.0, -50.0, -405.0]\n",
      "Agent 0 : Proba distribution on those states : \n",
      " [[1.0, 0.0], [0.0, 1.0], [1.0, 0.0], [0.99, 0.01], [0.12, 0.88], [0.0, 1.0], [0.0, 1.0], [0.12, 0.88], [0.12, 0.88], [1.0, 0.0]]\n",
      "Agent 0 : Proba distribution on the 0 state : \n",
      " [0.12 0.88]\n",
      "Agent 0 : Predicted Values and True Return : \n",
      " [-13.0, -4.0, -7.0, -6.0, -4.0, -4.0, -4.0, -8.0, -4.0, -4.0] \n",
      " [-122.0, -393.0, -477.0, -24.0, -527.0, -527.0, -527.0, -505.0, -14.0, -44.0]\n",
      "Agent 0 : Proba distribution on those states : \n",
      " [[0.0, 1.0], [0.06, 0.94], [0.99, 0.01], [0.0, 1.0], [0.06, 0.94], [0.06, 0.94], [0.06, 0.94], [0.99, 0.01], [0.06, 0.94], [0.06, 0.94]]\n",
      "Agent 0 : Proba distribution on the 0 state : \n",
      " [0.06 0.94]\n",
      "Agent 0 : Predicted Values and True Return : \n",
      " [-4.0, -4.0, -6.0, -4.0, -6.0, -9.0, -4.0, -4.0, -4.0, -11.0] \n",
      " [-143.0, -28.0, -28.0, -331.0, -28.0, -244.0, -21.0, -415.0, -15.0, -24.0]\n",
      "Agent 0 : Proba distribution on those states : \n",
      " [[0.03, 0.97], [0.03, 0.97], [0.0, 1.0], [0.03, 0.97], [0.0, 1.0], [0.0, 1.0], [0.03, 0.97], [0.03, 0.97], [0.03, 0.97], [1.0, 0.0]]\n",
      "Agent 0 : Proba distribution on the 0 state : \n",
      " [0.03 0.97]\n",
      "Agent 0 : Predicted Values and True Return : \n",
      " [-7.0, -8.0, -4.0, -7.0, -9.0, -8.0, -8.0, -8.0, -4.0, -4.0] \n",
      " [-18.0, -383.0, -18.0, -20.0, -17.0, -149.0, -44.0, -369.0, -527.0, -362.0]\n",
      "Agent 0 : Proba distribution on those states : \n",
      " [[0.0, 1.0], [0.98, 0.02], [0.01, 0.99], [0.0, 1.0], [0.0, 1.0], [0.98, 0.02], [0.98, 0.02], [0.98, 0.02], [0.01, 0.99], [0.01, 0.99]]\n",
      "Agent 0 : Proba distribution on the 0 state : \n",
      " [0.01 0.99]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent 0 : Predicted Values and True Return : \n",
      " [-5.0, -8.0, -5.0, -7.0, -5.0, -7.0, -7.0, -10.0, -7.0, -5.0] \n",
      " [-46.0, -17.0, -140.0, -12.0, -16.0, -15.0, -13.0, -13.0, -28.0, -18.0]\n",
      "Agent 0 : Proba distribution on those states : \n",
      " [[0.0, 1.0], [0.96, 0.04], [0.0, 1.0], [0.0, 1.0], [0.0, 1.0], [0.0, 1.0], [0.0, 1.0], [1.0, 0.0], [0.0, 1.0], [0.0, 1.0]]\n",
      "Agent 0 : Proba distribution on the 0 state : \n",
      " [0. 1.]\n",
      "Agent 0 : Predicted Values and True Return : \n",
      " [-5.0, -9.0, -11.0, -5.0, -5.0, -5.0, -5.0, -5.0, -7.0, -10.0] \n",
      " [-15.0, -40.0, -14.0, -16.0, -76.0, -20.0, -132.0, -24.0, -16.0, -32.0]\n",
      "Agent 0 : Proba distribution on those states : \n",
      " [[0.0, 1.0], [0.0, 1.0], [1.0, 0.0], [0.0, 1.0], [0.0, 1.0], [0.0, 1.0], [0.0, 1.0], [0.0, 1.0], [0.0, 1.0], [0.0, 1.0]]\n",
      "Agent 0 : Proba distribution on the 0 state : \n",
      " [0. 1.]\n",
      "Agent 0 : Predicted Values and True Return : \n",
      " [-5.0, -8.0, -11.0, -7.0, -5.0, -9.0, -11.0, -5.0, -5.0, -10.0] \n",
      " [-16.0, -24.0, -17.0, -20.0, -527.0, -393.0, -527.0, -527.0, -527.0, -25.0]\n",
      "Agent 0 : Proba distribution on those states : \n",
      " [[0.0, 1.0], [0.74, 0.26], [0.99, 0.01], [0.0, 1.0], [0.0, 1.0], [0.0, 1.0], [0.0, 1.0], [0.0, 1.0], [0.0, 1.0], [0.0, 1.0]]\n",
      "Agent 0 : Proba distribution on the 0 state : \n",
      " [0. 1.]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-152e0d5072ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0maction_required\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSARSDs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maction_required\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mactions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\MLforFlowOptimisationOrigine\\Vissim\\Vissim_env_class.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, actions)\u001b[0m\n\u001b[0;32m    106\u001b[0m                 \u001b[1;33m[\u001b[0m\u001b[0mscu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscu\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSCUs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mscu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_required\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m                 \u001b[1;33m[\u001b[0m\u001b[0mscu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscu\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSCUs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m                 \u001b[1;31m# not a nice way of doing this creatung the dictionnary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\MLforFlowOptimisationOrigine\\Vissim\\Vissim_env_class.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    106\u001b[0m                 \u001b[1;33m[\u001b[0m\u001b[0mscu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscu\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSCUs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mscu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_required\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m                 \u001b[1;33m[\u001b[0m\u001b[0mscu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscu\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSCUs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m                 \u001b[1;31m# not a nice way of doing this creatung the dictionnary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\MLforFlowOptimisationOrigine\\Vissim\\Vissim_SCU_class.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    320\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_counter\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m                         \u001b[1;31m# These 'if' clauses mean update computation only happens if needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m                         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_counter\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0.\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m                                 \u001b[1;31m# if update counter just went zero\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m                                 \u001b[1;31m# then ask for an action\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\MLforFlowOptimisationOrigine\\Vissim\\Vissim_SCU_class.py\u001b[0m in \u001b[0;36m_color_changer\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    239\u001b[0m                                 \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mred_time\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m                                         \u001b[1;31m# Skip the red stage and go directly to red amber\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 241\u001b[1;33m                                         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mredamber_time\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    242\u001b[0m \t\t\t\t\t\t[self.signal_groups[idx].SetAttValue(\"SigState\", Amber_to_Redamber(value)) \\\n\u001b[0;32m    243\u001b[0m \t\t\t\t\t\t\t\t\tfor idx,value in enumerate(self.change_vector) if value != 0]\n",
      "\u001b[1;32m~\\Desktop\\MLforFlowOptimisationOrigine\\Vissim\\Vissim_SCU_class.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    239\u001b[0m                                 \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mred_time\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m                                         \u001b[1;31m# Skip the red stage and go directly to red amber\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 241\u001b[1;33m                                         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mredamber_time\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    242\u001b[0m \t\t\t\t\t\t[self.signal_groups[idx].SetAttValue(\"SigState\", Amber_to_Redamber(value)) \\\n\u001b[0;32m    243\u001b[0m \t\t\t\t\t\t\t\t\tfor idx,value in enumerate(self.change_vector) if value != 0]\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2\\lib\\site-packages\\win32com\\client\\dynamic.py\u001b[0m in \u001b[0;36mSetAttValue\u001b[1;34m(self, Attribut, arg1)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_state = env.get_state()\n",
    "actions = {}\n",
    "for idx, s in start_state.items():\n",
    "            actions[idx] = Agents[idx].choose_action(s)\n",
    "\n",
    "for _ in range(100000):\n",
    "    action_required, SARSDs = env.step_to_next_action(actions)\n",
    "    if action_required : \n",
    "        actions = dict()\n",
    "        for idx , sarsd in SARSDs.items():\n",
    "            s,a,r,ns,d = sarsd\n",
    "            \n",
    "            #print(sarsd)\n",
    "            Agents[idx].remember(s,a,r,ns,d)\n",
    "            if len(Agents[idx].memory) >= Agents[idx].n_step_size :\n",
    "                Agents[idx].learn() \n",
    "            \n",
    "            # in order to find the next action you need to evaluate the \"next_state\" because it is the current state of the simulator\n",
    "            actions[idx] = int(Agents[idx].choose_action(ns))\n",
    "            #print(actions)\n",
    "            \n",
    "    \n",
    "    # For the saving , monitoring of the agent\n",
    "    if env.done :\n",
    "        env.reset()\n",
    "        for idx, agent in enumerate(Agents):\n",
    "                    predicted_values, true_values, proba0, probas = agent.value_check(horizon, n_sample)\n",
    "                    print (\"Agent {} : Predicted Values and True Return : \\n {} \\n {}\" .format(idx, predicted_values, true_values))\n",
    "                    print (\"Agent {} : Proba distribution on those states : \\n {}\" .format(idx, probas))\n",
    "                    print (\"Agent {} : Proba distribution on the 0 state : \\n {}\" .format(idx, proba0))\n",
    "                    agent.reset()\n",
    "                    \n",
    "        \n",
    "        for idx, s in start_state.items():\n",
    "            actions[idx] = Agents[idx].choose_action(s)\n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[], [], [], [], []], [[], [], [], [], []], [[], [], [], [], []]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = range(5)\n",
    "b = range(3)\n",
    "\n",
    "b = [[[] for _ in a] for bla in b]\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "a = 3\n",
    "def foo():\n",
    "    global a\n",
    "    b = a\n",
    "    for i in range(b):\n",
    "        print(i)\n",
    "foo()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
