{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Vissim_env_class import environment\n",
    "from Actor_critic_class import ACAgent\n",
    "from MasterAC_Agent import MasterAC_Agent\n",
    "from MasterDQN_Agent import MasterDQN_Agent\n",
    "\n",
    "# Network Specific Libraries\n",
    "from Balance_Functions import balance_dictionary\n",
    "\n",
    "# General Libraries\n",
    "import numpy as np \n",
    "import pylab as plt\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_name  = 'Balance'\n",
    "#vissim_working_directory =  'C:\\\\Users\\\\Rzhang\\\\Desktop\\\\MLforFlowOptimisationOrigine\\\\Vissim\\\\'\n",
    "vissim_working_directory = \"E:\\Backup - Onedrive\\Desktop\\ATI\\0_TMF\\MLforFlowOptimisation\\Vissim\"\n",
    "sim_length = 1800\n",
    "\n",
    "# all controller actions\n",
    "Balance_dictionary =\\\n",
    "{\\\n",
    "    # Controller Number 2 \n",
    "    0 : {'compatible_actions' : {   0 : [1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0],\n",
    "                                    1 : [0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1],\n",
    "                                    2 : [0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0] },\n",
    "         \n",
    "         'link' : [2, 40, 7, 38],\n",
    "         'lane' : ['2-1', '2-2', '2-3', '40-1', '7-1', '7-2', '7-3', '38-1'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'green_time' : 8,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [8],\n",
    "         'state_type' : 'Queues',\n",
    "         'reward_type' : 'Queues'\n",
    "         \n",
    "         \n",
    "        },\n",
    "    # Controller Number 3\n",
    "    1 : {'compatible_actions' : {   0 : [0, 1, 0, 0, 1, 0, 1, 1],\n",
    "                                    1 : [1, 0, 0, 1, 0, 0, 0, 0],\n",
    "                                    2 : [0, 0, 1, 0, 0, 1, 0, 0] },\n",
    "         \n",
    "         'link' : [5, 48, 70, 46],\n",
    "         'lane' : ['5-1', '5-2', '5-3', '48-1', '70-1', '70-2', '70-3', '46-1'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'green_time' : 8,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [8],\n",
    "         'state_type' : 'Queues',\n",
    "         'reward_type' : 'Queues'\n",
    "        },\n",
    "    # Controller Number 4\n",
    "    2 : {'compatible_actions' : {   0 : [0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                                    1 : [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                                    2 : [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                                    3 : [0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]},\n",
    "         \n",
    "         'link' : [73, 100, 84, 95],\n",
    "         'lane' : ['73-1', '73-2', '73-3', '100-1', '100-2', '100-3', '100-4',\\\n",
    "                  '84-1', '84-2', '84-3', '95-1', '95-2', '95-3', '95-4'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'green_time' : 8,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [14],\n",
    "         'state_type' : 'Queues',\n",
    "         'reward_type' : 'Queues'\n",
    "        },\n",
    "    # Controller Number 5\n",
    "    3 : {'compatible_actions' : {   0 : [0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0],\n",
    "                                    1 : [1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0],\n",
    "                                    2 : [0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1]},\n",
    "         \n",
    "         'link' : [87, 36, 10, 34],\n",
    "         'lane' : ['87-1', '87-2', '87-3', '36-1', '10-1', '10-2', '10-3', '34-1'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'green_time' : 8,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [8],\n",
    "         'state_type' : 'Queues',\n",
    "         'reward_type' : 'Queues'\n",
    "        },\n",
    "    # Controller Number 6 \n",
    "    4 : {'compatible_actions' : {   0 : [0, 1, 1, 0, 0],\n",
    "                                    1 : [1, 1, 0, 0, 0],\n",
    "                                    2 : [0, 0, 0, 1, 0]},\n",
    "         'link' : [8, 24, 13],\n",
    "         'lane' : ['8-1', '8-2', '24-1', '13-1', '13-2', '13-3'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'green_time' : 8,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [6],\n",
    "         'state_type' : 'Queues',\n",
    "         'reward_type' : 'Queues'\n",
    "        },\n",
    "    # Controller Number 8\n",
    "    5 : {'compatible_actions' : {   0 : [1, 0, 1, 0, 1, 0],\n",
    "                                    1 : [0, 1, 0, 1, 0, 1]},\n",
    "         'link' : [26, 23, 35],\n",
    "         'lane' : ['26-1', '23-1', '35-1'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'green_time' : 8,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [3],\n",
    "         'state_type' : 'Queues',\n",
    "         'reward_type' : 'Queues'\n",
    "         \n",
    "        },\n",
    "    # Controller Number 9\n",
    "    6 : {'compatible_actions' : {   0 : [0, 1, 0, 1, 1, 1],\n",
    "                                    1 : [1, 0, 1, 0, 0, 0]},\n",
    "         'link' : [51, 92, 64, 19],\n",
    "         'lane' : ['51-1', '92-1', '92-2', '64-1', '19-1', '19-2'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'green_time' : 8,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [6],\n",
    "         'state_type' : 'Queues',\n",
    "         'reward_type' : 'Queues'\n",
    "        },\n",
    "    # Contoller Number 10\n",
    "    7 : {'compatible_actions' : {   0 : [0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "                                    1 : [0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "                                    2 : [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]},\n",
    "         'link' : [18, 66, 16],\n",
    "         'lane' : ['18-1', '18-2', '18-3', '66-1', '16-1', '16-2', '16-3'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'green_time' : 8,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [7],\n",
    "         'state_type' : 'Queues',\n",
    "         'reward_type' : 'Queues'\n",
    "        },\n",
    "    # Controller Number 12\n",
    "    8 : {'compatible_actions' : {   0 : [1, 0, 1, 0, 0, 0, 0],\n",
    "                                    1 : [0, 1, 0, 0, 0, 0, 0]},\n",
    "         'link' : [62, 45, 44],\n",
    "         'lane' : ['62-1', '45-1', '44-1'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'green_time' : 8,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [3],\n",
    "         'state_type' : 'Queues',\n",
    "         'reward_type' : 'Queues'\n",
    "        },\n",
    "    # Controller Number 13\n",
    "    9 : {'compatible_actions' : {   0 : [0, 1, 0, 1, 1, 0, 1, 0],\n",
    "                                    1 : [1, 0, 1, 0, 0, 1, 0, 1]},\n",
    "         'link' : [60, 43, 55, 58],\n",
    "         'lane' : ['60-1', '43-1', '55-1', '58-1'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'green_time' : 8,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [4],\n",
    "         'state_type' : 'Queues',\n",
    "         'reward_type' : 'Queues'\n",
    "            \n",
    "        },\n",
    "    # Controller 15\n",
    "    10 : {'compatible_actions' : {  0 : [1, 0, 1, 0, 0, 1, 0, 1],\n",
    "                                    1 : [0, 1, 0, 1, 1, 0, 1, 0]},\n",
    "         'link' : [32, 42, 30, 39],\n",
    "         'lane' : ['32-1', '42-1', '30-1', '39-1'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'green_time' : 8,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [4],\n",
    "         'state_type' : 'Queues',\n",
    "         'reward_type' : 'Queues'\n",
    "        },\n",
    "    # Controller 16\n",
    "    11 : {'compatible_actions' :  { 0 : [1, 0, 1, 0, 0, 1, 0, 1],\n",
    "                                    1 : [0, 1, 0, 1, 1, 0, 1, 0]},\n",
    "         'link' : [29, 50, 28, 47],\n",
    "         'lane' : ['29-1', '50-1', '28-1', '47-1'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'green_time' : 8,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [4],\n",
    "         'state_type' : 'Queues',\n",
    "         'reward_type' : 'Queues'\n",
    "        },\n",
    "    # Controller 17\n",
    "    12 : {'compatible_actions' :  { 0 : [1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1],\n",
    "                                    1 : [0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1],\n",
    "                                    2 : [0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0],\n",
    "                                    3 : [0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0]},\n",
    "         'link' : [27, 22, 25, 77],\n",
    "         'lane' : ['27-1', '22-1', '22-2', '22-3', '25-1', '77-1', '77-2'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'green_time' : 8,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [7],\n",
    "         'state_type' : 'Queues',\n",
    "         'reward_type' : 'Queues'\n",
    "            \n",
    "        },\n",
    "    # Controller 33 \n",
    "    13 : {'compatible_actions' :  { 0 : [1, 0, 0, 1, 0, 0, 1, 0, 0],\n",
    "                                    1 : [0, 0, 1, 1, 0, 1, 0, 0, 0],\n",
    "                                    2 : [0, 1, 0, 0, 1, 1, 0, 1, 1]},\n",
    "         'link' : [68, 71, 75],\n",
    "         'lane' : ['68-1', '68-2', '68-3', '71-1', '71-2', '75-1'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'green_time' : 8,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [6],\n",
    "         'state_type' : 'Queues',\n",
    "         'reward_type' : 'Queues'\n",
    "        }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "env = environment(model_name, vissim_working_directory, sim_length, Balance_dictionary,\\\n",
    "            timesteps_per_second = 1, mode = 'training', delete_results = True, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "env.SCUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "env.SCUs[0].state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "actions = dict()\n",
    "for i in range(len(env.SCUs)):\n",
    "    actions[i]=0\n",
    "    \n",
    "print(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Cyclic_Control():\n",
    "    def __init__(self,size):\n",
    "        self.action = 0\n",
    "        self.size = size\n",
    "        \n",
    "    def choose_action(self,state=None):\n",
    "        self.action = (self.action + 1) % self.size\n",
    "        return self.action\n",
    "CC = [] \n",
    "\n",
    "for idx, info in Balance_dictionary.items():\n",
    "        cycle_size = len(info['compatible_actions'])\n",
    "        CC.append(Cyclic_Control(cycle_size))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Training loop / simulation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_state = env.get_state()\n",
    "for idx, s in start_state.items():\n",
    "    actions[idx] = CC[idx].choose_action(s)\n",
    "    \n",
    "for _ in range(10000):\n",
    "    action_required, SARSDs = env.step(actions)\n",
    "    if action_required : \n",
    "        actions = dict()\n",
    "        for idx , sarsd in SARSDs.items():\n",
    "            s,a,r,ns,d = sarsd\n",
    "            #print(sarsd)\n",
    "            \n",
    "            # in order to find the next action you need to evaluate the \"next_state\" because it is the current state of the simulator\n",
    "            actions[idx] = CC[idx].choose_action(ns)\n",
    "        \n",
    "    if env.done :\n",
    "        env.reset()\n",
    "        for idx, s in start_state.items():\n",
    "            actions[idx] = CC[idx].choose_action(ns)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Balance RL AC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_name  = 'Balance'\n",
    "vissim_working_directory =  'C:\\\\Users\\\\Rzhang\\\\Desktop\\\\MLforFlowOptimisationOrigine\\\\Vissim\\\\'\n",
    "sim_length = 1800\n",
    "agent_type = 'AC'\n",
    "\n",
    "# all controller actions\n",
    "Balance_dictionary = balance_dictionary(agent_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "env = environment(model_name, vissim_working_directory, sim_length, Balance_dictionary,\\\n",
    "            timesteps_per_second = 1, mode = 'training', delete_results = True, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Agent hyperparameters\n",
    "gamma = 0.85\n",
    "alpha = 0.0005\n",
    "value = 25\n",
    "entropy = 5000\n",
    "n_step_size = 11\n",
    "reduce_entropy_every = 1000\n",
    "entropy_threshold = 0.5\n",
    "timesteps_per_second = 1\n",
    "\n",
    "\n",
    "# for the monitoring only for AC\n",
    "horizon = 50\n",
    "n_sample = 10\n",
    "\n",
    "Balance_MultiAc_Agents = MasterAC_Agent(model_name, vissim_working_directory, sim_length, Balance_dictionary, n_step_size, gamma, alpha, entropy, value, \\\n",
    "                timesteps_per_second = timesteps_per_second, verbose = True, horizon = 100, \\\n",
    "                n_sample = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Balance_MultiAc_Agents.train(1000)\n",
    "\n",
    "Balance_MultiAc_Agents.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Balance_MultiAc_Agents = MasterAC_Agent(model_name, vissim_working_directory, sim_length, Balance_dictionary, n_step_size, gamma, alpha, entropy, value, \\\n",
    "                timesteps_per_second = timesteps_per_second, verbose = True, horizon = 100, \\\n",
    "                n_sample = 10)\n",
    "\n",
    "Balance_MultiAc_Agents.load(best = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Agents = []\n",
    "for idx, info in Balance_dictionary['junctions'].items():\n",
    "        acts = info['compatible_actions']\n",
    "        Agent = ACAgent(info['state_size'], len(acts), idx, n_step_size, gamma, alpha, entropy, value)\n",
    "        Agents.append(Agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "start_state = env.get_state()\n",
    "actions = {}\n",
    "for idx, s in start_state.items():\n",
    "            actions[idx] = int(Agents[idx].choose_action(s))\n",
    "\n",
    "for i in range(30000):\n",
    "    action_required, SARSDs = env.step_to_next_action(actions)\n",
    "    if action_required : \n",
    "        actions = dict()\n",
    "        for idx , sarsd in SARSDs.items():\n",
    "            s,a,r,ns,d = sarsd\n",
    "            \n",
    "            #print(sarsd)\n",
    "            Agents[idx].remember(s,a,r,ns,d)\n",
    "            if len(Agents[idx].memory) >= Agents[idx].n_step_size :\n",
    "                Agents[idx].learn() \n",
    "            \n",
    "            # in order to find the next action you need to evaluate the \"next_state\" because it is the current state of the simulator\n",
    "            actions[idx] = int(Agents[idx].choose_action(ns))\n",
    "            #print(actions)\n",
    "            \n",
    "            if (i+1)%reduce_entropy_every == 0:\n",
    "                if Agents[idx].params['entropy'] >= entropy_threshold :\n",
    "                    Agents[idx].reduce_entropy()\n",
    "                    print (\"Agent {} : Entropy reduced to {} \" .format(idx, Agents[idx].params['entropy']))\n",
    "        \n",
    "    # For the saving , monitoring of the agent \n",
    "    if env.done :\n",
    "        env.reset()\n",
    "        \n",
    "        \n",
    "        # Only for AC\n",
    "        for idx, agent in enumerate(Agents):\n",
    "            predicted_values, true_values, proba0, probas = agent.value_check(horizon, n_sample)\n",
    "            print (\"Agent {} : Predicted Values and True Return : \\n {} \\n {}\" .format(idx, predicted_values, true_values))\n",
    "            print (\"Agent {} : Proba distribution on those states : \\n {}\" .format(idx, probas))\n",
    "            print (\"Agent {} : Proba distribution on the 0 state : \\n {}\" .format(idx, proba0))\n",
    "            agent.reset()\n",
    "                    \n",
    "        \n",
    "        for idx, s in start_state.items():\n",
    "            actions[idx] = Agents[idx].choose_action(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Balance DQN Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "## Initialization Parameters ##\n",
    "###############################\n",
    "\n",
    "intersection = \"1_2_4\"\n",
    "map_name  = 'Balance_int'+str(intersection)\n",
    "model_name = map_name\n",
    "vissim_working_directory = 'C:\\\\Users\\\\acabrejasegea\\\\OneDrive - The Alan Turing Institute\\\\Desktop\\\\ATI\\\\0_TMF\\\\MLforFlowOptimisation\\\\Vissim\\\\'\n",
    "#vissim_working_directory = \"E:\\\\OneDrive - University of Warwick\\\\Desktop\\\\ATI\\\\0_TMF\\\\MLforFlowOptimisation\\\\Vissim\"\n",
    "\n",
    "## Simulation Parameters\n",
    "Random_Seed = 44\n",
    "sim_length = 9001\n",
    "timesteps_per_second = 1\n",
    "agent_type = \"DDQN\"\n",
    "#actions_set = 'default_actions'     # 'default_actions' or 'all_actions'\n",
    "actions_set = 'all_actions'\n",
    "\n",
    "## DQN Hyperaramenters\n",
    "episodes = 500\n",
    "copy_weights_frequency = 10\n",
    "\n",
    "PER_activated = True\n",
    "memory_size = 5000\n",
    "batch_size = 128\n",
    "batches_per_episode = 10\n",
    "\n",
    "alpha = 0.00005\n",
    "gamma = 0.95\n",
    "\n",
    "# Load and partition balance dictionary\n",
    "Balance_dictionary = balance_dictionary(agent_type)\n",
    "if intersection == \"1_2_4\":\n",
    "    intersection = 1\n",
    "elif intersection == \"11_12\":\n",
    "    intersection = 11\n",
    "partial_dictionary = {\"junctions\": { (intersection-1) : Balance_dictionary[\"junctions\"][intersection-1]},\\\n",
    "                      \"demand\": Balance_dictionary[\"demand\"]}\n",
    "\n",
    "Session_ID = map_name + \"_\" + actions_set + \"_\" + str(episodes) + \"_\" + str(sim_length-1) + \"_\" + agent_type\n",
    "print(\"Current simulation: {}\".format(Session_ID))\n",
    "\n",
    "# Exploration Schedule (\"linear\" or \"geometric\")\n",
    "exploration_schedule = \"geometric\"\n",
    "epsilon_start = 1\n",
    "epsilon_end   = 0.01\n",
    "\n",
    "def choose_schedule(exploration_schedule, espilon_start, epsilon_end, episodes):\n",
    "    if exploration_schedule == \"linear\":\n",
    "        epsilon_decay = 1.2*(epsilon_end - epsilon_start)/(episodes-1)\n",
    "        epsilon_sequence = [1 + epsilon_decay * entry for entry in range(episodes+1)]\n",
    "        epsilon_sequence = [0.01 if entry < 0.01 else entry for entry in epsilon_sequence]\n",
    "    elif exploration_schedule == \"geometric\":\n",
    "        epsilon_decay = np.power(epsilon_end/epsilon_start, 1./(episodes-1)) # Geometric decay\n",
    "        epsilon_sequence = [epsilon_start * epsilon_decay ** entry for entry in range(episodes+1)]\n",
    "        epsilon_sequence = [0.01 if entry < 0.01 else entry for entry in epsilon_sequence]\n",
    "    elif exploration_schedule == \"entropy\":\n",
    "        pass\n",
    "    else:\n",
    "        print(\"ERROR: Unrecognized choice of exploration schedule.\")\n",
    "        \n",
    "    # Plotting exploration schedule\n",
    "    plt.figure(figsize=(8,4.5))\n",
    "    x_series = np.array(range(1,episodes+1))\n",
    "    y_series = epsilon_sequence[0:episodes]\n",
    "    plt.plot(x_series, y_series, '-b')\n",
    "    plt.xlabel('Episodes')\n",
    "    plt.ylabel('Ratio of random exploration')\n",
    "    plt.title('Exploration schedule')\n",
    "    plt.show()\n",
    "    return(epsilon_sequence)\n",
    "\n",
    "epsilon_sequence = choose_schedule(exploration_schedule, epsilon_start, epsilon_end, episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Deploy Agents\n",
    "Balance_int_MultiDQN_Agents = MasterDQN_Agent(model_name, vissim_working_directory, sim_length, partial_dictionary, actions_set,\\\n",
    "                gamma, alpha, agent_type, memory_size, PER_activated, batch_size, batches_per_episode, copy_weights_frequency, epsilon_sequence,\\\n",
    "                Random_Seed, timesteps_per_second, Session_ID, verbose = True)\n",
    "Balance_int_MultiDQN_Agents.prepopulate_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Deploy Environment\n",
    "env = None\n",
    "env = environment(model_name, vissim_working_directory, sim_length, partial_dictionary, actions_set,\\\n",
    "                  Random_Seed = Random_Seed, timesteps_per_second = timesteps_per_second, mode = 'debug', delete_results = True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Test to ensure correct deployment of agents\n",
    "\n",
    "# Test 1: Check number of agents\n",
    "print(env.SCUs.items())\n",
    "\n",
    "# Test 2: Check Dictionary for each agent\n",
    "agent = 0\n",
    "print(\"state_type: \" + env.SCUs[agent].state_type)\n",
    "print(\"state_size: \")\n",
    "print(env.SCUs[agent].state_size)\n",
    "print(\"reward_type: \")\n",
    "print(env.SCUs[agent].reward_type)\n",
    "print(\"compatible_actions: \")\n",
    "print(env.SCUs[agent].compatible_actions)\n",
    "print(\"all_actions: \")\n",
    "print(env.SCUs[agent].all_actions)\n",
    "print(\"Lanes_names: \" )\n",
    "print(env.SCUs[agent].Lanes_names)\n",
    "print(\"Links_names: \")\n",
    "print(env.SCUs[agent].Links_names)\n",
    "print(\"time_steps_per_second: \" + str(env.SCUs[agent].time_steps_per_second))\n",
    "print(\"queues_counter_ID: \" )\n",
    "print(env.SCUs[agent].queues_counter_ID)\n",
    "print(\"queues_counters: \")\n",
    "print(env.SCUs[agent].queues_counters)\n",
    "print(\"signal_controller: \")\n",
    "print(env.SCUs[agent].signal_controller)\n",
    "print(\"Signal_Groups: \" )\n",
    "print(env.SCUs[agent].signal_groups)\n",
    "print(\"Node: \" + str(env.SCUs[agent].Node))\n",
    "\n",
    "## CORRECT - No apparent issues from this test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Tests to ensure correct STATE READING\n",
    "timesteps = 1\n",
    "for i in range(timesteps):\n",
    "    env.Vissim.Simulation.RunSingleStep()\n",
    "\n",
    "## Test 3: Correct Reading of queues from QUEUE COUNTERS\n",
    "print(\"queues_counter_ID: \" )\n",
    "print(env.SCUs[0].queues_counter_ID)\n",
    "print([env.Vissim.Net.QueueCounters.ItemByKey(i).AttValue('QLen(Current, Last)') for i in env.SCUs[0].queues_counter_ID])\n",
    "    \n",
    "# Test 4: Correct Reading of Aggregated Queues by SCU\n",
    "print(env.SCUs[0].calculate_queues())\n",
    "\n",
    "## Test 5: Correct Reading of Global Queues by ENVIRONMENT\n",
    "print(env.get_queues())\n",
    "\n",
    "## CORRECT - No apparent issues from this test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Test 6: Correct Reading of Initial State, and Generation of according actions\n",
    "start_state = env.get_state()\n",
    "actions = {}\n",
    "print(\"Dict([(Agent_ID, array(state))])\")\n",
    "print(start_state.items())\n",
    "print(\"\")\n",
    "for idx, s in start_state.items():\n",
    "    actions[idx] = Balance_int_MultiDQN_Agents.Agents[idx].choose_action(s)\n",
    "print(\"{Agent_ID : Chosen_Action}\")\n",
    "print(actions)\n",
    "\n",
    "## CORRECT - No apparent issues from this test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Test 7: Correct Reading of General State from SCU and Generation of according actions\n",
    "SARSDs = env.step_to_next_action(actions)\n",
    "actions = dict()\n",
    "for idx , sarsd in SARSDs.items():\n",
    "    s,a,r,ns,d = sarsd\n",
    "    \n",
    "print(\"Agent_ID: \" + str(SARSDs.keys()))\n",
    "print(\"Agent_State:\")\n",
    "print(SARSDs[0][0][0])\n",
    "print(\"Agent_Action: \" + str(SARSDs[0][1]))\n",
    "print(\"Agent_Reward: \" + str(SARSDs[0][2]))\n",
    "print(\"Agent_Next_State:\")\n",
    "print(SARSDs[0][3][0])\n",
    "print(\"Done: \" + str(SARSDs[0][4]))\n",
    "\n",
    "## CORRECT - No apparent issues from this test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Test 8: Correct operation of signal groups\n",
    "signal_group = 5\n",
    "env.SCUs[0].signal_groups[signal_group].SetAttValue(\"SigState\", \"GREEN\")\n",
    "env.Vissim.Simulation.RunSingleStep()\n",
    "\n",
    "## CORRECT - No apparent issues from this test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "###### Test 9-1: Correct implementation of actions (SETUP)\n",
    "for idx, agent in Balance_int_MultiDQN_Agents.Agents.items():\n",
    "    agent.reset()\n",
    "\n",
    "start_state = env.get_state()\n",
    "print(\"Initial State: {Agent_ID: initual queues}\")\n",
    "print(start_state)\n",
    "actions = {}\n",
    "for idx, s in start_state.items():\n",
    "    actions[idx] = Balance_int_MultiDQN_Agents.Agents[idx].choose_action(s)\n",
    "print(\"Initial Choice of Actions: {Agent_ID: action}\")    \n",
    "print(actions)\n",
    "\n",
    "# That is not a clean way to do this\n",
    "def to_dictionary(dictionary,idx,value):\n",
    "    \"\"\"\n",
    "    Assign a value to an index in a dictionary\n",
    "    \"\"\"\n",
    "    dictionary[idx] = value\n",
    "    \n",
    "## CORRECT - No apparent issues from this test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###### Test 9-2: Correct implementation of actions (EXECUTION)\n",
    "##\n",
    "## ATTENTION: If an \"index out of range\" is requested, the system will break an will\\\n",
    "##            require a reset. This does not affect normal simulation.\n",
    "\n",
    "actions[0] = 4\n",
    "# This is step_to_next_action() function\n",
    "while not env.action_required:\n",
    "    \n",
    "    # This is the step() function\n",
    "    Sarsd = dict()\n",
    "    \n",
    "    # The default position is that no action is required, only a step of simulator\n",
    "    env.action_required = False\n",
    "    #print(\"false 1\")\n",
    "    \n",
    "    [scu.action_update(actions[0] , green_time = 5 ) for idx, scu in env.SCUs.items() if scu.action_required]\n",
    "    \n",
    "    [scu.update() for idx,scu in env.SCUs.items()]\n",
    "    \n",
    "    env.Vissim.Simulation.RunSingleStep()\n",
    "    \n",
    "    [to_dictionary(Sarsd,idx,scu.sars()+[env.done]) for idx,scu in env.SCUs.items() if scu.action_required ]\n",
    "    \n",
    "    if len(Sarsd) > 0 or env.done :\n",
    "        env.action_required = True\n",
    "        #print(\"TRUE\")\n",
    "    \n",
    "    print(Sarsd)\n",
    "        \n",
    "env.action_required = False\n",
    "#print(\"false 2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Test 10: Correct changing of phases based on actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Test 11: Correct calculation of rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balance RL DQN Partial Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current simulation: Balance_int3_all_actions_500_10800_DDQN_Queues\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of tensorflow.python.keras.layers.core failed: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\acabrejasegea\\AppData\\Local\\Continuum\\anaconda3\\envs\\vissim\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"C:\\Users\\acabrejasegea\\AppData\\Local\\Continuum\\anaconda3\\envs\\vissim\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 434, in superreload\n",
      "    module = reload(module)\n",
      "  File \"C:\\Users\\acabrejasegea\\AppData\\Local\\Continuum\\anaconda3\\envs\\vissim\\lib\\imp.py\", line 314, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"C:\\Users\\acabrejasegea\\AppData\\Local\\Continuum\\anaconda3\\envs\\vissim\\lib\\importlib\\__init__.py\", line 148, in reload\n",
      "    raise ImportError(msg.format(name), name=name)\n",
      "ImportError: module DQNAgents not in sys.modules\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "intersection = 3\n",
    "map_name  = 'Balance_int'+str(intersection)\n",
    "model_name = map_name\n",
    "vissim_working_directory = 'C:\\\\Users\\\\acabrejasegea\\\\OneDrive - The Alan Turing Institute\\\\Desktop\\\\ATI\\\\0_TMF\\\\MLforFlowOptimisation\\\\Vissim\\\\'\n",
    "#vissim_working_directory = \"E:\\\\OneDrive - University of Warwick\\\\Desktop\\\\ATI\\\\0_TMF\\\\MLforFlowOptimisation\\\\Vissim\"\n",
    "\n",
    "## Simulation Parameters\n",
    "Random_Seed = 10\n",
    "sim_length = 10801\n",
    "timesteps_per_second = 1\n",
    "agent_type = \"DDQN\"\n",
    "actions = 'all_actions'     # 'default_actions' or 'all_actions'\n",
    "\n",
    "## DQN Hyperaramenters\n",
    "episodes = 1000\n",
    "copy_weights_frequency = 10\n",
    "\n",
    "PER_activated = True\n",
    "memory_size = 10000\n",
    "batch_size = 256\n",
    "batches_per_episode = 10\n",
    "\n",
    "alpha = 0.00005\n",
    "gamma = 0.95\n",
    "\n",
    "# Load and partition balance dictionary\n",
    "Balance_dictionary = balance_dictionary(agent_type)\n",
    "if intersection == \"1_2_4\":\n",
    "    intersection = 1\n",
    "elif intersection == \"2_4\":\n",
    "    intersection = 2\n",
    "elif intersection == \"11_12\":\n",
    "    intersection = 11\n",
    "partial_dictionary = {\"junctions\": { (intersection-1) : Balance_dictionary[\"junctions\"][intersection-1]},\\\n",
    "                      \"demand\": Balance_dictionary[\"demand\"]}\n",
    "\n",
    "Session_ID = map_name + \"_\" + actions + \"_\" + str(episodes) + \"_\" + str(sim_length-1) + \"_\" + agent_type + \"_Queues4\"\n",
    "print(\"Current simulation: {}\".format(Session_ID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x324 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Exploration Schedule (\"linear\" or \"geometric\")\n",
    "exploration_schedule = \"linear\"\n",
    "epsilon_start = 1\n",
    "epsilon_end   = 0.01\n",
    "\n",
    "def choose_schedule(exploration_schedule, espilon_start, epsilon_end, episodes):\n",
    "    if exploration_schedule == \"linear\":\n",
    "        epsilon_decay = 1.2*(epsilon_end - epsilon_start)/(episodes-1)\n",
    "        epsilon_sequence = [1 + epsilon_decay * entry for entry in range(episodes+1)]\n",
    "        epsilon_sequence = [0.01 if entry < 0.01 else entry for entry in epsilon_sequence]\n",
    "    elif exploration_schedule == \"geometric\":\n",
    "        epsilon_decay = np.power(epsilon_end/epsilon_start, 1./(episodes-1)) # Geometric decay\n",
    "        epsilon_sequence = [epsilon_start * epsilon_decay ** entry for entry in range(episodes+1)]\n",
    "        epsilon_sequence = [0.01 if entry < 0.01 else entry for entry in epsilon_sequence]\n",
    "    elif exploration_schedule == \"entropy\":\n",
    "        pass\n",
    "    else:\n",
    "        print(\"ERROR: Unrecognized choice of exploration schedule.\")\n",
    "        \n",
    "    # Plotting exploration schedule\n",
    "    plt.figure(figsize=(8,4.5))\n",
    "    x_series = np.array(range(1,episodes+1))\n",
    "    y_series = epsilon_sequence[0:episodes]\n",
    "    plt.plot(x_series, y_series, '-b')\n",
    "    plt.xlabel('Episodes')\n",
    "    plt.ylabel('Ratio of random exploration')\n",
    "    plt.title('Exploration schedule')\n",
    "    plt.show()\n",
    "    return(epsilon_sequence)\n",
    "\n",
    "epsilon_sequence = choose_schedule(exploration_schedule, epsilon_start, epsilon_end, episodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTERSECTION 2: SETTING UP AGENT\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 14)]              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 48)                720       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 48)                2352      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 48)                2352      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 8)                 392       \n",
      "=================================================================\n",
      "Total params: 5,816\n",
      "Trainable params: 5,816\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Deployed instance of Double Deep Q Learning Agent(s) at Intersection 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Balance_int_MultiDQN_Agents = MasterDQN_Agent(model_name, vissim_working_directory, sim_length, partial_dictionary, actions,\\\n",
    "                gamma, alpha, agent_type, memory_size, PER_activated, batch_size, batches_per_episode, copy_weights_frequency, epsilon_sequence,\\\n",
    "                Random_Seed, timesteps_per_second, Session_ID, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experience file not found. Generating now...\n",
      "Working Directory set to: C:\\Users\\acabrejasegea\\OneDrive - The Alan Turing Institute\\Desktop\\ATI\\0_TMF\\MLforFlowOptimisation\\Vissim\\\n",
      "Generating Cache...\n",
      "Cache generated.\n",
      "\n",
      "****************************\n",
      "*   COM Server dispatched  *\n",
      "****************************\n",
      "\n",
      "Attempting to load Model File: Balance_int3.inpx ...\n",
      "Model File load process successful.\n",
      "Simulation length set to 10801 seconds.\n",
      "Results from Previous Simulations: Deleted. Fresh Start Available.\n",
      "Fetched and containerized Network Object \n",
      "\n",
      "*******************************************************\n",
      "*                                                     *\n",
      "*                COM SETUP COMPLETE                   *\n",
      "*                                                     *\n",
      "*******************************************************\n",
      "\n",
      "Random seed set in simulator. Random Seed = 10\n",
      "Deploying Network Parser...\n",
      "Successful Network Crawl: Identified SignalControllers, Links, Lanes and Vehicle Inputs.\n",
      "\n",
      "Setting Simulation mode to: training\n",
      "Starting Deployments of Signal Control Units...\n",
      "SCUs successfully deployed. Elapsed time 0.13 seconds.\n",
      "\n",
      "After 0 actions taken by the Agents,  Agent 0 memory is 0.0 percent full\n",
      "After 1000 actions taken by the Agents,  Agent 0 memory is 10.0 percent full\n",
      "Random Seed Set to 11\n",
      "After 2000 actions taken by the Agents,  Agent 0 memory is 20.0 percent full\n",
      "Random Seed Set to 12\n",
      "After 3000 actions taken by the Agents,  Agent 0 memory is 30.0 percent full\n",
      "Random Seed Set to 13\n",
      "After 4000 actions taken by the Agents,  Agent 0 memory is 40.0 percent full\n",
      "Random Seed Set to 14\n",
      "After 5000 actions taken by the Agents,  Agent 0 memory is 50.0 percent full\n",
      "Random Seed Set to 15\n",
      "After 6000 actions taken by the Agents,  Agent 0 memory is 60.0 percent full\n",
      "Random Seed Set to 16\n",
      "After 7000 actions taken by the Agents,  Agent 0 memory is 70.0 percent full\n",
      "Random Seed Set to 17\n",
      "After 8000 actions taken by the Agents,  Agent 0 memory is 80.0 percent full\n",
      "Random Seed Set to 18\n",
      "After 9000 actions taken by the Agents,  Agent 0 memory is 90.0 percent full\n",
      "Memory filled. Saving as:C:\\Users\\acabrejasegea\\OneDrive - The Alan Turing Institute\\Desktop\\ATI\\0_TMF\\MLforFlowOptimisation\\Vissim\\Balance_int3\\Agents_Results\\DDQN\\Balance_int3_all_actions_500_10800_DDQN_Queues\\Agent0_PERPre_10000.p\n"
     ]
    }
   ],
   "source": [
    "Balance_int_MultiDQN_Agents.prepopulate_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working Directory set to: C:\\Users\\acabrejasegea\\OneDrive - The Alan Turing Institute\\Desktop\\ATI\\0_TMF\\MLforFlowOptimisation\\Vissim\\\n",
      "Generating Cache...\n",
      "Cache generated.\n",
      "\n",
      "****************************\n",
      "*   COM Server dispatched  *\n",
      "****************************\n",
      "\n",
      "Attempting to load Model File: Balance_int3.inpx ...\n",
      "Model File load process successful.\n",
      "Simulation length set to 10801 seconds.\n",
      "Results from Previous Simulations: Deleted. Fresh Start Available.\n",
      "Fetched and containerized Network Object \n",
      "\n",
      "*******************************************************\n",
      "*                                                     *\n",
      "*                COM SETUP COMPLETE                   *\n",
      "*                                                     *\n",
      "*******************************************************\n",
      "\n",
      "Random seed set in simulator. Random Seed = 303\n",
      "Deploying Network Parser...\n",
      "Successful Network Crawl: Identified SignalControllers, Links, Lanes and Vehicle Inputs.\n",
      "\n",
      "Setting Simulation mode to: training\n",
      "Starting Deployments of Signal Control Units...\n",
      "SCUs successfully deployed. Elapsed time 0.12 seconds.\n",
      "\n",
      "start\n",
      "Random Seed Set to 304\n",
      "Episode 294: Finished running.\n",
      "Agent 0, Average Reward: -604.5\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 136021.0938\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 130301.5312\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 136401.1250\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 137079.3125\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 136892.8281\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 142179.2188\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 134155.0781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 135609.7969\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 134951.9688\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 134046.9688\n",
      "Reducing exploration for all agents to 0.3001\n",
      "\n",
      "Episode 295: Starting computation.\n",
      "Random Seed Set to 305\n",
      "Episode 295: Finished running.\n",
      "Agent 0, Average Reward: -652.73\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 135970.2656\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 133835.0000\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 134973.5781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 138393.4375\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 131713.6719\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 131394.7344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 134888.5938\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 131584.9844\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 133732.6719\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 135478.8281\n",
      "Reducing exploration for all agents to 0.2977\n",
      "\n",
      "Episode 296: Starting computation.\n",
      "Random Seed Set to 306\n",
      "Episode 296: Finished running.\n",
      "Agent 0, Average Reward: -813.75\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 123195.2891\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 122926.9922\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 121564.3828\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 125315.3516\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 125451.1797\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 124797.2422\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 122523.8750\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 122128.5234\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 125787.6484\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 122850.5078\n",
      "Reducing exploration for all agents to 0.2953\n",
      "\n",
      "Episode 297: Starting computation.\n",
      "Random Seed Set to 307\n",
      "Episode 297: Finished running.\n",
      "Agent 0, Average Reward: -1321.4\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 144261.0000\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 150854.3750\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 153202.2500\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 149402.9375\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 149231.5625\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 146335.0156\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 140466.2812\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 149971.2969\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 149299.4688\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 143073.0156\n",
      "Reducing exploration for all agents to 0.2929\n",
      "\n",
      "Episode 298: Starting computation.\n",
      "Random Seed Set to 308\n",
      "Episode 298: Finished running.\n",
      "Agent 0, Average Reward: -956.55\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 130864.2500\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 122758.0703\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 130696.6719\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 130625.0234\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 130603.0391\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 130667.2812\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 128934.9766\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 125190.6953\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 128989.5703\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 131700.9375\n",
      "Reducing exploration for all agents to 0.2905\n",
      "\n",
      "Episode 299: Starting computation.\n",
      "Random Seed Set to 309\n",
      "Episode 299: Finished running.\n",
      "Agent 0, Average Reward: -632.19\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 115124.0078\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 119527.0078\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 120196.3906\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 123042.3047\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 123758.8047\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 121073.9922\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 120402.0547\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 117442.0000\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 115837.3438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 118233.4609\n",
      "Reducing exploration for all agents to 0.2882\n",
      "\n",
      "Episode 300: Starting computation.\n",
      "Random Seed Set to 310\n",
      "Episode 300: Finished running.\n",
      "Agent 0, Average Reward: -1183.91\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 137170.1250\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 143231.4375\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 140604.7031\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 145235.9688\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 141153.1875\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 138988.0625\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 139143.0000\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 144375.0625\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 141007.6875\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 142952.4688\n",
      "Weights succesfully copied to Target model for Agent 2.\n",
      "Saving architecture, weights and optimizer state for agent-2\n",
      "Dumping agent-2 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Dumping Loss Results into pickle file.\n",
      "Reducing exploration for all agents to 0.2858\n",
      "\n",
      "Episode 301: Starting computation.\n",
      "Random Seed Set to 311\n",
      "Episode 301: Finished running.\n",
      "Agent 0, Average Reward: -683.77\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 145799.2344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 145699.7812\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 135807.4844\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 145475.3281\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 149040.8125\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 140762.5000\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 145166.0781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 144142.0000\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 145877.6094\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 140777.2656\n",
      "Reducing exploration for all agents to 0.2834\n",
      "\n",
      "Episode 302: Starting computation.\n",
      "Random Seed Set to 312\n",
      "Episode 302: Finished running.\n",
      "Agent 0, Average Reward: -605.79\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 142062.3594\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 140040.5938\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 134146.0156\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 142918.0156\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 141592.3125\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 141504.1875\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 140197.9375\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 141365.6406\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 140924.0000\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 142438.0312\n",
      "Reducing exploration for all agents to 0.281\n",
      "\n",
      "Episode 303: Starting computation.\n",
      "Random Seed Set to 313\n",
      "Episode 303: Finished running.\n",
      "Agent 0, Average Reward: -1323.5\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 166553.1875\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 169130.4219\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 170253.0156\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 178401.5938\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 166715.5312\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 166372.0781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 165986.4062\n",
      "Train on 256 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/256 - 0s - loss: 167514.5156\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 168799.0781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 158418.4219\n",
      "Reducing exploration for all agents to 0.2786\n",
      "\n",
      "Episode 304: Starting computation.\n",
      "Random Seed Set to 314\n",
      "Episode 304: Finished running.\n",
      "Agent 0, Average Reward: -741.48\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 166523.7812\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 160606.0312\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 169399.6250\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 169996.0938\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 169595.4688\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 167362.7500\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 167107.3125\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 169752.5156\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 166129.6094\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 164931.1250\n",
      "Reducing exploration for all agents to 0.2762\n",
      "\n",
      "Episode 305: Starting computation.\n",
      "Random Seed Set to 315\n",
      "Episode 305: Finished running.\n",
      "Agent 0, Average Reward: -1145.78\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 151231.1562\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 151839.8281\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 159831.2031\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 160701.1406\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 160153.0469\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 156547.6875\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 157349.9844\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 154319.7969\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 156069.9844\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 158969.1406\n",
      "Reducing exploration for all agents to 0.2739\n",
      "\n",
      "Episode 306: Starting computation.\n",
      "Random Seed Set to 316\n",
      "Episode 306: Finished running.\n",
      "Agent 0, Average Reward: -965.14\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 155004.7969\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 152156.0156\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 150975.3594\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 150598.2656\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 156116.2344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 155400.2812\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 155542.1562\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 159039.1094\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 154467.9531\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 152078.7656\n",
      "Reducing exploration for all agents to 0.2715\n",
      "\n",
      "Episode 307: Starting computation.\n",
      "Random Seed Set to 317\n",
      "Episode 307: Finished running.\n",
      "Agent 0, Average Reward: -1003.62\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 163207.1406\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 167347.7969\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 167650.5938\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 167293.7031\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 170836.9844\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 162663.2969\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 164477.2031\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 164071.6250\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 165235.5156\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 166484.7344\n",
      "Reducing exploration for all agents to 0.2691\n",
      "\n",
      "Episode 308: Starting computation.\n",
      "Random Seed Set to 318\n",
      "Episode 308: Finished running.\n",
      "Agent 0, Average Reward: -1038.79\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 147210.0781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 155529.0781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 158901.5781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 151789.8906\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 147606.9688\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 155710.1406\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 156521.7656\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 154921.4844\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 150109.7969\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 157885.9062\n",
      "Reducing exploration for all agents to 0.2667\n",
      "\n",
      "Episode 309: Starting computation.\n",
      "Random Seed Set to 319\n",
      "Episode 309: Finished running.\n",
      "Agent 0, Average Reward: -1116.61\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 165250.7969\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 165492.5781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 172063.5312\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 166483.0938\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 165433.0312\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 169094.1875\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 164380.9531\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 167816.5000\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 163484.1562\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 163749.2812\n",
      "Reducing exploration for all agents to 0.2643\n",
      "\n",
      "Episode 310: Starting computation.\n",
      "Random Seed Set to 320\n",
      "Episode 310: Finished running.\n",
      "Agent 0, Average Reward: -614.42\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 165866.5469\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 162412.9531\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 162848.8906\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 170022.7969\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 161370.4531\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 164603.4844\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 173459.1719\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 167271.8594\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 164509.5156\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 162579.4531\n",
      "Weights succesfully copied to Target model for Agent 2.\n",
      "Reducing exploration for all agents to 0.262\n",
      "\n",
      "Episode 311: Starting computation.\n",
      "Random Seed Set to 321\n",
      "Episode 311: Finished running.\n",
      "Agent 0, Average Reward: -778.85\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 145184.8750\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 144427.6719\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 141718.4844\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 142410.0156\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 146742.9531\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 144958.7500\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 154126.8125\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 147187.1719\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 147619.7031\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 153165.1094\n",
      "Reducing exploration for all agents to 0.2596\n",
      "\n",
      "Episode 312: Starting computation.\n",
      "Random Seed Set to 322\n",
      "Episode 312: Finished running.\n",
      "Agent 0, Average Reward: -732.66\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 144739.9844\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 148444.3906\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 148487.0625\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 149416.5781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 149168.7656\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 152969.3594\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 149266.4219\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 149927.2969\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 146644.5469\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 150156.1719\n",
      "Reducing exploration for all agents to 0.2572\n",
      "\n",
      "Episode 313: Starting computation.\n",
      "Random Seed Set to 323\n",
      "Episode 313: Finished running.\n",
      "Agent 0, Average Reward: -938.69\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 136587.3906\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 139758.5781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 144436.4375\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 140510.2656\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 141125.4844\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 141633.7344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 137456.8906\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 141067.0781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 141431.7031\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 137890.8906\n",
      "Reducing exploration for all agents to 0.2548\n",
      "\n",
      "Episode 314: Starting computation.\n",
      "Random Seed Set to 324\n",
      "Episode 314: Finished running.\n",
      "Agent 0, Average Reward: -643.44\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 124798.9531\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 125586.4453\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 121189.3203\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 124212.8516\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 123081.0312\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 119778.9141\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 124364.6250\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 129443.3828\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 127586.0859\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 124978.4141\n",
      "Reducing exploration for all agents to 0.2524\n",
      "\n",
      "Episode 315: Starting computation.\n",
      "Random Seed Set to 325\n",
      "Episode 315: Finished running.\n",
      "Agent 0, Average Reward: -969.15\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 123087.2266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 123901.0625\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 125909.8828\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 125643.1328\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 118351.9609\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 122405.3984\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 128047.9297\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 122958.2734\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 121340.0078\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 123961.9688\n",
      "Reducing exploration for all agents to 0.2501\n",
      "\n",
      "Episode 316: Starting computation.\n",
      "Random Seed Set to 326\n",
      "Episode 316: Finished running.\n",
      "Agent 0, Average Reward: -881.48\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 117941.6953\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 116100.0078\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 116833.2188\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 116835.4297\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 118851.2734\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 123386.0078\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 120392.7031\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 118276.1953\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 116542.1250\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 118977.2891\n",
      "Reducing exploration for all agents to 0.2477\n",
      "\n",
      "Episode 317: Starting computation.\n",
      "Random Seed Set to 327\n",
      "Episode 317: Finished running.\n",
      "Agent 0, Average Reward: -959.72\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 115495.8984\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 113606.5078\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 113763.0078\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 113671.9297\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 113853.9141\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 110134.4141\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 116723.2734\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 115285.6562\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 113319.3281\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 118777.3047\n",
      "Reducing exploration for all agents to 0.2453\n",
      "\n",
      "Episode 318: Starting computation.\n",
      "Random Seed Set to 328\n",
      "Episode 318: Finished running.\n",
      "Agent 0, Average Reward: -702.23\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 120115.1484\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 117319.2734\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 111418.0938\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 112147.0391\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 117761.6953\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 113983.6250\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 115638.7031\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 113852.2734\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 118727.3125\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 118112.6484\n",
      "Reducing exploration for all agents to 0.2429\n",
      "\n",
      "Episode 319: Starting computation.\n",
      "Random Seed Set to 329\n",
      "Episode 319: Finished running.\n",
      "Agent 0, Average Reward: -1143.88\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 125055.4141\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 125621.6484\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 123655.8281\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 124079.5078\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 129530.7891\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 131006.5234\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 128703.2969\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 123811.7266\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 127274.1719\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 125349.7734\n",
      "Reducing exploration for all agents to 0.2405\n",
      "\n",
      "Episode 320: Starting computation.\n",
      "Random Seed Set to 330\n",
      "Episode 320: Finished running.\n",
      "Agent 0, Average Reward: -946.4\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 132631.2656\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 134366.6875\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 134162.0156\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 134075.8438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 135581.2500\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 128817.6797\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 141973.8906\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 134906.8594\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 136894.0938\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 134997.7344\n",
      "Weights succesfully copied to Target model for Agent 2.\n",
      "Saving architecture, weights and optimizer state for agent-2\n",
      "Dumping agent-2 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Dumping Loss Results into pickle file.\n",
      "Reducing exploration for all agents to 0.2382\n",
      "\n",
      "Episode 321: Starting computation.\n",
      "Random Seed Set to 331\n",
      "Episode 321: Finished running.\n",
      "Agent 0, Average Reward: -1021.0\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 141248.3594\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 142275.9844\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 144934.2656\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 146555.4531\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 145189.2031\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 142159.2500\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 150454.5625\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 146544.4688\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 146574.2031\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 146733.4844\n",
      "Reducing exploration for all agents to 0.2358\n",
      "\n",
      "Episode 322: Starting computation.\n",
      "Random Seed Set to 332\n",
      "Episode 322: Finished running.\n",
      "Agent 0, Average Reward: -1366.38\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 171645.7344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 176165.2656\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 175532.5156\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 175477.3594\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 172661.4062\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 171350.9531\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 165894.6875\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 171074.6094\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 176577.2656\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 171002.5156\n",
      "Reducing exploration for all agents to 0.2334\n",
      "\n",
      "Episode 323: Starting computation.\n",
      "Random Seed Set to 333\n",
      "Episode 323: Finished running.\n",
      "Agent 0, Average Reward: -1016.91\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 173363.2344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 169696.3906\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 168691.9844\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 178080.1094\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 168655.6719\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 169199.7969\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 171469.6719\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 168182.4062\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 175210.9844\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 172311.2969\n",
      "Reducing exploration for all agents to 0.231\n",
      "\n",
      "Episode 324: Starting computation.\n",
      "Random Seed Set to 334\n",
      "Episode 324: Finished running.\n",
      "Agent 0, Average Reward: -1561.01\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 201196.2969\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 203005.2344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 199876.2656\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 202584.6094\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 200150.2969\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 206628.3906\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 203312.7812\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 197997.6719\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 199643.2500\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 204592.6875\n",
      "Reducing exploration for all agents to 0.2286\n",
      "\n",
      "Episode 325: Starting computation.\n",
      "Random Seed Set to 335\n",
      "Episode 325: Finished running.\n",
      "Agent 0, Average Reward: -1074.88\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 209035.1250\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 205941.8125\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 207052.2656\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 210728.5156\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 203651.1094\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 205386.8281\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 208796.1406\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 211322.3906\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 205670.2031\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 212474.3594\n",
      "Reducing exploration for all agents to 0.2263\n",
      "\n",
      "Episode 326: Starting computation.\n",
      "Random Seed Set to 336\n",
      "Episode 326: Finished running.\n",
      "Agent 0, Average Reward: -1052.34\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 216458.1719\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 217484.8906\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 215372.3906\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 220959.7344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 216069.6719\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 218507.2344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 214337.2969\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 215761.2188\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 218998.3594\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 216651.5469\n",
      "Reducing exploration for all agents to 0.2239\n",
      "\n",
      "Episode 327: Starting computation.\n",
      "Random Seed Set to 337\n",
      "Episode 327: Finished running.\n",
      "Agent 0, Average Reward: -1382.92\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 228296.1719\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 227299.7500\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 226676.6719\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 225450.9219\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 226928.1406\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 230712.3594\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 232580.7344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 229177.3281\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 227736.0156\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 226418.0000\n",
      "Reducing exploration for all agents to 0.2215\n",
      "\n",
      "Episode 328: Starting computation.\n",
      "Random Seed Set to 338\n",
      "Episode 328: Finished running.\n",
      "Agent 0, Average Reward: -933.3\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 221895.7656\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 221003.6250\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 225075.6562\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 223187.7031\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 221637.6719\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 220854.0781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 216613.1406\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 222639.4062\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 222031.8594\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 222586.0781\n",
      "Reducing exploration for all agents to 0.2191\n",
      "\n",
      "Episode 329: Starting computation.\n",
      "Random Seed Set to 339\n",
      "Episode 329: Finished running.\n",
      "Agent 0, Average Reward: -1039.68\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 219003.1406\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 220066.7344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 228062.5156\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 227780.2188\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 225548.5781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 219524.1719\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 222998.0000\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 221607.0000\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 221132.4844\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 220361.0469\n",
      "Reducing exploration for all agents to 0.2167\n",
      "\n",
      "Episode 330: Starting computation.\n",
      "Random Seed Set to 340\n",
      "Episode 330: Finished running.\n",
      "Agent 0, Average Reward: -1324.03\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 223213.4531\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 218602.8438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 219712.2656\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 224111.2969\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 218931.7188\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 226962.2656\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 225927.4844\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 224987.1875\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 231536.2969\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 224411.0469\n",
      "Weights succesfully copied to Target model for Agent 2.\n",
      "Reducing exploration for all agents to 0.2143\n",
      "\n",
      "Episode 331: Starting computation.\n",
      "Random Seed Set to 341\n",
      "Episode 331: Finished running.\n",
      "Agent 0, Average Reward: -1077.1\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 231060.5781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 228055.3594\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 229437.7656\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 234006.0625\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 240814.3281\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 237846.4062\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 228362.0469\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 230078.2969\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 241378.0781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 229740.4062\n",
      "Reducing exploration for all agents to 0.212\n",
      "\n",
      "Episode 332: Starting computation.\n",
      "Random Seed Set to 342\n",
      "Episode 332: Finished running.\n",
      "Agent 0, Average Reward: -1149.81\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 214348.4531\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 213280.8594\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 217907.5312\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 211755.5156\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 211982.5781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 215131.0781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 205134.6719\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 210320.5938\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 214802.5625\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 214011.6094\n",
      "Reducing exploration for all agents to 0.2096\n",
      "\n",
      "Episode 333: Starting computation.\n",
      "Random Seed Set to 343\n",
      "Episode 333: Finished running.\n",
      "Agent 0, Average Reward: -1050.49\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 211776.9531\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 213444.7969\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 221251.3906\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 212970.3438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 214475.3594\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 210537.6250\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 209075.2031\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 215201.4844\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 216057.4844\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 211640.0469\n",
      "Reducing exploration for all agents to 0.2072\n",
      "\n",
      "Episode 334: Starting computation.\n",
      "Random Seed Set to 344\n",
      "Episode 334: Finished running.\n",
      "Agent 0, Average Reward: -1345.28\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 220218.6719\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 215649.5938\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 217969.9531\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 221994.7031\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 220335.1719\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 221764.2500\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 224621.6094\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 215671.2656\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 222982.2656\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 225581.0625\n",
      "Reducing exploration for all agents to 0.2048\n",
      "\n",
      "Episode 335: Starting computation.\n",
      "Random Seed Set to 345\n",
      "Episode 335: Finished running.\n",
      "Agent 0, Average Reward: -707.13\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 201195.7656\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 195764.4219\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 198594.4219\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 199555.0781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 192533.8750\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 195886.7344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 198163.4531\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 195340.8594\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 190713.1562\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 195289.5781\n",
      "Reducing exploration for all agents to 0.2024\n",
      "\n",
      "Episode 336: Starting computation.\n",
      "Random Seed Set to 346\n",
      "Episode 336: Finished running.\n",
      "Agent 0, Average Reward: -868.68\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 195715.5156\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 194086.5312\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 188691.8438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 188152.3438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 195821.0625\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 192565.5625\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 193178.6719\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 196536.5781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 198157.7344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 195389.5312\n",
      "Reducing exploration for all agents to 0.2001\n",
      "\n",
      "Episode 337: Starting computation.\n",
      "Random Seed Set to 347\n",
      "Episode 337: Finished running.\n",
      "Agent 0, Average Reward: -1288.2\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 201693.4844\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 195615.7344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 202292.7344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 197463.9219\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 203711.9531\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 205585.6562\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 200534.6406\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 198534.6719\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 198439.3281\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 206562.7969\n",
      "Reducing exploration for all agents to 0.1977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Episode 338: Starting computation.\n",
      "Random Seed Set to 348\n",
      "Episode 338: Finished running.\n",
      "Agent 0, Average Reward: -1343.54\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 198203.0156\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 198681.4688\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 201326.3281\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 199599.8438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 191464.5625\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 198520.2812\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 195396.1406\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 192015.0469\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 195199.6719\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 201562.9219\n",
      "Reducing exploration for all agents to 0.1953\n",
      "\n",
      "Episode 339: Starting computation.\n",
      "Random Seed Set to 349\n",
      "Episode 339: Finished running.\n",
      "Agent 0, Average Reward: -945.22\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 191101.6719\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 190694.2656\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 192056.5781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 191764.8594\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 191708.8594\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 190416.4219\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 198216.4219\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 186992.4062\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 189496.5781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 192318.4844\n",
      "Reducing exploration for all agents to 0.1929\n",
      "\n",
      "Episode 340: Starting computation.\n",
      "Random Seed Set to 350\n",
      "Episode 340: Finished running.\n",
      "Agent 0, Average Reward: -1303.12\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 182636.2031\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 194661.6094\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 195911.0469\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 199356.1094\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 193402.2188\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 190088.0781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 187165.3438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 191194.9844\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 199087.7656\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 189055.6719\n",
      "Weights succesfully copied to Target model for Agent 2.\n",
      "Saving architecture, weights and optimizer state for agent-2\n",
      "Dumping agent-2 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Dumping Loss Results into pickle file.\n",
      "Reducing exploration for all agents to 0.1905\n",
      "\n",
      "Episode 341: Starting computation.\n",
      "Random Seed Set to 351\n",
      "Episode 341: Finished running.\n",
      "Agent 0, Average Reward: -850.71\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 186265.7656\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 188864.8281\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 191520.6719\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 194982.8594\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 190319.5625\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 191060.7188\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 189024.1719\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 190455.6719\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 188776.1094\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 194859.4844\n",
      "Reducing exploration for all agents to 0.1882\n",
      "\n",
      "Episode 342: Starting computation.\n",
      "Random Seed Set to 352\n",
      "Episode 342: Finished running.\n",
      "Agent 0, Average Reward: -1221.41\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 188811.3281\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 196842.8594\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 193072.5312\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 192039.9844\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 180492.9375\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 189577.9219\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 193294.4531\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 185205.1094\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 193043.6719\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 189971.2969\n",
      "Reducing exploration for all agents to 0.1858\n",
      "\n",
      "Episode 343: Starting computation.\n",
      "Random Seed Set to 353\n",
      "Episode 343: Finished running.\n",
      "Agent 0, Average Reward: -1334.84\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 209274.8906\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 218596.4531\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 212185.3281\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 217756.1875\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 209575.5781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 217242.8594\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 221715.7656\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 222340.4219\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 222366.9844\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 212438.6719\n",
      "Reducing exploration for all agents to 0.1834\n",
      "\n",
      "Episode 344: Starting computation.\n",
      "Random Seed Set to 354\n",
      "Episode 344: Finished running.\n",
      "Agent 0, Average Reward: -1090.3\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 222633.8125\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 215282.1406\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 219431.1250\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 215575.4219\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 224109.1719\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 226049.1562\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 212220.2031\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 221406.6719\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 214264.0469\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 217217.7031\n",
      "Reducing exploration for all agents to 0.181\n",
      "\n",
      "Episode 345: Starting computation.\n",
      "Random Seed Set to 355\n",
      "Episode 345: Finished running.\n",
      "Agent 0, Average Reward: -1016.7\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 202347.1719\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 205181.2656\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 209274.2656\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 203720.9219\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 206276.7969\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 211599.8594\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 205727.8906\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 201116.4062\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 202755.0625\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 204797.2656\n",
      "Reducing exploration for all agents to 0.1786\n",
      "\n",
      "Episode 346: Starting computation.\n",
      "Random Seed Set to 356\n",
      "Episode 346: Finished running.\n",
      "Agent 0, Average Reward: -1381.04\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 209626.0781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 216794.7969\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 213939.2344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 210481.8125\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 215920.5156\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 211133.2344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 209805.9219\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 209770.0781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 214382.9219\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 218669.5938\n",
      "Reducing exploration for all agents to 0.1763\n",
      "\n",
      "Episode 347: Starting computation.\n",
      "Random Seed Set to 357\n",
      "Episode 347: Finished running.\n",
      "Agent 0, Average Reward: -1024.62\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 213770.3594\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 214649.6406\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 214852.4688\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 205013.2344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 216889.0312\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 215515.5469\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 204005.5000\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 213293.1250\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 214500.5156\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 214372.8281\n",
      "Reducing exploration for all agents to 0.1739\n",
      "\n",
      "Episode 348: Starting computation.\n",
      "Random Seed Set to 358\n",
      "Episode 348: Finished running.\n",
      "Agent 0, Average Reward: -1182.28\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 204785.4375\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 207429.2656\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 208031.1719\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 209247.7031\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 206896.7969\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 207333.4844\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 209872.7031\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 208541.9531\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 206994.7656\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 204156.6875\n",
      "Reducing exploration for all agents to 0.1715\n",
      "\n",
      "Episode 349: Starting computation.\n",
      "Random Seed Set to 359\n",
      "Episode 349: Finished running.\n",
      "Agent 0, Average Reward: -1172.55\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 219736.3906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 218358.2969\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 215253.0312\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 208979.6719\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 214272.4844\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 218548.1094\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 210312.0781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 211917.0156\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 208349.9844\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 210285.5312\n",
      "Reducing exploration for all agents to 0.1691\n",
      "\n",
      "Episode 350: Starting computation.\n",
      "Random Seed Set to 360\n",
      "Episode 350: Finished running.\n",
      "Agent 0, Average Reward: -1116.66\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 199835.9531\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 198351.5625\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 201070.9531\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 196516.1406\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 198619.7656\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 201082.4219\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 202849.9219\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 208407.8438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 200096.9531\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 197989.0000\n",
      "Weights succesfully copied to Target model for Agent 2.\n",
      "Reducing exploration for all agents to 0.1667\n",
      "\n",
      "Episode 351: Starting computation.\n",
      "Random Seed Set to 361\n",
      "Episode 351: Finished running.\n",
      "Agent 0, Average Reward: -1182.89\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 214856.3281\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 221088.5469\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 210256.2812\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 210186.3750\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 204270.7344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 216134.9688\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 209558.9219\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 208939.4844\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 216683.8594\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 211971.7344\n",
      "Reducing exploration for all agents to 0.1644\n",
      "\n",
      "Episode 352: Starting computation.\n",
      "Random Seed Set to 362\n",
      "Episode 352: Finished running.\n",
      "Agent 0, Average Reward: -1136.82\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 200049.9219\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 210187.9531\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 202643.4219\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 203346.1094\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 201706.6406\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 202159.4844\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 212969.0938\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 206310.1719\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 202166.2969\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 200059.2188\n",
      "Reducing exploration for all agents to 0.162\n",
      "\n",
      "Episode 353: Starting computation.\n",
      "Random Seed Set to 363\n",
      "Episode 353: Finished running.\n",
      "Agent 0, Average Reward: -1322.9\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 210462.1094\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 210419.1719\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 215811.5000\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 216336.4531\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 212379.3281\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 219833.8906\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 212464.4531\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 209884.0156\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 209216.9375\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 212354.2031\n",
      "Reducing exploration for all agents to 0.1596\n",
      "\n",
      "Episode 354: Starting computation.\n",
      "Random Seed Set to 364\n",
      "Episode 354: Finished running.\n",
      "Agent 0, Average Reward: -1149.8\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 197780.8281\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 196931.4688\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 206178.3594\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 201713.7656\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 195696.7344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 202632.1719\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 205028.6094\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 201064.3594\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 195330.3906\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 196344.0469\n",
      "Reducing exploration for all agents to 0.1572\n",
      "\n",
      "Episode 355: Starting computation.\n",
      "Random Seed Set to 365\n",
      "Episode 355: Finished running.\n",
      "Agent 0, Average Reward: -1195.51\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 203685.2031\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 200369.8594\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 205072.2344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 200738.0781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 204884.6094\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 202756.8125\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 195903.5156\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 202069.4844\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 199423.2031\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 196357.2031\n",
      "Reducing exploration for all agents to 0.1548\n",
      "\n",
      "Episode 356: Starting computation.\n",
      "Random Seed Set to 366\n",
      "Episode 356: Finished running.\n",
      "Agent 0, Average Reward: -1220.21\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 199168.3125\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 200314.2969\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 200669.2969\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 205110.7344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 194976.9531\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 209526.4062\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 203083.1406\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 202057.4375\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 206127.1719\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 205708.1250\n",
      "Reducing exploration for all agents to 0.1524\n",
      "\n",
      "Episode 357: Starting computation.\n",
      "Random Seed Set to 367\n",
      "Episode 357: Finished running.\n",
      "Agent 0, Average Reward: -1023.08\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 195094.2188\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 193889.7031\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 192868.1094\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 190441.9375\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 193381.5156\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 187333.2344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 193248.8281\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 197224.5938\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 199331.2031\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 189578.5156\n",
      "Reducing exploration for all agents to 0.1501\n",
      "\n",
      "Episode 358: Starting computation.\n",
      "Random Seed Set to 368\n",
      "Episode 358: Finished running.\n",
      "Agent 0, Average Reward: -1061.31\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 187952.2344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 191833.3125\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 189126.8125\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 191338.3750\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 191341.2969\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 191710.8281\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 191627.5469\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 188693.0469\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 195989.5625\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 189805.5938\n",
      "Reducing exploration for all agents to 0.1477\n",
      "\n",
      "Episode 359: Starting computation.\n",
      "Random Seed Set to 369\n",
      "Episode 359: Finished running.\n",
      "Agent 0, Average Reward: -1101.53\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 192257.6406\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 195470.2188\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 187241.1562\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 186735.2656\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 187883.7969\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 191450.0781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 193681.4531\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 192019.0781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 190385.2188\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 189211.7344\n",
      "Reducing exploration for all agents to 0.1453\n",
      "\n",
      "Episode 360: Starting computation.\n",
      "Random Seed Set to 370\n",
      "Episode 360: Finished running.\n",
      "Agent 0, Average Reward: -1477.12\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 196160.2344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 197572.0781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 205159.3594\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 199749.0469\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 203956.9375\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 197712.8281\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 197545.2656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 197406.6250\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 202225.4219\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 204613.6719\n",
      "Weights succesfully copied to Target model for Agent 2.\n",
      "Saving architecture, weights and optimizer state for agent-2\n",
      "Dumping agent-2 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Dumping Loss Results into pickle file.\n",
      "Reducing exploration for all agents to 0.1429\n",
      "\n",
      "Episode 361: Starting computation.\n",
      "Random Seed Set to 371\n",
      "Episode 361: Finished running.\n",
      "Agent 0, Average Reward: -954.9\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 200884.0312\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 203758.7031\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 199414.6562\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 198984.1094\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 197970.8906\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 200956.0781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 201597.9219\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 196926.7344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 203438.0781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 198115.4688\n",
      "Reducing exploration for all agents to 0.1405\n",
      "\n",
      "Episode 362: Starting computation.\n",
      "Random Seed Set to 372\n",
      "Episode 362: Finished running.\n",
      "Agent 0, Average Reward: -1247.52\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 201447.5312\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 197962.5000\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 198970.3281\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 207027.2500\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 204361.5938\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 205720.9375\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 204128.6406\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 204476.1094\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 202735.1406\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 208907.1406\n",
      "Reducing exploration for all agents to 0.1382\n",
      "\n",
      "Episode 363: Starting computation.\n",
      "Random Seed Set to 373\n",
      "Episode 363: Finished running.\n",
      "Agent 0, Average Reward: -985.52\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 196064.1406\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 199320.9688\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 196941.1406\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 189199.0469\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 197710.6719\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 192539.2812\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 195240.3594\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 192875.7031\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 197122.9531\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 192471.9844\n",
      "Reducing exploration for all agents to 0.1358\n",
      "\n",
      "Episode 364: Starting computation.\n",
      "Random Seed Set to 374\n",
      "Episode 364: Finished running.\n",
      "Agent 0, Average Reward: -992.87\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 190408.8750\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 186988.6406\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 190699.3906\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 187844.1094\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 181088.6094\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 191122.0781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 188811.7656\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 192990.1094\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 195877.7344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 190149.8281\n",
      "Reducing exploration for all agents to 0.1334\n",
      "\n",
      "Episode 365: Starting computation.\n",
      "Random Seed Set to 375\n",
      "Episode 365: Finished running.\n",
      "Agent 0, Average Reward: -1137.18\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 189799.4062\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 191545.1406\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 193686.4844\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 190966.8125\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 197703.7031\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 186689.6875\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 195058.9219\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 192765.3750\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 189827.5938\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 190038.7344\n",
      "Reducing exploration for all agents to 0.131\n",
      "\n",
      "Episode 366: Starting computation.\n",
      "Random Seed Set to 376\n",
      "Episode 366: Finished running.\n",
      "Agent 0, Average Reward: -1176.25\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 189659.0312\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 191059.3281\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 190558.3594\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 191459.4844\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 196528.1094\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 186410.0156\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 190588.5781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 189313.1562\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 190291.3906\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 195947.5938\n",
      "Reducing exploration for all agents to 0.1286\n",
      "\n",
      "Episode 367: Starting computation.\n",
      "Random Seed Set to 377\n",
      "Episode 367: Finished running.\n",
      "Agent 0, Average Reward: -1073.06\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 181510.9219\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 189696.8750\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 187540.4688\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 185650.8125\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 185891.5469\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 185767.6562\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 183363.8438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 186485.3906\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 186147.5000\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 186127.9844\n",
      "Reducing exploration for all agents to 0.1263\n",
      "\n",
      "Episode 368: Starting computation.\n",
      "Random Seed Set to 378\n",
      "Episode 368: Finished running.\n",
      "Agent 0, Average Reward: -1337.87\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 189832.2031\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 185151.6406\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 186178.7344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 188828.8906\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 187071.4062\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 191445.5312\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 187896.5781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 189098.4219\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 187726.2969\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 183589.2656\n",
      "Reducing exploration for all agents to 0.1239\n",
      "\n",
      "Episode 369: Starting computation.\n",
      "Random Seed Set to 379\n",
      "Episode 369: Finished running.\n",
      "Agent 0, Average Reward: -907.87\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 184179.5156\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 178886.7188\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 181504.7656\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 181344.4219\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 183798.0781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 178201.0312\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 179725.7656\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 180382.4844\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 186270.9375\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 177260.7969\n",
      "Reducing exploration for all agents to 0.1215\n",
      "\n",
      "Episode 370: Starting computation.\n",
      "Random Seed Set to 380\n",
      "Episode 370: Finished running.\n",
      "Agent 0, Average Reward: -961.24\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 174395.0938\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 169617.7344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 171551.1406\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 169814.3438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 165030.8906\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 171914.3281\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 168019.3281\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 168476.8594\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 166138.5781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 172698.4844\n",
      "Weights succesfully copied to Target model for Agent 2.\n",
      "Reducing exploration for all agents to 0.1191\n",
      "\n",
      "Episode 371: Starting computation.\n",
      "Random Seed Set to 381\n",
      "Episode 371: Finished running.\n",
      "Agent 0, Average Reward: -1065.44\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 182720.6875\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 182539.3750\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 182733.4844\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 182569.5156\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 179416.2344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 183464.7344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 178472.5938\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 175850.7344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 189078.2344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 185152.6094\n",
      "Reducing exploration for all agents to 0.1167\n",
      "\n",
      "Episode 372: Starting computation.\n",
      "Random Seed Set to 382\n",
      "Episode 372: Finished running.\n",
      "Agent 0, Average Reward: -985.2\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 185162.8906\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 180299.5781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 180285.5469\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 182738.0156\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 187332.1406\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 183112.1719\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 179852.3906\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 183941.9531\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 175809.5938\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 179081.2344\n",
      "Reducing exploration for all agents to 0.1144\n",
      "\n",
      "Episode 373: Starting computation.\n",
      "Random Seed Set to 383\n",
      "Episode 373: Finished running.\n",
      "Agent 0, Average Reward: -919.1\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 173097.8750\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 172189.4219\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 174124.6406\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 186258.4219\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 172540.3594\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 170663.7344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 176295.6094\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 176092.6562\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 172934.9844\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 179731.1250\n",
      "Reducing exploration for all agents to 0.112\n",
      "\n",
      "Episode 374: Starting computation.\n",
      "Random Seed Set to 384\n",
      "Episode 374: Finished running.\n",
      "Agent 0, Average Reward: -852.51\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 165378.7031\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 155547.1719\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 160617.0938\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 165125.6406\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 163752.9688\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 158311.1094\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 152464.4844\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 162050.2656\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 158073.4219\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 165247.6875\n",
      "Reducing exploration for all agents to 0.1096\n",
      "\n",
      "Episode 375: Starting computation.\n",
      "Random Seed Set to 385\n",
      "Episode 375: Finished running.\n",
      "Agent 0, Average Reward: -1240.87\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 158553.3438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 153737.9844\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 157139.7031\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 162423.5469\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 157061.0312\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 153403.4531\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 156138.9062\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 150217.3906\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 150999.3594\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 160648.1406\n",
      "Reducing exploration for all agents to 0.1072\n",
      "\n",
      "Episode 376: Starting computation.\n",
      "Random Seed Set to 386\n",
      "Episode 376: Finished running.\n",
      "Agent 0, Average Reward: -1103.52\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 162139.5312\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 160471.2344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 159354.5156\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 156838.0156\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 160190.4219\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 158399.5781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 166091.5156\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 153960.0000\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 152451.1094\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 156325.4844\n",
      "Reducing exploration for all agents to 0.1048\n",
      "\n",
      "Episode 377: Starting computation.\n",
      "Random Seed Set to 387\n",
      "Episode 377: Finished running.\n",
      "Agent 0, Average Reward: -764.81\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 151294.6094\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 156226.4062\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 155084.7344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 151804.3438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 153319.0469\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 152574.0312\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 152357.3594\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 153654.5938\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 150973.1406\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 154141.4375\n",
      "Reducing exploration for all agents to 0.1025\n",
      "\n",
      "Episode 378: Starting computation.\n",
      "Random Seed Set to 388\n",
      "Episode 378: Finished running.\n",
      "Agent 0, Average Reward: -1172.85\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 152214.6719\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 159994.1250\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 155425.1406\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 154897.6406\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 156485.8594\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 158353.3281\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 156155.8281\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 158056.8281\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 154700.8750\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 159013.0469\n",
      "Reducing exploration for all agents to 0.1001\n",
      "\n",
      "Episode 379: Starting computation.\n",
      "Random Seed Set to 389\n",
      "Episode 379: Finished running.\n",
      "Agent 0, Average Reward: -941.43\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 153612.2344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 146487.9219\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 145214.6719\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 151699.3594\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 146841.6406\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 150208.4531\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 147225.3906\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 144120.1406\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 147306.5781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 146105.3281\n",
      "Reducing exploration for all agents to 0.0977\n",
      "\n",
      "Episode 380: Starting computation.\n",
      "Random Seed Set to 390\n",
      "Episode 380: Finished running.\n",
      "Agent 0, Average Reward: -1076.63\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 147931.7344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 156096.7656\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 151424.9219\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 152071.3125\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 152527.1250\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 152864.5156\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 139792.5156\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 150034.8906\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 154209.1406\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 154493.0469\n",
      "Weights succesfully copied to Target model for Agent 2.\n",
      "Saving architecture, weights and optimizer state for agent-2\n",
      "Dumping agent-2 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Dumping Loss Results into pickle file.\n",
      "Reducing exploration for all agents to 0.0953\n",
      "\n",
      "Episode 381: Starting computation.\n",
      "Random Seed Set to 391\n",
      "Episode 381: Finished running.\n",
      "Agent 0, Average Reward: -1566.35\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 193021.5312\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 179459.8750\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 192638.4531\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 191046.6719\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 185780.7656\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 184379.7656\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 188388.5625\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 183326.3438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 192069.8281\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 188022.4688\n",
      "Reducing exploration for all agents to 0.0929\n",
      "\n",
      "Episode 382: Starting computation.\n",
      "Random Seed Set to 392\n",
      "Episode 382: Finished running.\n",
      "Agent 0, Average Reward: -858.91\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 179410.6875\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 183440.5781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 182604.0781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 188836.0781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 181340.4531\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 188102.2656\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 180493.9531\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 171988.5781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 178876.5000\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 180124.2031\n",
      "Reducing exploration for all agents to 0.0905\n",
      "\n",
      "Episode 383: Starting computation.\n",
      "Random Seed Set to 393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 383: Finished running.\n",
      "Agent 0, Average Reward: -1390.44\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 187153.4844\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 189796.0156\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 186020.6250\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 180365.0469\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 179462.2031\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 191060.8594\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 184093.3281\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 182963.8125\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 191913.8125\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 184466.4844\n",
      "Reducing exploration for all agents to 0.0882\n",
      "\n",
      "Episode 384: Starting computation.\n",
      "Random Seed Set to 394\n",
      "Episode 384: Finished running.\n",
      "Agent 0, Average Reward: -1201.93\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 207742.4688\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 202534.5469\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 203985.5000\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 202635.5938\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 202748.2188\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 202104.5469\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 203386.9062\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 204141.8594\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 204852.6094\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 204015.7969\n",
      "Reducing exploration for all agents to 0.0858\n",
      "\n",
      "Episode 385: Starting computation.\n",
      "Random Seed Set to 395\n",
      "Episode 385: Finished running.\n",
      "Agent 0, Average Reward: -1242.63\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 204431.3281\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 202062.0781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 202192.8594\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 208730.8594\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 204130.5781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 199889.9531\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 203568.4219\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 201102.7969\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 198518.6406\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 204305.9375\n",
      "Reducing exploration for all agents to 0.0834\n",
      "\n",
      "Episode 386: Starting computation.\n",
      "Random Seed Set to 396\n",
      "Episode 386: Finished running.\n",
      "Agent 0, Average Reward: -1716.87\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 247551.3438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 246765.3750\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 249872.8594\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 244374.6875\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 246492.1250\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 249294.8906\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 246764.6406\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 243380.2031\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 244837.0781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 244715.7969\n",
      "Reducing exploration for all agents to 0.081\n",
      "\n",
      "Episode 387: Starting computation.\n",
      "Random Seed Set to 397\n",
      "Episode 387: Finished running.\n",
      "Agent 0, Average Reward: -1138.51\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 243879.1094\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 249843.1094\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 249486.0156\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 251920.9531\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 251028.6250\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 246854.1719\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 248345.3281\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 246855.7656\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 249830.1719\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 250952.9375\n",
      "Reducing exploration for all agents to 0.0786\n",
      "\n",
      "Episode 388: Starting computation.\n",
      "Random Seed Set to 398\n",
      "Episode 388: Finished running.\n",
      "Agent 0, Average Reward: -991.94\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 236737.5625\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 234025.4688\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 239328.5938\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 234940.0938\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 219087.0781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 230634.1719\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 232078.2188\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 234074.0469\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 224345.1094\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 229918.4375\n",
      "Reducing exploration for all agents to 0.0763\n",
      "\n",
      "Episode 389: Starting computation.\n",
      "Random Seed Set to 399\n",
      "Episode 389: Finished running.\n",
      "Agent 0, Average Reward: -1139.2\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 227976.7656\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 234939.8906\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 235906.1719\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 232548.7969\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 237752.2656\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 240748.7344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 237009.4844\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 239316.3438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 235818.0000\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 229488.9688\n",
      "Reducing exploration for all agents to 0.0739\n",
      "\n",
      "Episode 390: Starting computation.\n",
      "Random Seed Set to 400\n",
      "Episode 390: Finished running.\n",
      "Agent 0, Average Reward: -1125.39\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 221069.7500\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 221790.2344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 229176.4219\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 228099.3594\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 230979.4844\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 226309.1719\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 225161.4219\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 225896.5781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 226605.5625\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 222008.5781\n",
      "Weights succesfully copied to Target model for Agent 2.\n",
      "Reducing exploration for all agents to 0.0715\n",
      "\n",
      "Episode 391: Starting computation.\n",
      "Random Seed Set to 401\n",
      "Episode 391: Finished running.\n",
      "Agent 0, Average Reward: -688.94\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 210037.4688\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 214049.3281\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 213029.5156\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 204099.1562\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 210137.4531\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 207743.9688\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 209071.9844\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 207850.9062\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 209412.8438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 208107.3594\n",
      "Reducing exploration for all agents to 0.0691\n",
      "\n",
      "Episode 392: Starting computation.\n",
      "Random Seed Set to 402\n",
      "Episode 392: Finished running.\n",
      "Agent 0, Average Reward: -820.14\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 195692.9219\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 189587.1719\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 197965.7969\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 196483.5156\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 198163.8906\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 198117.8594\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 196186.6406\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 194857.5469\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 190151.5469\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 189614.7031\n",
      "Reducing exploration for all agents to 0.0667\n",
      "\n",
      "Episode 393: Starting computation.\n",
      "Random Seed Set to 403\n",
      "Episode 393: Finished running.\n",
      "Agent 0, Average Reward: -1099.57\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 169033.7344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 165876.5156\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 170367.1094\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 168911.6719\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 167290.4531\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 168099.0469\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 166365.8281\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 169628.4844\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 166629.4375\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 170032.5781\n",
      "Reducing exploration for all agents to 0.0644\n",
      "\n",
      "Episode 394: Starting computation.\n",
      "Random Seed Set to 404\n",
      "Episode 394: Finished running.\n",
      "Agent 0, Average Reward: -800.67\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 143998.3125\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 141344.5625\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 139919.7031\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 142507.2656\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 141369.9844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 143783.9219\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 143938.7656\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 142290.8281\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 142626.2500\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 141328.5781\n",
      "Reducing exploration for all agents to 0.062\n",
      "\n",
      "Episode 395: Starting computation.\n",
      "Random Seed Set to 405\n",
      "Episode 395: Finished running.\n",
      "Agent 0, Average Reward: -978.4\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 145190.4062\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 143339.1719\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 148658.5156\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 142601.4375\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 137731.9531\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 135510.1094\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 145542.9531\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 148569.5625\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 141279.1406\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 146927.4531\n",
      "Reducing exploration for all agents to 0.0596\n",
      "\n",
      "Episode 396: Starting computation.\n",
      "Random Seed Set to 406\n",
      "Episode 396: Finished running.\n",
      "Agent 0, Average Reward: -1332.95\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 145220.1875\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 138886.4844\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 140585.3906\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 136488.8281\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 143378.6094\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 140213.9219\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 148064.4531\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 143943.0938\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 142462.7969\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 142054.3750\n",
      "Reducing exploration for all agents to 0.0572\n",
      "\n",
      "Episode 397: Starting computation.\n",
      "Random Seed Set to 407\n",
      "Episode 397: Finished running.\n",
      "Agent 0, Average Reward: -1723.33\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 173136.0469\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 182575.7344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 178361.1094\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 183160.2344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 183993.8750\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 175832.9375\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 177909.3594\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 179111.3281\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 178398.2344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 179066.6719\n",
      "Reducing exploration for all agents to 0.0548\n",
      "\n",
      "Episode 398: Starting computation.\n",
      "Random Seed Set to 408\n",
      "Episode 398: Finished running.\n",
      "Agent 0, Average Reward: -1085.97\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 184774.6875\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 187902.5469\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 178877.5156\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 185195.7969\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 183173.9531\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 187807.7344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 183630.5781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 178582.6875\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 185071.1406\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 185663.5156\n",
      "Reducing exploration for all agents to 0.0525\n",
      "\n",
      "Episode 399: Starting computation.\n",
      "Random Seed Set to 409\n",
      "Episode 399: Finished running.\n",
      "Agent 0, Average Reward: -1240.84\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 201121.7344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 194005.7656\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 197123.5781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 193649.4219\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 194792.6562\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 200503.2344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 194848.6094\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 201724.7656\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 202512.2344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 192285.0781\n",
      "Reducing exploration for all agents to 0.0501\n",
      "\n",
      "Episode 400: Starting computation.\n",
      "Random Seed Set to 410\n",
      "Episode 400: Finished running.\n",
      "Agent 0, Average Reward: -951.7\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 185397.9531\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 193463.1094\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 193366.6719\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 188032.5000\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 189956.2031\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 192786.8750\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 199118.7969\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 190087.3125\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 192162.3594\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 192146.2969\n",
      "Weights succesfully copied to Target model for Agent 2.\n",
      "Saving architecture, weights and optimizer state for agent-2\n",
      "Dumping agent-2 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Dumping Loss Results into pickle file.\n",
      "Reducing exploration for all agents to 0.0477\n",
      "\n",
      "Episode 401: Starting computation.\n",
      "Random Seed Set to 411\n",
      "Episode 401: Finished running.\n",
      "Agent 0, Average Reward: -1244.49\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 216998.5625\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 226032.4688\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 222223.4531\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 227453.0469\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 221204.3594\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 219558.2344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 221075.3906\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 223761.6719\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 231003.9531\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 221830.7344\n",
      "Reducing exploration for all agents to 0.0453\n",
      "\n",
      "Episode 402: Starting computation.\n",
      "Random Seed Set to 412\n",
      "Episode 402: Finished running.\n",
      "Agent 0, Average Reward: -762.54\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 218571.9531\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 208544.7656\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 210015.3594\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 217590.9531\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 215198.2344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 207136.5781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 215545.8125\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 217294.9531\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 207226.2188\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 209907.1406\n",
      "Reducing exploration for all agents to 0.0429\n",
      "\n",
      "Episode 403: Starting computation.\n",
      "Random Seed Set to 413\n",
      "Episode 403: Finished running.\n",
      "Agent 0, Average Reward: -841.67\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 191657.5469\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 203170.2344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 200689.9688\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 199579.0469\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 195621.2031\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 199284.7500\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 199254.8906\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 196298.9844\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 200235.9844\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 198637.6406\n",
      "Reducing exploration for all agents to 0.0406\n",
      "\n",
      "Episode 404: Starting computation.\n",
      "Random Seed Set to 414\n",
      "Episode 404: Finished running.\n",
      "Agent 0, Average Reward: -751.25\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 154421.6094\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 155215.9844\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 155193.5156\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 154889.3281\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 154073.2344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 158078.7812\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 154266.9688\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 150009.4219\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 152847.6406\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 150762.5312\n",
      "Reducing exploration for all agents to 0.0382\n",
      "\n",
      "Episode 405: Starting computation.\n",
      "Random Seed Set to 415\n",
      "Episode 405: Finished running.\n",
      "Agent 0, Average Reward: -1137.53\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 158107.2031\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 155574.7500\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 151579.0938\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 148701.5312\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 153877.8438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 147617.9531\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 150466.9844\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 155348.2656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 152491.8906\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 153078.2344\n",
      "Reducing exploration for all agents to 0.0358\n",
      "\n",
      "Episode 406: Starting computation.\n",
      "Random Seed Set to 416\n",
      "Episode 406: Finished running.\n",
      "Agent 0, Average Reward: -1023.14\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 143196.5469\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 135796.9844\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 146361.1406\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 143663.3281\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 145741.9531\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 143176.1562\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 137730.0781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 143747.5781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 143645.9531\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 145061.3281\n",
      "Reducing exploration for all agents to 0.0334\n",
      "\n",
      "Episode 407: Starting computation.\n",
      "Random Seed Set to 417\n",
      "Episode 407: Finished running.\n",
      "Agent 0, Average Reward: -821.04\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 136572.7969\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 137768.0469\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 140670.5625\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 140032.0625\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 142653.7344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 139228.9531\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 141259.2031\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 138984.9531\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 138345.3906\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 140792.2344\n",
      "Reducing exploration for all agents to 0.031\n",
      "\n",
      "Episode 408: Starting computation.\n",
      "Random Seed Set to 418\n",
      "Episode 408: Finished running.\n",
      "Agent 0, Average Reward: -850.52\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 114360.9062\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 110004.7031\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 113431.7188\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 108591.9844\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 118051.0312\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 113870.3438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 109897.7812\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 109506.0781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 119190.9688\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 104736.7500\n",
      "Reducing exploration for all agents to 0.0286\n",
      "\n",
      "Episode 409: Starting computation.\n",
      "Random Seed Set to 419\n",
      "Episode 409: Finished running.\n",
      "Agent 0, Average Reward: -995.07\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 120042.4297\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 120355.7188\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 117477.8594\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 120767.2500\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 118925.7969\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 121043.9531\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 114846.3281\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 113291.3828\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 117756.9844\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 114508.3047\n",
      "Reducing exploration for all agents to 0.0263\n",
      "\n",
      "Episode 410: Starting computation.\n",
      "Random Seed Set to 420\n",
      "Episode 410: Finished running.\n",
      "Agent 0, Average Reward: -1012.12\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 118335.1094\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 123095.5625\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 122150.2500\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 123066.3750\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 123318.8438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 120822.5781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 122470.7188\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 125458.8828\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 117207.2031\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 121770.9844\n",
      "Weights succesfully copied to Target model for Agent 2.\n",
      "Reducing exploration for all agents to 0.0239\n",
      "\n",
      "Episode 411: Starting computation.\n",
      "Random Seed Set to 421\n",
      "Episode 411: Finished running.\n",
      "Agent 0, Average Reward: -1014.97\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 140224.5781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 141090.8281\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 136889.6406\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 139346.8281\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 138610.0781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 142136.7188\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 139853.0312\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 139627.5781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 138200.3594\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 133376.6406\n",
      "Reducing exploration for all agents to 0.0215\n",
      "\n",
      "Episode 412: Starting computation.\n",
      "Random Seed Set to 422\n",
      "Episode 412: Finished running.\n",
      "Agent 0, Average Reward: -1186.31\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 143696.0781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 146555.7969\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 144306.2500\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 140683.6094\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 139788.9219\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 138655.0469\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 144657.5938\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 142357.3750\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 138386.1562\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 144253.5781\n",
      "Reducing exploration for all agents to 0.0191\n",
      "\n",
      "Episode 413: Starting computation.\n",
      "Random Seed Set to 423\n",
      "Episode 413: Finished running.\n",
      "Agent 0, Average Reward: -1150.47\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 146458.5938\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 152843.3281\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 145702.5469\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 152404.3906\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 154415.9375\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 152973.0781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 149998.7969\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 147019.7969\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 144640.6406\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 149102.5625\n",
      "Reducing exploration for all agents to 0.0167\n",
      "\n",
      "Episode 414: Starting computation.\n",
      "Random Seed Set to 424\n",
      "Episode 414: Finished running.\n",
      "Agent 0, Average Reward: -1009.99\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 151905.1094\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 154949.4062\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 151746.4531\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 157430.2969\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 150753.5469\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 157421.0156\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 157422.3281\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 161103.9688\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 149529.3281\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 150494.0625\n",
      "Reducing exploration for all agents to 0.0144\n",
      "\n",
      "Episode 415: Starting computation.\n",
      "Random Seed Set to 425\n",
      "Episode 415: Finished running.\n",
      "Agent 0, Average Reward: -985.08\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 164273.0156\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 156414.0312\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 167998.4062\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 157605.0469\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 166730.0625\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 162640.5781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 167625.6094\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 159353.7344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 153096.0156\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 162018.5469\n",
      "Reducing exploration for all agents to 0.012\n",
      "\n",
      "Episode 416: Starting computation.\n",
      "Random Seed Set to 426\n",
      "Episode 416: Finished running.\n",
      "Agent 0, Average Reward: -1941.41\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 215778.4375\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 206491.1719\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 209645.7656\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 216709.6250\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 219192.4844\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 209819.3594\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 207897.7188\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 214298.6719\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 212697.1406\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 218325.3906\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 417: Starting computation.\n",
      "Random Seed Set to 427\n",
      "Episode 417: Finished running.\n",
      "Agent 0, Average Reward: -2201.84\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 292205.5000\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 294892.4062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 286143.8750\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 275951.4375\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 287510.4688\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 276308.6562\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 282415.1250\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 269865.6250\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 265171.5000\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 274458.2812\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 418: Starting computation.\n",
      "Random Seed Set to 428\n",
      "Episode 418: Finished running.\n",
      "Agent 0, Average Reward: -1820.28\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 314315.7812\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 326940.3125\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 323072.6250\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 323627.2500\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 321020.2812\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 315823.1250\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 312953.7500\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 314909.5625\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 320153.6562\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 312018.7500\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 419: Starting computation.\n",
      "Random Seed Set to 429\n",
      "Episode 419: Finished running.\n",
      "Agent 0, Average Reward: -1696.05\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 338457.3750\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 337710.8438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 331516.9062\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 326736.0625\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 327101.0625\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 331300.3438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 341638.7812\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 329459.5312\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 336686.5625\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 328278.2500\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 420: Starting computation.\n",
      "Random Seed Set to 430\n",
      "Episode 420: Finished running.\n",
      "Agent 0, Average Reward: -926.32\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 321919.5938\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 318996.3750\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 312174.9688\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 311253.5000\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 312501.8125\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 318524.8125\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 310918.2500\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 312273.6250\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 322410.9375\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 310213.9688\n",
      "Weights succesfully copied to Target model for Agent 2.\n",
      "Saving architecture, weights and optimizer state for agent-2\n",
      "Dumping agent-2 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Dumping Loss Results into pickle file.\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 421: Starting computation.\n",
      "Random Seed Set to 431\n",
      "Episode 421: Finished running.\n",
      "Agent 0, Average Reward: -1523.38\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 370602.2188\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 369505.0000\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 378156.0938\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 371168.7500\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 364829.8750\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 369663.0312\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 372516.8438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 364735.3750\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 361933.6875\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 372148.3125\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 422: Starting computation.\n",
      "Random Seed Set to 432\n",
      "Episode 422: Finished running.\n",
      "Agent 0, Average Reward: -811.99\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 359177.3125\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 355873.1875\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 363004.3438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 360436.3750\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 355671.4062\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 368640.1875\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 351273.5000\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 365981.8438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 356655.9375\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 352939.2500\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 423: Starting computation.\n",
      "Random Seed Set to 433\n",
      "Episode 423: Finished running.\n",
      "Agent 0, Average Reward: -876.65\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 307460.7812\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 297841.7188\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 308823.6562\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 307259.4062\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 303686.1875\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 298006.0625\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 301105.0000\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 310311.8125\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 303975.9062\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 294332.0000\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 424: Starting computation.\n",
      "Random Seed Set to 434\n",
      "Episode 424: Finished running.\n",
      "Agent 0, Average Reward: -1790.06\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 274939.5625\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 270572.7500\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 270785.5938\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 268525.1250\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 260674.9062\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 270562.7188\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 273774.7812\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 271674.0000\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 274923.5625\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 273977.9375\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 425: Starting computation.\n",
      "Random Seed Set to 435\n",
      "Episode 425: Finished running.\n",
      "Agent 0, Average Reward: -931.37\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 229037.2969\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 226123.5156\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 232885.8906\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 227873.7031\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 227671.3906\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 228022.2344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 223925.4844\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 219989.2500\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 228397.0312\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 221267.1719\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 426: Starting computation.\n",
      "Random Seed Set to 436\n",
      "Episode 426: Finished running.\n",
      "Agent 0, Average Reward: -1096.57\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 206703.7656\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 205861.2969\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 200903.3750\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 202816.7969\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 209439.8594\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 208952.7344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 203747.6719\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 208013.4219\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 203373.2344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 201542.5469\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 427: Starting computation.\n",
      "Random Seed Set to 437\n",
      "Episode 427: Finished running.\n",
      "Agent 0, Average Reward: -1236.3\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 214652.0469\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 219771.0781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 212229.0781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 212236.5781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 217268.0781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 214577.3438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 212572.4062\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 207856.9844\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 215392.0469\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 215680.9844\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 428: Starting computation.\n",
      "Random Seed Set to 438\n",
      "Episode 428: Finished running.\n",
      "Agent 0, Average Reward: -931.39\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 183761.1406\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 181698.1719\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 178300.4531\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 178107.0938\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 181942.7344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 172937.0469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 178539.7656\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 175398.2031\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 175575.5156\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 182270.9062\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 429: Starting computation.\n",
      "Random Seed Set to 439\n",
      "Episode 429: Finished running.\n",
      "Agent 0, Average Reward: -1241.19\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 189893.7344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 189497.3750\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 189053.8281\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 191107.3125\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 195164.1406\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 194427.8594\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 189513.2812\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 191409.6094\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 187026.5781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 191924.7031\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 430: Starting computation.\n",
      "Random Seed Set to 440\n",
      "Episode 430: Finished running.\n",
      "Agent 0, Average Reward: -837.52\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 182590.7969\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 186988.7031\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 183439.7969\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 182711.5781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 191578.8281\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 182266.5469\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 183749.2031\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 181235.4375\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 187163.2656\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 188122.2969\n",
      "Weights succesfully copied to Target model for Agent 2.\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 431: Starting computation.\n",
      "Random Seed Set to 441\n",
      "Episode 431: Finished running.\n",
      "Agent 0, Average Reward: -914.91\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 157293.2969\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 155956.7500\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 166418.4219\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 160532.7031\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 159514.7500\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 150355.4062\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 159174.8125\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 157531.9688\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 158306.5625\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 157978.5469\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 432: Starting computation.\n",
      "Random Seed Set to 442\n",
      "Episode 432: Finished running.\n",
      "Agent 0, Average Reward: -1009.11\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 152583.2656\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 154772.0156\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 151401.1562\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 153917.4219\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 147430.2656\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 151707.0469\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 154610.1406\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 149755.7812\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 151257.1406\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 152800.9219\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 433: Starting computation.\n",
      "Random Seed Set to 443\n",
      "Episode 433: Finished running.\n",
      "Agent 0, Average Reward: -2359.74\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 231251.6562\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 225994.2969\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 234832.0156\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 232045.5469\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 228796.3438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 229626.2031\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 231546.3281\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 233018.7812\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 232213.0000\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 229698.1875\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 434: Starting computation.\n",
      "Random Seed Set to 444\n",
      "Episode 434: Finished running.\n",
      "Agent 0, Average Reward: -2267.33\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 298788.1250\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 295064.0000\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 294446.7500\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 293374.4375\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 287483.9375\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 292637.1250\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 293614.3750\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 293901.4688\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 287886.2500\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 292648.9375\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 435: Starting computation.\n",
      "Random Seed Set to 445\n",
      "Episode 435: Finished running.\n",
      "Agent 0, Average Reward: -936.91\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 297285.0625\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 289064.7188\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 288798.0938\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 293591.0625\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 288891.4688\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 291590.7188\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 285991.5938\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 288966.7188\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 290875.4688\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 287150.0312\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 436: Starting computation.\n",
      "Random Seed Set to 446\n",
      "Episode 436: Finished running.\n",
      "Agent 0, Average Reward: -1038.14\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 277143.7188\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 277904.7188\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 285165.0625\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 281417.1250\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 283732.2188\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 281269.9688\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 277995.6875\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 277011.3438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 277741.2812\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 277184.0312\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 437: Starting computation.\n",
      "Random Seed Set to 447\n",
      "Episode 437: Finished running.\n",
      "Agent 0, Average Reward: -1039.58\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 290969.3750\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 284486.6250\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 287949.6562\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 287650.7812\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 289766.9688\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 281280.2812\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 283675.3438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 283944.2812\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 287807.9062\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 277980.4062\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 438: Starting computation.\n",
      "Random Seed Set to 448\n",
      "Episode 438: Finished running.\n",
      "Agent 0, Average Reward: -976.04\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 285549.4062\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 288545.3438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 287598.5312\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 295066.4688\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 282114.5938\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 283954.4375\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 281315.7188\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 288659.0312\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 287625.2500\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 286018.4062\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 439: Starting computation.\n",
      "Random Seed Set to 449\n",
      "Episode 439: Finished running.\n",
      "Agent 0, Average Reward: -1045.63\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 285076.1875\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 283648.7500\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 281754.8438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 279491.5312\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 281099.2188\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 288966.2188\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 285291.9375\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 279155.8438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 283499.3125\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 278508.7188\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 440: Starting computation.\n",
      "Random Seed Set to 450\n",
      "Episode 440: Finished running.\n",
      "Agent 0, Average Reward: -866.9\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 214546.1094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 208008.0156\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 213158.9062\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 212731.5781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 212848.1719\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 210734.6719\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 217115.5469\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 213979.5469\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 208279.2344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 208396.6875\n",
      "Weights succesfully copied to Target model for Agent 2.\n",
      "Saving architecture, weights and optimizer state for agent-2\n",
      "Dumping agent-2 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Dumping Loss Results into pickle file.\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 441: Starting computation.\n",
      "Random Seed Set to 451\n",
      "Episode 441: Finished running.\n",
      "Agent 0, Average Reward: -1218.63\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 177985.8125\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 164620.7656\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 171762.1406\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 166761.8281\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 166310.1094\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 167550.4062\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 165836.5156\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 167065.9531\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 166655.7031\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 166974.9844\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 442: Starting computation.\n",
      "Random Seed Set to 452\n",
      "Episode 442: Finished running.\n",
      "Agent 0, Average Reward: -1008.7\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 153284.1719\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 153127.4844\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 153288.9844\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 161941.4062\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 152754.2656\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 153294.3750\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 152848.4844\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 150996.6719\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 156890.4062\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 154654.8438\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 443: Starting computation.\n",
      "Random Seed Set to 453\n",
      "Episode 443: Finished running.\n",
      "Agent 0, Average Reward: -757.05\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 144299.1562\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 150538.7969\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 148196.4531\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 147427.7812\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 155598.8906\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 150720.1406\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 149996.1406\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 151561.1406\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 151695.1094\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 150743.7969\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 444: Starting computation.\n",
      "Random Seed Set to 454\n",
      "Episode 444: Finished running.\n",
      "Agent 0, Average Reward: -1186.64\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 150238.2656\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 157007.0469\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 153206.5000\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 157121.8906\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 152483.8594\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 156459.2656\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 156782.2031\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 152053.4531\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 155682.2031\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 149436.6562\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 445: Starting computation.\n",
      "Random Seed Set to 455\n",
      "Episode 445: Finished running.\n",
      "Agent 0, Average Reward: -1647.58\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 195157.3906\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 183220.8594\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 177437.2969\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 188019.3906\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 190757.7969\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 189806.4219\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 180918.8125\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 181009.4375\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 187600.1094\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 181864.3281\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 446: Starting computation.\n",
      "Random Seed Set to 456\n",
      "Episode 446: Finished running.\n",
      "Agent 0, Average Reward: -2057.28\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 245905.3594\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 253029.7969\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 243414.1562\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 249566.0625\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 247317.1562\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 248637.7969\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 245798.1094\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 244645.4062\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 249791.2500\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 241849.6719\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 447: Starting computation.\n",
      "Random Seed Set to 457\n",
      "Episode 447: Finished running.\n",
      "Agent 0, Average Reward: -1161.49\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 253255.6562\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 261084.5312\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 261410.2656\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 257748.6719\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 254393.6562\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 250381.5156\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 257492.8438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 249844.7344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 259938.6094\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 250542.2969\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 448: Starting computation.\n",
      "Random Seed Set to 458\n",
      "Episode 448: Finished running.\n",
      "Agent 0, Average Reward: -1328.93\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 252418.9531\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 254287.6875\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 251644.4688\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 254671.9219\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 243699.8594\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 241109.8750\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 248324.7969\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 249898.5469\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 247323.6562\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 249741.2656\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 449: Starting computation.\n",
      "Random Seed Set to 459\n",
      "Episode 449: Finished running.\n",
      "Agent 0, Average Reward: -1673.77\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 273259.9375\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 273474.8438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 272955.3438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 277873.4688\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 273522.0312\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 274114.6250\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 279942.1875\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 271674.7500\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 273805.3125\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 272584.2188\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 450: Starting computation.\n",
      "Random Seed Set to 460\n",
      "Episode 450: Finished running.\n",
      "Agent 0, Average Reward: -1641.42\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 305225.0000\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 299841.9062\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 306502.7188\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 300852.6562\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 295226.9688\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 298118.4062\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 303836.4688\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 302356.3125\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 301332.6562\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 302490.4688\n",
      "Weights succesfully copied to Target model for Agent 2.\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 451: Starting computation.\n",
      "Random Seed Set to 461\n",
      "Episode 451: Finished running.\n",
      "Agent 0, Average Reward: -1787.43\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 343346.8438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 355347.4688\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 334650.8438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 336985.0312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 351269.5938\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 344875.0312\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 336445.9062\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 341993.1250\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 345133.3438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 342529.5312\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 452: Starting computation.\n",
      "Random Seed Set to 462\n",
      "Episode 452: Finished running.\n",
      "Agent 0, Average Reward: -1999.23\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 359455.5000\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 357801.4062\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 366979.9375\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 353359.0000\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 356819.8750\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 358027.4062\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 358350.2812\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 351344.3750\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 352016.4688\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 358346.7812\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 453: Starting computation.\n",
      "Random Seed Set to 463\n",
      "Episode 453: Finished running.\n",
      "Agent 0, Average Reward: -1783.56\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 334200.7188\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 330181.9688\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 337219.0938\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 329658.5000\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 329050.2188\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 335215.4688\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 329851.7812\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 327362.6562\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 335867.4688\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 328404.2500\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 454: Starting computation.\n",
      "Random Seed Set to 464\n",
      "Episode 454: Finished running.\n",
      "Agent 0, Average Reward: -1897.67\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 367037.9062\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 359172.2812\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 364122.5938\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 361657.8125\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 362570.1250\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 358995.4062\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 362298.4688\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 362249.4375\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 356944.4062\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 358803.0938\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 455: Starting computation.\n",
      "Random Seed Set to 465\n",
      "Episode 455: Finished running.\n",
      "Agent 0, Average Reward: -1650.92\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 371818.1875\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 364166.0938\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 369371.2500\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 373696.5938\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 373613.0938\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 366157.0938\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 371000.5312\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 366990.3438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 363776.4688\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 363424.2812\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 456: Starting computation.\n",
      "Random Seed Set to 466\n",
      "Episode 456: Finished running.\n",
      "Agent 0, Average Reward: -2013.39\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 391414.4688\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 385113.5312\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 383406.7500\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 382970.3125\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 384654.2812\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 386452.8438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 390850.4688\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 386247.5312\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 380655.3125\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 388812.4062\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 457: Starting computation.\n",
      "Random Seed Set to 467\n",
      "Episode 457: Finished running.\n",
      "Agent 0, Average Reward: -1816.14\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 397583.4688\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 392993.0000\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 398067.6562\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 384215.7500\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 387254.9062\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 387610.3125\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 396565.0938\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 390496.0000\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 392476.5312\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 387532.7500\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 458: Starting computation.\n",
      "Random Seed Set to 468\n",
      "Episode 458: Finished running.\n",
      "Agent 0, Average Reward: -1200.22\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 361027.7812\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 362032.3438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 363074.4688\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 362653.4375\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 361160.5312\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 364672.4062\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 362884.0625\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 357467.4688\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 357203.1562\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 359783.7812\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 459: Starting computation.\n",
      "Random Seed Set to 469\n",
      "Episode 459: Finished running.\n",
      "Agent 0, Average Reward: -894.98\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 308750.6562\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 316876.0625\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 310051.2500\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 310710.0938\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 308954.3125\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 306954.5312\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 310162.9375\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 308322.4062\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 310593.5938\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 303753.6875\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 460: Starting computation.\n",
      "Random Seed Set to 470\n",
      "Episode 460: Finished running.\n",
      "Agent 0, Average Reward: -1321.35\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 285690.7188\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 279428.8125\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 287830.7188\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 282714.3438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 279339.3438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 282753.5312\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 281645.0312\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 281868.8438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 275603.6875\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 283086.0312\n",
      "Weights succesfully copied to Target model for Agent 2.\n",
      "Saving architecture, weights and optimizer state for agent-2\n",
      "Dumping agent-2 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Dumping Loss Results into pickle file.\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 461: Starting computation.\n",
      "Random Seed Set to 471\n",
      "Episode 461: Finished running.\n",
      "Agent 0, Average Reward: -1253.74\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 283474.9062\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 282737.0938\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 290228.2812\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 289606.1562\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 280718.3438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 288254.3125\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 287346.1875\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 283569.1875\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 279632.6562\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 280759.1562\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 462: Starting computation.\n",
      "Random Seed Set to 472\n",
      "Episode 462: Finished running.\n",
      "Agent 0, Average Reward: -1148.78\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 258393.7812\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 265096.9688\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 257551.3906\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 258610.3125\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 264470.7500\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 259454.9219\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 261972.1406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 257300.5312\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 261925.2344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 268441.2812\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 463: Starting computation.\n",
      "Random Seed Set to 473\n",
      "Episode 463: Finished running.\n",
      "Agent 0, Average Reward: -1163.65\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 214782.7656\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 219982.6094\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 217681.2969\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 217930.1094\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 224707.0938\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 218588.1562\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 216281.5781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 212666.0312\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 215893.2344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 213847.4531\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 464: Starting computation.\n",
      "Random Seed Set to 474\n",
      "Episode 464: Finished running.\n",
      "Agent 0, Average Reward: -1520.19\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 202875.1094\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 204976.8438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 208193.1562\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 202820.2188\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 193078.3438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 202606.8281\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 210660.3594\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 205793.2188\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 203610.2344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 201619.5781\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 465: Starting computation.\n",
      "Random Seed Set to 475\n",
      "Episode 465: Finished running.\n",
      "Agent 0, Average Reward: -994.07\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 201035.0938\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 193323.8594\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 191042.9531\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 194697.2031\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 197745.2031\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 191036.4531\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 196338.8750\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 192278.4219\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 192279.3281\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 191821.0625\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 466: Starting computation.\n",
      "Random Seed Set to 476\n",
      "Episode 466: Finished running.\n",
      "Agent 0, Average Reward: -1100.49\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 204200.1719\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 200040.2500\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 205874.5625\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 201965.6094\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 200944.0938\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 200187.7031\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 204946.4531\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 200923.4219\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 200236.2969\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 201657.6562\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 467: Starting computation.\n",
      "Random Seed Set to 477\n",
      "Episode 467: Finished running.\n",
      "Agent 0, Average Reward: -908.97\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 189886.9375\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 188790.4844\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 189985.2812\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 186775.8750\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 190176.8125\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 190511.5781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 190656.4375\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 186533.7969\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 190954.6094\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 193461.1094\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 468: Starting computation.\n",
      "Random Seed Set to 478\n",
      "Episode 468: Finished running.\n",
      "Agent 0, Average Reward: -769.06\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 166953.1250\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 167163.2188\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 168627.4375\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 163006.9844\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 168987.6250\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 171690.7344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 163939.2812\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 172900.6406\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 167585.1406\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 164184.1406\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 469: Starting computation.\n",
      "Random Seed Set to 479\n",
      "Episode 469: Finished running.\n",
      "Agent 0, Average Reward: -1078.01\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 171354.7344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 161468.3750\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 157312.7812\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 163307.4531\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 163967.9688\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 163038.3438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 161063.7188\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 167006.5469\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 168336.2344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 168909.2500\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 470: Starting computation.\n",
      "Random Seed Set to 480\n",
      "Episode 470: Finished running.\n",
      "Agent 0, Average Reward: -1194.52\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 162896.3906\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 160374.1719\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 170327.9844\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 154425.7344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 168098.2500\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 160917.9531\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 163790.0156\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 166608.6094\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 153370.2031\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 164207.2031\n",
      "Weights succesfully copied to Target model for Agent 2.\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 471: Starting computation.\n",
      "Random Seed Set to 481\n",
      "Episode 471: Finished running.\n",
      "Agent 0, Average Reward: -1390.24\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 169589.8594\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 179850.8438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 172804.1875\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 170982.7812\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 171272.1406\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 171328.1719\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 176399.1562\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 178283.3594\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 164811.2344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 171605.5312\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 472: Starting computation.\n",
      "Random Seed Set to 482\n",
      "Episode 472: Finished running.\n",
      "Agent 0, Average Reward: -921.76\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 169387.0156\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 155606.1719\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 163938.7656\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 164857.7344\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 165759.0469\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 162225.5469\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 164522.8125\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 164860.1094\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 153500.5625\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 167110.7344\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 473: Starting computation.\n",
      "Random Seed Set to 483\n",
      "Episode 473: Finished running.\n",
      "Agent 0, Average Reward: -2137.46\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 216608.4219\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 224716.7969\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 223297.3906\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 225654.4844\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 227137.2031\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 218449.4219\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 212402.7031\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 223365.9531\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 218324.4219\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 223219.9531\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 474: Starting computation.\n",
      "Random Seed Set to 484\n",
      "Episode 474: Finished running.\n",
      "Agent 0, Average Reward: -2164.24\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 282843.1875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 285468.4062\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 281093.4688\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 277704.6250\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 282540.0312\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 281967.4062\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 278765.0312\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 282337.9062\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 280188.6562\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 274850.5312\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 475: Starting computation.\n",
      "Random Seed Set to 485\n",
      "Episode 475: Finished running.\n",
      "Agent 0, Average Reward: -1103.31\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 290862.9062\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 281519.8750\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 293289.5938\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 288032.1250\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 296866.6250\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 291653.7188\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 291208.2188\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 293176.2812\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 282327.4375\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 286502.2188\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 476: Starting computation.\n",
      "Random Seed Set to 486\n",
      "Episode 476: Finished running.\n",
      "Agent 0, Average Reward: -1848.21\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 322384.4062\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 322810.5312\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 318717.4062\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 324482.7500\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 325223.2500\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 324107.2812\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 319625.6562\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 324435.9688\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 327529.9688\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 324113.9688\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 477: Starting computation.\n",
      "Random Seed Set to 487\n",
      "Episode 477: Finished running.\n",
      "Agent 0, Average Reward: -1827.39\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 349330.2812\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 346834.0312\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 351651.6562\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 353590.9688\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 351034.7188\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 344151.9062\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 349931.2812\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 338655.6562\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 352486.7812\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 346020.3750\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 478: Starting computation.\n",
      "Random Seed Set to 488\n",
      "Episode 478: Finished running.\n",
      "Agent 0, Average Reward: -2067.41\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 378082.7500\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 380775.5000\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 382217.2188\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 375597.0625\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 375010.5625\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 372350.4688\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 373225.9688\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 370020.9062\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 376973.4375\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 373176.3125\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 479: Starting computation.\n",
      "Random Seed Set to 489\n",
      "Episode 479: Finished running.\n",
      "Agent 0, Average Reward: -1808.48\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 403042.5312\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 409106.5938\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 408489.8438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 402825.0312\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 406995.8438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 410266.9688\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 408196.1875\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 407921.5312\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 400879.3125\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 397635.2500\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 480: Starting computation.\n",
      "Random Seed Set to 490\n",
      "Episode 480: Finished running.\n",
      "Agent 0, Average Reward: -1639.64\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 374335.6562\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 374739.9062\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 377426.7812\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 377986.7188\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 379356.3125\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 375540.0312\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 374655.1562\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 369651.5938\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 375097.7812\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 372170.2188\n",
      "Weights succesfully copied to Target model for Agent 2.\n",
      "Saving architecture, weights and optimizer state for agent-2\n",
      "Dumping agent-2 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Dumping Loss Results into pickle file.\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 481: Starting computation.\n",
      "Random Seed Set to 491\n",
      "Episode 481: Finished running.\n",
      "Agent 0, Average Reward: -2103.04\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 396525.6562\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 403103.4062\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 400669.6875\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 396258.4688\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 393316.5312\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 397753.0312\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 392972.4688\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 394865.1875\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 395052.8438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 395408.6250\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 482: Starting computation.\n",
      "Random Seed Set to 492\n",
      "Episode 482: Finished running.\n",
      "Agent 0, Average Reward: -2142.87\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 447073.1562\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 451184.7812\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 446321.3438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 443826.5938\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 445274.4062\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 442619.4688\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 432213.6562\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 442134.8438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 438503.5938\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 442234.5938\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 483: Starting computation.\n",
      "Random Seed Set to 493\n",
      "Episode 483: Finished running.\n",
      "Agent 0, Average Reward: -1903.43\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 443422.1875\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 443138.6562\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 442576.8438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 435303.9062\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 440118.6562\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 432583.4688\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 435128.8438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 434727.7188\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 430054.8438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 437047.6562\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 484: Starting computation.\n",
      "Random Seed Set to 494\n",
      "Episode 484: Finished running.\n",
      "Agent 0, Average Reward: -1876.77\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 435124.5312\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 438351.7812\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 440014.9062\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 426472.5312\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 434990.3438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 428609.4062\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 434126.1562\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 429143.3438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 430054.2188\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 432119.9062\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 485: Starting computation.\n",
      "Random Seed Set to 495\n",
      "Episode 485: Finished running.\n",
      "Agent 0, Average Reward: -568.05\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 372833.2188\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 375456.5000\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 370054.6562\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 365376.5000\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 373955.6562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 368675.1250\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 364648.5938\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 368148.5312\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 360549.2500\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 363913.1562\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 486: Starting computation.\n",
      "Random Seed Set to 496\n",
      "Episode 486: Finished running.\n",
      "Agent 0, Average Reward: -1111.31\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 337880.5000\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 336066.5312\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 331232.0000\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 329919.0625\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 326571.8125\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 334259.9688\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 327132.5938\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 328931.4375\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 323369.7500\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 320843.7188\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 487: Starting computation.\n",
      "Random Seed Set to 497\n",
      "Episode 487: Finished running.\n",
      "Agent 0, Average Reward: -1101.54\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 301416.8438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 300019.9375\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 304195.7188\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 308452.1562\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 299675.6562\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 303021.7812\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 304450.8438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 303839.0938\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 305596.8438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 300793.8438\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 488: Starting computation.\n",
      "Random Seed Set to 498\n",
      "Episode 488: Finished running.\n",
      "Agent 0, Average Reward: -1525.5\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 265975.6562\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 271067.4688\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 268088.3750\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 269525.1562\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 267189.0000\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 267910.7500\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 266077.1562\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 263766.2188\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 259480.8750\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 264335.8438\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 489: Starting computation.\n",
      "Random Seed Set to 499\n",
      "Episode 489: Finished running.\n",
      "Agent 0, Average Reward: -1625.31\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 242507.2031\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 238969.1094\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 243013.3125\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 243381.2969\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 241585.4844\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 237752.6250\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 240367.3281\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 237975.0781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 237988.9219\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 239113.9531\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 490: Starting computation.\n",
      "Random Seed Set to 500\n",
      "Episode 490: Finished running.\n",
      "Agent 0, Average Reward: -1551.32\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 220328.9844\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 221214.5156\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 224159.5625\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 224672.1875\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 228152.8125\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 219876.8594\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 219216.2969\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 218542.8594\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 219833.2656\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 222688.2344\n",
      "Weights succesfully copied to Target model for Agent 2.\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 491: Starting computation.\n",
      "Random Seed Set to 501\n",
      "Episode 491: Finished running.\n",
      "Agent 0, Average Reward: -1135.76\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 203400.5312\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 211218.1875\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 207842.8281\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 213801.2031\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 207582.8281\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 208033.6250\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 208505.1719\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 207884.7969\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 209565.7031\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 203491.2344\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 492: Starting computation.\n",
      "Random Seed Set to 502\n",
      "Episode 492: Finished running.\n",
      "Agent 0, Average Reward: -1309.57\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 226356.3281\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 234870.3281\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 225543.3594\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 228830.9375\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 231398.2656\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 226642.3438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 230065.2969\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 228615.0781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 225726.5469\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 226969.9062\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 493: Starting computation.\n",
      "Random Seed Set to 503\n",
      "Episode 493: Finished running.\n",
      "Agent 0, Average Reward: -949.56\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 228753.4062\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 225169.9219\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 219941.7188\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 225804.3594\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 217087.9844\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 217840.0781\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 218018.7656\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 221620.5000\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 219889.5156\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 215452.2656\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 494: Starting computation.\n",
      "Random Seed Set to 504\n",
      "Episode 494: Finished running.\n",
      "Agent 0, Average Reward: -1265.2\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 233923.4531\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 231671.8125\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 224760.6719\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 230843.9219\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 229772.5469\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 229841.9062\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 230931.1094\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 235859.2656\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 230512.4375\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 231580.1094\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 495: Starting computation.\n",
      "Random Seed Set to 505\n",
      "Episode 495: Finished running.\n",
      "Agent 0, Average Reward: -2369.42\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 287621.5938\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 289250.9375\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 293911.2500\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 288978.3125\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 281797.5938\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 292816.1250\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 289384.1562\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 286957.4062\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 284294.9688\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 284201.3438\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 496: Starting computation.\n",
      "Random Seed Set to 506\n",
      "Episode 496: Finished running.\n",
      "Agent 0, Average Reward: -2195.39\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 330377.3750\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 336447.7500\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 336030.1562\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 338866.6250\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 334987.5938\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 333965.2812\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 328321.9688\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 331389.8438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 328442.2188\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 332614.4062\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 497: Starting computation.\n",
      "Random Seed Set to 507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 497: Finished running.\n",
      "Agent 0, Average Reward: -2547.81\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 411278.8438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 405016.2188\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 401798.9688\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 402887.1562\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 405106.5625\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 401383.8438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 398937.0625\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 405128.6562\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 400891.0938\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 400721.4062\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 498: Starting computation.\n",
      "Random Seed Set to 508\n",
      "Episode 498: Finished running.\n",
      "Agent 0, Average Reward: -744.86\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 390342.7188\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 389118.8125\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 389050.7812\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 383865.3438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 387040.5938\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 380405.7188\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 384964.0312\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 382097.4062\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 389029.8125\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 389101.1562\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 499: Starting computation.\n",
      "Random Seed Set to 509\n",
      "Episode 499: Finished running.\n",
      "Agent 0, Average Reward: -756.32\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 365348.8750\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 375365.9062\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 369741.3125\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 371601.9375\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 365008.5312\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 368662.0312\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 370105.5000\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 371406.0312\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 368236.8438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 365553.8125\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 500: Starting computation.\n",
      "Random Seed Set to 510\n",
      "Episode 500: Finished running.\n",
      "Agent 0, Average Reward: -999.46\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 366537.2500\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 366481.9688\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 362421.3438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 366086.0312\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 362181.9688\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 360826.0938\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 362298.5312\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 363037.0312\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 353527.8438\n",
      "Train on 256 samples\n",
      "256/256 - 0s - loss: 354210.5938\n",
      "Weights succesfully copied to Target model for Agent 2.\n",
      "Saving architecture, weights and optimizer state for agent-2\n",
      "Dumping agent-2 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Dumping Loss Results into pickle file.\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 501: Starting computation.\n"
     ]
    }
   ],
   "source": [
    "Balance_int_MultiDQN_Agents.train(episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving architecture, weights and optimizer state for agent-2\n",
      "Dumping agent-2 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Dumping Loss Results into pickle file.\n"
     ]
    }
   ],
   "source": [
    "Balance_int_MultiDQN_Agents.save(episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Balance_int_MultiDQN_Agents.demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intersection 3\n",
      "Agent 3: Training Loss and Average Reward during training successfuly saved to file:\n",
      "C:\\Users\\acabrejasegea\\OneDrive - The Alan Turing Institute\\Desktop\\ATI\\0_TMF\\MLforFlowOptimisation\\Vissim\\Balance_int3\\Agents_Results\\DDQN\\Balance_int3_all_actions_500_10800_DDQN_Queues/Agent3_Loss_average_reward.json\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## AGENT TRAINING RESULTS\n",
    "# Path to results folder\n",
    "results_path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", agent_type, Session_ID)\n",
    "\n",
    "# Loop over each agent\n",
    "for idx , agent in Balance_int_MultiDQN_Agents.Agents.items():\n",
    "    intersection_number_in_vissim = Balance_int_MultiDQN_Agents.Agents[0].signal_id + 1\n",
    "    print(\"Intersection \"+str(intersection_number_in_vissim))\n",
    "    \n",
    "    ## SAVE TRAINING DATA TO JSON.\n",
    "    json_filename = \"Agent{}_Loss_average_reward.json\".format(intersection_number_in_vissim)\n",
    "    Loss_reward = dict()   \n",
    "    # Loss dictionary\n",
    "    for epoch, loss in enumerate(agent.loss):\n",
    "        loss_dict = { epoch : loss }\n",
    "    Loss_reward['Agent{} loss'.format(intersection_number_in_vissim)] = loss_dict\n",
    "    # Reward dictionary            \n",
    "    episode = [i for i in range(len(agent.reward_storage))]\n",
    "    Loss_reward['Agent{} Average_Reward'.format(intersection_number_in_vissim)] = agent.reward_storage\n",
    "    # Store as JSON\n",
    "    with open(results_path + \"/\" + json_filename, 'w') as f:\n",
    "        json.dump(Loss_reward, f)\n",
    "    print(\"Agent {}: Training Loss and Average Reward during training successfuly saved to file:\".format(intersection_number_in_vissim))\n",
    "    print(results_path + \"/\" + json_filename)\n",
    "    \n",
    "    ## LOADING DATA FROM JSON\n",
    "    #results_path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", agent_type, Session_ID)\n",
    "    #dictionary_filename = \"Agent{}_Loss_average_reward.json\".format(intersection_number_in_vissim)\n",
    "    #with open(results_path + \"/\" + json_filename, 'r') as fp:\n",
    "    #    data = json.load(fp)\n",
    "    #print(data)\n",
    "    \n",
    "    ## TRAINING PLOTS\n",
    "    loss_plot_filename  = \"Agent{}_Loss.png\".format(intersection_number_in_vissim)\n",
    "    reward_plot_filename  = \"Agent{}_average_reward.png\".format(intersection_number_in_vissim) \n",
    "    \n",
    "    ## Loss Plot\n",
    "    plt.figure('LossAgent'+str(idx),figsize=(16,9))\n",
    "    plt.plot(agent.loss)\n",
    "    #plt.yscale('log')\n",
    "\n",
    "    plt.xlabel('Training Epoch',fontsize=18)\n",
    "    plt.ylabel('Loss',fontsize=18)\n",
    "    plt.title('Agent {} Loss over training'.format(intersection_number_in_vissim),fontsize=18)\n",
    "    plt.savefig(results_path + \"/\" + loss_plot_filename)\n",
    "\n",
    "    ## Average Reward Plot\n",
    "    plt.figure('RewardAgent'+str(idx),figsize=(16,9))\n",
    "    plt.plot(agent.reward_storage)\n",
    "    plt.xlabel('Training Episode',fontsize=18)\n",
    "    plt.ylabel('Average reward',fontsize=18)\n",
    "    plt.title('Agent {} average reward over training'.format(intersection_number_in_vissim),fontsize=18)\n",
    "    plt.savefig(results_path + \"/\" + reward_plot_filename)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Pre-Trained Agent 2, Architecture, Optimizer and Memory.\n",
      "C:\\Users\\acabrejasegea\\OneDrive - The Alan Turing Institute\\Desktop\\ATI\\0_TMF\\MLforFlowOptimisation\\Vissim\\Balance_int3\\Agents_Results\\DDQN\\Balance_int3_all_actions_500_10800_DDQN_Queues\\BestAgent2.h5\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\acabrejasegea\\\\OneDrive - The Alan Turing Institute\\\\Desktop\\\\ATI\\\\0_TMF\\\\MLforFlowOptimisation\\\\Vissim\\\\Balance_int3\\\\Agents_Results\\\\DDQN\\\\Balance_int3_all_actions_500_10800_DDQN_Queues\\\\Episode1000Agent2_Train.p'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-e75a4ae19b99>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mBalance_int_MultiDQN_Agents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\OneDrive - The Alan Turing Institute\\Desktop\\ATI\\0_TMF\\MLforFlowOptimisation\\Vissim\\MasterDQN_Agent.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(self, episode, best)\u001b[0m\n\u001b[0;32m    402\u001b[0m \t\t\"\"\"\n\u001b[0;32m    403\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0magent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAgents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 404\u001b[1;33m                         \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_agent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvissim_working_directory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_name\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magent_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession_ID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepisode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    405\u001b[0m                         \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilon_sequence\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mepisode\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber_of_episode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepisode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - The Alan Turing Institute\\Desktop\\ATI\\0_TMF\\MLforFlowOptimisation\\Vissim\\General_agent.py\u001b[0m in \u001b[0;36mload_agent\u001b[1;34m(self, vissim_working_directory, model_name, agent_type, Session_ID, episode, best)\u001b[0m\n\u001b[0;32m    117\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMemory_Filename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m                 \u001b[0mTraining_Progress_Filename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvissim_working_directory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Agents_Results\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0magent_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSession_ID\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Episode'\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepisode\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;34m'Agent'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_Train'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.p'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreward_storage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTraining_Progress_Filename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m                 \u001b[0mLoss_Filename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvissim_working_directory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Agents_Results\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0magent_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSession_ID\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Episode'\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepisode\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;34m'Agent'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_Loss'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.p'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLoss_Filename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\acabrejasegea\\\\OneDrive - The Alan Turing Institute\\\\Desktop\\\\ATI\\\\0_TMF\\\\MLforFlowOptimisation\\\\Vissim\\\\Balance_int3\\\\Agents_Results\\\\DDQN\\\\Balance_int3_all_actions_500_10800_DDQN_Queues\\\\Episode1000Agent2_Train.p'"
     ]
    }
   ],
   "source": [
    "Balance_int_MultiDQN_Agents.load(1000, best = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Balance_int_MultiDQN_Agents.demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Balance_int_MultiDQN_Agents.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results_path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", agent_type, Session_ID)\n",
    "time = [t for t in range(len(Balance_int_MultiDQN_Agents.Cumulative_Totale_network_stop_delay))]\n",
    "\n",
    "########################################\n",
    "## Queues over time for each junction ##\n",
    "########################################\n",
    "for idx, queues in Balance_int_MultiDQN_Agents.Episode_Queues.items():\n",
    "    # Identify Junction ID in map\n",
    "    intersection_number_in_vissim = Balance_int_MultiDQN_Agents.Agents[0].signal_id + 1\n",
    "    \n",
    "    queues = np.array(queues)\n",
    "    queues = queues.T\n",
    "    number_queues = np.size(queues,0)\n",
    "    \n",
    "    plt.figure('1'+str(idx),figsize=(16, 9))\n",
    "    \n",
    "    Queues = dict()\n",
    "    Queues['Time'] = time\n",
    "    Queues_legend = []\n",
    "    \n",
    "    for i, queue in enumerate(queues):\n",
    "        plt.plot(queue, label = \"Queue\"+str(i))\n",
    "        Queues[str(i)] = queue.tolist()\n",
    "        Queues_legend.append(\"Queue\"+str(i))\n",
    "    \n",
    "    ## Plot the queues\n",
    "    plt.xlabel('Time [s]',fontsize=18)\n",
    "    plt.ylabel('Queue Length',fontsize=18)\n",
    "    plt.title('Junction {} Queue length'.format(intersection_number_in_vissim),fontsize=18)\n",
    "    plt.gca().legend(Queues_legend)\n",
    "    \n",
    "    filename = \"Junction{}_Queues.png\".format(intersection_number_in_vissim)           \n",
    "    plt.savefig(results_path + \"/\" + filename)\n",
    "    \n",
    "    # Store as JSON\n",
    "    json_filename = \"Junction{}_Queues.json\".format(intersection_number_in_vissim)        \n",
    "    with open(results_path + \"/\" + json_filename, 'w') as f:\n",
    "        json.dump(Queues, f)\n",
    "        \n",
    "    ### LOADING DATA FROM JSON\n",
    "    #results_path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", agent_type, Session_ID)\n",
    "    #json_filename = \"Junction{}_Queues.json\".format(intersection_number_in_vissim)\n",
    "    #with open(results_path + \"/\" + json_filename, 'r') as fp:\n",
    "    #    data = json.load(fp)\n",
    "    #print(data)\n",
    "        \n",
    "    # Success Message\n",
    "    print(\"Agent {}: Queues during Test successfuly saved to file:\".format(intersection_number_in_vissim))\n",
    "    print(results_path + \"/\" + json_filename)\n",
    "       \n",
    "        \n",
    "###################################################        \n",
    "## Accumulated delay over time for each junction ##\n",
    "###################################################\n",
    "for idx, delay in Balance_int_MultiDQN_Agents.Cumulative_Episode_Delays.items():\n",
    "    # Identify Junction ID in map\n",
    "    intersection_number_in_vissim = Balance_int_MultiDQN_Agents.Agents[idx].signal_id + 1\n",
    "\n",
    "    # Extract and process delay data\n",
    "    Delay = dict()   \n",
    "    Delay['Time'] = time\n",
    "    Delay['Junction {} delay'.format(intersection_number_in_vissim)] = delay\n",
    "    \n",
    "    # Store as JSON\n",
    "    json_filename = \"Junction{}_Cumulative_Delay.json\".format(intersection_number_in_vissim)        \n",
    "    with open(results_path + \"/\" + json_filename, 'w') as f:\n",
    "        json.dump(Delay, f)\n",
    "        \n",
    "    # Success Message\n",
    "    print(\"Agent {}: Test Cumulative Delay successfuly saved to file:\".format(intersection_number_in_vissim))\n",
    "    print(results_path + \"/\" + json_filename)\n",
    "    \n",
    "    ### Loading data from JSON\n",
    "    #results_path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", agent_type, Session_ID)\n",
    "    #dictionary_filename = \"Junction{}_Cumulative_Delay.json\".format(intersection_number_in_vissim)\n",
    "    #with open(results_path + \"/\" + json_filename, 'r') as fp:\n",
    "    #    data = json.load(fp)\n",
    "    #print(data)\n",
    "\n",
    "    # Plot the cumulative delay\n",
    "    plt.figure('2'+str(idx),figsize=(16, 9))\n",
    "    plt.plot(delay)\n",
    "    plt.xlabel('Time [s]',fontsize=18)\n",
    "    plt.ylabel('Accumulated Delay',fontsize=18)\n",
    "    plt.title('Junction {} Delay'.format(intersection_number_in_vissim),fontsize=18)\n",
    "    plt.gca().legend('Junction accumulated delay')\n",
    "    \n",
    "    filename = \"Junction{}_Cumulative_Delay.png\".format(intersection_number_in_vissim)\n",
    "    plt.savefig(results_path + \"/\" + filename)\n",
    "    \n",
    "    \n",
    "    \n",
    "########################################################    \n",
    "## Accumulated stop delay over time for each junction ##\n",
    "########################################################\n",
    "for idx, stop_delay in Balance_int_MultiDQN_Agents.Cumulative_Episode_stop_Delays.items():\n",
    "    # Identify Junction ID in map\n",
    "    intersection_number_in_vissim = Balance_int_MultiDQN_Agents.Agents[idx].signal_id + 1    \n",
    "    \n",
    "    # Extract and process stop delay data\n",
    "    Stop_delay = dict()   \n",
    "    Stop_delay['Time'] = time\n",
    "    Stop_delay['Junction {} stop delay'.format(intersection_number_in_vissim)] = stop_delay\n",
    "    \n",
    "    # Store as JSON\n",
    "    json_filename = \"Junction{}_Cumulative_Stop_Delay.json\".format(intersection_number_in_vissim)        \n",
    "    with open(results_path + \"/\" + json_filename, 'w') as f:\n",
    "        json.dump(Stop_delay, f)\n",
    "    \n",
    "    # Success Message\n",
    "    print(\"Agent {}: Test Cumulative Stop Delay successfuly saved to file:\".format(intersection_number_in_vissim))\n",
    "    print(results_path + \"/\" + json_filename)\n",
    "        \n",
    "    ### Loading data from JSON\n",
    "    #results_path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", agent_type, Session_ID)\n",
    "    #dictionary_filename = \"Junction{}_Cumulative_Stop_Delay.json\".format(intersection_number_in_vissim)\n",
    "    #with open(results_path + \"/\" + json_filename, 'r') as fp:\n",
    "    #    data = json.load(fp)\n",
    "    #print(data)\n",
    "    \n",
    "    # Plot the cumulative stop delay\n",
    "    plt.figure('3'+str(idx),figsize=(16, 9))\n",
    "    plt.plot(stop_delay)\n",
    "    plt.xlabel('Time [s]',fontsize=18)\n",
    "    plt.ylabel('Accumulated Stop Delay',fontsize=18)\n",
    "    plt.title('Junction {} Stop Delay'.format(intersection_number_in_vissim),fontsize=18)\n",
    "    plt.gca().legend('Junction accumulated Stop delay')\n",
    "    \n",
    "    filename = \"Junction{}_Cumulative_Stop_Delay.png\".format(intersection_number_in_vissim)\n",
    "    plt.savefig(results_path + \"/\" + filename)\n",
    "\n",
    "    \n",
    "    \n",
    "###############################################\n",
    "## ONLY IF THERE IS MORE THAN ONE CONTROLLER ##\n",
    "##    These are the global network plots     ##\n",
    "###############################################\n",
    "\n",
    "if len(Balance_int_MultiDQN_Agents.Agents) > 1:\n",
    "    ########################################    \n",
    "    ## Global Accumulated delay over time ##\n",
    "    ########################################\n",
    "    \n",
    "    # Process global delay data\n",
    "    Global_delay = dict()   \n",
    "    Global_delay['Time'] = time\n",
    "    Global_delay['Global accumulated Delay'] = Balance_int_MultiDQN_Agents.Cumulative_Totale_network_delay\n",
    "    \n",
    "    # Store as JSON\n",
    "    json_filename = \"Global_Cumulative_Delay.json\"\n",
    "    with open(results_path + \"/\" + json_filename, 'w') as f:\n",
    "        json.dump(Global_delay, f)\n",
    "    \n",
    "    # Success Message\n",
    "    print(\"Agent {}: Test Cumulative Global Delay successfuly saved to file:\")\n",
    "    print(results_path + \"/\" + json_filename)\n",
    "        \n",
    "    ### Loading data from JSON\n",
    "    #results_path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", agent_type, Session_ID)\n",
    "    #dictionary_filename = \"Global_Cumulative_Delay.json\"\n",
    "    #with open(results_path + \"/\" + json_filename, 'r') as fp:\n",
    "    #    data = json.load(fp)\n",
    "    #print(data)\n",
    "\n",
    "    \n",
    "    # Plot the global delay\n",
    "    plt.figure('4',figsize=(16,9))\n",
    "    plt.plot(Cumulative_Totale_network_delay)\n",
    "    plt.xlabel('Time [s]',fontsize=18)\n",
    "    plt.ylabel('Global accumulated Delay',fontsize=18)\n",
    "    plt.title('Global accumulated Delay',fontsize=18)\n",
    "    plt.gca().legend('Global accumulated delay')\n",
    "\n",
    "    filename = \"Global_Cumulative_Delay.png\".format(intersection_number_in_vissim)\n",
    "    plt.savefig(results_path + \"/\" + filename)\n",
    "\n",
    "\n",
    "    #############################################\n",
    "    ## Global Accumulated stop delay over time ##\n",
    "    #############################################\n",
    "    \n",
    "    # Process global stop delay data\n",
    "    Global_stop_delay = dict()   \n",
    "    Global_stop_delay['Time'] = time\n",
    "    Global_stop_delay['Global accumulated stop Delay'] = Balance_int_MultiDQN_Agents.Cumulative_Totale_network_stop_delay\n",
    "    \n",
    "    # Store as JSON\n",
    "    json_filename = \"Global_Cumulative_Stop_Delay.json\"\n",
    "    with open(results_path + \"/\" + json_filename, 'w') as f:\n",
    "        json.dump(Global_stop_delay, f)\n",
    "    \n",
    "    # Success Message\n",
    "    print(\"Agent {}: Test Cumulative Global Stop Delay successfuly saved to file:\")\n",
    "    print(results_path + \"/\" + json_filename)\n",
    "        \n",
    "    ### Loading data from JSON\n",
    "    #results_path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", agent_type, Session_ID)\n",
    "    #dictionary_filename = \"Global_Cumulative_Stop_Delay.json\"\n",
    "    #with open(results_path + \"/\" + json_filename, 'r') as fp:\n",
    "    #    data = json.load(fp)\n",
    "    #print(data)\n",
    "\n",
    "    # Plot the global stop delay\n",
    "    plt.figure('5'+str(idx),figsize=(16, 9))\n",
    "    plt.plot(Cumulative_Totale_network_stop_delay)\n",
    "    plt.xlabel('Time [s]',fontsize=18)\n",
    "    plt.ylabel('Global accumulated stop Delay',fontsize=18)\n",
    "    plt.title('Global accumulated stop Delay',fontsize=18)\n",
    "    plt.gca().legend('Global accumulated stop Delay')\n",
    "    \n",
    "    filename = \"Global_Cumulative_Delay.png\".format(intersection_number_in_vissim)\n",
    "    plt.savefig(results_path + \"/\" + filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Balance RL DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "map_name  = 'Balance'\n",
    "model_name = map_name\n",
    "\n",
    "vissim_working_directory = 'C:\\\\Users\\\\acabrejasegea\\\\OneDrive - The Alan Turing Institute\\\\Desktop\\\\ATI\\\\0_TMF\\\\MLforFlowOptimisation\\\\Vissim\\\\'\n",
    "#vissim_working_directory = \"E:\\\\OneDrive - University of Warwick\\\\Desktop\\\\ATI\\\\0_TMF\\\\MLforFlowOptimisation\\\\Vissim\"\n",
    "\n",
    "## Simulation Parameters\n",
    "Random_Seed = 44\n",
    "sim_length = 3601\n",
    "timesteps_per_second = 1\n",
    "agent_type = \"DQN\"\n",
    "actions = 'default_actions'     # 'default_actions' or 'all_actions'\n",
    "\n",
    "## DQN Hyperaramenters\n",
    "episodes = 500\n",
    "copy_weights_frequency = 10\n",
    "\n",
    "PER_activated = True\n",
    "memory_size = 5000\n",
    "batch_size = 128\n",
    "batches_per_episode = 10\n",
    "\n",
    "alpha = 0.00005\n",
    "gamma = 0.95\n",
    "\n",
    "# Load and partition balance dictionary\n",
    "Balance_dictionary = balance_dictionary(agent_type)\n",
    "\n",
    "Session_ID = map_name + \"_\" + actions + \"_\" + str(episodes) + \"_\" + str(sim_length-1) + \"_\" + agent_type\n",
    "print(\"Current simulation: {}\".format(Session_ID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Exploration Schedule (\"linear\" or \"geometric\")\n",
    "exploration_schedule = \"geometric\"\n",
    "epsilon_start = 1\n",
    "epsilon_end   = 0.001\n",
    "\n",
    "Random_Seed = 100\n",
    "\n",
    "def choose_schedule(exploration_schedule, espilon_start, epsilon_end, episodes):\n",
    "    if exploration_schedule == \"linear\":\n",
    "        epsilon_decay = 1.2*(epsilon_end - epsilon_start)/(episodes-1)\n",
    "        epsilon_sequence = [1 + epsilon_decay * entry for entry in range(episodes+1)]\n",
    "        epsilon_sequence = [0 if entry < 0 else entry for entry in epsilon_sequence]\n",
    "    elif exploration_schedule == \"geometric\":\n",
    "        epsilon_decay = np.power(epsilon_end/epsilon_start, 1./(episodes-1)) # Geometric decay\n",
    "        epsilon_sequence = [epsilon_start * epsilon_decay ** entry for entry in range(episodes+1)]\n",
    "    elif exploration_schedule == \"entropy\":\n",
    "        pass\n",
    "    else:\n",
    "        print(\"ERROR: Unrecognized choice of exploration schedule.\")\n",
    "        \n",
    "    # Plotting exploration schedule\n",
    "    plt.figure(figsize=(8,4.5))\n",
    "    x_series = np.array(range(1,episodes+1))\n",
    "    y_series = epsilon_sequence[0:episodes]\n",
    "    plt.plot(x_series, y_series, '-b')\n",
    "    plt.xlabel('Episodes')\n",
    "    plt.ylabel('Ratio of random exploration')\n",
    "    plt.title('Exploration schedule')\n",
    "    plt.show()\n",
    "    return(epsilon_sequence)\n",
    "\n",
    "epsilon_sequence = choose_schedule(exploration_schedule, epsilon_start, epsilon_end, episodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Balance_MultiDQN_Agents = MasterDQN_Agent(model_name, vissim_working_directory, sim_length, Balance_dictionary, actions,\\\n",
    "                gamma, alpha, agent_type, memory_size, PER_activated, batch_size, batches_per_episode, copy_weights_frequency, epsilon_sequence,\\\n",
    "                Random_Seed, timesteps_per_second, Session_ID, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Balance_MultiDQN_Agents.prepopulate_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Balance_MultiDQN_Agents.train(episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Balance_MultiDQN_Agents.save(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Balance_MultiDQN_Agents.demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# For the agent training\n",
    "ploty = 1\n",
    "for idx , agent in Balance_MultiDQN_Agents.Agents.items():\n",
    "    print(\"Agent \"+str(idx))\n",
    "    #print(ploty)\n",
    "    #plt.subplot(14, 2, ploty)\n",
    "\n",
    "    plt.figure('6'+str(idx),figsize=(4.5, 3))\n",
    "    \n",
    "    Loss_rewarddf = pd.DataFrame()   \n",
    "    \n",
    "    plt.plot(agent.loss)\n",
    "    plt.xlabel('Episode',fontsize=18)\n",
    "    plt.ylabel('Loss',fontsize=18)\n",
    "    plt.title('Agent{} Loss over training'.format(idx),fontsize=18)\n",
    "    plt.gca().legend('Agent Loss over training')\n",
    "    \n",
    "    Path  = os.path.join(vissim_working_directory, model_name, \"DQN\", \\\n",
    "                        \"Agent{}_Loss.png\".format(idx)) \n",
    "    #plt.savefig(Path)\n",
    "    \n",
    "    csv_Path = os.path.join(vissim_working_directory, model_name, \"DQN\", \\\n",
    "                           \"Agent{}_Loss_average_reward.csv\".format(idx)) \n",
    "    ploty+=1\n",
    "    #print(ploty)\n",
    "\n",
    "    \n",
    "    #plt.subplot(14, 2, ploty)\n",
    "    plt.figure('7'+str(idx),figsize=(4.5, 3))\n",
    "    plt.plot(agent.reward_storage)\n",
    "    plt.xlabel('Episode',fontsize=18)\n",
    "    plt.ylabel('Average reward',fontsize=18)\n",
    "    plt.title('Agent{} average reward over training'.format(idx),fontsize=18)\n",
    "    plt.gca().legend('Agent reward over training')\n",
    "    \n",
    "    Path  = os.path.join(vissim_working_directory, model_name, \"DQN\", Session_ID,\\\n",
    "                        \"Agent{}_average_reward.png\".format(idx)) \n",
    "    #plt.savefig(Path)\n",
    "    \n",
    "    \n",
    "    episode = [i for i in range(len(agent.reward_storage))]\n",
    "    \n",
    "    Loss_rewarddf['episode'] = episode \n",
    "    Loss_rewarddf['Agent{} loss'.format(idx)] = agent.loss\n",
    "    Loss_rewarddf['Agent{} Average_Reward'.format(idx)] = agent.reward_storage\n",
    "    \n",
    "    #Loss_rewarddf.to_csv(csv_Path,index=False)\n",
    "    ploty+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Balance_MultiDQN_Agents.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "time = [t for t in range(len(Cumulative_Totale_network_stop_delay))]\n",
    "\n",
    "# Queues ovzer time for each junction\n",
    "for idx, queues in Balance_MultiDQN_Agents.Episode_Queues.items():\n",
    "    queues = np.array(queues)\n",
    "    queues = queues.T\n",
    "    \n",
    "    plt.figure('1'+str(idx),figsize=(16, 9))\n",
    "    \n",
    "    Queuesdf = pd.DataFrame()\n",
    "    \n",
    "    Queuesdf['Time'] = time\n",
    "    Queues_legend = []\n",
    "    \n",
    "    for i, queue in enumerate(queues):\n",
    "        plt.plot(queue, label = \"Queue\"+str(i))\n",
    "        Queuesdf[str(i)] = queue\n",
    "        Queues_legend.append(\"Queue\"+str(i))\n",
    "        \n",
    "    plt.xlabel('Time [s]',fontsize=18)\n",
    "    plt.ylabel('Queue Length',fontsize=18)\n",
    "    plt.title('Junction {} Queue length'.format(idx),fontsize=18)\n",
    "    #plt.gca().legend(Queues_legend)\n",
    "    \n",
    "    Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Junction{}_Queues.png\".format(idx))               \n",
    "    plt.savefig(Path)\n",
    "    \n",
    "    csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Junction{}_Queues.csv\".format(idx))        \n",
    "   \n",
    "    Queuesdf.to_csv(csv_Path,index=False)\n",
    "    plt.legend()\n",
    "        \n",
    "        \n",
    "# Accumulated delay over time for each junction\n",
    "for idx, delay in Balance_MultiDQN_Agents.Cumulative_Episode_Delays.items():\n",
    "    \n",
    "    plt.figure('2'+str(idx),figsize=(16, 9))\n",
    "    \n",
    "    delaydf = pd.DataFrame()   \n",
    "    delaydf['Time'] = time\n",
    "    delaydf['Junction {} delay'.format(idx)] = delay\n",
    "    \n",
    "    plt.plot(delay)\n",
    "    plt.xlabel('Time [s]',fontsize=18)\n",
    "    plt.ylabel('Accumulated Delay',fontsize=18)\n",
    "    plt.title('Junction {} Delay'.format(idx),fontsize=18)\n",
    "    plt.gca().legend('Junction accumulated delay')\n",
    "    \n",
    "    Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                            \"Junction{}_Cumulative_Delay.png\".format(idx))\n",
    "    csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Junction{}_Cumulative_Delay.csv\".format(idx))   \n",
    "    plt.savefig(Path)\n",
    "\n",
    "    delaydf.to_csv(csv_Path,index=False)\n",
    "    \n",
    "    \n",
    "# Accumulated stop delay over time for each junction\n",
    "for idx, stop_delay in Balance_MultiDQN_Agents.Cumulative_Episode_stop_Delays.items():\n",
    "    \n",
    "    plt.figure('3'+str(idx),figsize=(16, 9))\n",
    "    \n",
    "    stop_delaydf = pd.DataFrame()   \n",
    "    stop_delaydf['Time'] = time\n",
    "    stop_delaydf['Junction {} stop delay'.format(idx)] = stop_delay\n",
    "\n",
    "    plt.plot(stop_delay)\n",
    "    plt.xlabel('Time [s]',fontsize=18)\n",
    "    plt.ylabel('Accumulated Stop Delay',fontsize=18)\n",
    "    plt.title('Junction {} Stop Delay'.format(idx),fontsize=18)\n",
    "    plt.gca().legend('Junction accumulated Stop delay')\n",
    "    \n",
    "    Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                            \"Junction{}_Cumulative_stop_Delay.png\".format(idx))\n",
    "    csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Junction{}_Cumulative_stop_Delay.csv\".format(idx))\n",
    "    plt.savefig(Path)\n",
    "    stop_delaydf.to_csv(csv_Path,index=False)\n",
    "    \n",
    "# Global Accumulated delay over time\n",
    "plt.figure('4',figsize=(16,9))\n",
    "\n",
    "\n",
    "Global_delaydf = pd.DataFrame()   \n",
    "Global_delaydf['Time'] = time\n",
    "Global_delaydf['Global accumulated Delay'] = Balance_MultiDQN_Agents.Cumulative_Totale_network_delay\n",
    "\n",
    "plt.plot(Cumulative_Totale_network_delay)\n",
    "plt.xlabel('Time [s]',fontsize=18)\n",
    "plt.ylabel('Global accumulated Delay',fontsize=18)\n",
    "plt.title('Global accumulated Delay',fontsize=18)\n",
    "plt.gca().legend('Global accumulated delay')\n",
    "\n",
    "Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Total_Cumulative_Delay.png\")\n",
    "csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Total_Cumulative_Delay.csv\")\n",
    "plt.savefig(Path)\n",
    "Global_delaydf.to_csv(csv_Path,index=False)\n",
    "\n",
    "# Global Accumulated stop delay over time\n",
    "plt.figure('5'+str(idx),figsize=(16, 9))\n",
    "\n",
    "Global_stop_delaydf = pd.DataFrame()   \n",
    "Global_stop_delaydf['Time'] = time\n",
    "Global_stop_delaydf['Global accumulated stop Delay'] = Balance_MultiDQN_Agents.Cumulative_Totale_network_stop_delay\n",
    "\n",
    "plt.plot(Cumulative_Totale_network_stop_delay)\n",
    "plt.xlabel('Time [s]',fontsize=18)\n",
    "plt.ylabel('Global accumulated stop Delay',fontsize=18)\n",
    "plt.title('Global accumulated stop Delay',fontsize=18)\n",
    "plt.gca().legend('Global accumulated stop Delay')\n",
    "\n",
    "Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Total_Cumulative_stop_Delay.png\")\n",
    "csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Total_Cumulative_stop_Delay.csv\")\n",
    "plt.savefig(Path)\n",
    "Global_stop_delaydf.to_csv(csv_Path,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Balance_MultiDQN_Agents.load(498, best = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Balance_MultiDQN_Agents.demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Single_Cross_Straight AC\n",
    "\n",
    "---> The lack of speed comes from the size of the model (particularly the change of color of the heads). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_name  = 'Single_Cross_Straight'\n",
    "vissim_working_directory =  'C:\\\\Users\\\\Rzhang\\\\Desktop\\\\MLforFlowOptimisationOrigine\\\\Vissim\\\\'\n",
    "sim_length = 3601\n",
    "\n",
    "agent_type = \"AC\"\n",
    "Session_ID = \"Single_Cross_Straigth_AC\"\n",
    "\n",
    "\n",
    "\n",
    "# all controller actions\n",
    "Single_Cross_Straight_dictionary =\\\n",
    "{'junctions' : {\n",
    "    # Controller Number 0 \n",
    "    0 : {'default_actions' : {     0 : [1, 0, 1, 0],\n",
    "                                     1 : [0, 1, 0, 1]\n",
    "        },\n",
    "         \n",
    "         'all_actions' : {     0 : [1, 0, 1, 0],\n",
    "                                     1 : [0, 1, 0, 1]\n",
    "        },\n",
    " \n",
    "         'link' : [1, 3, 5, 7],\n",
    "         'lane' : ['1-1', '3-1', '5-1', '7-1'],\n",
    "         'agent_type' : agent_type,\n",
    "         'controled_by_com' : True,\n",
    "         'green_time' : 6,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [5],\n",
    "         'state_type' : 'QueuesSig',\n",
    "         'reward_type' : 'Queues' }\n",
    "        },\n",
    " 'demand' : { 'default' : [400, 400, 400, 400],\n",
    "             \n",
    "             0 : [200,200,200,200],\n",
    "             1 : [400,400,400,400],\n",
    "             2 : [900,500,900,500],\n",
    "             3 : [1000,500,1000,500],\n",
    "             4 : [700,500,700,500],\n",
    "             5 : [500,700,500,700],\n",
    "             6 : [500,1000,500,1000],\n",
    "             7 : [500,900,500,900],\n",
    "             8 : [400,400,400,400],\n",
    "             9 : [200,200,200,200]\n",
    "            }\n",
    " \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gamma = 0.95\n",
    "alpha = 0.00001\n",
    "\n",
    "\n",
    "value = 0.5\n",
    "entropy = 0.5\n",
    "n_step_size = 16\n",
    "state_size = [5]\n",
    "reduce_entropy_every = 100\n",
    "Random_Seed = 100\n",
    "\n",
    "\n",
    "\n",
    "# for the monitoring\n",
    "horizon = 50\n",
    "n_sample = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Straight_MultiAC_Agents = MasterAC_Agent(model_name, vissim_working_directory, sim_length, Single_Cross_Straight_dictionary,\\\n",
    "                n_step_size, gamma, alpha, entropy, value, \\\n",
    "                Random_Seed = Random_Seed, timesteps_per_second = 1, Session_ID = Session_ID, verbose = True, \\\n",
    "                 horizon = horizon, n_sample = n_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Straight_MultiAC_Agents.train(200) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Straight_MultiAC_Agents.save(401)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Straight_MultiAC_Agents.load(200, best = True)\n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Episode_Queues, Cumulative_Episode_Delays,Cumulative_Episode_stop_Delays, Cumulative_Totale_network_delay,Cumulative_Totale_network_stop_delay = Single_Cross_Straight_MultiAC_Agents.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "time = [t for t in range(len(Cumulative_Totale_network_stop_delay))]\n",
    "\n",
    "# Queues ovzer time for each junction\n",
    "for idx, queues in Episode_Queues.items():\n",
    "    queues = np.array(Episode_Queues[0])\n",
    "    queues = queues.T\n",
    "    \n",
    "    plt.figure('1'+str(idx),figsize=(16, 9))\n",
    "    \n",
    "    Queuesdf = pd.DataFrame()\n",
    "    \n",
    "    Queuesdf['Time'] = time\n",
    "    Queues_legend = []\n",
    "    \n",
    "    for i, queue in enumerate(queues):\n",
    "        plt.plot(queue)\n",
    "        Queuesdf[str(i)] = queue\n",
    "        Queues_legend.append(\"Queue\"+str(i))\n",
    "        \n",
    "    plt.xlabel('Time [s]',fontsize=18)\n",
    "    plt.ylabel('Queue Length',fontsize=18)\n",
    "    plt.title('Junction {} Queue length'.format(idx),fontsize=18)\n",
    "    plt.gca().legend(Queues_legend)\n",
    "    \n",
    "    Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Junction{}_Queues.png\".format(idx))               \n",
    "    plt.savefig(Path)\n",
    "    \n",
    "    csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Junction{}_Queues.csv\".format(idx))        \n",
    "   \n",
    "    Queuesdf.to_csv(csv_Path,index=False)\n",
    "        \n",
    "        \n",
    "# Accumulated delay over time for each junction\n",
    "for idx, delay in Cumulative_Episode_Delays.items():\n",
    "    \n",
    "    plt.figure('2'+str(idx),figsize=(16, 9))\n",
    "    \n",
    "    delaydf = pd.DataFrame()   \n",
    "    delaydf['Time'] = time\n",
    "    delaydf['Junction {} delay'.format(idx)] = delay\n",
    "    \n",
    "    plt.plot(delay)\n",
    "    plt.xlabel('Time [s]',fontsize=18)\n",
    "    plt.ylabel('Accumulated Delay',fontsize=18)\n",
    "    plt.title('Junction {} Delay'.format(idx),fontsize=18)\n",
    "    plt.gca().legend('Junction accumulated delay')\n",
    "    \n",
    "    Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                            \"Junction{}_Cumulative_Delay.png\".format(idx))\n",
    "    csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Junction{}_Cumulative_Delay.csv\".format(idx))   \n",
    "    plt.savefig(Path)\n",
    "\n",
    "    delaydf.to_csv(csv_Path,index=False)\n",
    "    \n",
    "    \n",
    "# Accumulated stop delay over time for each junction\n",
    "for idx, stop_delay in Cumulative_Episode_stop_Delays.items():\n",
    "    \n",
    "    plt.figure('3'+str(idx),figsize=(16, 9))\n",
    "    \n",
    "    stop_delaydf = pd.DataFrame()   \n",
    "    stop_delaydf['Time'] = time\n",
    "    stop_delaydf['Junction {} stop delay'.format(idx)] = stop_delay\n",
    "\n",
    "    plt.plot(stop_delay)\n",
    "    plt.xlabel('Time [s]',fontsize=18)\n",
    "    plt.ylabel('Accumulated Stop Delay',fontsize=18)\n",
    "    plt.title('Junction {} Stop Delay'.format(idx),fontsize=18)\n",
    "    plt.gca().legend('Junction accumulated Stop delay')\n",
    "    \n",
    "    Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                            \"Junction{}_Cumulative_stop_Delay.png\".format(idx))\n",
    "    csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Junction{}_Cumulative_stop_Delay.csv\".format(idx))\n",
    "    plt.savefig(Path)\n",
    "    stop_delaydf.to_csv(csv_Path,index=False)\n",
    "    \n",
    "# Global Accumulated delay over time\n",
    "plt.figure('4',figsize=(16,9))\n",
    "\n",
    "\n",
    "Global_delaydf = pd.DataFrame()   \n",
    "Global_delaydf['Time'] = time\n",
    "Global_delaydf['Global accumulated Delay'] = Cumulative_Totale_network_delay\n",
    "\n",
    "plt.plot(Cumulative_Totale_network_delay)\n",
    "plt.xlabel('Time [s]',fontsize=18)\n",
    "plt.ylabel('Global accumulated Delay',fontsize=18)\n",
    "plt.title('Global accumulated Delay',fontsize=18)\n",
    "plt.gca().legend('Global accumulated delay')\n",
    "\n",
    "Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Total_Cumulative_Delay.png\")\n",
    "csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Total_Cumulative_Delay.csv\")\n",
    "plt.savefig(Path)\n",
    "Global_delaydf.to_csv(csv_Path,index=False)\n",
    "\n",
    "# Global Accumulated stop delay over time\n",
    "plt.figure('5'+str(idx),figsize=(16, 9))\n",
    "\n",
    "Global_stop_delaydf = pd.DataFrame()   \n",
    "Global_stop_delaydf['Time'] = time\n",
    "Global_stop_delaydf['Global accumulated stop Delay'] = Cumulative_Totale_network_stop_delay\n",
    "\n",
    "plt.plot(Cumulative_Totale_network_stop_delay)\n",
    "plt.xlabel('Time [s]',fontsize=18)\n",
    "plt.ylabel('Global accumulated stop Delay',fontsize=18)\n",
    "plt.title('Global accumulated stop Delay',fontsize=18)\n",
    "plt.gca().legend('Global accumulated stop Delay')\n",
    "\n",
    "Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Total_Cumulative_stop_Delay.png\")\n",
    "csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Total_Cumulative_stop_Delay.csv\")\n",
    "plt.savefig(Path)\n",
    "Global_stop_delaydf.to_csv(csv_Path,index=False)\n",
    "\n",
    "\n",
    "# For the agent training\n",
    "\n",
    "for idx , agent in  Single_Cross_Straight_MultiAC_Agents.Agents.items():  \n",
    "    plt.figure('6'+str(idx),figsize=(16, 9))\n",
    "    \n",
    "    Loss_rewarddf = pd.DataFrame()   \n",
    "    \n",
    "    plt.plot(agent.loss)\n",
    "    plt.xlabel('Episode',fontsize=18)\n",
    "    plt.ylabel('Loss',fontsize=18)\n",
    "    plt.title('Agent{} Loss over training'.format(idx),fontsize=18)\n",
    "    plt.gca().legend('Agent Loss over training')\n",
    "    \n",
    "    Path  = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Agent{}_Loss.png\".format(idx)) \n",
    "    plt.savefig(Path)\n",
    "    \n",
    "    csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                           \"Agent{}_Loss_average_reward.csv\".format(idx)) \n",
    "    \n",
    "    \n",
    "    plt.figure('7'+str(idx),figsize=(16, 9))\n",
    "    plt.plot(agent.reward_storage)\n",
    "    plt.xlabel('Episode',fontsize=18)\n",
    "    plt.ylabel('Average reward',fontsize=18)\n",
    "    plt.title('Agent{} average reward over training'.format(idx),fontsize=18)\n",
    "    plt.gca().legend('Agent reward over training')\n",
    "    \n",
    "    Path  = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Agent{}_average_reward.png\".format(idx)) \n",
    "    plt.savefig(Path)\n",
    "    \n",
    "    \n",
    "    episode = [i for i in range(len(agent.reward_storage))]\n",
    "    \n",
    "    Loss_rewarddf['episode'] = episode \n",
    "    Loss_rewarddf['Agent{} loss'.format(idx)] = agent.loss\n",
    "    Loss_rewarddf['Agent{} Average_Reward'.format(idx)] = agent.reward_storage\n",
    "    \n",
    "    Loss_rewarddf.to_csv(csv_Path,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Straight_MultiAC_Agents.Agents[0].Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Straight_MultiAC_Agents.demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Single_Cross_Straight DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_name  = 'Single_Cross_Straight'\n",
    "vissim_working_directory =  'C:\\\\Users\\\\Rzhang\\\\Desktop\\\\MLforFlowOptimisationOrigine\\\\Vissim\\\\'\n",
    "sim_length = 3601\n",
    "\n",
    "agent_type = \"DuelingDQN\"\n",
    "Session_ID = \"Single_Cross_Straigth_DuelingDQN20c0\"\n",
    "\n",
    "# all controller actions\n",
    "# all controller actions\n",
    "Single_Cross_Straight_dictionary =\\\n",
    "{'junctions' : {\n",
    "    # Controller Number 0 \n",
    "    0 : {'default_actions' : {     0 : [1, 0, 1, 0],\n",
    "                                     1 : [0, 1, 0, 1]\n",
    "        },\n",
    "         \n",
    "         'all_actions' : {     0 : [1, 0, 1, 0],\n",
    "                                     1 : [0, 1, 0, 1]\n",
    "        },\n",
    " \n",
    "         'link' : [1, 3, 5, 7],\n",
    "         'lane' : ['1-1', '3-1', '5-1', '7-1'],\n",
    "         'agent_type' : agent_type,\n",
    "         'controled_by_com' : True,\n",
    "         'green_time' : 6,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [5],\n",
    "         'state_type' : 'QueuesSig',\n",
    "         'reward_type' : 'Queues',\n",
    "         'queues_counter_ID' : [1,2,3,4]  }\n",
    "        },\n",
    " 'demand' : { 'default' : [400, 400, 400, 400],\n",
    "             \n",
    "             0 : [200,200,200,200],\n",
    "             1 : [400,400,400,400],\n",
    "             2 : [900,500,900,500],\n",
    "             3 : [1000,500,1000,500],\n",
    "             4 : [700,500,700,500],\n",
    "             5 : [500,700,500,700],\n",
    "             6 : [500,1000,500,1000],\n",
    "             7 : [500,900,500,900],\n",
    "             8 : [400,400,400,400],\n",
    "             9 : [200,200,200,200]\n",
    "            }\n",
    " \n",
    "}\n",
    "\n",
    "## DQN Hyperaramenters\n",
    "episodes = 300\n",
    "copy_weights_frequency = 10\n",
    "\n",
    "PER_activated = True\n",
    "memory_size = 1000\n",
    "batch_size = 128\n",
    "\n",
    "gamma = 0.95\n",
    "alpha = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Exploration Schedule (\"linear\" or \"geometric\")\n",
    "exploration_schedule = \"geometric\"\n",
    "epsilon_start = 1\n",
    "epsilon_end   = 0.001\n",
    "\n",
    "Random_Seed = 100\n",
    "\n",
    "def choose_schedule(exploration_schedule, espilon_start, epsilon_end, episodes):\n",
    "    if exploration_schedule == \"linear\":\n",
    "        epsilon_decay = 1.2*(epsilon_end - epsilon_start)/(episodes-1)\n",
    "        epsilon_sequence = [1 + epsilon_decay * entry for entry in range(episodes+1)]\n",
    "        epsilon_sequence = [0 if entry < 0 else entry for entry in epsilon_sequence]\n",
    "    elif exploration_schedule == \"geometric\":\n",
    "        epsilon_decay = np.power(epsilon_end/epsilon_start, 1./(episodes-1)) # Geometric decay\n",
    "        epsilon_sequence = [epsilon_start * epsilon_decay ** entry for entry in range(episodes+1)]\n",
    "    elif exploration_schedule == \"entropy\":\n",
    "        pass\n",
    "    else:\n",
    "        print(\"ERROR: Unrecognized choice of exploration schedule.\")\n",
    "        \n",
    "    # Plotting exploration schedule\n",
    "    plt.figure(figsize=(8,4.5))\n",
    "    x_series = np.array(range(1,episodes+1))\n",
    "    y_series = epsilon_sequence[0:episodes]\n",
    "    plt.plot(x_series, y_series, '-b')\n",
    "    plt.xlabel('Episodes')\n",
    "    plt.ylabel('Ratio of random exploration')\n",
    "    plt.title('Exploration schedule')\n",
    "    plt.show()\n",
    "    return(epsilon_sequence)\n",
    "\n",
    "epsilon_sequence = choose_schedule(exploration_schedule, epsilon_start, epsilon_end, episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Straight_MultiDQN_Agents = MasterDQN_Agent(model_name, vissim_working_directory, sim_length, Single_Cross_Straight_dictionary,\\\n",
    "                gamma, alpha, agent_type, memory_size, PER_activated, batch_size, copy_weights_frequency, epsilon_sequence,\\\n",
    "                Random_Seed = Random_Seed, timesteps_per_second = 1, Session_ID = Session_ID, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Straight_MultiDQN_Agents.prepopulate_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Straight_MultiDQN_Agents.train(episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Straight_MultiDQN_Agents.save(401)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Straight_MultiDQN_Agents.load(300 , best = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Episode_Queues, Cumulative_Episode_Delays,Cumulative_Episode_stop_Delays, Cumulative_Totale_network_delay,Cumulative_Totale_network_stop_delay  = Single_Cross_Straight_MultiDQN_Agents.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "time = [t for t in range(len(Cumulative_Totale_network_stop_delay))]\n",
    "\n",
    "# Queues ovzer time for each junction\n",
    "for idx, queues in Episode_Queues.items():\n",
    "    queues = np.array(Episode_Queues[0])\n",
    "    queues = queues.T\n",
    "    \n",
    "    plt.figure('1'+str(idx),figsize=(16, 9))\n",
    "    \n",
    "    Queuesdf = pd.DataFrame()\n",
    "    \n",
    "    Queuesdf['Time'] = time\n",
    "    Queues_legend = []\n",
    "    \n",
    "    for i, queue in enumerate(queues):\n",
    "        plt.plot(queue)\n",
    "        Queuesdf[str(i)] = queue\n",
    "        Queues_legend.append(\"Queue\"+str(i))\n",
    "        \n",
    "    plt.xlabel('Time [s]',fontsize=18)\n",
    "    plt.ylabel('Queue Length',fontsize=18)\n",
    "    plt.title('Junction {} Queue length'.format(idx),fontsize=18)\n",
    "    plt.gca().legend(Queues_legend)\n",
    "    \n",
    "    Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Junction{}_Queues.png\".format(idx))               \n",
    "    plt.savefig(Path)\n",
    "    \n",
    "    csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Junction{}_Queues.csv\".format(idx))        \n",
    "   \n",
    "    Queuesdf.to_csv(csv_Path,index=False)\n",
    "        \n",
    "        \n",
    "# Accumulated delay over time for each junction\n",
    "for idx, delay in Cumulative_Episode_Delays.items():\n",
    "    \n",
    "    plt.figure('2'+str(idx),figsize=(16, 9))\n",
    "    \n",
    "    delaydf = pd.DataFrame()   \n",
    "    delaydf['Time'] = time\n",
    "    delaydf['Junction {} delay'.format(idx)] = delay\n",
    "    \n",
    "    plt.plot(delay)\n",
    "    plt.xlabel('Time [s]',fontsize=18)\n",
    "    plt.ylabel('Accumulated Delay',fontsize=18)\n",
    "    plt.title('Junction {} Delay'.format(idx),fontsize=18)\n",
    "    plt.gca().legend('Junction accumulated delay')\n",
    "    \n",
    "    Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                            \"Junction{}_Cumulative_Delay.png\".format(idx))\n",
    "    csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Junction{}_Cumulative_Delay.csv\".format(idx))   \n",
    "    plt.savefig(Path)\n",
    "\n",
    "    delaydf.to_csv(csv_Path,index=False)\n",
    "    \n",
    "    \n",
    "# Accumulated stop delay over time for each junction\n",
    "for idx, stop_delay in Cumulative_Episode_stop_Delays.items():\n",
    "    \n",
    "    plt.figure('3'+str(idx),figsize=(16, 9))\n",
    "    \n",
    "    stop_delaydf = pd.DataFrame()   \n",
    "    stop_delaydf['Time'] = time\n",
    "    stop_delaydf['Junction {} stop delay'.format(idx)] = stop_delay\n",
    "\n",
    "    plt.plot(stop_delay)\n",
    "    plt.xlabel('Time [s]',fontsize=18)\n",
    "    plt.ylabel('Accumulated Stop Delay',fontsize=18)\n",
    "    plt.title('Junction {} Stop Delay'.format(idx),fontsize=18)\n",
    "    plt.gca().legend('Junction accumulated Stop delay')\n",
    "    \n",
    "    Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                            \"Junction{}_Cumulative_stop_Delay.png\".format(idx))\n",
    "    csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Junction{}_Cumulative_stop_Delay.csv\".format(idx))\n",
    "    plt.savefig(Path)\n",
    "    stop_delaydf.to_csv(csv_Path,index=False)\n",
    "    \n",
    "# Global Accumulated delay over time\n",
    "plt.figure('4',figsize=(16,9))\n",
    "\n",
    "\n",
    "Global_delaydf = pd.DataFrame()   \n",
    "Global_delaydf['Time'] = time\n",
    "Global_delaydf['Global accumulated Delay'] = Cumulative_Totale_network_delay\n",
    "\n",
    "plt.plot(Cumulative_Totale_network_delay)\n",
    "plt.xlabel('Time [s]',fontsize=18)\n",
    "plt.ylabel('Global accumulated Delay',fontsize=18)\n",
    "plt.title('Global accumulated Delay',fontsize=18)\n",
    "plt.gca().legend('Global accumulated delay')\n",
    "\n",
    "Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Total_Cumulative_Delay.png\")\n",
    "csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Total_Cumulative_Delay.csv\")\n",
    "plt.savefig(Path)\n",
    "Global_delaydf.to_csv(csv_Path,index=False)\n",
    "\n",
    "# Global Accumulated stop delay over time\n",
    "plt.figure('5'+str(idx),figsize=(16, 9))\n",
    "\n",
    "Global_stop_delaydf = pd.DataFrame()   \n",
    "Global_stop_delaydf['Time'] = time\n",
    "Global_stop_delaydf['Global accumulated stop Delay'] = Cumulative_Totale_network_stop_delay\n",
    "\n",
    "plt.plot(Cumulative_Totale_network_stop_delay)\n",
    "plt.xlabel('Time [s]',fontsize=18)\n",
    "plt.ylabel('Global accumulated stop Delay',fontsize=18)\n",
    "plt.title('Global accumulated stop Delay',fontsize=18)\n",
    "plt.gca().legend('Global accumulated stop Delay')\n",
    "\n",
    "Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Total_Cumulative_stop_Delay.png\")\n",
    "csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Total_Cumulative_stop_Delay.csv\")\n",
    "plt.savefig(Path)\n",
    "Global_stop_delaydf.to_csv(csv_Path,index=False)\n",
    "\n",
    "\n",
    "# For the agent training\n",
    "\n",
    "for idx , agent in  Single_Cross_Straight_MultiDQN_Agents.Agents.items():  \n",
    "    plt.figure('6'+str(idx),figsize=(16, 9))\n",
    "    \n",
    "    Loss_rewarddf = pd.DataFrame()   \n",
    "    \n",
    "    plt.plot(agent.loss)\n",
    "    plt.xlabel('Episode',fontsize=18)\n",
    "    plt.ylabel('Loss',fontsize=18)\n",
    "    plt.title('Agent{} Loss over training'.format(idx),fontsize=18)\n",
    "    plt.gca().legend('Agent Loss over training')\n",
    "    \n",
    "    Path  = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Agent{}_Loss.png\".format(idx)) \n",
    "    plt.savefig(Path)\n",
    "    \n",
    "    csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                           \"Agent{}_Loss_average_reward.csv\".format(idx)) \n",
    "    \n",
    "    \n",
    "    plt.figure('7'+str(idx),figsize=(16, 9))\n",
    "    plt.plot(agent.reward_storage)\n",
    "    plt.xlabel('Episode',fontsize=18)\n",
    "    plt.ylabel('Average reward',fontsize=18)\n",
    "    plt.title('Agent{} average reward over training'.format(idx),fontsize=18)\n",
    "    plt.gca().legend('Agent reward over training')\n",
    "    \n",
    "    Path  = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Agent{}_average_reward.png\".format(idx)) \n",
    "    plt.savefig(Path)\n",
    "    \n",
    "    \n",
    "    episode = [i for i in range(len(agent.reward_storage))]\n",
    "    \n",
    "    Loss_rewarddf['episode'] = episode \n",
    "    Loss_rewarddf['Agent{} loss'.format(idx)] = agent.loss\n",
    "    Loss_rewarddf['Agent{} Average_Reward'.format(idx)] = agent.reward_storage\n",
    "    \n",
    "    Loss_rewarddf.to_csv(csv_Path,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Straight_MultiDQN_Agents.demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Single_Cross_Triple 4 actions AC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_name  = 'Single_Cross_Triple'\n",
    "vissim_working_directory =  'C:\\\\Users\\\\Rzhang\\\\Desktop\\\\MLforFlowOptimisationOrigine\\\\Vissim\\\\'\n",
    "sim_length = 3600\n",
    "\n",
    "agent_type = \"AC\"\n",
    "Session_ID = \"Single_Cross_TripleAC4test1\"\n",
    "\n",
    "# all controller actions\n",
    "Single_Cross_Triple_dictionary4 =\\\n",
    "{\\\n",
    "    # Controller Number 0 \n",
    "   'junctions' : {0 : {'default_actions' :  {    0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             },\n",
    "         \n",
    "         'all_actions' :        {            0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             },\n",
    " \n",
    "         'link' : [1, 3, 5, 7],\n",
    "         'lane' : ['1-1', '1-2', '1-3', '3-1', '3-2', '3-3', '5-1', '5-2', '5-3', '7-1', '7-2', '7-3'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'agent_type' : agent_type,\n",
    "         'green_time' : 6,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [13],\n",
    "         'state_type' : 'QueuesSig',\n",
    "         'reward_type' : 'Queues' \n",
    "         }\n",
    "    },\n",
    "   'demand' : {\"default\" : [400,400,400,400] }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gamma = 0.85\n",
    "alpha = 0.00005\n",
    "\n",
    "\n",
    "value = 0.5\n",
    "entropy = 5000\n",
    "n_step_size = 4\n",
    "state_size = [13]\n",
    "reduce_entropy_every = 100\n",
    "Random_Seed = 100\n",
    "\n",
    "\n",
    "\n",
    "# for the monitoring\n",
    "horizon = 50\n",
    "n_sample = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Triple4_MultiAC_Agents = MasterAC_Agent(model_name, vissim_working_directory, sim_length, Single_Cross_Triple_dictionary4,\\\n",
    "                n_step_size, gamma, alpha, entropy, value, \\\n",
    "                Random_Seed = Random_Seed, timesteps_per_second = 1, Session_ID = Session_ID, verbose = True, \\\n",
    "                 horizon = horizon, n_sample = n_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Triple4_MultiAC_Agents.train(400) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Triple4_MultiAC_Agents.save(401)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Triple4_MultiAC_Agents.load(50, best = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Episode_Queues, Cumulative_Episode_Delays, Cumulative_Totale_network_delay = Single_Cross_Triple4_MultiAC_Agents.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Triple4_MultiAC_Agents.demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Single_Cross_Triple 4 action DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_name  = 'Single_Cross_Triple'\n",
    "vissim_working_directory =  'C:\\\\Users\\\\Rzhang\\\\Desktop\\\\MLforFlowOptimisationOrigine\\\\Vissim\\\\'\n",
    "sim_length = 3601\n",
    "\n",
    "Session_ID = \"Single_Cross_Triple4_actions\"\n",
    "#Session_ID = \"DQN\"\n",
    "\n",
    "agent_type = \"DuelingDDQN\"\n",
    "\n",
    "# all controller actions\n",
    "Single_Cross_Triple_dictionary4 =\\\n",
    "{ 'junctions' : {\n",
    "    # Controller Number 0 \n",
    "    0 : {'default_actions' :    {    0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                     1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                     2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                     3 : [0,0,0,0,0,0,0,0,0,1,1,1]},\n",
    "         \n",
    "         \n",
    "         'all_actions' :       {    0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                     1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                     2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                     3 : [0,0,0,0,0,0,0,0,0,1,1,1]},\n",
    "         \n",
    " \n",
    "         'link' : [1, 3, 5, 7],\n",
    "         'lane' : ['1-1', '1-2', '1-3', '3-1', '3-2', '3-3', '5-1', '5-2', '5-3', '7-1', '7-2', '7-3'],\n",
    "         'controled_by_com' : True,\n",
    "         'agent_type' : agent_type,\n",
    "         'green_time' : 6,\n",
    "         'redamber_time' : 1,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [13],\n",
    "         'state_type' : 'QueuesSig',\n",
    "         'reward_type' : 'Queues' \n",
    "         },\n",
    "        },\n",
    "     'demand' : { 'default' : [400, 400, 400, 400]}\n",
    "                  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## DQN Hyperaramenters\n",
    "episodes = 400\n",
    "copy_weights_frequency = 5\n",
    "\n",
    "PER_activated = True\n",
    "memory_size = 1000\n",
    "batch_size = 128\n",
    "\n",
    "gamma = 0.95\n",
    "alpha = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Exploration Schedule (\"linear\" or \"geometric\")\n",
    "exploration_schedule = \"geometric\"\n",
    "epsilon_start = 1\n",
    "epsilon_end   = 0.001\n",
    "\n",
    "Random_Seed = 100\n",
    "\n",
    "def choose_schedule(exploration_schedule, espilon_start, epsilon_end, episodes):\n",
    "    if exploration_schedule == \"linear\":\n",
    "        epsilon_decay = 1.2*(epsilon_end - epsilon_start)/(episodes-1)\n",
    "        epsilon_sequence = [1 + epsilon_decay * entry for entry in range(episodes+1)]\n",
    "        epsilon_sequence = [0 if entry < 0 else entry for entry in epsilon_sequence]\n",
    "    elif exploration_schedule == \"geometric\":\n",
    "        epsilon_decay = np.power(epsilon_end/epsilon_start, 1./(episodes-1)) # Geometric decay\n",
    "        epsilon_sequence = [epsilon_start * epsilon_decay ** entry for entry in range(episodes+1)]\n",
    "    elif exploration_schedule == \"entropy\":\n",
    "        pass\n",
    "    else:\n",
    "        print(\"ERROR: Unrecognized choice of exploration schedule.\")\n",
    "        \n",
    "    # Plotting exploration schedule\n",
    "    plt.figure(figsize=(8,4.5))\n",
    "    x_series = np.array(range(1,episodes+1))\n",
    "    y_series = epsilon_sequence[0:episodes]\n",
    "    plt.plot(x_series, y_series, '-b')\n",
    "    plt.xlabel('Episodes')\n",
    "    plt.ylabel('Ratio of random exploration')\n",
    "    plt.title('Exploration schedule')\n",
    "    plt.show()\n",
    "    return(epsilon_sequence)\n",
    "\n",
    "epsilon_sequence = choose_schedule(exploration_schedule, epsilon_start, epsilon_end, episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Triple4_MultiDQN_Agents = MasterDQN_Agent(model_name, vissim_working_directory, sim_length, Single_Cross_Triple_dictionary4,\\\n",
    "                gamma, alpha, agent_type, memory_size, PER_activated, batch_size, copy_weights_frequency, epsilon_sequence,\\\n",
    "                Random_Seed = Random_Seed, timesteps_per_second = 1, Session_ID = Session_ID, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Triple4_MultiDQN_Agents.prepopulate_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Triple4_MultiDQN_Agents.train(120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Triple4_MultiDQN_Agents.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Triple4_MultiDQN_Agents.load(best = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Episode_Queues, Cumulative_Episode_Delays, Cumulative_Totale_network_delay = Single_Cross_Triple4_MultiDQN_Agents.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# To be arranged for multy agents\n",
    "\n",
    "queues = np.array(Episode_Queues[0])\n",
    "queues = queues.T\n",
    "\n",
    "delay = Cumulative_Episode_Delays[0]\n",
    "\n",
    "# Plot the queues\n",
    "plt.figure(1)\n",
    "for queue in queues:\n",
    "    plt.plot(queue)\n",
    "\n",
    "# plot the junctions delays\n",
    "plt.figure(2)\n",
    "plt.plot(delay)\n",
    "\n",
    "#plot the total delays \n",
    "plt.figure(3)\n",
    "plt.plot(Cumulative_Totale_network_delay)\n",
    "\n",
    "# Dont freak out the 2 delays are not the same because the node is not covering all the junction\n",
    "\n",
    "\"\"\"\n",
    "Because the cars never leave the nodes the delay is not computed correctly (when the agent doesn't work) \n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(4)\n",
    "plt.plot(Single_Cross_Triple4_MultiDQN_Agents.Agents[0].loss)\n",
    "\n",
    "plt.figure(5)\n",
    "plt.plot(Single_Cross_Triple4_MultiDQN_Agents.Agents[0].reward_storage)\n",
    "print(Single_Cross_Triple4_MultiDQN_Agents.Agents[0].reward_storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Triple4_MultiDQN_Agents.demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Single_Cross_Triple 8 actions AC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_name  = 'Single_Cross_Triple'\n",
    "vissim_working_directory =  'C:\\\\Users\\\\Rzhang\\\\Desktop\\\\MLforFlowOptimisationOrigine\\\\Vissim\\\\'\n",
    "sim_length = 3601\n",
    "\n",
    "agent_type = \"AC\"\n",
    "Session_ID = \"Single_Cross_Triple8_actions_AC10\"\n",
    "\n",
    "# all controller actions\n",
    "Single_Cross_Triple_dictionary8 =\\\n",
    "{\\\n",
    "    # Controller Number 0 \n",
    "   'junctions' : {0 : {'default_actions' :  {    0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    "         \n",
    "         'all_actions' :        {            0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    " \n",
    "         'link' : [1, 3, 5, 7],\n",
    "         'lane' : ['1-1', '1-2', '1-3', '3-1', '3-2', '3-3', '5-1', '5-2', '5-3', '7-1', '7-2', '7-3'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'agent_type' : agent_type,\n",
    "         'green_time' : 6,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [13],\n",
    "         'state_type' : 'QueuesSig',\n",
    "         'reward_type' : 'Queues' ,\n",
    "         'queues_counter_ID' : [1,2,3,4,5,6,7,8,9,10,11,12]             \n",
    "         }\n",
    "    },\n",
    "   'demand' : { 'default' : [400, 400, 400, 400],\n",
    "             \n",
    "             0 : [300,300,300,300],\n",
    "             1 : [600,600,600,600],\n",
    "             2 : [1350,750,1350,750],\n",
    "             3 : [1500,750,1500,750],\n",
    "             4 : [1050,750,1050,750],\n",
    "             5 : [750,1050,750,1050],\n",
    "             6 : [750,1500,750,1500],\n",
    "             7 : [750,1350,750,1350],\n",
    "             8 : [600,600,600,600],\n",
    "             9 : [300,300,300,300]\n",
    "            }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gamma = 0.95\n",
    "alpha = 0.000001\n",
    "\n",
    "\n",
    "value = 5\n",
    "entropy = 500\n",
    "n_step_size = 4\n",
    "state_size = [13]\n",
    "reduce_entropy_every = 100\n",
    "Random_Seed = 100\n",
    "\n",
    "\n",
    "\n",
    "# for the monitoring\n",
    "horizon = 50\n",
    "n_sample = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Triple8_MultiAC_Agents = MasterAC_Agent(model_name, vissim_working_directory, sim_length, Single_Cross_Triple_dictionary8,\\\n",
    "                n_step_size, gamma, alpha, entropy, value, \\\n",
    "                Random_Seed = Random_Seed, timesteps_per_second = 1, Session_ID = Session_ID, verbose = True, \\\n",
    "                 horizon = horizon, n_sample = n_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Triple8_MultiAC_Agents.train(400) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Triple8_MultiAC_Agents.save(401)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Triple8_MultiAC_Agents.load(50, best = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Episode_Queues, Cumulative_Episode_Delays, Cumulative_Totale_network_delay = Single_Cross_Triple8_MultiAC_Agents.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Triple8_MultiAC_Agents.demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Single_Cross_Triple 8 actions DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_name  = 'Single_Cross_Triple'\n",
    "#vissim_working_directory =  'C:\\\\Users\\\\Rzhang\\\\Desktop\\\\MLforFlowOptimisationOrigine\\\\Vissim\\\\'\n",
    "vissim_working_directory = 'C:\\\\Users\\\\acabrejasegea\\\\OneDrive - The Alan Turing Institute\\\\Desktop\\\\ATI\\\\0_TMF\\\\MLforFlowOptimisation\\\\Vissim\\\\'\n",
    "\n",
    "sim_length = 3601\n",
    "\n",
    "agent_type = \"DuelingDDQN\"\n",
    "Session_ID = \"Single_Cross_Triple8_actions_DuelingDDQN20c10\"\n",
    "\n",
    "# all controller actions\n",
    "Single_Cross_Triple_dictionary8 =\\\n",
    "{\\\n",
    "    # Controller Number 0 \n",
    "   'junctions' : {0 : {'default_actions' :  {    0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    "         \n",
    "         'all_actions' :        {            0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    " \n",
    "         'link' : [1, 3, 5, 7],\n",
    "         'lane' : ['1-1', '1-2', '1-3', '3-1', '3-2', '3-3', '5-1', '5-2', '5-3', '7-1', '7-2', '7-3'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'agent_type' : agent_type,\n",
    "         'green_time' : 6,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [13],\n",
    "         'state_type' : 'QueuesSig',\n",
    "         'reward_type' : 'Queues' ,\n",
    "         'queues_counter_ID' : [1,2,3,4,5,6,7,8,9,10,11,12]             \n",
    "         }\n",
    "    },\n",
    "   'demand' : { 'default' : [400, 400, 400, 400],\n",
    "             \n",
    "             0 : [300,300,300,300],\n",
    "             1 : [600,600,600,600],\n",
    "             2 : [1350,750,1350,750],\n",
    "             3 : [1500,750,1500,750],\n",
    "             4 : [1050,750,1050,750],\n",
    "             5 : [750,1050,750,1050],\n",
    "             6 : [750,1500,750,1500],\n",
    "             7 : [750,1350,750,1350],\n",
    "             8 : [600,600,600,600],\n",
    "             9 : [300,300,300,300]\n",
    "            }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## DQN Hyperaramenters\n",
    "episodes = 400 \n",
    "copy_weights_frequency = 20 # On a successfull run I copied the weight every 50\n",
    "\n",
    "PER_activated = True\n",
    "memory_size = 1000\n",
    "batch_size = 128\n",
    "\n",
    "gamma = 0.95\n",
    "alpha = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Exploration Schedule (\"linear\" or \"geometric\")\n",
    "exploration_schedule = \"geometric\"\n",
    "epsilon_start = 1\n",
    "epsilon_end   = 0.001\n",
    "\n",
    "Random_Seed = 100\n",
    "\n",
    "def choose_schedule(exploration_schedule, espilon_start, epsilon_end, episodes):\n",
    "    if exploration_schedule == \"linear\":\n",
    "        epsilon_decay = 1.2*(epsilon_end - epsilon_start)/(episodes-1)\n",
    "        epsilon_sequence = [1 + epsilon_decay * entry for entry in range(episodes+1)]\n",
    "        epsilon_sequence = [0 if entry < 0 else entry for entry in epsilon_sequence]\n",
    "    elif exploration_schedule == \"geometric\":\n",
    "        epsilon_decay = np.power(epsilon_end/epsilon_start, 1./(episodes-1)) # Geometric decay\n",
    "        epsilon_sequence = [epsilon_start * epsilon_decay ** entry for entry in range(episodes+1)]\n",
    "    elif exploration_schedule == \"entropy\":\n",
    "        pass\n",
    "    else:\n",
    "        print(\"ERROR: Unrecognized choice of exploration schedule.\")\n",
    "        \n",
    "    # Plotting exploration schedule\n",
    "    plt.figure(figsize=(8,4.5))\n",
    "    x_series = np.array(range(1,episodes+1))\n",
    "    y_series = epsilon_sequence[0:episodes]\n",
    "    plt.plot(x_series, y_series, '-b')\n",
    "    plt.xlabel('Episodes')\n",
    "    plt.ylabel('Ratio of random exploration')\n",
    "    plt.title('Exploration schedule')\n",
    "    plt.show()\n",
    "    return(epsilon_sequence)\n",
    "\n",
    "epsilon_sequence = choose_schedule(exploration_schedule, epsilon_start, epsilon_end, episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Triple8_MultiDQN_Agents = MasterDQN_Agent(model_name, vissim_working_directory, sim_length, Single_Cross_Triple_dictionary8,\\\n",
    "                gamma, alpha, agent_type, memory_size, PER_activated, batch_size, copy_weights_frequency, epsilon_sequence,\\\n",
    "                Random_Seed = Random_Seed, timesteps_per_second = 1, Session_ID = Session_ID, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Triple8_MultiDQN_Agents.prepopulate_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Triple8_MultiDQN_Agents.train(episodes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Triple8_MultiDQN_Agents.save(401)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Triple8_MultiDQN_Agents.load(400,best = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Episode_Queues, Cumulative_Episode_Delays,Cumulative_Episode_stop_Delays, Cumulative_Totale_network_delay,Cumulative_Totale_network_stop_delay  = Single_Cross_Triple8_MultiDQN_Agents.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "time = [t for t in range(len(Cumulative_Totale_network_stop_delay))]\n",
    "\n",
    "# Queues ovzer time for each junction\n",
    "for idx, queues in Episode_Queues.items():\n",
    "    queues = np.array(queues)\n",
    "    queues = queues.T\n",
    "    \n",
    "    plt.figure('1'+str(idx),figsize=(16, 9))\n",
    "    \n",
    "    Queuesdf = pd.DataFrame()\n",
    "    \n",
    "    Queuesdf['Time'] = time\n",
    "    Queues_legend = []\n",
    "    \n",
    "    for i, queue in enumerate(queues):\n",
    "        plt.plot(queue, label = \"Queue\"+str(i))\n",
    "        Queuesdf[str(i)] = queue\n",
    "        Queues_legend.append(\"Queue\"+str(i))\n",
    "        \n",
    "    plt.xlabel('Time [s]',fontsize=18)\n",
    "    plt.ylabel('Queue Length',fontsize=18)\n",
    "    plt.title('Junction {} Queue length'.format(idx),fontsize=18)\n",
    "    #plt.gca().legend(Queues_legend)\n",
    "    \n",
    "    Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Junction{}_Queues.png\".format(idx))               \n",
    "    plt.savefig(Path)\n",
    "    \n",
    "    csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Junction{}_Queues.csv\".format(idx))        \n",
    "   \n",
    "    Queuesdf.to_csv(csv_Path,index=False)\n",
    "    plt.legend()\n",
    "        \n",
    "        \n",
    "# Accumulated delay over time for each junction\n",
    "for idx, delay in Cumulative_Episode_Delays.items():\n",
    "    \n",
    "    plt.figure('2'+str(idx),figsize=(16, 9))\n",
    "    \n",
    "    delaydf = pd.DataFrame()   \n",
    "    delaydf['Time'] = time\n",
    "    delaydf['Junction {} delay'.format(idx)] = delay\n",
    "    \n",
    "    plt.plot(delay)\n",
    "    plt.xlabel('Time [s]',fontsize=18)\n",
    "    plt.ylabel('Accumulated Delay',fontsize=18)\n",
    "    plt.title('Junction {} Delay'.format(idx),fontsize=18)\n",
    "    plt.gca().legend('Junction accumulated delay')\n",
    "    \n",
    "    Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                            \"Junction{}_Cumulative_Delay.png\".format(idx))\n",
    "    csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Junction{}_Cumulative_Delay.csv\".format(idx))   \n",
    "    plt.savefig(Path)\n",
    "\n",
    "    delaydf.to_csv(csv_Path,index=False)\n",
    "    \n",
    "    \n",
    "# Accumulated stop delay over time for each junction\n",
    "for idx, stop_delay in Cumulative_Episode_stop_Delays.items():\n",
    "    \n",
    "    plt.figure('3'+str(idx),figsize=(16, 9))\n",
    "    \n",
    "    stop_delaydf = pd.DataFrame()   \n",
    "    stop_delaydf['Time'] = time\n",
    "    stop_delaydf['Junction {} stop delay'.format(idx)] = stop_delay\n",
    "\n",
    "    plt.plot(stop_delay)\n",
    "    plt.xlabel('Time [s]',fontsize=18)\n",
    "    plt.ylabel('Accumulated Stop Delay',fontsize=18)\n",
    "    plt.title('Junction {} Stop Delay'.format(idx),fontsize=18)\n",
    "    plt.gca().legend('Junction accumulated Stop delay')\n",
    "    \n",
    "    Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                            \"Junction{}_Cumulative_stop_Delay.png\".format(idx))\n",
    "    csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Junction{}_Cumulative_stop_Delay.csv\".format(idx))\n",
    "    plt.savefig(Path)\n",
    "    stop_delaydf.to_csv(csv_Path,index=False)\n",
    "    \n",
    "# Global Accumulated delay over time\n",
    "plt.figure('4',figsize=(16,9))\n",
    "\n",
    "\n",
    "Global_delaydf = pd.DataFrame()   \n",
    "Global_delaydf['Time'] = time\n",
    "Global_delaydf['Global accumulated Delay'] = Cumulative_Totale_network_delay\n",
    "\n",
    "plt.plot(Cumulative_Totale_network_delay)\n",
    "plt.xlabel('Time [s]',fontsize=18)\n",
    "plt.ylabel('Global accumulated Delay',fontsize=18)\n",
    "plt.title('Global accumulated Delay',fontsize=18)\n",
    "plt.gca().legend('Global accumulated delay')\n",
    "\n",
    "Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Total_Cumulative_Delay.png\")\n",
    "csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Total_Cumulative_Delay.csv\")\n",
    "plt.savefig(Path)\n",
    "Global_delaydf.to_csv(csv_Path,index=False)\n",
    "\n",
    "# Global Accumulated stop delay over time\n",
    "plt.figure('5'+str(idx),figsize=(16, 9))\n",
    "\n",
    "Global_stop_delaydf = pd.DataFrame()   \n",
    "Global_stop_delaydf['Time'] = time\n",
    "Global_stop_delaydf['Global accumulated stop Delay'] = Cumulative_Totale_network_stop_delay\n",
    "\n",
    "plt.plot(Cumulative_Totale_network_stop_delay)\n",
    "plt.xlabel('Time [s]',fontsize=18)\n",
    "plt.ylabel('Global accumulated stop Delay',fontsize=18)\n",
    "plt.title('Global accumulated stop Delay',fontsize=18)\n",
    "plt.gca().legend('Global accumulated stop Delay')\n",
    "\n",
    "Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Total_Cumulative_stop_Delay.png\")\n",
    "csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Total_Cumulative_stop_Delay.csv\")\n",
    "plt.savefig(Path)\n",
    "Global_stop_delaydf.to_csv(csv_Path,index=False)\n",
    "\n",
    "\n",
    "# For the agent training\n",
    "\n",
    "for idx , agent in Single_Cross_Triple8_MultiDQN_Agents.Agents.items():  \n",
    "    plt.figure('6'+str(idx),figsize=(16, 9))\n",
    "    \n",
    "    Loss_rewarddf = pd.DataFrame()   \n",
    "    \n",
    "    plt.plot(agent.loss)\n",
    "    plt.xlabel('Episode',fontsize=18)\n",
    "    plt.ylabel('Loss',fontsize=18)\n",
    "    plt.title('Agent{} Loss over training'.format(idx),fontsize=18)\n",
    "    plt.gca().legend('Agent Loss over training')\n",
    "    \n",
    "    Path  = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Agent{}_Loss.png\".format(idx)) \n",
    "    plt.savefig(Path)\n",
    "    \n",
    "    csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                           \"Agent{}_Loss_average_reward.csv\".format(idx)) \n",
    "    \n",
    "    \n",
    "    plt.figure('7'+str(idx),figsize=(16, 9))\n",
    "    plt.plot(agent.reward_storage)\n",
    "    plt.xlabel('Episode',fontsize=18)\n",
    "    plt.ylabel('Average reward',fontsize=18)\n",
    "    plt.title('Agent{} average reward over training'.format(idx),fontsize=18)\n",
    "    plt.gca().legend('Agent reward over training')\n",
    "    \n",
    "    Path  = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Agent{}_average_reward.png\".format(idx)) \n",
    "    plt.savefig(Path)\n",
    "    \n",
    "    \n",
    "    episode = [i for i in range(len(agent.reward_storage))]\n",
    "    \n",
    "    Loss_rewarddf['episode'] = episode \n",
    "    Loss_rewarddf['Agent{} loss'.format(idx)] = agent.loss\n",
    "    Loss_rewarddf['Agent{} Average_Reward'.format(idx)] = agent.reward_storage\n",
    "    \n",
    "    Loss_rewarddf.to_csv(csv_Path,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Triple8_MultiDQN_Agents.demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Five intersection DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name  = 'Five_intersection'\n",
    "#vissim_working_directory =  'C:\\\\Users\\\\Rzhang\\\\Desktop\\\\MLforFlowOptimisationOrigine\\\\Vissim\\\\'\n",
    "vissim_working_directory = 'C:\\\\Users\\\\acabrejasegea\\\\OneDrive - The Alan Turing Institute\\\\Desktop\\\\ATI\\\\0_TMF\\\\MLforFlowOptimisation\\\\Vissim\\\\'\n",
    "\n",
    "sim_length = 3601\n",
    "\n",
    "agent_type = \"DuelingDDQN\"\n",
    "Session_ID = \"Five5transfert\"\n",
    "\n",
    "# all controller actions\n",
    "Five_intersection_dictionary =\\\n",
    "{\\\n",
    "    # Controller Number 0 \n",
    "   'junctions' : {0 : {'default_actions' :  {    0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    "         \n",
    "         'all_actions' :        {            0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    " \n",
    "         'link' : [],\n",
    "         'lane' : ['11-1', '11-2', '11-3', '12-1', '12-2', '12-3', '13-1', '13-2', '13-3', '14-1', '14-2', '14-3'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'agent_type' : agent_type,\n",
    "         'green_time' : 6,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [13],\n",
    "         'state_type' : 'QueuesSig',\n",
    "         'reward_type' : 'Queues',\n",
    "         'queues_counter_ID' : [1,2,3,4,5,6,7,8,9,10,11,12]\n",
    "         },\n",
    "                  1 : {'default_actions' :  {    0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    "         \n",
    "         'all_actions' :        {            0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    " \n",
    "         'link' : [],\n",
    "         'lane' : ['21-1', '21-2', '21-3', '22-1', '22-2', '22-3', '23-1', '23-2', '23-3', '24-1', '24-2', '24-3'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'agent_type' : agent_type,\n",
    "         'green_time' : 6,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [13],\n",
    "         'state_type' : 'QueuesSig',\n",
    "         'reward_type' : 'Queues' ,\n",
    "        'queues_counter_ID' : [13,14,15,16,17,18,19,20,21,22,23,24]\n",
    "         },\n",
    "                  2 : {'default_actions' :  {    0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    "         \n",
    "         'all_actions' :        {            0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    " \n",
    "         'link' : [],\n",
    "         'lane' : ['31-1', '31-2', '31-3', '32-1', '32-2', '32-3', '33-1', '33-2', '33-3', '34-1', '34-2', '34-3'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'agent_type' : agent_type,\n",
    "         'green_time' : 6,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [13],\n",
    "         'state_type' : 'QueuesSig',\n",
    "         'reward_type' : 'Queues' ,\n",
    "         'queues_counter_ID' : [25,26,27,28,29,30,31,32,33,34,35,36]\n",
    "         },\n",
    "                  3 : {'default_actions' :  {    0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    "         \n",
    "         'all_actions' :        {            0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    " \n",
    "         'link' : [],\n",
    "         'lane' : ['41-1', '41-2', '41-3', '42-1', '42-2', '42-3', '43-1', '43-2', '43-3', '44-1', '44-2', '44-3'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'agent_type' : agent_type,\n",
    "         'green_time' : 6,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [13],\n",
    "         'state_type' : 'QueuesSig',\n",
    "         'reward_type' : 'Queues' ,\n",
    "          'queues_counter_ID' : [37,38,39,40,41,42,43,44,45,46,47,48]\n",
    "         },\n",
    "                  4 : {'default_actions' :  {    0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    "         \n",
    "         'all_actions' :        {            0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    " \n",
    "         'link' : [],\n",
    "         'lane' : ['51-1', '51-2', '51-3', '52-1', '52-2', '52-3', '53-1', '53-2', '53-3', '54-1', '54-2', '54-3'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'agent_type' : agent_type,\n",
    "         'green_time' : 6,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [13],\n",
    "         'state_type' : 'QueuesSig',\n",
    "         'reward_type' : 'Queues' ,\n",
    "         'queues_counter_ID' : [49,50,51,52,53,54,55,56,57,58,59,60]\n",
    "         }\n",
    "    },\n",
    "   'demand' : { 'default' : [400,400,400,400,400,400,400,400,400,400,400,400],\n",
    "             \n",
    "             0 : [200,200,200,200,200,200,200,200,200,200,200,200],\n",
    "             1 : [400,400,400,400,400,400,400,400,400,400,400,400],\n",
    "             2 : [500,900,500,500,900,500,500,900,500,500,900,500],\n",
    "             3 : [500,1000,500,500,1000,500,500,1000,500,500,1000,500],\n",
    "             4 : [500,700,500,500,700,500,500,700,500,500,700,500],\n",
    "             5 : [500,700,500,500,700,500,500,700,500,500,700,500],\n",
    "             6 : [500,1000,500,500,1000,500,500,1000,500,500,1000,500],\n",
    "             7 : [500,900,500,500,900,500,500,900,500,500,900,500],\n",
    "             8 : [400,400,400,400,400,400,400,400,400,400,400,400],\n",
    "             9 : [200,200,200,200,200,200,200,200,200,200,200,200]\n",
    "            }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DQN Hyperaramenters\n",
    "episodes = 400\n",
    "copy_weights_frequency = 20 # On a successfull run I copied the weight every 50\n",
    "\n",
    "PER_activated = True\n",
    "memory_size = 1000\n",
    "batch_size = 128\n",
    "\n",
    "gamma = 0.95\n",
    "alpha = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploration Schedule (\"linear\" or \"geometric\")\n",
    "exploration_schedule = \"geometric\"\n",
    "epsilon_start = 1\n",
    "epsilon_end   = 0.001\n",
    "\n",
    "Random_Seed = 100\n",
    "\n",
    "def choose_schedule(exploration_schedule, espilon_start, epsilon_end, episodes):\n",
    "    if exploration_schedule == \"linear\":\n",
    "        epsilon_decay = 1.2*(epsilon_end - epsilon_start)/(episodes-1)\n",
    "        epsilon_sequence = [1 + epsilon_decay * entry for entry in range(episodes+1)]\n",
    "        epsilon_sequence = [0 if entry < 0 else entry for entry in epsilon_sequence]\n",
    "    elif exploration_schedule == \"geometric\":\n",
    "        epsilon_decay = np.power(epsilon_end/epsilon_start, 1./(episodes-1)) # Geometric decay\n",
    "        epsilon_sequence = [epsilon_start * epsilon_decay ** entry for entry in range(episodes+1)]\n",
    "    elif exploration_schedule == \"entropy\":\n",
    "        pass\n",
    "    else:\n",
    "        print(\"ERROR: Unrecognized choice of exploration schedule.\")\n",
    "        \n",
    "    # Plotting exploration schedule\n",
    "    plt.figure(figsize=(8,4.5))\n",
    "    x_series = np.array(range(1,episodes+1))\n",
    "    y_series = epsilon_sequence[0:episodes]\n",
    "    plt.plot(x_series, y_series, '-b')\n",
    "    plt.xlabel('Episodes')\n",
    "    plt.ylabel('Ratio of random exploration')\n",
    "    plt.title('Exploration schedule')\n",
    "    plt.show()\n",
    "    return(epsilon_sequence)\n",
    "\n",
    "epsilon_sequence = choose_schedule(exploration_schedule, epsilon_start, epsilon_end, episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Five_intersection_MultiDQN_Agents = MasterDQN_Agent(model_name, vissim_working_directory, sim_length, Five_intersection_dictionary,\\\n",
    "                gamma, alpha, agent_type, memory_size, PER_activated, batch_size, copy_weights_frequency, epsilon_sequence,\\\n",
    "                Random_Seed = Random_Seed, timesteps_per_second = 1, Session_ID = Session_ID, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Five_intersection_MultiDQN_Agents.prepopulate_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Five_intersection_MultiDQN_Agents.train(episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Five_intersection_MultiDQN_Agents.save(401)\n",
    "Five_intersection_MultiDQN_Agents.load(400,best = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Five_intersection_MultiDQN_Agents.Agents[0].load_agent(vissim_working_directory, 'Single_Cross_Triple', 'Single_Cross_Triple8_actions',400 , best = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Episode_Queues, Cumulative_Episode_Delays,Cumulative_Episode_stop_Delays, Cumulative_Totale_network_delay,Cumulative_Totale_network_stop_delay = Five_intersection_MultiDQN_Agents.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = [t for t in range(len(Cumulative_Totale_network_stop_delay))]\n",
    "\n",
    "\n",
    "# Queues ovzer time for each junction\n",
    "for idx, queues in Episode_Queues.items():\n",
    "    queues = np.array(queues)\n",
    "    queues = queues.T\n",
    "    \n",
    "    plt.figure('1'+str(idx),figsize=(16, 9))\n",
    "    \n",
    "    Queuesdf = pd.DataFrame()\n",
    "    \n",
    "    Queuesdf['Time'] = time\n",
    "    \n",
    "    for i, queue in enumerate(queues):\n",
    "        plt.plot(queue)\n",
    "        Queuesdf[str(i)] = queue\n",
    "        \n",
    "    plt.xlabel('Time [s]')\n",
    "    plt.ylabel('Queue Length')\n",
    "    plt.title('Junction {} Queue length'.format(idx))\n",
    "    plt.gca().legend(('West Queue','South Queue', 'East Queue', 'North Queue'))\n",
    "    \n",
    "    Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Junction{}_Queues.png\".format(idx))               \n",
    "    plt.savefig(Path)\n",
    "    \n",
    "    csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Junction{}_Queues.csv\".format(idx))        \n",
    "   \n",
    "    Queuesdf.to_csv(csv_Path,index=False)\n",
    "        \n",
    "        \n",
    "# Accumulated delay over time for each junction\n",
    "for idx, delay in Cumulative_Episode_Delays.items():\n",
    "    \n",
    "    plt.figure('2'+str(idx),figsize=(16, 9))\n",
    "    \n",
    "    delaydf = pd.DataFrame()   \n",
    "    delaydf['Time'] = time\n",
    "    delaydf['Junction {} delay'.format(idx)] = delay\n",
    "    \n",
    "    plt.plot(delay)\n",
    "    plt.xlabel('Time [s]')\n",
    "    plt.ylabel('Accumulated Delay')\n",
    "    plt.title('Junction {} Delay'.format(idx))\n",
    "    plt.gca().legend('Junction accumulated delay')\n",
    "    \n",
    "    Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                            \"Junction{}_Cumulative_Delay.png\".format(idx))\n",
    "    csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Junction{}_Cumulative_Delay.csv\".format(idx))   \n",
    "    plt.savefig(Path)\n",
    "\n",
    "    delaydf.to_csv(csv_Path,index=False)\n",
    "    \n",
    "    \n",
    "# Accumulated stop delay over time for each junction\n",
    "for idx, stop_delay in Cumulative_Episode_stop_Delays.items():\n",
    "    \n",
    "    plt.figure('3'+str(idx),figsize=(16, 9))\n",
    "    \n",
    "    stop_delaydf = pd.DataFrame()   \n",
    "    stop_delaydf['Time'] = time\n",
    "    stop_delaydf['Junction {} stop delay'.format(idx)] = stop_delay\n",
    "\n",
    "    plt.plot(stop_delay)\n",
    "    plt.xlabel('Time [s]')\n",
    "    plt.ylabel('Accumulated Stop Delay')\n",
    "    plt.title('Junction {} Stop Delay'.format(idx))\n",
    "    plt.gca().legend('Junction accumulated Stop delay')\n",
    "    \n",
    "    Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                            \"Junction{}_Cumulative_stop_Delay.png\".format(idx))\n",
    "    csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Junction{}_Cumulative_stop_Delay.csv\".format(idx))\n",
    "    plt.savefig(Path)\n",
    "    stop_delaydf.to_csv(csv_Path,index=False)\n",
    "    \n",
    "# Global Accumulated delay over time\n",
    "plt.figure('4',figsize=(16,9))\n",
    "\n",
    "\n",
    "Global_delaydf = pd.DataFrame()   \n",
    "Global_delaydf['Time'] = time\n",
    "Global_delaydf['Global accumulated Delay'] = Cumulative_Totale_network_delay\n",
    "\n",
    "plt.plot(Cumulative_Totale_network_delay)\n",
    "plt.xlabel('Time [s]')\n",
    "plt.ylabel('Global accumulated Delay')\n",
    "plt.title('Global accumulated Delay')\n",
    "plt.gca().legend('Global accumulated delay')\n",
    "\n",
    "Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Total_Cumulative_Delay.png\")\n",
    "csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Total_Cumulative_Delay.csv\")\n",
    "plt.savefig(Path)\n",
    "Global_delaydf.to_csv(csv_Path,index=False)\n",
    "\n",
    "# Global Accumulated stop delay over time\n",
    "plt.figure('5'+str(idx),figsize=(16, 9))\n",
    "\n",
    "Global_stop_delaydf = pd.DataFrame()   \n",
    "Global_stop_delaydf['Time'] = time\n",
    "Global_stop_delaydf['Global accumulated stop Delay'] = Cumulative_Totale_network_stop_delay\n",
    "\n",
    "plt.plot(Cumulative_Totale_network_stop_delay)\n",
    "plt.xlabel('Time [s]')\n",
    "plt.ylabel('Global accumulated stop Delay')\n",
    "plt.title('Global accumulated stop Delay')\n",
    "plt.gca().legend('Global accumulated stop Delay')\n",
    "\n",
    "Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Total_Cumulative_stop_Delay.png\")\n",
    "csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Total_Cumulative_stop_Delay.csv\")\n",
    "plt.savefig(Path)\n",
    "Global_stop_delaydf.to_csv(csv_Path,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Five_intersection_MultiDQN_Agents.Agents[2] = Five_intersection_MultiDQN_Agents.Agents[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Five_intersection_MultiDQN_Agents.demo()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
