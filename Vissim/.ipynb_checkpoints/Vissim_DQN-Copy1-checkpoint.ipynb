{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device: /device:GPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "## VISSIM Modules\n",
    "import win32com.client as com\n",
    "import os\n",
    "\n",
    "## RL Modules\n",
    "import tensorflow as tf\n",
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"ERROR: GPU DEVICE NOT FOUND.\")\n",
    "\n",
    "from keras.models import load_model\n",
    "    \n",
    "## Data Management Modules\n",
    "import pickle\n",
    "\n",
    "## User Defined Modules\n",
    "import Simulator_Functions as SF\n",
    "\n",
    "from RLAgents import DQNAgent\n",
    "from NParser import NetworkParser\n",
    "from COMServer import COMServerDispatch, COMServerReload\n",
    "from TupleToList import toList\n",
    "## Other Modules\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Network Model Parameters\n",
    "Random_Seed = 42\n",
    "model_name  = 'Single_Cross_Straight'\n",
    "vissim_working_directory = 'C:\\\\Users\\\\acabrejasegea\\\\OneDrive - The Alan Turing Institute\\\\Desktop\\\\ATI\\\\0_TMF\\\\MLforFlowOptimisation\\\\Vissim\\\\'\n",
    "program = 'DuelingDDQN' # DQN, DuelingDQN, DDQN, DuelingDDQN\n",
    "reward_type = 'Queues'\n",
    "state_type  = 'Queues'\n",
    "## Use of additional files?\n",
    "flag_read_additionally  = False\n",
    "## Load trained model?\n",
    "Demo_Mode = False\n",
    "load_trained = False\n",
    "Quickmode = True\n",
    "SaveResultsAgent = True\n",
    "# Random demand\n",
    "Random_Demand = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data handling flags\n",
    "# Flag for restarting the COM Server\n",
    "reset_flag = True\n",
    "#cache_flag = False\n",
    "# If a fresh start is needed, all previous results from simulations are deleted\n",
    "Start_Fresh = True\n",
    "# Debug action\n",
    "debug_action = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RL Hyperparamenters\n",
    "# Number of simulations, save every \"n\" episodes and copy weights with frequency \"f\"\n",
    "episodes = 200\n",
    "partial_save_at = 10\n",
    "copy_weights_frequency = 5\n",
    "reset_frequency = 10\n",
    "# Timesteps per simulation (1 timestep = 0.1 sec), length for random population is a multiple of episode\n",
    "simulation_length = 36000*1\n",
    "memory_population_length = simulation_length*5\n",
    "## State-Action Parameters\n",
    "state_size = 4\n",
    "action_size = 5\n",
    "# Memory Size\n",
    "memory_size = 5000\n",
    "# Batch Size\n",
    "batch_size = 128\n",
    "# Learning Rate\n",
    "alpha   = 0.0001\n",
    "# Discount Factor\n",
    "gamma   = 0.9\n",
    "# Exploration Schedule\n",
    "epsilon_start = 1\n",
    "epsilon_end   = 0.01\n",
    "epsilon_decay = (epsilon_end - epsilon_start)/episodes\n",
    "#epsilon_decay = np.power(epsilon_end/epsilon_start, 1./(episodes+1)) # Geometric decay\n",
    "# Demand Schedule\n",
    "demands = [100, 200, 400, 600, 800, 1000]\n",
    "# Session ID\n",
    "Session_ID = 'Episodes'+str(episodes)+'_Program'+program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working Directory set to: C:\\Users\\acabrejasegea\\OneDrive - The Alan Turing Institute\\Desktop\\ATI\\0_TMF\\MLforFlowOptimisation\\Vissim\\\n",
      "Generating Cache...\n",
      "Cache generated.\n",
      "\n",
      "****************************\n",
      "*   COM Server dispatched  *\n",
      "****************************\n",
      "\n",
      "Loading Model File: Single_Cross_Straight.inpx ...\n",
      "Load process successful\n",
      "Simulation length set to 18000.0 seconds.\n",
      "Results from Previous Simulations: Deleted. Fresh Start Available.\n",
      "Fetched and containerized Simulation Object\n",
      "Fetched and containerized Network Object \n",
      "\n",
      "*******************************************************\n",
      "*                                                     *\n",
      "*                 SETUP COMPLETE                      *\n",
      "*                                                     *\n",
      "*******************************************************\n",
      "\n",
      "Random seed set in simulator. Random Seed = 42\n",
      "NetworkParser has succesfully crawled the model network.\n",
      "Deploying instance of Dueling Double Deep Q Learning Agent(s)\n",
      "Deployed 1 agent(s) of the Class DuelingDDQN.\n",
      "Populating memory with Random Actions....\n",
      "Episode: 1/200, Epsilon:1, Average reward: -52.95\n",
      "Prediction for [500,0,500,0] is: [[-246.53227 -489.22046 -268.00333 -442.75916 -428.25574]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 2/200, Epsilon:1.0, Average reward: -213.12\n",
      "Prediction for [500,0,500,0] is: [[-295.02954 -530.0299  -310.1613  -488.0218  -474.18262]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 3/200, Epsilon:0.99, Average reward: -112.92\n",
      "Prediction for [500,0,500,0] is: [[-344.90723 -579.41223 -359.53027 -538.7968  -522.809  ]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 4/200, Epsilon:0.99, Average reward: -181.74\n",
      "Prediction for [500,0,500,0] is: [[-391.84207 -621.30945 -411.9912  -581.77704 -567.79364]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 5/200, Epsilon:0.98, Average reward: -288.32\n",
      "Prediction for [500,0,500,0] is: [[-435.96832 -659.36694 -458.3191  -625.9944  -608.2538 ]]\n",
      "Weights succesfully copied to Target model.\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 6/200, Epsilon:0.98, Average reward: -120.5\n",
      "Prediction for [500,0,500,0] is: [[-467.86658 -693.0533  -490.53235 -663.9585  -645.0977 ]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 7/200, Epsilon:0.97, Average reward: -18.26\n",
      "Prediction for [500,0,500,0] is: [[-501.6464  -731.62445 -528.8666  -702.63257 -680.4668 ]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 8/200, Epsilon:0.97, Average reward: -403.45\n",
      "Prediction for [500,0,500,0] is: [[-537.1592  -767.41785 -569.3624  -740.5723  -719.9129 ]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 9/200, Epsilon:0.96, Average reward: -161.42\n",
      "Prediction for [500,0,500,0] is: [[-587.4455  -812.85376 -616.37683 -783.1758  -762.8545 ]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 10/200, Epsilon:0.96, Average reward: -46.81\n",
      "Prediction for [500,0,500,0] is: [[-627.5181  -852.27057 -660.5515  -827.20325 -802.80597]]\n",
      "Weights succesfully copied to Target model.\n",
      "Saving architecture, weights and optimizer state for agent-0\n",
      "Dumping agent-0 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Model, architecture, weights, optimizer, memory and training results succesfully saved. Succesfully Terminated.\n",
      "Saved Partial results at the end of episode 10.\n",
      "Sever Redispatched.\n",
      "Redispatched\n",
      "Episode: 11/200, Epsilon:0.95, Average reward: -124.94\n",
      "Prediction for [500,0,500,0] is: [[-656.91125 -880.28357 -690.0117  -850.8108  -826.07446]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 12/200, Epsilon:0.95, Average reward: -53.68\n",
      "Prediction for [500,0,500,0] is: [[-696.448   -917.73944 -731.3635  -889.53156 -861.8999 ]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 13/200, Epsilon:0.94, Average reward: -187.59\n",
      "Prediction for [500,0,500,0] is: [[-738.34424 -951.4487  -776.6362  -929.3606  -896.81976]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 14/200, Epsilon:0.94, Average reward: -75.26\n",
      "Prediction for [500,0,500,0] is: [[-778.16125 -990.3319  -818.3103  -980.2379  -943.0981 ]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 15/200, Epsilon:0.93, Average reward: -17.78\n",
      "Prediction for [500,0,500,0] is: [[ -816.0546 -1024.9467  -860.352  -1017.6286  -986.9889]]\n",
      "Weights succesfully copied to Target model.\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 16/200, Epsilon:0.93, Average reward: -38.72\n",
      "Prediction for [500,0,500,0] is: [[ -851.5136  -1066.6884   -907.50256 -1058.0876  -1028.149  ]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 17/200, Epsilon:0.92, Average reward: -29.26\n",
      "Prediction for [500,0,500,0] is: [[ -902.19446 -1108.0105   -957.628   -1105.8618  -1081.829  ]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 18/200, Epsilon:0.92, Average reward: -142.45\n",
      "Prediction for [500,0,500,0] is: [[ -944.2384  -1148.4374  -1004.45276 -1151.8983  -1133.182  ]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 19/200, Epsilon:0.91, Average reward: -207.23\n",
      "Prediction for [500,0,500,0] is: [[ -980.2958 -1186.2131 -1044.9319 -1187.7163 -1168.842 ]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 20/200, Epsilon:0.91, Average reward: -22.11\n",
      "Prediction for [500,0,500,0] is: [[-1018.3032 -1225.4069 -1082.8971 -1229.8169 -1212.7422]]\n",
      "Weights succesfully copied to Target model.\n",
      "Saving architecture, weights and optimizer state for agent-0\n",
      "Dumping agent-0 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Model, architecture, weights, optimizer, memory and training results succesfully saved. Succesfully Terminated.\n",
      "Saved Partial results at the end of episode 20.\n",
      "Sever Redispatched.\n",
      "Redispatched\n",
      "Episode: 21/200, Epsilon:0.9, Average reward: -232.91\n",
      "Prediction for [500,0,500,0] is: [[-1061.852  -1263.9366 -1124.0781 -1265.6217 -1247.183 ]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 22/200, Epsilon:0.9, Average reward: -245.92\n",
      "Prediction for [500,0,500,0] is: [[-1100.99   -1294.6411 -1167.5653 -1308.8699 -1285.8835]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 23/200, Epsilon:0.89, Average reward: -56.85\n",
      "Prediction for [500,0,500,0] is: [[-1165.8599 -1361.7828 -1227.5195 -1375.1608 -1354.0879]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 24/200, Epsilon:0.89, Average reward: -247.11\n",
      "Prediction for [500,0,500,0] is: [[-1191.7441 -1393.199  -1255.0769 -1401.0021 -1380.9956]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 25/200, Epsilon:0.88, Average reward: -60.01\n",
      "Prediction for [500,0,500,0] is: [[-1226.8444 -1428.7247 -1294.9906 -1429.3632 -1418.1124]]\n",
      "Weights succesfully copied to Target model.\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 26/200, Epsilon:0.88, Average reward: -221.26\n",
      "Prediction for [500,0,500,0] is: [[-1259.8173 -1464.8511 -1328.6783 -1467.3131 -1449.3909]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 27/200, Epsilon:0.87, Average reward: -111.87\n",
      "Prediction for [500,0,500,0] is: [[-1312.0438 -1521.2375 -1391.3859 -1520.2988 -1509.3741]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 28/200, Epsilon:0.87, Average reward: -217.27\n",
      "Prediction for [500,0,500,0] is: [[-1378.5964 -1584.6478 -1465.7432 -1578.5029 -1576.5887]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 29/200, Epsilon:0.86, Average reward: -84.52\n",
      "Prediction for [500,0,500,0] is: [[-1445.3002 -1639.9967 -1530.323  -1634.3495 -1628.0122]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 30/200, Epsilon:0.86, Average reward: -180.26\n",
      "Prediction for [500,0,500,0] is: [[-1466.7654 -1656.8899 -1557.162  -1652.8591 -1652.1133]]\n",
      "Weights succesfully copied to Target model.\n",
      "Saving architecture, weights and optimizer state for agent-0\n",
      "Dumping agent-0 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Model, architecture, weights, optimizer, memory and training results succesfully saved. Succesfully Terminated.\n",
      "Saved Partial results at the end of episode 30.\n",
      "Sever Redispatched.\n",
      "Redispatched\n",
      "Episode: 31/200, Epsilon:0.85, Average reward: -81.79\n",
      "Prediction for [500,0,500,0] is: [[-1505.6975 -1698.3029 -1596.9137 -1699.8367 -1698.6335]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 32/200, Epsilon:0.85, Average reward: -95.66\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for [500,0,500,0] is: [[-1568.1525 -1763.7385 -1670.2191 -1755.6902 -1758.404 ]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 33/200, Epsilon:0.84, Average reward: -34.45\n",
      "Prediction for [500,0,500,0] is: [[-1622.3274 -1812.8846 -1716.6942 -1811.3569 -1809.9363]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 34/200, Epsilon:0.84, Average reward: -129.45\n",
      "Prediction for [500,0,500,0] is: [[-1654.81   -1846.2216 -1752.4712 -1847.9187 -1842.5908]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 35/200, Epsilon:0.83, Average reward: -109.47\n",
      "Prediction for [500,0,500,0] is: [[-1677.1102 -1869.8575 -1772.2382 -1873.643  -1863.293 ]]\n",
      "Weights succesfully copied to Target model.\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 36/200, Epsilon:0.83, Average reward: -103.01\n",
      "Prediction for [500,0,500,0] is: [[-1726.1952 -1918.9298 -1826.539  -1922.5018 -1910.9967]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 37/200, Epsilon:0.82, Average reward: -205.33\n",
      "Prediction for [500,0,500,0] is: [[-1803.7367 -1989.7245 -1906.8201 -1992.8677 -1980.4893]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 38/200, Epsilon:0.82, Average reward: -76.41\n",
      "Prediction for [500,0,500,0] is: [[-1856.5166 -2030.594  -1947.249  -2035.4633 -2027.5502]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 39/200, Epsilon:0.81, Average reward: -93.6\n",
      "Prediction for [500,0,500,0] is: [[-1898.7605 -2058.7295 -1975.569  -2066.486  -2054.3142]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 40/200, Epsilon:0.81, Average reward: -70.34\n",
      "Prediction for [500,0,500,0] is: [[-1936.1868 -2087.2468 -2012.2974 -2094.5073 -2082.9067]]\n",
      "Weights succesfully copied to Target model.\n",
      "Saving architecture, weights and optimizer state for agent-0\n",
      "Dumping agent-0 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Model, architecture, weights, optimizer, memory and training results succesfully saved. Succesfully Terminated.\n",
      "Saved Partial results at the end of episode 40.\n",
      "Sever Redispatched.\n",
      "Redispatched\n",
      "Episode: 41/200, Epsilon:0.8, Average reward: -118.88\n",
      "Prediction for [500,0,500,0] is: [[-1979.3656 -2131.4275 -2045.6434 -2146.472  -2125.0017]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 42/200, Epsilon:0.8, Average reward: -116.06\n",
      "Prediction for [500,0,500,0] is: [[-2024.0725 -2177.1924 -2099.8833 -2190.3086 -2174.56  ]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 43/200, Epsilon:0.79, Average reward: -25.04\n",
      "Prediction for [500,0,500,0] is: [[-2093.587  -2242.3552 -2159.0938 -2252.194  -2238.1584]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 44/200, Epsilon:0.79, Average reward: -144.06\n",
      "Prediction for [500,0,500,0] is: [[-2114.636  -2253.3242 -2177.9685 -2262.3667 -2253.5613]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 45/200, Epsilon:0.78, Average reward: -199.52\n",
      "Prediction for [500,0,500,0] is: [[-2136.2134 -2282.8674 -2206.498  -2293.585  -2293.8562]]\n",
      "Weights succesfully copied to Target model.\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 46/200, Epsilon:0.78, Average reward: -56.93\n",
      "Prediction for [500,0,500,0] is: [[-2192.5598 -2341.5723 -2269.4812 -2351.4338 -2350.0227]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 47/200, Epsilon:0.77, Average reward: -31.8\n",
      "Prediction for [500,0,500,0] is: [[-2272.1257 -2406.9644 -2334.3682 -2419.897  -2420.3103]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 48/200, Epsilon:0.77, Average reward: -94.32\n",
      "Prediction for [500,0,500,0] is: [[-2279.2534 -2413.7844 -2337.6738 -2423.554  -2424.9653]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 49/200, Epsilon:0.76, Average reward: -199.06\n",
      "Prediction for [500,0,500,0] is: [[-2300.9888 -2426.826  -2365.027  -2441.8857 -2443.1558]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 50/200, Epsilon:0.76, Average reward: -218.22\n",
      "Prediction for [500,0,500,0] is: [[-2322.5796 -2432.458  -2393.47   -2435.8418 -2455.5432]]\n",
      "Weights succesfully copied to Target model.\n",
      "Saving architecture, weights and optimizer state for agent-0\n",
      "Dumping agent-0 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Model, architecture, weights, optimizer, memory and training results succesfully saved. Succesfully Terminated.\n",
      "Saved Partial results at the end of episode 50.\n",
      "Sever Redispatched.\n",
      "Redispatched\n",
      "Episode: 51/200, Epsilon:0.75, Average reward: -216.85\n",
      "Prediction for [500,0,500,0] is: [[-2369.9941 -2467.2388 -2433.8455 -2472.3252 -2491.7808]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 52/200, Epsilon:0.75, Average reward: -18.0\n",
      "Prediction for [500,0,500,0] is: [[-2428.822  -2510.385  -2482.8772 -2529.4265 -2533.984 ]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 53/200, Epsilon:0.74, Average reward: -65.79\n",
      "Prediction for [500,0,500,0] is: [[-2486.8743 -2569.2888 -2539.5376 -2581.4092 -2592.5327]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 54/200, Epsilon:0.74, Average reward: -161.98\n",
      "Prediction for [500,0,500,0] is: [[-2527.4844 -2614.4062 -2577.3691 -2623.6587 -2631.8352]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 55/200, Epsilon:0.73, Average reward: -215.04\n",
      "Prediction for [500,0,500,0] is: [[-2530.5398 -2605.5266 -2572.0376 -2619.5735 -2625.5525]]\n",
      "Weights succesfully copied to Target model.\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 56/200, Epsilon:0.73, Average reward: -83.14\n",
      "Prediction for [500,0,500,0] is: [[-2545.4504 -2610.7861 -2582.6357 -2636.3384 -2637.9229]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 57/200, Epsilon:0.72, Average reward: -60.82\n",
      "Prediction for [500,0,500,0] is: [[-2608.2563 -2654.6138 -2627.8423 -2686.1511 -2679.5562]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 58/200, Epsilon:0.72, Average reward: -194.64\n",
      "Prediction for [500,0,500,0] is: [[-2657.8665 -2690.57   -2667.2207 -2722.5027 -2719.1218]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 59/200, Epsilon:0.71, Average reward: -120.63\n",
      "Prediction for [500,0,500,0] is: [[-2686.2388 -2723.8198 -2687.9429 -2764.6167 -2749.9502]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 60/200, Epsilon:0.71, Average reward: -209.71\n",
      "Prediction for [500,0,500,0] is: [[-2725.6943 -2764.2961 -2721.2358 -2804.4053 -2785.8125]]\n",
      "Weights succesfully copied to Target model.\n",
      "Saving architecture, weights and optimizer state for agent-0\n",
      "Dumping agent-0 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Model, architecture, weights, optimizer, memory and training results succesfully saved. Succesfully Terminated.\n",
      "Saved Partial results at the end of episode 60.\n",
      "Sever Redispatched.\n",
      "Redispatched\n",
      "Episode: 61/200, Epsilon:0.7, Average reward: -161.81\n",
      "Prediction for [500,0,500,0] is: [[-2768.2222 -2799.7568 -2764.3936 -2846.3826 -2826.9824]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 62/200, Epsilon:0.7, Average reward: -142.68\n",
      "Prediction for [500,0,500,0] is: [[-2803.9143 -2834.5535 -2801.162  -2880.189  -2860.5535]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 63/200, Epsilon:0.69, Average reward: -28.49\n",
      "Prediction for [500,0,500,0] is: [[-2862.571  -2893.389  -2868.2231 -2923.29   -2907.2007]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 64/200, Epsilon:0.69, Average reward: -176.45\n",
      "Prediction for [500,0,500,0] is: [[-2932.1172 -2958.4507 -2928.9927 -2985.446  -2966.352 ]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 65/200, Epsilon:0.68, Average reward: -297.03\n",
      "Prediction for [500,0,500,0] is: [[-2978.7603 -3001.5981 -2971.789  -3037.595  -3002.5964]]\n",
      "Weights succesfully copied to Target model.\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 66/200, Epsilon:0.68, Average reward: -141.9\n",
      "Prediction for [500,0,500,0] is: [[-3028.575  -3041.902  -3021.7317 -3079.7732 -3041.6658]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 67/200, Epsilon:0.67, Average reward: -143.83\n",
      "Prediction for [500,0,500,0] is: [[-3088.1245 -3096.4656 -3083.4258 -3127.208  -3101.9382]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 68/200, Epsilon:0.67, Average reward: -136.14\n",
      "Prediction for [500,0,500,0] is: [[-3141.0586 -3136.3062 -3121.0774 -3174.7954 -3140.4282]]\n",
      "Reloading complete. Executing new episode...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 69/200, Epsilon:0.66, Average reward: -187.96\n",
      "Prediction for [500,0,500,0] is: [[-3159.1333 -3165.438  -3146.4902 -3208.9407 -3179.1372]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 70/200, Epsilon:0.66, Average reward: -105.64\n",
      "Prediction for [500,0,500,0] is: [[-3185.0405 -3217.5474 -3195.4492 -3249.0906 -3224.8743]]\n",
      "Weights succesfully copied to Target model.\n",
      "Saving architecture, weights and optimizer state for agent-0\n",
      "Dumping agent-0 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Model, architecture, weights, optimizer, memory and training results succesfully saved. Succesfully Terminated.\n",
      "Saved Partial results at the end of episode 70.\n",
      "Sever Redispatched.\n",
      "Redispatched\n",
      "Episode: 71/200, Epsilon:0.65, Average reward: -30.52\n",
      "Prediction for [500,0,500,0] is: [[-3213.9563 -3241.6804 -3221.8552 -3274.4802 -3252.4446]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 72/200, Epsilon:0.65, Average reward: -113.07\n",
      "Prediction for [500,0,500,0] is: [[-3238.4685 -3279.5771 -3252.753  -3303.6    -3287.6829]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 73/200, Epsilon:0.64, Average reward: -134.3\n",
      "Prediction for [500,0,500,0] is: [[-3305.0466 -3345.3372 -3320.9846 -3373.1416 -3357.416 ]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 74/200, Epsilon:0.64, Average reward: -108.96\n",
      "Prediction for [500,0,500,0] is: [[-3257.9358 -3317.9692 -3290.6526 -3346.292  -3329.2048]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 75/200, Epsilon:0.63, Average reward: -165.21\n",
      "Prediction for [500,0,500,0] is: [[-3320.8857 -3375.2285 -3362.3755 -3396.564  -3377.013 ]]\n",
      "Weights succesfully copied to Target model.\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 76/200, Epsilon:0.63, Average reward: -65.75\n",
      "Prediction for [500,0,500,0] is: [[-3332.6345 -3380.233  -3362.866  -3402.9573 -3381.0325]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 77/200, Epsilon:0.62, Average reward: -224.49\n",
      "Prediction for [500,0,500,0] is: [[-3320.269  -3364.5618 -3363.0732 -3389.0083 -3377.012 ]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 78/200, Epsilon:0.62, Average reward: -38.19\n",
      "Prediction for [500,0,500,0] is: [[-3347.2178 -3392.3958 -3393.1123 -3417.9321 -3402.9688]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 79/200, Epsilon:0.61, Average reward: -86.7\n",
      "Prediction for [500,0,500,0] is: [[-3369.594  -3405.4985 -3412.9905 -3437.6755 -3419.7407]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 80/200, Epsilon:0.61, Average reward: -67.94\n",
      "Prediction for [500,0,500,0] is: [[-3403.5684 -3435.7122 -3438.6016 -3465.247  -3439.3171]]\n",
      "Weights succesfully copied to Target model.\n",
      "Saving architecture, weights and optimizer state for agent-0\n",
      "Dumping agent-0 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Model, architecture, weights, optimizer, memory and training results succesfully saved. Succesfully Terminated.\n",
      "Saved Partial results at the end of episode 80.\n",
      "Sever Redispatched.\n",
      "Redispatched\n",
      "Episode: 81/200, Epsilon:0.6, Average reward: -227.46\n",
      "Prediction for [500,0,500,0] is: [[-3412.4167 -3448.0652 -3449.986  -3470.5952 -3449.126 ]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 82/200, Epsilon:0.6, Average reward: -136.09\n",
      "Prediction for [500,0,500,0] is: [[-3420.4626 -3446.219  -3459.5732 -3470.8765 -3461.2646]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 83/200, Epsilon:0.59, Average reward: -54.99\n",
      "Prediction for [500,0,500,0] is: [[-3452.639  -3472.029  -3501.6465 -3501.057  -3491.5022]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 84/200, Epsilon:0.59, Average reward: -89.86\n",
      "Prediction for [500,0,500,0] is: [[-3484.5193 -3501.5493 -3539.8855 -3536.775  -3531.7678]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 85/200, Epsilon:0.58, Average reward: -244.86\n",
      "Prediction for [500,0,500,0] is: [[-3498.5066 -3514.585  -3561.7178 -3553.4717 -3541.5764]]\n",
      "Weights succesfully copied to Target model.\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 86/200, Epsilon:0.58, Average reward: -83.83\n",
      "Prediction for [500,0,500,0] is: [[-3526.4985 -3541.1106 -3594.4326 -3579.922  -3567.692 ]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 87/200, Epsilon:0.57, Average reward: -151.56\n",
      "Prediction for [500,0,500,0] is: [[-3602.3157 -3610.2793 -3667.053  -3658.009  -3644.1777]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 88/200, Epsilon:0.57, Average reward: -222.84\n",
      "Prediction for [500,0,500,0] is: [[-3641.7131 -3643.119  -3702.2773 -3694.3645 -3685.0376]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 89/200, Epsilon:0.56, Average reward: -39.76\n",
      "Prediction for [500,0,500,0] is: [[-3678.3445 -3678.723  -3736.4731 -3732.9082 -3733.8418]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 90/200, Epsilon:0.56, Average reward: -153.74\n",
      "Prediction for [500,0,500,0] is: [[-3649.5825 -3658.0867 -3706.3252 -3707.2383 -3713.799 ]]\n",
      "Weights succesfully copied to Target model.\n",
      "Saving architecture, weights and optimizer state for agent-0\n",
      "Dumping agent-0 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Model, architecture, weights, optimizer, memory and training results succesfully saved. Succesfully Terminated.\n",
      "Saved Partial results at the end of episode 90.\n",
      "Sever Redispatched.\n",
      "Redispatched\n",
      "Episode: 91/200, Epsilon:0.55, Average reward: -122.72\n",
      "Prediction for [500,0,500,0] is: [[-3624.1433 -3625.164  -3680.2034 -3685.7363 -3689.5625]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 92/200, Epsilon:0.55, Average reward: -253.56\n",
      "Prediction for [500,0,500,0] is: [[-3667.3684 -3679.1736 -3729.227  -3753.5732 -3757.3057]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 93/200, Epsilon:0.54, Average reward: -352.25\n",
      "Prediction for [500,0,500,0] is: [[-3698.0115 -3694.0933 -3754.2827 -3786.7275 -3791.9998]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 94/200, Epsilon:0.54, Average reward: -27.96\n",
      "Prediction for [500,0,500,0] is: [[-3756.5322 -3737.64   -3800.9622 -3835.6367 -3835.8025]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 95/200, Epsilon:0.53, Average reward: -57.83\n",
      "Prediction for [500,0,500,0] is: [[-3799.2    -3778.1462 -3844.9202 -3880.2866 -3879.5576]]\n",
      "Weights succesfully copied to Target model.\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 96/200, Epsilon:0.53, Average reward: -102.92\n",
      "Prediction for [500,0,500,0] is: [[-3832.5918 -3803.1401 -3857.8628 -3905.3088 -3903.4988]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 97/200, Epsilon:0.52, Average reward: -184.64\n",
      "Prediction for [500,0,500,0] is: [[-3853.994  -3834.7732 -3885.9075 -3937.274  -3940.6006]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 98/200, Epsilon:0.52, Average reward: -104.58\n",
      "Prediction for [500,0,500,0] is: [[-3912.944  -3888.42   -3947.4844 -3990.6892 -4007.5154]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 99/200, Epsilon:0.51, Average reward: -52.97\n",
      "Prediction for [500,0,500,0] is: [[-3965.7593 -3933.7358 -3991.6465 -4038.604  -4056.148 ]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 100/200, Epsilon:0.51, Average reward: -60.99\n",
      "Prediction for [500,0,500,0] is: [[-4000.2603 -3958.208  -4019.991  -4061.1587 -4083.9   ]]\n",
      "Weights succesfully copied to Target model.\n",
      "Saving architecture, weights and optimizer state for agent-0\n",
      "Dumping agent-0 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Model, architecture, weights, optimizer, memory and training results succesfully saved. Succesfully Terminated.\n",
      "Saved Partial results at the end of episode 100.\n",
      "Sever Redispatched.\n",
      "Redispatched\n",
      "Episode: 101/200, Epsilon:0.5, Average reward: -44.74\n",
      "Prediction for [500,0,500,0] is: [[-4014.5042 -3977.2783 -4040.5085 -4085.624  -4109.9424]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 102/200, Epsilon:0.5, Average reward: -85.58\n",
      "Prediction for [500,0,500,0] is: [[-4086.8997 -4049.366  -4116.499  -4162.0786 -4196.682 ]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 103/200, Epsilon:0.5, Average reward: -293.29\n",
      "Prediction for [500,0,500,0] is: [[-4116.0503 -4073.4072 -4150.5825 -4189.5884 -4234.1997]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 104/200, Epsilon:0.49, Average reward: -52.09\n",
      "Prediction for [500,0,500,0] is: [[-4197.24   -4151.5977 -4235.6465 -4274.569  -4313.8833]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading complete. Executing new episode...\n",
      "Episode: 105/200, Epsilon:0.49, Average reward: -63.94\n",
      "Prediction for [500,0,500,0] is: [[-4162.013  -4103.7534 -4200.439  -4229.6133 -4282.0796]]\n",
      "Weights succesfully copied to Target model.\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 106/200, Epsilon:0.48, Average reward: -114.01\n",
      "Prediction for [500,0,500,0] is: [[-4163.2036 -4101.888  -4195.8916 -4236.573  -4284.816 ]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 107/200, Epsilon:0.48, Average reward: -250.23\n",
      "Prediction for [500,0,500,0] is: [[-4151.851  -4092.7957 -4181.6284 -4229.945  -4278.0625]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 108/200, Epsilon:0.47, Average reward: -252.9\n",
      "Prediction for [500,0,500,0] is: [[-4230.546  -4165.097  -4251.9585 -4305.985  -4354.16  ]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 109/200, Epsilon:0.47, Average reward: -65.04\n",
      "Prediction for [500,0,500,0] is: [[-4292.148  -4221.403  -4312.2207 -4372.724  -4422.7056]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 110/200, Epsilon:0.46, Average reward: -199.36\n",
      "Prediction for [500,0,500,0] is: [[-4300.516  -4233.129  -4333.4404 -4371.1133 -4439.118 ]]\n",
      "Weights succesfully copied to Target model.\n",
      "Saving architecture, weights and optimizer state for agent-0\n",
      "Dumping agent-0 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Model, architecture, weights, optimizer, memory and training results succesfully saved. Succesfully Terminated.\n",
      "Saved Partial results at the end of episode 110.\n",
      "Sever Redispatched.\n",
      "Redispatched\n",
      "Episode: 111/200, Epsilon:0.46, Average reward: -90.43\n",
      "Prediction for [500,0,500,0] is: [[-4261.341  -4189.1313 -4297.4634 -4329.2134 -4389.045 ]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 112/200, Epsilon:0.45, Average reward: -64.07\n",
      "Prediction for [500,0,500,0] is: [[-4314.5913 -4224.9663 -4342.9365 -4369.2964 -4435.7803]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 113/200, Epsilon:0.45, Average reward: -149.17\n",
      "Prediction for [500,0,500,0] is: [[-4317.6777 -4244.596  -4366.918  -4398.972  -4462.3   ]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 114/200, Epsilon:0.44, Average reward: -189.62\n",
      "Prediction for [500,0,500,0] is: [[-4314.8384 -4234.9077 -4364.981  -4394.0376 -4462.605 ]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 115/200, Epsilon:0.44, Average reward: -82.92\n",
      "Prediction for [500,0,500,0] is: [[-4342.397  -4255.5425 -4379.7886 -4415.513  -4485.3555]]\n",
      "Weights succesfully copied to Target model.\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 116/200, Epsilon:0.43, Average reward: -220.03\n",
      "Prediction for [500,0,500,0] is: [[-4297.56   -4227.124  -4335.8745 -4390.17   -4459.8545]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 117/200, Epsilon:0.43, Average reward: -187.26\n",
      "Prediction for [500,0,500,0] is: [[-4296.277  -4214.1895 -4314.5625 -4381.225  -4451.5146]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 118/200, Epsilon:0.42, Average reward: -192.7\n",
      "Prediction for [500,0,500,0] is: [[-4283.913  -4212.072  -4314.432  -4383.8345 -4455.895 ]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 119/200, Epsilon:0.42, Average reward: -188.19\n",
      "Prediction for [500,0,500,0] is: [[-4302.8213 -4222.7427 -4333.8276 -4399.1987 -4477.501 ]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 120/200, Epsilon:0.41, Average reward: -114.9\n",
      "Prediction for [500,0,500,0] is: [[-4299.218  -4220.042  -4327.958  -4399.414  -4473.9194]]\n",
      "Weights succesfully copied to Target model.\n",
      "Saving architecture, weights and optimizer state for agent-0\n",
      "Dumping agent-0 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Model, architecture, weights, optimizer, memory and training results succesfully saved. Succesfully Terminated.\n",
      "Saved Partial results at the end of episode 120.\n",
      "Sever Redispatched.\n",
      "Redispatched\n",
      "Episode: 121/200, Epsilon:0.41, Average reward: -128.9\n",
      "Prediction for [500,0,500,0] is: [[-4302.0264 -4230.081  -4327.343  -4402.398  -4475.9834]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 122/200, Epsilon:0.4, Average reward: -31.4\n",
      "Prediction for [500,0,500,0] is: [[-4345.1885 -4270.4507 -4359.32   -4434.886  -4507.0957]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 123/200, Epsilon:0.4, Average reward: -49.31\n",
      "Prediction for [500,0,500,0] is: [[-4372.8726 -4283.7437 -4381.9683 -4450.88   -4528.5044]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 124/200, Epsilon:0.39, Average reward: -11.77\n",
      "Prediction for [500,0,500,0] is: [[-4332.2617 -4245.7075 -4345.8916 -4410.9116 -4481.16  ]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 125/200, Epsilon:0.39, Average reward: -306.12\n",
      "Prediction for [500,0,500,0] is: [[-4336.046 -4261.315 -4354.14  -4419.857 -4499.468]]\n",
      "Weights succesfully copied to Target model.\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 126/200, Epsilon:0.38, Average reward: -113.96\n",
      "Prediction for [500,0,500,0] is: [[-4341.9985 -4273.4937 -4373.622  -4433.6826 -4520.2725]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 127/200, Epsilon:0.38, Average reward: -70.41\n",
      "Prediction for [500,0,500,0] is: [[-4361.8877 -4285.363  -4385.4473 -4448.4165 -4531.9546]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 128/200, Epsilon:0.37, Average reward: -38.9\n",
      "Prediction for [500,0,500,0] is: [[-4350.8584 -4280.8506 -4376.799  -4442.1367 -4525.466 ]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 129/200, Epsilon:0.37, Average reward: -234.35\n",
      "Prediction for [500,0,500,0] is: [[-4374.414  -4295.073  -4391.639  -4462.417  -4543.2803]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 130/200, Epsilon:0.36, Average reward: -155.32\n",
      "Prediction for [500,0,500,0] is: [[-4383.77   -4304.9307 -4400.1025 -4470.7603 -4545.527 ]]\n",
      "Weights succesfully copied to Target model.\n",
      "Saving architecture, weights and optimizer state for agent-0\n",
      "Dumping agent-0 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Model, architecture, weights, optimizer, memory and training results succesfully saved. Succesfully Terminated.\n",
      "Saved Partial results at the end of episode 130.\n",
      "Sever Redispatched.\n",
      "Redispatched\n",
      "Episode: 131/200, Epsilon:0.36, Average reward: -316.31\n",
      "Prediction for [500,0,500,0] is: [[-4373.046  -4296.9966 -4389.893  -4466.6157 -4545.116 ]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 132/200, Epsilon:0.35, Average reward: -140.44\n",
      "Prediction for [500,0,500,0] is: [[-4379.337  -4314.4556 -4400.7183 -4468.9355 -4554.3438]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 133/200, Epsilon:0.35, Average reward: -101.65\n",
      "Prediction for [500,0,500,0] is: [[-4404.381  -4338.3804 -4426.9204 -4495.8584 -4583.3374]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 134/200, Epsilon:0.34, Average reward: -97.12\n",
      "Prediction for [500,0,500,0] is: [[-4414.663  -4347.975  -4445.3857 -4506.767  -4601.161 ]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 135/200, Epsilon:0.34, Average reward: -36.08\n",
      "Prediction for [500,0,500,0] is: [[-4409.0845 -4348.7383 -4438.5806 -4497.958  -4600.621 ]]\n",
      "Weights succesfully copied to Target model.\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 136/200, Epsilon:0.33, Average reward: -53.14\n",
      "Prediction for [500,0,500,0] is: [[-4425.3135 -4362.795  -4451.7905 -4511.5996 -4613.0376]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 137/200, Epsilon:0.33, Average reward: -106.05\n",
      "Prediction for [500,0,500,0] is: [[-4425.488  -4367.1367 -4461.03   -4513.3965 -4620.884 ]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 138/200, Epsilon:0.32, Average reward: -94.57\n",
      "Prediction for [500,0,500,0] is: [[-4473.5923 -4414.7925 -4504.873  -4553.9146 -4656.302 ]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 139/200, Epsilon:0.32, Average reward: -188.0\n",
      "Prediction for [500,0,500,0] is: [[-4474.6646 -4415.577  -4510.4937 -4548.7764 -4655.061 ]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 140/200, Epsilon:0.31, Average reward: -130.43\n",
      "Prediction for [500,0,500,0] is: [[-4499.248  -4438.737  -4525.9214 -4572.935  -4677.0093]]\n",
      "Weights succesfully copied to Target model.\n",
      "Saving architecture, weights and optimizer state for agent-0\n",
      "Dumping agent-0 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Model, architecture, weights, optimizer, memory and training results succesfully saved. Succesfully Terminated.\n",
      "Saved Partial results at the end of episode 140.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sever Redispatched.\n",
      "Redispatched\n",
      "Episode: 141/200, Epsilon:0.31, Average reward: -46.89\n",
      "Prediction for [500,0,500,0] is: [[-4562.0825 -4491.085  -4581.255  -4625.04   -4727.376 ]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 142/200, Epsilon:0.3, Average reward: -62.88\n",
      "Prediction for [500,0,500,0] is: [[-4594.294  -4527.1777 -4621.8677 -4659.0913 -4763.837 ]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 143/200, Epsilon:0.3, Average reward: -28.66\n",
      "Prediction for [500,0,500,0] is: [[-4624.14   -4557.4917 -4635.021  -4679.9663 -4780.901 ]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 144/200, Epsilon:0.29, Average reward: -180.74\n",
      "Prediction for [500,0,500,0] is: [[-4575.5845 -4488.3936 -4576.93   -4618.9463 -4718.9253]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 145/200, Epsilon:0.29, Average reward: -89.87\n",
      "Prediction for [500,0,500,0] is: [[-4605.151  -4513.3994 -4599.752  -4640.5884 -4739.884 ]]\n",
      "Weights succesfully copied to Target model.\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 146/200, Epsilon:0.28, Average reward: -146.91\n",
      "Prediction for [500,0,500,0] is: [[-4599.969  -4517.509  -4579.0654 -4626.9883 -4729.0513]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 147/200, Epsilon:0.28, Average reward: -189.53\n",
      "Prediction for [500,0,500,0] is: [[-4656.033  -4555.985  -4627.138  -4671.4956 -4778.8384]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 148/200, Epsilon:0.27, Average reward: -67.06\n",
      "Prediction for [500,0,500,0] is: [[-4652.018  -4552.476  -4636.248  -4674.9697 -4781.534 ]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 149/200, Epsilon:0.27, Average reward: -83.36\n",
      "Prediction for [500,0,500,0] is: [[-4687.8174 -4595.6816 -4697.265  -4708.3037 -4827.4336]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 150/200, Epsilon:0.26, Average reward: -37.23\n",
      "Prediction for [500,0,500,0] is: [[-4741.254  -4650.5767 -4747.119  -4764.836  -4885.5723]]\n",
      "Weights succesfully copied to Target model.\n",
      "Saving architecture, weights and optimizer state for agent-0\n",
      "Dumping agent-0 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Model, architecture, weights, optimizer, memory and training results succesfully saved. Succesfully Terminated.\n",
      "Saved Partial results at the end of episode 150.\n",
      "Sever Redispatched.\n",
      "Redispatched\n",
      "Episode: 151/200, Epsilon:0.26, Average reward: -271.36\n",
      "Prediction for [500,0,500,0] is: [[-4755.222  -4669.1816 -4776.0894 -4788.273  -4922.108 ]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 152/200, Epsilon:0.25, Average reward: -217.22\n",
      "Prediction for [500,0,500,0] is: [[-4738.2485 -4657.874  -4763.617  -4770.214  -4907.7666]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 153/200, Epsilon:0.25, Average reward: -116.66\n",
      "Prediction for [500,0,500,0] is: [[-4768.953  -4688.841  -4793.9575 -4805.8525 -4943.6016]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 154/200, Epsilon:0.24, Average reward: -239.22\n",
      "Prediction for [500,0,500,0] is: [[-4799.095  -4733.099  -4823.618  -4846.9355 -4982.196 ]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 155/200, Epsilon:0.24, Average reward: -201.22\n",
      "Prediction for [500,0,500,0] is: [[-4825.2764 -4752.7437 -4837.315  -4875.9927 -5009.6665]]\n",
      "Weights succesfully copied to Target model.\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 156/200, Epsilon:0.23, Average reward: -136.3\n",
      "Prediction for [500,0,500,0] is: [[-4868.0796 -4796.099  -4878.4214 -4914.992  -5051.4976]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 157/200, Epsilon:0.23, Average reward: -443.58\n",
      "Prediction for [500,0,500,0] is: [[-4866.0635 -4798.873  -4865.436  -4923.76   -5054.491 ]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 158/200, Epsilon:0.22, Average reward: -136.19\n",
      "Prediction for [500,0,500,0] is: [[-4886.6035 -4820.381  -4890.1772 -4950.576  -5084.972 ]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 159/200, Epsilon:0.22, Average reward: -403.91\n",
      "Prediction for [500,0,500,0] is: [[-4906.1377 -4834.716  -4898.8496 -4967.4033 -5097.766 ]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 160/200, Epsilon:0.21, Average reward: -447.1\n",
      "Prediction for [500,0,500,0] is: [[-4877.0625 -4825.5054 -4871.3843 -4958.018  -5084.8047]]\n",
      "Weights succesfully copied to Target model.\n",
      "Saving architecture, weights and optimizer state for agent-0\n",
      "Dumping agent-0 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Model, architecture, weights, optimizer, memory and training results succesfully saved. Succesfully Terminated.\n",
      "Saved Partial results at the end of episode 160.\n",
      "Sever Redispatched.\n",
      "Redispatched\n",
      "Episode: 161/200, Epsilon:0.21, Average reward: -45.91\n",
      "Prediction for [500,0,500,0] is: [[-4838.4033 -4794.5293 -4837.579  -4934.6113 -5054.6084]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 162/200, Epsilon:0.2, Average reward: -194.27\n",
      "Prediction for [500,0,500,0] is: [[-4911.963  -4867.6685 -4915.078  -5012.0396 -5138.5615]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 163/200, Epsilon:0.2, Average reward: -211.83\n",
      "Prediction for [500,0,500,0] is: [[-4922.6113 -4870.66   -4922.3037 -5011.5054 -5142.2627]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 164/200, Epsilon:0.19, Average reward: -45.0\n",
      "Prediction for [500,0,500,0] is: [[-4947.238  -4879.593  -4935.0225 -5024.1367 -5156.9653]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 165/200, Epsilon:0.19, Average reward: -388.1\n",
      "Prediction for [500,0,500,0] is: [[-4905.16   -4833.5547 -4889.087  -4974.009  -5094.874 ]]\n",
      "Weights succesfully copied to Target model.\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 166/200, Epsilon:0.18, Average reward: -432.21\n",
      "Prediction for [500,0,500,0] is: [[-4907.3115 -4833.1904 -4881.678  -4968.338  -5089.2993]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 167/200, Epsilon:0.18, Average reward: -214.74\n",
      "Prediction for [500,0,500,0] is: [[-4941.0923 -4869.931  -4920.4546 -5005.11   -5129.6304]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 168/200, Epsilon:0.17, Average reward: -42.24\n",
      "Prediction for [500,0,500,0] is: [[-4993.973  -4927.8994 -4962.378  -5058.826  -5182.5044]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 169/200, Epsilon:0.17, Average reward: -51.48\n",
      "Prediction for [500,0,500,0] is: [[-4972.7847 -4897.928  -4938.6123 -5020.562  -5156.2407]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 170/200, Epsilon:0.16, Average reward: -274.48\n",
      "Prediction for [500,0,500,0] is: [[-4941.0747 -4892.846  -4924.9478 -5008.581  -5154.623 ]]\n",
      "Weights succesfully copied to Target model.\n",
      "Saving architecture, weights and optimizer state for agent-0\n",
      "Dumping agent-0 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Model, architecture, weights, optimizer, memory and training results succesfully saved. Succesfully Terminated.\n",
      "Saved Partial results at the end of episode 170.\n",
      "Sever Redispatched.\n",
      "Redispatched\n",
      "Episode: 171/200, Epsilon:0.16, Average reward: -116.12\n",
      "Prediction for [500,0,500,0] is: [[-4906.5933 -4869.819  -4902.2466 -4986.485  -5131.3267]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 172/200, Epsilon:0.15, Average reward: -18.35\n",
      "Prediction for [500,0,500,0] is: [[-4895.926  -4871.486  -4895.7827 -4984.9565 -5130.8633]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 173/200, Epsilon:0.15, Average reward: -292.1\n",
      "Prediction for [500,0,500,0] is: [[-4903.0503 -4884.317  -4913.5728 -4995.911  -5140.519 ]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 174/200, Epsilon:0.14, Average reward: -31.42\n",
      "Prediction for [500,0,500,0] is: [[-4962.8003 -4928.7524 -4953.696  -5047.5703 -5178.9194]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 175/200, Epsilon:0.14, Average reward: -451.38\n",
      "Prediction for [500,0,500,0] is: [[-5001.1084 -4963.142  -4984.084  -5080.2485 -5200.421 ]]\n",
      "Weights succesfully copied to Target model.\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 176/200, Epsilon:0.13, Average reward: -181.06\n",
      "Prediction for [500,0,500,0] is: [[-5028.8433 -4992.987  -5019.4126 -5112.5996 -5233.258 ]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 177/200, Epsilon:0.13, Average reward: -359.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for [500,0,500,0] is: [[-5086.242  -5045.5186 -5079.1006 -5165.055  -5287.103 ]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 178/200, Epsilon:0.12, Average reward: -148.6\n",
      "Prediction for [500,0,500,0] is: [[-5102.6694 -5070.5254 -5089.6025 -5185.0073 -5287.3613]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 179/200, Epsilon:0.12, Average reward: -190.23\n",
      "Prediction for [500,0,500,0] is: [[-5164.8047 -5136.8164 -5156.6567 -5243.4004 -5340.824 ]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 180/200, Epsilon:0.11, Average reward: -20.47\n",
      "Prediction for [500,0,500,0] is: [[-5192.087 -5160.394 -5177.64  -5267.076 -5360.669]]\n",
      "Weights succesfully copied to Target model.\n",
      "Saving architecture, weights and optimizer state for agent-0\n",
      "Dumping agent-0 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Model, architecture, weights, optimizer, memory and training results succesfully saved. Succesfully Terminated.\n",
      "Saved Partial results at the end of episode 180.\n",
      "Sever Redispatched.\n",
      "Redispatched\n",
      "Episode: 181/200, Epsilon:0.11, Average reward: -36.19\n",
      "Prediction for [500,0,500,0] is: [[-5172.222  -5141.939  -5150.12   -5250.84   -5336.4487]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 182/200, Epsilon:0.1, Average reward: -210.01\n",
      "Prediction for [500,0,500,0] is: [[-5239.0547 -5206.5444 -5216.666  -5323.7935 -5414.918 ]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 183/200, Epsilon:0.1, Average reward: -58.3\n",
      "Prediction for [500,0,500,0] is: [[-5216.466  -5177.0835 -5185.365  -5305.663  -5390.4097]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 184/200, Epsilon:0.09, Average reward: -67.57\n",
      "Prediction for [500,0,500,0] is: [[-5218.799  -5181.583  -5180.411  -5305.8857 -5387.972 ]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 185/200, Epsilon:0.09, Average reward: -64.21\n",
      "Prediction for [500,0,500,0] is: [[-5219.744  -5176.3384 -5174.8076 -5301.486  -5364.4136]]\n",
      "Weights succesfully copied to Target model.\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 186/200, Epsilon:0.08, Average reward: -338.74\n",
      "Prediction for [500,0,500,0] is: [[-5252.556  -5215.943  -5210.8887 -5330.8    -5394.2563]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 187/200, Epsilon:0.08, Average reward: -36.22\n",
      "Prediction for [500,0,500,0] is: [[-5291.864  -5248.213  -5239.8184 -5356.5317 -5425.5093]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 188/200, Epsilon:0.07, Average reward: -87.44\n",
      "Prediction for [500,0,500,0] is: [[-5283.8916 -5252.568  -5243.751  -5352.354  -5427.1865]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 189/200, Epsilon:0.07, Average reward: -66.8\n",
      "Prediction for [500,0,500,0] is: [[-5297.642  -5258.906  -5238.243  -5360.1504 -5419.9067]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 190/200, Epsilon:0.06, Average reward: -269.81\n",
      "Prediction for [500,0,500,0] is: [[-5271.8306 -5227.4624 -5211.715  -5332.808  -5380.4565]]\n",
      "Weights succesfully copied to Target model.\n",
      "Saving architecture, weights and optimizer state for agent-0\n",
      "Dumping agent-0 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Model, architecture, weights, optimizer, memory and training results succesfully saved. Succesfully Terminated.\n",
      "Saved Partial results at the end of episode 190.\n",
      "Sever Redispatched.\n",
      "Redispatched\n",
      "Episode: 191/200, Epsilon:0.06, Average reward: -62.22\n",
      "Prediction for [500,0,500,0] is: [[-5243.7153 -5196.9688 -5175.2715 -5302.972  -5356.9   ]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 192/200, Epsilon:0.05, Average reward: -256.34\n",
      "Prediction for [500,0,500,0] is: [[-5280.951  -5225.5376 -5201.5493 -5333.0557 -5383.0254]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 193/200, Epsilon:0.05, Average reward: -34.02\n",
      "Prediction for [500,0,500,0] is: [[-5344.1865 -5274.499  -5259.4214 -5381.7915 -5438.6494]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 194/200, Epsilon:0.04, Average reward: -75.81\n",
      "Prediction for [500,0,500,0] is: [[-5357.3286 -5289.3804 -5272.536  -5396.317  -5455.693 ]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 195/200, Epsilon:0.04, Average reward: -65.84\n",
      "Prediction for [500,0,500,0] is: [[-5335.2466 -5271.792  -5248.3857 -5364.1016 -5412.7056]]\n",
      "Weights succesfully copied to Target model.\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 196/200, Epsilon:0.03, Average reward: -135.38\n",
      "Prediction for [500,0,500,0] is: [[-5363.6846 -5306.7305 -5277.721  -5388.899  -5441.971 ]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 197/200, Epsilon:0.03, Average reward: -123.57\n",
      "Prediction for [500,0,500,0] is: [[-5405.426  -5339.926  -5305.6533 -5415.1685 -5469.8154]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 198/200, Epsilon:0.02, Average reward: -19.1\n",
      "Prediction for [500,0,500,0] is: [[-5367.2866 -5308.756  -5258.283  -5377.3423 -5428.2026]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 199/200, Epsilon:0.02, Average reward: -30.53\n",
      "Prediction for [500,0,500,0] is: [[-5308.4316 -5254.8057 -5197.113  -5327.5166 -5355.219 ]]\n",
      "Reloading complete. Executing new episode...\n",
      "Episode: 200/200, Epsilon:0.01, Average reward: -265.2\n",
      "Prediction for [500,0,500,0] is: [[-5317.802  -5268.0835 -5213.4116 -5340.81   -5374.6733]]\n",
      "Weights succesfully copied to Target model.\n",
      "Saving architecture, weights and optimizer state for agent-0\n",
      "Dumping agent-0 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Model, architecture, weights, optimizer, memory and training results succesfully saved. Succesfully Terminated.\n",
      "Saved Partial results at the end of episode 200.\n",
      "Saving architecture, weights and optimizer state for agent-0\n",
      "Dumping agent-0 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Model, architecture, weights, optimizer, memory and training results succesfully saved. Succesfully Terminated.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Initialize storage\n",
    "    reward_storage = []\n",
    "    \n",
    "    # If previous agents aren't to be loaded, proceed to memory population\n",
    "    if not load_trained:\n",
    "        # Initialize simulation\n",
    "        if 'Vissim' not in globals() or Vissim == None:\n",
    "            Vissim, Simulation, Network, cache_flag = COMServerDispatch(model_name, vissim_working_directory,\\\n",
    "                                                                        memory_population_length, Start_Fresh,\\\n",
    "                                                                        reset_flag = True, verbose = True)\n",
    "        else:\n",
    "            Vissim = com.Dispatch(\"Vissim.Vissim\")\n",
    "            Simulation, Network = COMServerReload(Vissim, model_name, vissim_working_directory,\\\n",
    "                                                  memory_population_length, Start_Fresh, reset_flag = True)\n",
    "        \n",
    "    # Setting Random Seed\n",
    "    Vissim.Simulation.SetAttValue('RandSeed', Random_Seed)\n",
    "    print ('Random seed set in simulator. Random Seed = '+str(Random_Seed))\n",
    "\n",
    "    # Deploy Network Parser (crawl network)\n",
    "    npa = NetworkParser(Vissim)\n",
    "    print('NetworkParser has succesfully crawled the model network.')\n",
    "    \n",
    "    # Initialize agents\n",
    "    if program == \"DQN\":\n",
    "        Agents = [DQNAgent(state_size, action_size, ID, state_type, npa, memory_size, gamma, 0 if Demo_Mode else epsilon_start,\\\n",
    "                           epsilon_end, epsilon_decay, alpha, copy_weights_frequency, Vissim, DoubleDQN = False, Dueling = False) for ID in npa.signal_controllers_ids] \n",
    "        agents_deployed = True\n",
    "    elif program == \"DuelingDQN\":\n",
    "        Agents = [DQNAgent(state_size, action_size, ID, state_type, npa, memory_size, gamma, 0 if Demo_Mode else epsilon_start,\\\n",
    "                           epsilon_end, epsilon_decay, alpha, copy_weights_frequency, Vissim, DoubleDQN = False, Dueling = False) for ID in npa.signal_controllers_ids] \n",
    "        agents_deployed = True\n",
    "    elif program == \"DDQN\":\n",
    "        Agents = [DQNAgent(state_size, action_size, ID, state_type, npa, memory_size, gamma, 0 if Demo_Mode else epsilon_start,\\\n",
    "                           epsilon_end, epsilon_decay, alpha, copy_weights_frequency, Vissim, DoubleDQN = True, Dueling = False) for ID in npa.signal_controllers_ids] \n",
    "        agents_deployed = True\n",
    "    elif program == \"DuelingDDQN\":\n",
    "        Agents = [DQNAgent(state_size, action_size, ID, state_type, npa, memory_size, gamma, 0 if Demo_Mode else epsilon_start,\\\n",
    "                           epsilon_end, epsilon_decay, alpha, copy_weights_frequency, Vissim, DoubleDQN = True, Dueling = True) for ID in npa.signal_controllers_ids] \n",
    "        agents_deployed = True\n",
    "    else:\n",
    "        print(\"Incorrect Agent Class selected. Deployment could not be completed.\")\n",
    "        quit()\n",
    "    \n",
    "    if agents_deployed:\n",
    "        print(\"Deployed {} agent(s) of the Class {}.\".format(len(Agents), program))\n",
    "    \n",
    "    if Demo_Mode:\n",
    "        Agents = SF.load_agents(vissim_working_directory, model_name, Agents, Session_ID)\n",
    "        SF.run_simulation_episode(Agents, Vissim, state_type, state_size, memory_population_length, Demo_Mode)\n",
    "        Vissim = None\n",
    "    # Load previous trained data\n",
    "    elif load_trained:\n",
    "        Agents = SF.load_agents(vissim_working_directory, model_name, Agents, Session_ID)\n",
    "    # If previous data isn't to be loaded, have an initial longer random run to populate memory\n",
    "    else:\n",
    "        print('Populating memory with Random Actions....')\n",
    "        SF.Set_Quickmode(Vissim)\n",
    "        SF.run_simulation_episode(Agents, Vissim, state_type, state_size, memory_population_length, Demo_Mode)\n",
    "    \n",
    "    # Iterations of the simulation\n",
    "    for episode in range(episodes):\n",
    "        # Completely re-dispatch server every N iterations for performance\n",
    "        if episode % reset_frequency == 0 and episode !=0:\n",
    "            Vissim = None\n",
    "            Vissim, Simulation, Network, cache_flag = COMServerDispatch(model_name, vissim_working_directory,\\\n",
    "                                                                        simulation_length, Start_Fresh,\\\n",
    "                                                                        reset_flag = False, verbose = False)\n",
    "            print(\"Redispatched\")\n",
    "        elif episode != 0:\n",
    "            # If not the first episode, reset state at the start\n",
    "            Simulation, Network = COMServerReload(Vissim, model_name, vissim_working_directory,\\\n",
    "                                                simulation_length, Start_Fresh, reset_flag = False)\n",
    "        npa = NetworkParser(Vissim) \n",
    "        for index, agent in enumerate(Agents):\n",
    "            agent.update_IDS(npa.signal_controllers_ids[index], npa)\n",
    "            agent.episode_reward = []\n",
    "        \n",
    "        # Change demand for every episode\n",
    "        if Random_Demand:\n",
    "            for vehicle_input in range(1,5):\n",
    "                Vissim.Net.VehicleInputs.ItemByKey(vehicle_input).SetAttValue('Volume(1)', demands[np.random.randint(0,len(demands)-1)])\n",
    "        \n",
    "        # Use max speed for Simulator\n",
    "        if Quickmode:\n",
    "            SF.Set_Quickmode(Vissim)           \n",
    "        \n",
    "        # Run Episode\n",
    "        SF.run_simulation_episode(Agents, Vissim, state_type, state_size, simulation_length, Demo_Mode)\n",
    "        \n",
    "        # Calculate episode average reward\n",
    "        reward_storage, average_reward = SF.average_reward(reward_storage, Agents, episode, episodes)\n",
    "        \n",
    "        # Train agent with experience of episode (indicated batch size)\n",
    "        for agent in Agents:\n",
    "            agent.replay(batch_size, episode)\n",
    "        # Security save for long trainings\n",
    "        if SaveResultsAgent:\n",
    "            if (episode+1)%partial_save_at == 0:\n",
    "                SF.save_agents(vissim_working_directory, model_name, Agents, Session_ID, reward_storage)\n",
    "                print('Saved Partial results at the end of episode {}.'.format(episode+1))\n",
    "\n",
    "    #Saving agents memory, weights and optimizer\n",
    "    if SaveResultsAgent:\n",
    "        SF.save_agents(vissim_working_directory, model_name, Agents, Session_ID, reward_storage)\n",
    "        print(\"Model, architecture, weights, optimizer, memory and training results succesfully saved. Succesfully Terminated.\")\n",
    "    \n",
    "    # Plotting training progress\n",
    "    x_series = range(1,len(reward_storage)+1)\n",
    "    fit = np.polyfit(x_series,reward_storage,1)\n",
    "    fit_fn = np.poly1d(fit) \n",
    "    plt.plot(x_series,reward_storage, '-b', x_series, fit_fn(x_series), '--r')\n",
    "    plt.xlabel('Episodes')\n",
    "    plt.ylabel('Average ageng reward in episode')\n",
    "    plt.title('Training evolution and trend')\n",
    "    plt.gca().legend(('Episode Reward','Linear Trend'))\n",
    "    plt.show()\n",
    "    \n",
    "    # Close Vissim\n",
    "    Vissim = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Demo_Mode = True\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize storage\n",
    "    reward_storage = []\n",
    "    \n",
    "    # If previous agents aren't to be loaded, proceed to memory population\n",
    "    if not load_trained:\n",
    "        # Initialize simulation\n",
    "        if 'Vissim' not in globals() or Vissim == None:\n",
    "            Vissim, Simulation, Network, cache_flag = COMServerDispatch(model_name, vissim_working_directory,\\\n",
    "                                                                        memory_population_length, Start_Fresh, reset_flag = True)\n",
    "        else:\n",
    "            Vissim = com.Dispatch(\"Vissim.Vissim\")\n",
    "            Simulation, Network = COMServerReload(Vissim, model_name, vissim_working_directory,\\\n",
    "                                                  memory_population_length, Start_Fresh, reset_flag = True)\n",
    "        \n",
    "    # Setting Random Seed\n",
    "    Vissim.Simulation.SetAttValue('RandSeed', Random_Seed)\n",
    "    print ('Random seed set in simulator. Random Seed = '+str(Random_Seed))\n",
    "\n",
    "    # Deploy Network Parser (crawl network)\n",
    "    npa = NetworkParser(Vissim)\n",
    "    print('NetworkParser has succesfully crawled the model network.')\n",
    "    \n",
    "    # Initialize agents\n",
    "    if program == \"DQN\":\n",
    "        Agents = [DQNAgent(state_size, action_size, ID, state_type, npa, memory_size, gamma, 0 if Demo_Mode else epsilon_start,\\\n",
    "                           epsilon_end, epsilon_decay, alpha, Vissim, DoubleDQN = False, Dueling = False) for ID in npa.signal_controllers_ids] \n",
    "        agents_deployed = True\n",
    "    elif program == \"DDQN\":\n",
    "        Agents = [DQNAgent(state_size, action_size, ID, state_type, npa, memory_size, gamma, 0 if Demo_Mode else epsilon_start,\\\n",
    "                           epsilon_end, epsilon_decay, alpha, Vissim, DoubleDQN = True, Dueling = False) for ID in npa.signal_controllers_ids] \n",
    "        agents_deployed = True\n",
    "    elif program == \"DuelingDQN\":\n",
    "        Agents = [DQNAgent(state_size, action_size, ID, state_type, npa, memory_size, gamma, 0 if Demo_Mode else epsilon_start,\\\n",
    "                           epsilon_end, epsilon_decay, alpha, copy_weights_frequency, Vissim, DoubleDQN = True, Dueling = True) for ID in npa.signal_controllers_ids] \n",
    "      \n",
    "        agents_deployed = True\n",
    "    else:\n",
    "        print(\"Incorrect Agent Class selected. Deployment could not be completed.\")\n",
    "        quit()\n",
    "    \n",
    "    if agents_deployed:\n",
    "        print(\"Deployed {} agent(s) of the Class {}.\".format(len(Agents), program))\n",
    "    \n",
    "    if Demo_Mode:\n",
    "        for index, agent in enumerate(Agents):\n",
    "            Filename = os.path.join(vissim_working_directory, model_name, model_name+'_'+ Session_ID + '_Agent'+str(index)+'.h5')\n",
    "            agent.model = load_model(Filename)\n",
    "            Memory_Filename = os.path.join(vissim_working_directory, model_name, model_name+'_'+ Session_ID + '_Agent'+str(index)+'_Memory'+'.p')\n",
    "            agent.memory = pickle.load(open(Memory_Filename, 'rb'))\n",
    "        print('Items successfully loaded.')        \n",
    "        SF.run_simulation_episode(Agents, Vissim, state_type, state_size, memory_population_length, Demo_Mode = True)\n",
    "        Vissim = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "    Vissim, Simulation, Network, cache_flag = COMServerDispatch(model_name, vissim_working_directory,\\\n",
    "                                                            memory_population_length, Start_Fresh, reset_flag = False)\n",
    "\n",
    "\n",
    "# Iterations of the simulation\n",
    "    for episode in range(episodes):\n",
    "        if episode != 0:\n",
    "            # If not the first episode, reset state at the start\n",
    "            Simulation, Network = COMServerReload(Vissim, model_name, vissim_working_directory,\\\n",
    "                                                simulation_length, Start_Fresh, reset_flag = False)\n",
    "        npa = NetworkParser(Vissim) \n",
    "        for index, agent in enumerate(Agents):\n",
    "            agent.update_IDS(npa.signal_controllers_ids[index], npa)\n",
    "            agent.episode_reward = []\n",
    "        \n",
    "        # Change demand for every episode\n",
    "        if Random_Demand:\n",
    "            for vehicle_input in range(1,5):\n",
    "                Vissim.Net.VehicleInputs.ItemByKey(vehicle_input).SetAttValue('Volume(1)', demands[np.random.randint(0,6)])\n",
    "        \n",
    "        # Use max speed for Simulator\n",
    "        if Quickmode:\n",
    "            SF.Set_Quickmode(Vissim)           \n",
    "        \n",
    "        # Run Episode\n",
    "        SF.run_simulation_episode(Agents, Vissim, state_type, state_size, simulation_length, Demo_Mode)\n",
    "        \n",
    "        # Calculate episode average reward\n",
    "        reward_storage, average_reward = SF.average_reward(reward_storage, Agents, episode, episodes)\n",
    "        \n",
    "        # Train agent with experience of episode (indicated batch size)\n",
    "        for agent in Agents:\n",
    "            agent.replay(batch_size, episode)\n",
    "        # Security save for long trainings\n",
    "        if SaveResultsAgent:\n",
    "            if (episode+1)%partial_save_at == 0:\n",
    "                SF.save_agents(vissim_working_directory, model_name, Agents, Session_ID, reward_storage)\n",
    "                print('Saved Partial results at the end of episode {}.'.format(episode+1))\n",
    "\n",
    "    #Saving agents memory, weights and optimizer\n",
    "    if SaveResultsAgent:\n",
    "        SF.save_agents(vissim_working_directory, model_name, Agents, Session_ID, reward_storage)\n",
    "    \n",
    "    # Plotting training progress\n",
    "    x_series = range(1,len(reward_storage)+1)\n",
    "    fit = np.polyfit(x_series,reward_storage,1)\n",
    "    fit_fn = np.poly1d(fit) \n",
    "    plt.plot(x_series,reward_storage, '-b', x_series, fit_fn(x_series), '--r')\n",
    "    plt.xlabel('Episodes')\n",
    "    plt.ylabel('Average ageng reward in episode')\n",
    "    plt.title('Training evolution and trend')\n",
    "    plt.gca().legend(('Episode Reward','Linear Trend'))\n",
    "    plt.show()\n",
    "    \n",
    "    # Close Vissim\n",
    "    Vissim = None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "vissimgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
