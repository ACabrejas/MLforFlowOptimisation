{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Vissim_env_class import environment\n",
    "from Actor_critic_class import ACAgent\n",
    "from MasterAC_Agent import MasterAC_Agent\n",
    "from MasterDQN_Agent import MasterDQN_Agent\n",
    "\n",
    "# Network Specific Libraries\n",
    "from Balance_Functions import balance_dictionary\n",
    "\n",
    "# General Libraries\n",
    "import numpy as np \n",
    "import pylab as plt\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_name  = 'Balance'\n",
    "#vissim_working_directory =  'C:\\\\Users\\\\Rzhang\\\\Desktop\\\\MLforFlowOptimisationOrigine\\\\Vissim\\\\'\n",
    "vissim_working_directory = \"E:\\Backup - Onedrive\\Desktop\\ATI\\0_TMF\\MLforFlowOptimisation\\Vissim\"\n",
    "sim_length = 1800\n",
    "\n",
    "# all controller actions\n",
    "Balance_dictionary =\\\n",
    "{\\\n",
    "    # Controller Number 2 \n",
    "    0 : {'compatible_actions' : {   0 : [1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0],\n",
    "                                    1 : [0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1],\n",
    "                                    2 : [0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0] },\n",
    "         \n",
    "         'link' : [2, 40, 7, 38],\n",
    "         'lane' : ['2-1', '2-2', '2-3', '40-1', '7-1', '7-2', '7-3', '38-1'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'green_time' : 8,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [8],\n",
    "         'state_type' : 'Queues',\n",
    "         'reward_type' : 'Queues'\n",
    "         \n",
    "         \n",
    "        },\n",
    "    # Controller Number 3\n",
    "    1 : {'compatible_actions' : {   0 : [0, 1, 0, 0, 1, 0, 1, 1],\n",
    "                                    1 : [1, 0, 0, 1, 0, 0, 0, 0],\n",
    "                                    2 : [0, 0, 1, 0, 0, 1, 0, 0] },\n",
    "         \n",
    "         'link' : [5, 48, 70, 46],\n",
    "         'lane' : ['5-1', '5-2', '5-3', '48-1', '70-1', '70-2', '70-3', '46-1'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'green_time' : 8,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [8],\n",
    "         'state_type' : 'Queues',\n",
    "         'reward_type' : 'Queues'\n",
    "        },\n",
    "    # Controller Number 4\n",
    "    2 : {'compatible_actions' : {   0 : [0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                                    1 : [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                                    2 : [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                                    3 : [0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]},\n",
    "         \n",
    "         'link' : [73, 100, 84, 95],\n",
    "         'lane' : ['73-1', '73-2', '73-3', '100-1', '100-2', '100-3', '100-4',\\\n",
    "                  '84-1', '84-2', '84-3', '95-1', '95-2', '95-3', '95-4'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'green_time' : 8,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [14],\n",
    "         'state_type' : 'Queues',\n",
    "         'reward_type' : 'Queues'\n",
    "        },\n",
    "    # Controller Number 5\n",
    "    3 : {'compatible_actions' : {   0 : [0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0],\n",
    "                                    1 : [1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0],\n",
    "                                    2 : [0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1]},\n",
    "         \n",
    "         'link' : [87, 36, 10, 34],\n",
    "         'lane' : ['87-1', '87-2', '87-3', '36-1', '10-1', '10-2', '10-3', '34-1'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'green_time' : 8,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [8],\n",
    "         'state_type' : 'Queues',\n",
    "         'reward_type' : 'Queues'\n",
    "        },\n",
    "    # Controller Number 6 \n",
    "    4 : {'compatible_actions' : {   0 : [0, 1, 1, 0, 0],\n",
    "                                    1 : [1, 1, 0, 0, 0],\n",
    "                                    2 : [0, 0, 0, 1, 0]},\n",
    "         'link' : [8, 24, 13],\n",
    "         'lane' : ['8-1', '8-2', '24-1', '13-1', '13-2', '13-3'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'green_time' : 8,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [6],\n",
    "         'state_type' : 'Queues',\n",
    "         'reward_type' : 'Queues'\n",
    "        },\n",
    "    # Controller Number 8\n",
    "    5 : {'compatible_actions' : {   0 : [1, 0, 1, 0, 1, 0],\n",
    "                                    1 : [0, 1, 0, 1, 0, 1]},\n",
    "         'link' : [26, 23, 35],\n",
    "         'lane' : ['26-1', '23-1', '35-1'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'green_time' : 8,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [3],\n",
    "         'state_type' : 'Queues',\n",
    "         'reward_type' : 'Queues'\n",
    "         \n",
    "        },\n",
    "    # Controller Number 9\n",
    "    6 : {'compatible_actions' : {   0 : [0, 1, 0, 1, 1, 1],\n",
    "                                    1 : [1, 0, 1, 0, 0, 0]},\n",
    "         'link' : [51, 92, 64, 19],\n",
    "         'lane' : ['51-1', '92-1', '92-2', '64-1', '19-1', '19-2'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'green_time' : 8,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [6],\n",
    "         'state_type' : 'Queues',\n",
    "         'reward_type' : 'Queues'\n",
    "        },\n",
    "    # Contoller Number 10\n",
    "    7 : {'compatible_actions' : {   0 : [0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "                                    1 : [0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "                                    2 : [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]},\n",
    "         'link' : [18, 66, 16],\n",
    "         'lane' : ['18-1', '18-2', '18-3', '66-1', '16-1', '16-2', '16-3'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'green_time' : 8,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [7],\n",
    "         'state_type' : 'Queues',\n",
    "         'reward_type' : 'Queues'\n",
    "        },\n",
    "    # Controller Number 12\n",
    "    8 : {'compatible_actions' : {   0 : [1, 0, 1, 0, 0, 0, 0],\n",
    "                                    1 : [0, 1, 0, 0, 0, 0, 0]},\n",
    "         'link' : [62, 45, 44],\n",
    "         'lane' : ['62-1', '45-1', '44-1'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'green_time' : 8,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [3],\n",
    "         'state_type' : 'Queues',\n",
    "         'reward_type' : 'Queues'\n",
    "        },\n",
    "    # Controller Number 13\n",
    "    9 : {'compatible_actions' : {   0 : [0, 1, 0, 1, 1, 0, 1, 0],\n",
    "                                    1 : [1, 0, 1, 0, 0, 1, 0, 1]},\n",
    "         'link' : [60, 43, 55, 58],\n",
    "         'lane' : ['60-1', '43-1', '55-1', '58-1'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'green_time' : 8,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [4],\n",
    "         'state_type' : 'Queues',\n",
    "         'reward_type' : 'Queues'\n",
    "            \n",
    "        },\n",
    "    # Controller 15\n",
    "    10 : {'compatible_actions' : {  0 : [1, 0, 1, 0, 0, 1, 0, 1],\n",
    "                                    1 : [0, 1, 0, 1, 1, 0, 1, 0]},\n",
    "         'link' : [32, 42, 30, 39],\n",
    "         'lane' : ['32-1', '42-1', '30-1', '39-1'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'green_time' : 8,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [4],\n",
    "         'state_type' : 'Queues',\n",
    "         'reward_type' : 'Queues'\n",
    "        },\n",
    "    # Controller 16\n",
    "    11 : {'compatible_actions' :  { 0 : [1, 0, 1, 0, 0, 1, 0, 1],\n",
    "                                    1 : [0, 1, 0, 1, 1, 0, 1, 0]},\n",
    "         'link' : [29, 50, 28, 47],\n",
    "         'lane' : ['29-1', '50-1', '28-1', '47-1'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'green_time' : 8,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [4],\n",
    "         'state_type' : 'Queues',\n",
    "         'reward_type' : 'Queues'\n",
    "        },\n",
    "    # Controller 17\n",
    "    12 : {'compatible_actions' :  { 0 : [1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1],\n",
    "                                    1 : [0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1],\n",
    "                                    2 : [0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0],\n",
    "                                    3 : [0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0]},\n",
    "         'link' : [27, 22, 25, 77],\n",
    "         'lane' : ['27-1', '22-1', '22-2', '22-3', '25-1', '77-1', '77-2'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'green_time' : 8,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [7],\n",
    "         'state_type' : 'Queues',\n",
    "         'reward_type' : 'Queues'\n",
    "            \n",
    "        },\n",
    "    # Controller 33 \n",
    "    13 : {'compatible_actions' :  { 0 : [1, 0, 0, 1, 0, 0, 1, 0, 0],\n",
    "                                    1 : [0, 0, 1, 1, 0, 1, 0, 0, 0],\n",
    "                                    2 : [0, 1, 0, 0, 1, 1, 0, 1, 1]},\n",
    "         'link' : [68, 71, 75],\n",
    "         'lane' : ['68-1', '68-2', '68-3', '71-1', '71-2', '75-1'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'green_time' : 8,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [6],\n",
    "         'state_type' : 'Queues',\n",
    "         'reward_type' : 'Queues'\n",
    "        }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "env = environment(model_name, vissim_working_directory, sim_length, Balance_dictionary,\\\n",
    "            timesteps_per_second = 1, mode = 'training', delete_results = True, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "env.SCUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "env.SCUs[0].state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "actions = dict()\n",
    "for i in range(len(env.SCUs)):\n",
    "    actions[i]=0\n",
    "    \n",
    "print(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Cyclic_Control():\n",
    "    def __init__(self,size):\n",
    "        self.action = 0\n",
    "        self.size = size\n",
    "        \n",
    "    def choose_action(self,state=None):\n",
    "        self.action = (self.action + 1) % self.size\n",
    "        return self.action\n",
    "CC = [] \n",
    "\n",
    "for idx, info in Balance_dictionary.items():\n",
    "        cycle_size = len(info['compatible_actions'])\n",
    "        CC.append(Cyclic_Control(cycle_size))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Training loop / simulation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_state = env.get_state()\n",
    "for idx, s in start_state.items():\n",
    "    actions[idx] = CC[idx].choose_action(s)\n",
    "    \n",
    "for _ in range(10000):\n",
    "    action_required, SARSDs = env.step(actions)\n",
    "    if action_required : \n",
    "        actions = dict()\n",
    "        for idx , sarsd in SARSDs.items():\n",
    "            s,a,r,ns,d = sarsd\n",
    "            #print(sarsd)\n",
    "            \n",
    "            # in order to find the next action you need to evaluate the \"next_state\" because it is the current state of the simulator\n",
    "            actions[idx] = CC[idx].choose_action(ns)\n",
    "        \n",
    "    if env.done :\n",
    "        env.reset()\n",
    "        for idx, s in start_state.items():\n",
    "            actions[idx] = CC[idx].choose_action(ns)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Balance RL AC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_name  = 'Balance'\n",
    "vissim_working_directory =  'C:\\\\Users\\\\Rzhang\\\\Desktop\\\\MLforFlowOptimisationOrigine\\\\Vissim\\\\'\n",
    "sim_length = 1800\n",
    "agent_type = 'AC'\n",
    "\n",
    "# all controller actions\n",
    "Balance_dictionary = balance_dictionary(agent_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "env = environment(model_name, vissim_working_directory, sim_length, Balance_dictionary,\\\n",
    "            timesteps_per_second = 1, mode = 'training', delete_results = True, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Agent hyperparameters\n",
    "gamma = 0.85\n",
    "alpha = 0.0005\n",
    "value = 25\n",
    "entropy = 5000\n",
    "n_step_size = 11\n",
    "reduce_entropy_every = 1000\n",
    "entropy_threshold = 0.5\n",
    "timesteps_per_second = 1\n",
    "\n",
    "\n",
    "# for the monitoring only for AC\n",
    "horizon = 50\n",
    "n_sample = 10\n",
    "\n",
    "Balance_MultiAc_Agents = MasterAC_Agent(model_name, vissim_working_directory, sim_length, Balance_dictionary, n_step_size, gamma, alpha, entropy, value, \\\n",
    "                timesteps_per_second = timesteps_per_second, verbose = True, horizon = 100, \\\n",
    "                n_sample = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Balance_MultiAc_Agents.train(1000)\n",
    "\n",
    "Balance_MultiAc_Agents.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Balance_MultiAc_Agents = MasterAC_Agent(model_name, vissim_working_directory, sim_length, Balance_dictionary, n_step_size, gamma, alpha, entropy, value, \\\n",
    "                timesteps_per_second = timesteps_per_second, verbose = True, horizon = 100, \\\n",
    "                n_sample = 10)\n",
    "\n",
    "Balance_MultiAc_Agents.load(best = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Agents = []\n",
    "for idx, info in Balance_dictionary['junctions'].items():\n",
    "        acts = info['compatible_actions']\n",
    "        Agent = ACAgent(info['state_size'], len(acts), idx, n_step_size, gamma, alpha, entropy, value)\n",
    "        Agents.append(Agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "start_state = env.get_state()\n",
    "actions = {}\n",
    "for idx, s in start_state.items():\n",
    "            actions[idx] = int(Agents[idx].choose_action(s))\n",
    "\n",
    "for i in range(30000):\n",
    "    action_required, SARSDs = env.step_to_next_action(actions)\n",
    "    if action_required : \n",
    "        actions = dict()\n",
    "        for idx , sarsd in SARSDs.items():\n",
    "            s,a,r,ns,d = sarsd\n",
    "            \n",
    "            #print(sarsd)\n",
    "            Agents[idx].remember(s,a,r,ns,d)\n",
    "            if len(Agents[idx].memory) >= Agents[idx].n_step_size :\n",
    "                Agents[idx].learn() \n",
    "            \n",
    "            # in order to find the next action you need to evaluate the \"next_state\" because it is the current state of the simulator\n",
    "            actions[idx] = int(Agents[idx].choose_action(ns))\n",
    "            #print(actions)\n",
    "            \n",
    "            if (i+1)%reduce_entropy_every == 0:\n",
    "                if Agents[idx].params['entropy'] >= entropy_threshold :\n",
    "                    Agents[idx].reduce_entropy()\n",
    "                    print (\"Agent {} : Entropy reduced to {} \" .format(idx, Agents[idx].params['entropy']))\n",
    "        \n",
    "    # For the saving , monitoring of the agent \n",
    "    if env.done :\n",
    "        env.reset()\n",
    "        \n",
    "        \n",
    "        # Only for AC\n",
    "        for idx, agent in enumerate(Agents):\n",
    "            predicted_values, true_values, proba0, probas = agent.value_check(horizon, n_sample)\n",
    "            print (\"Agent {} : Predicted Values and True Return : \\n {} \\n {}\" .format(idx, predicted_values, true_values))\n",
    "            print (\"Agent {} : Proba distribution on those states : \\n {}\" .format(idx, probas))\n",
    "            print (\"Agent {} : Proba distribution on the 0 state : \\n {}\" .format(idx, proba0))\n",
    "            agent.reset()\n",
    "                    \n",
    "        \n",
    "        for idx, s in start_state.items():\n",
    "            actions[idx] = Agents[idx].choose_action(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Balance DQN Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "## Initialization Parameters ##\n",
    "###############################\n",
    "\n",
    "intersection = \"1_2_4\"\n",
    "map_name  = 'Balance_int'+str(intersection)\n",
    "model_name = map_name\n",
    "vissim_working_directory = 'C:\\\\Users\\\\acabrejasegea\\\\OneDrive - The Alan Turing Institute\\\\Desktop\\\\ATI\\\\0_TMF\\\\MLforFlowOptimisation\\\\Vissim\\\\'\n",
    "#vissim_working_directory = \"E:\\\\OneDrive - University of Warwick\\\\Desktop\\\\ATI\\\\0_TMF\\\\MLforFlowOptimisation\\\\Vissim\"\n",
    "\n",
    "## Simulation Parameters\n",
    "Random_Seed = 44\n",
    "sim_length = 9001\n",
    "timesteps_per_second = 1\n",
    "agent_type = \"DDQN\"\n",
    "#actions_set = 'default_actions'     # 'default_actions' or 'all_actions'\n",
    "actions_set = 'all_actions'\n",
    "\n",
    "## DQN Hyperaramenters\n",
    "episodes = 500\n",
    "copy_weights_frequency = 10\n",
    "\n",
    "PER_activated = True\n",
    "memory_size = 5000\n",
    "batch_size = 128\n",
    "batches_per_episode = 10\n",
    "\n",
    "alpha = 0.00005\n",
    "gamma = 0.95\n",
    "\n",
    "# Load and partition balance dictionary\n",
    "Balance_dictionary = balance_dictionary(agent_type)\n",
    "if intersection == \"1_2_4\":\n",
    "    intersection = 1\n",
    "elif intersection == \"11_12\":\n",
    "    intersection = 11\n",
    "partial_dictionary = {\"junctions\": { (intersection-1) : Balance_dictionary[\"junctions\"][intersection-1]},\\\n",
    "                      \"demand\": Balance_dictionary[\"demand\"]}\n",
    "\n",
    "Session_ID = map_name + \"_\" + actions_set + \"_\" + str(episodes) + \"_\" + str(sim_length-1) + \"_\" + agent_type\n",
    "print(\"Current simulation: {}\".format(Session_ID))\n",
    "\n",
    "# Exploration Schedule (\"linear\" or \"geometric\")\n",
    "exploration_schedule = \"geometric\"\n",
    "epsilon_start = 1\n",
    "epsilon_end   = 0.01\n",
    "\n",
    "def choose_schedule(exploration_schedule, espilon_start, epsilon_end, episodes):\n",
    "    if exploration_schedule == \"linear\":\n",
    "        epsilon_decay = 1.2*(epsilon_end - epsilon_start)/(episodes-1)\n",
    "        epsilon_sequence = [1 + epsilon_decay * entry for entry in range(episodes+1)]\n",
    "        epsilon_sequence = [0.01 if entry < 0.01 else entry for entry in epsilon_sequence]\n",
    "    elif exploration_schedule == \"geometric\":\n",
    "        epsilon_decay = np.power(epsilon_end/epsilon_start, 1./(episodes-1)) # Geometric decay\n",
    "        epsilon_sequence = [epsilon_start * epsilon_decay ** entry for entry in range(episodes+1)]\n",
    "        epsilon_sequence = [0.01 if entry < 0.01 else entry for entry in epsilon_sequence]\n",
    "    elif exploration_schedule == \"entropy\":\n",
    "        pass\n",
    "    else:\n",
    "        print(\"ERROR: Unrecognized choice of exploration schedule.\")\n",
    "        \n",
    "    # Plotting exploration schedule\n",
    "    plt.figure(figsize=(8,4.5))\n",
    "    x_series = np.array(range(1,episodes+1))\n",
    "    y_series = epsilon_sequence[0:episodes]\n",
    "    plt.plot(x_series, y_series, '-b')\n",
    "    plt.xlabel('Episodes')\n",
    "    plt.ylabel('Ratio of random exploration')\n",
    "    plt.title('Exploration schedule')\n",
    "    plt.show()\n",
    "    return(epsilon_sequence)\n",
    "\n",
    "epsilon_sequence = choose_schedule(exploration_schedule, epsilon_start, epsilon_end, episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Deploy Agents\n",
    "Balance_int_MultiDQN_Agents = MasterDQN_Agent(model_name, vissim_working_directory, sim_length, partial_dictionary, actions_set,\\\n",
    "                gamma, alpha, agent_type, memory_size, PER_activated, batch_size, batches_per_episode, copy_weights_frequency, epsilon_sequence,\\\n",
    "                Random_Seed, timesteps_per_second, Session_ID, verbose = True)\n",
    "Balance_int_MultiDQN_Agents.prepopulate_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Deploy Environment\n",
    "env = None\n",
    "env = environment(model_name, vissim_working_directory, sim_length, partial_dictionary, actions_set,\\\n",
    "                  Random_Seed = Random_Seed, timesteps_per_second = timesteps_per_second, mode = 'debug', delete_results = True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Test to ensure correct deployment of agents\n",
    "\n",
    "# Test 1: Check number of agents\n",
    "print(env.SCUs.items())\n",
    "\n",
    "# Test 2: Check Dictionary for each agent\n",
    "agent = 0\n",
    "print(\"state_type: \" + env.SCUs[agent].state_type)\n",
    "print(\"state_size: \")\n",
    "print(env.SCUs[agent].state_size)\n",
    "print(\"reward_type: \")\n",
    "print(env.SCUs[agent].reward_type)\n",
    "print(\"compatible_actions: \")\n",
    "print(env.SCUs[agent].compatible_actions)\n",
    "print(\"all_actions: \")\n",
    "print(env.SCUs[agent].all_actions)\n",
    "print(\"Lanes_names: \" )\n",
    "print(env.SCUs[agent].Lanes_names)\n",
    "print(\"Links_names: \")\n",
    "print(env.SCUs[agent].Links_names)\n",
    "print(\"time_steps_per_second: \" + str(env.SCUs[agent].time_steps_per_second))\n",
    "print(\"queues_counter_ID: \" )\n",
    "print(env.SCUs[agent].queues_counter_ID)\n",
    "print(\"queues_counters: \")\n",
    "print(env.SCUs[agent].queues_counters)\n",
    "print(\"signal_controller: \")\n",
    "print(env.SCUs[agent].signal_controller)\n",
    "print(\"Signal_Groups: \" )\n",
    "print(env.SCUs[agent].signal_groups)\n",
    "print(\"Node: \" + str(env.SCUs[agent].Node))\n",
    "\n",
    "## CORRECT - No apparent issues from this test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Tests to ensure correct STATE READING\n",
    "timesteps = 1\n",
    "for i in range(timesteps):\n",
    "    env.Vissim.Simulation.RunSingleStep()\n",
    "\n",
    "## Test 3: Correct Reading of queues from QUEUE COUNTERS\n",
    "print(\"queues_counter_ID: \" )\n",
    "print(env.SCUs[0].queues_counter_ID)\n",
    "print([env.Vissim.Net.QueueCounters.ItemByKey(i).AttValue('QLen(Current, Last)') for i in env.SCUs[0].queues_counter_ID])\n",
    "    \n",
    "# Test 4: Correct Reading of Aggregated Queues by SCU\n",
    "print(env.SCUs[0].calculate_queues())\n",
    "\n",
    "## Test 5: Correct Reading of Global Queues by ENVIRONMENT\n",
    "print(env.get_queues())\n",
    "\n",
    "## CORRECT - No apparent issues from this test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Test 6: Correct Reading of Initial State, and Generation of according actions\n",
    "start_state = env.get_state()\n",
    "actions = {}\n",
    "print(\"Dict([(Agent_ID, array(state))])\")\n",
    "print(start_state.items())\n",
    "print(\"\")\n",
    "for idx, s in start_state.items():\n",
    "    actions[idx] = Balance_int_MultiDQN_Agents.Agents[idx].choose_action(s)\n",
    "print(\"{Agent_ID : Chosen_Action}\")\n",
    "print(actions)\n",
    "\n",
    "## CORRECT - No apparent issues from this test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Test 7: Correct Reading of General State from SCU and Generation of according actions\n",
    "SARSDs = env.step_to_next_action(actions)\n",
    "actions = dict()\n",
    "for idx , sarsd in SARSDs.items():\n",
    "    s,a,r,ns,d = sarsd\n",
    "    \n",
    "print(\"Agent_ID: \" + str(SARSDs.keys()))\n",
    "print(\"Agent_State:\")\n",
    "print(SARSDs[0][0][0])\n",
    "print(\"Agent_Action: \" + str(SARSDs[0][1]))\n",
    "print(\"Agent_Reward: \" + str(SARSDs[0][2]))\n",
    "print(\"Agent_Next_State:\")\n",
    "print(SARSDs[0][3][0])\n",
    "print(\"Done: \" + str(SARSDs[0][4]))\n",
    "\n",
    "## CORRECT - No apparent issues from this test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Test 8: Correct operation of signal groups\n",
    "signal_group = 5\n",
    "env.SCUs[0].signal_groups[signal_group].SetAttValue(\"SigState\", \"GREEN\")\n",
    "env.Vissim.Simulation.RunSingleStep()\n",
    "\n",
    "## CORRECT - No apparent issues from this test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "###### Test 9-1: Correct implementation of actions (SETUP)\n",
    "for idx, agent in Balance_int_MultiDQN_Agents.Agents.items():\n",
    "    agent.reset()\n",
    "\n",
    "start_state = env.get_state()\n",
    "print(\"Initial State: {Agent_ID: initual queues}\")\n",
    "print(start_state)\n",
    "actions = {}\n",
    "for idx, s in start_state.items():\n",
    "    actions[idx] = Balance_int_MultiDQN_Agents.Agents[idx].choose_action(s)\n",
    "print(\"Initial Choice of Actions: {Agent_ID: action}\")    \n",
    "print(actions)\n",
    "\n",
    "# That is not a clean way to do this\n",
    "def to_dictionary(dictionary,idx,value):\n",
    "    \"\"\"\n",
    "    Assign a value to an index in a dictionary\n",
    "    \"\"\"\n",
    "    dictionary[idx] = value\n",
    "    \n",
    "## CORRECT - No apparent issues from this test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###### Test 9-2: Correct implementation of actions (EXECUTION)\n",
    "##\n",
    "## ATTENTION: If an \"index out of range\" is requested, the system will break an will\\\n",
    "##            require a reset. This does not affect normal simulation.\n",
    "\n",
    "actions[0] = 4\n",
    "# This is step_to_next_action() function\n",
    "while not env.action_required:\n",
    "    \n",
    "    # This is the step() function\n",
    "    Sarsd = dict()\n",
    "    \n",
    "    # The default position is that no action is required, only a step of simulator\n",
    "    env.action_required = False\n",
    "    #print(\"false 1\")\n",
    "    \n",
    "    [scu.action_update(actions[0] , green_time = 5 ) for idx, scu in env.SCUs.items() if scu.action_required]\n",
    "    \n",
    "    [scu.update() for idx,scu in env.SCUs.items()]\n",
    "    \n",
    "    env.Vissim.Simulation.RunSingleStep()\n",
    "    \n",
    "    [to_dictionary(Sarsd,idx,scu.sars()+[env.done]) for idx,scu in env.SCUs.items() if scu.action_required ]\n",
    "    \n",
    "    if len(Sarsd) > 0 or env.done :\n",
    "        env.action_required = True\n",
    "        #print(\"TRUE\")\n",
    "    \n",
    "    print(Sarsd)\n",
    "        \n",
    "env.action_required = False\n",
    "#print(\"false 2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Test 10: Correct changing of phases based on actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Test 11: Correct calculation of rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balance RL DQN Partial Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current simulation: Balance_int2_4_all_actions_100_10800_DuelingDDQN_delay\n"
     ]
    }
   ],
   "source": [
    "intersection = \"2_4\"\n",
    "map_name  = 'Balance_int'+str(intersection)\n",
    "model_name = map_name\n",
    "#vissim_working_directory = 'C:\\\\Users\\\\acabrejasegea\\\\OneDrive - The Alan Turing Institute\\\\Desktop\\\\ATI\\\\0_TMF\\\\MLforFlowOptimisation\\\\Vissim\\\\'\n",
    "vissim_working_directory = \"E:\\\\OneDrive - University of Warwick\\\\Desktop\\\\ATI\\\\0_TMF\\\\MLforFlowOptimisation\\\\Vissim\"\n",
    "\n",
    "## Simulation Parameters\n",
    "Random_Seed = 42\n",
    "sim_length = 10801\n",
    "timesteps_per_second = 1\n",
    "agent_type = \"DuelingDDQN\"\n",
    "actions = 'all_actions'     # 'default_actions' or 'all_actions'\n",
    "\n",
    "## DQN Hyperaramenters\n",
    "episodes = 100\n",
    "copy_weights_frequency = 10\n",
    "\n",
    "PER_activated = True\n",
    "memory_size = 10000\n",
    "batch_size = 256\n",
    "batches_per_episode = 10\n",
    "\n",
    "alpha = 0.001\n",
    "gamma = 0.95\n",
    "\n",
    "# Load and partition balance dictionary\n",
    "Balance_dictionary = balance_dictionary(agent_type)\n",
    "if intersection == \"1_2_4\":\n",
    "    intersection = 1\n",
    "elif intersection == \"2_4\":\n",
    "    intersection = 2\n",
    "elif intersection == \"11_12\":\n",
    "    intersection = 11\n",
    "partial_dictionary = {\"junctions\": { (intersection-1) : Balance_dictionary[\"junctions\"][intersection-1]},\\\n",
    "                      \"demand\": Balance_dictionary[\"demand\"]}\n",
    "\n",
    "Session_ID = map_name + \"_\" + actions + \"_\" + str(episodes) + \"_\" + str(sim_length-1) + \"_\" + agent_type + \"_delay\"\n",
    "print(\"Current simulation: {}\".format(Session_ID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x324 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Exploration Schedule (\"linear\" or \"geometric\")\n",
    "exploration_schedule = \"geometric\"\n",
    "epsilon_start = 1\n",
    "epsilon_end   = 0.01\n",
    "\n",
    "def choose_schedule(exploration_schedule, espilon_start, epsilon_end, episodes):\n",
    "    if exploration_schedule == \"linear\":\n",
    "        epsilon_decay = 1.2*(epsilon_end - epsilon_start)/(episodes-1)\n",
    "        epsilon_sequence = [1 + epsilon_decay * entry for entry in range(episodes+1)]\n",
    "        epsilon_sequence = [0.01 if entry < 0.01 else entry for entry in epsilon_sequence]\n",
    "    elif exploration_schedule == \"geometric\":\n",
    "        epsilon_decay = np.power(epsilon_end/epsilon_start, 1./(episodes-1)) # Geometric decay\n",
    "        epsilon_sequence = [epsilon_start * epsilon_decay ** entry for entry in range(episodes+1)]\n",
    "        epsilon_sequence = [0.01 if entry < 0.01 else entry for entry in epsilon_sequence]\n",
    "    elif exploration_schedule == \"entropy\":\n",
    "        pass\n",
    "    else:\n",
    "        print(\"ERROR: Unrecognized choice of exploration schedule.\")\n",
    "        \n",
    "    # Plotting exploration schedule\n",
    "    plt.figure(figsize=(8,4.5))\n",
    "    x_series = np.array(range(1,episodes+1))\n",
    "    y_series = epsilon_sequence[0:episodes]\n",
    "    plt.plot(x_series, y_series, '-b')\n",
    "    plt.xlabel('Episodes')\n",
    "    plt.ylabel('Ratio of random exploration')\n",
    "    plt.title('Exploration schedule')\n",
    "    plt.show()\n",
    "    return(epsilon_sequence)\n",
    "\n",
    "epsilon_sequence = choose_schedule(exploration_schedule, epsilon_start, epsilon_end, episodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTERSECTION 1: SETTING UP AGENT\n",
      "WARNING:tensorflow:From C:\\Users\\ACE\\Anaconda3\\envs\\vissim\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 24)           216         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 24)           600         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 24)           600         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 24)           600         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            25          dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 5)            125         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "policy (Lambda)                 (None, 5)            0           dense_5[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,166\n",
      "Trainable params: 2,166\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Deployed instance of Dueling Double Deep Q Learning Agent(s) at Intersection 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Balance_int_MultiDQN_Agents = MasterDQN_Agent(model_name, vissim_working_directory, sim_length, partial_dictionary, actions,\\\n",
    "                gamma, alpha, agent_type, memory_size, PER_activated, batch_size, batches_per_episode, copy_weights_frequency, epsilon_sequence,\\\n",
    "                Random_Seed, timesteps_per_second, Session_ID, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experience file not found. Generating now...\n",
      "Working Directory set to: E:\\OneDrive - University of Warwick\\Desktop\\ATI\\0_TMF\\MLforFlowOptimisation\\Vissim\n",
      "Generating Cache...\n",
      "Cache generated.\n",
      "\n",
      "****************************\n",
      "*   COM Server dispatched  *\n",
      "****************************\n",
      "\n",
      "Attempting to load Model File: Balance_int2_4.inpx ...\n",
      "Model File load process successful.\n",
      "Simulation length set to 10801 seconds.\n",
      "Results from Previous Simulations: Deleted. Fresh Start Available.\n",
      "Fetched and containerized Network Object \n",
      "\n",
      "*******************************************************\n",
      "*                                                     *\n",
      "*                COM SETUP COMPLETE                   *\n",
      "*                                                     *\n",
      "*******************************************************\n",
      "\n",
      "Random seed set in simulator. Random Seed = 42\n",
      "Deploying Network Parser...\n",
      "Successful Network Crawl: Identified SignalControllers, Links, Lanes and Vehicle Inputs.\n",
      "\n",
      "Setting Simulation mode to: training\n",
      "Starting Deployments of Signal Control Units...\n",
      "SCUs successfully deployed. Elapsed time 0.16 seconds.\n",
      "\n",
      "After 0 actions taken by the Agents,  Agent 0 memory is 0.0 percent full\n",
      "After 1000 actions taken by the Agents,  Agent 0 memory is 10.0 percent full\n",
      "Random Seed Set to 43\n",
      "After 2000 actions taken by the Agents,  Agent 0 memory is 20.0 percent full\n",
      "Random Seed Set to 44\n",
      "After 3000 actions taken by the Agents,  Agent 0 memory is 30.0 percent full\n",
      "Random Seed Set to 45\n",
      "After 4000 actions taken by the Agents,  Agent 0 memory is 40.0 percent full\n",
      "Random Seed Set to 46\n",
      "After 5000 actions taken by the Agents,  Agent 0 memory is 50.0 percent full\n",
      "Random Seed Set to 47\n",
      "After 6000 actions taken by the Agents,  Agent 0 memory is 60.0 percent full\n",
      "Random Seed Set to 48\n",
      "After 7000 actions taken by the Agents,  Agent 0 memory is 70.0 percent full\n",
      "After 8000 actions taken by the Agents,  Agent 0 memory is 80.0 percent full\n",
      "Random Seed Set to 49\n",
      "After 9000 actions taken by the Agents,  Agent 0 memory is 90.0 percent full\n",
      "Random Seed Set to 50\n",
      "Memory filled. Saving as:E:\\OneDrive - University of Warwick\\Desktop\\ATI\\0_TMF\\MLforFlowOptimisation\\Vissim\\Balance_int2_4\\Agents_Results\\DuelingDDQN\\Balance_int2_4_all_actions_100_10800_DuelingDDQN_delay\\Agent0_PERPre_10000.p\n"
     ]
    }
   ],
   "source": [
    "Balance_int_MultiDQN_Agents.prepopulate_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working Directory set to: E:\\OneDrive - University of Warwick\\Desktop\\ATI\\0_TMF\\MLforFlowOptimisation\\Vissim\n",
      "Generating Cache...\n",
      "Cache generated.\n",
      "\n",
      "****************************\n",
      "*   COM Server dispatched  *\n",
      "****************************\n",
      "\n",
      "Attempting to load Model File: Balance_int2_4.inpx ...\n",
      "Model File load process successful.\n",
      "Simulation length set to 10801 seconds.\n",
      "Results from Previous Simulations: Deleted. Fresh Start Available.\n",
      "Fetched and containerized Network Object \n",
      "\n",
      "*******************************************************\n",
      "*                                                     *\n",
      "*                COM SETUP COMPLETE                   *\n",
      "*                                                     *\n",
      "*******************************************************\n",
      "\n",
      "Random seed set in simulator. Random Seed = 42\n",
      "Deploying Network Parser...\n",
      "Successful Network Crawl: Identified SignalControllers, Links, Lanes and Vehicle Inputs.\n",
      "\n",
      "Setting Simulation mode to: training\n",
      "Starting Deployments of Signal Control Units...\n",
      "SCUs successfully deployed. Elapsed time 0.11 seconds.\n",
      "\n",
      "start\n",
      "Random Seed Set to 43\n",
      "Episode 1: Finished running.\n",
      "Agent 0, Average Reward: -105.12\n",
      "Saving architecture, weights, optimizer state for best agent-1\n",
      "256/256 - 1s - loss: 2707.4041\n",
      "256/256 - 0s - loss: 2300.6133\n",
      "256/256 - 0s - loss: 2139.7415\n",
      "256/256 - 0s - loss: 1649.3889\n",
      "256/256 - 0s - loss: 1346.7783\n",
      "256/256 - 0s - loss: 1549.9092\n",
      "256/256 - 0s - loss: 1150.4617\n",
      "256/256 - 0s - loss: 920.7325\n",
      "256/256 - 0s - loss: 1017.6574\n",
      "256/256 - 0s - loss: 834.9923\n",
      "Reducing exploration for all agents to 0.9545\n",
      "\n",
      "Episode 2: Starting computation.\n",
      "Random Seed Set to 44\n",
      "Episode 2: Finished running.\n",
      "Agent 0, Average Reward: -131.38\n",
      "256/256 - 0s - loss: 751.5034\n",
      "256/256 - 0s - loss: 609.2538\n",
      "256/256 - 0s - loss: 599.8215\n",
      "256/256 - 0s - loss: 583.5016\n",
      "256/256 - 0s - loss: 398.0771\n",
      "256/256 - 0s - loss: 412.3784\n",
      "256/256 - 0s - loss: 404.9133\n",
      "256/256 - 0s - loss: 358.6510\n",
      "256/256 - 0s - loss: 287.2169\n",
      "256/256 - 0s - loss: 253.8986\n",
      "Reducing exploration for all agents to 0.9112\n",
      "\n",
      "Episode 3: Starting computation.\n",
      "Random Seed Set to 45\n",
      "Episode 3: Finished running.\n",
      "Agent 0, Average Reward: -123.55\n",
      "256/256 - 0s - loss: 306.3996\n",
      "256/256 - 0s - loss: 318.9246\n",
      "256/256 - 0s - loss: 290.8978\n",
      "256/256 - 0s - loss: 288.8937\n",
      "256/256 - 0s - loss: 324.8740\n",
      "256/256 - 0s - loss: 314.9691\n",
      "256/256 - 0s - loss: 324.3665\n",
      "256/256 - 0s - loss: 351.8076\n",
      "256/256 - 0s - loss: 373.8144\n",
      "256/256 - 0s - loss: 519.9960\n",
      "Reducing exploration for all agents to 0.8697\n",
      "\n",
      "Episode 4: Starting computation.\n",
      "Random Seed Set to 46\n",
      "Episode 4: Finished running.\n",
      "Agent 0, Average Reward: -127.56\n",
      "256/256 - 0s - loss: 470.7027\n",
      "256/256 - 0s - loss: 660.8149\n",
      "256/256 - 0s - loss: 689.1954\n",
      "256/256 - 0s - loss: 685.4034\n",
      "256/256 - 0s - loss: 762.0146\n",
      "256/256 - 0s - loss: 880.1941\n",
      "256/256 - 0s - loss: 845.6914\n",
      "256/256 - 0s - loss: 916.7469\n",
      "256/256 - 0s - loss: 914.0833\n",
      "256/256 - 0s - loss: 736.1755\n",
      "Reducing exploration for all agents to 0.8302\n",
      "\n",
      "Episode 5: Starting computation.\n",
      "Random Seed Set to 47\n",
      "Episode 5: Finished running.\n",
      "Agent 0, Average Reward: -132.76\n",
      "256/256 - 0s - loss: 682.6525\n",
      "256/256 - 0s - loss: 591.5622\n",
      "256/256 - 0s - loss: 611.7634\n",
      "256/256 - 0s - loss: 636.4650\n",
      "256/256 - 0s - loss: 447.6978\n",
      "256/256 - 0s - loss: 567.5568\n",
      "256/256 - 0s - loss: 458.8694\n",
      "256/256 - 0s - loss: 466.3911\n",
      "256/256 - 0s - loss: 539.4222\n",
      "256/256 - 0s - loss: 454.1709\n",
      "Reducing exploration for all agents to 0.7925\n",
      "\n",
      "Episode 6: Starting computation.\n",
      "Random Seed Set to 48\n",
      "Episode 6: Finished running.\n",
      "Agent 0, Average Reward: -150.97\n",
      "256/256 - 0s - loss: 603.7562\n",
      "256/256 - 0s - loss: 535.8196\n",
      "256/256 - 0s - loss: 474.5077\n",
      "256/256 - 0s - loss: 473.5965\n",
      "256/256 - 0s - loss: 384.4839\n",
      "256/256 - 0s - loss: 336.4548\n",
      "256/256 - 0s - loss: 350.7684\n",
      "256/256 - 0s - loss: 360.4172\n",
      "256/256 - 0s - loss: 340.1246\n",
      "256/256 - 0s - loss: 377.4135\n",
      "Reducing exploration for all agents to 0.7565\n",
      "\n",
      "Episode 7: Starting computation.\n",
      "Random Seed Set to 49\n",
      "Episode 7: Finished running.\n",
      "Agent 0, Average Reward: -117.8\n",
      "256/256 - 0s - loss: 285.4641\n",
      "256/256 - 0s - loss: 509.5138\n",
      "256/256 - 0s - loss: 270.7427\n",
      "256/256 - 0s - loss: 329.7966\n",
      "256/256 - 0s - loss: 351.2021\n",
      "256/256 - 0s - loss: 286.2371\n",
      "256/256 - 0s - loss: 285.7945\n",
      "256/256 - 0s - loss: 282.9482\n",
      "256/256 - 0s - loss: 298.6577\n",
      "256/256 - 0s - loss: 297.9736\n",
      "Reducing exploration for all agents to 0.7221\n",
      "\n",
      "Episode 8: Starting computation.\n",
      "Random Seed Set to 50\n",
      "Episode 8: Finished running.\n",
      "Agent 0, Average Reward: -89.56\n",
      "Saving architecture, weights, optimizer state for best agent-1\n",
      "256/256 - 0s - loss: 354.2943\n",
      "256/256 - 0s - loss: 342.9333\n",
      "256/256 - 0s - loss: 383.4820\n",
      "256/256 - 0s - loss: 281.5467\n",
      "256/256 - 0s - loss: 314.1071\n",
      "256/256 - 0s - loss: 356.9656\n",
      "256/256 - 0s - loss: 320.3789\n",
      "256/256 - 0s - loss: 313.2361\n",
      "256/256 - 0s - loss: 263.1677\n",
      "256/256 - 0s - loss: 212.7411\n",
      "Reducing exploration for all agents to 0.6893\n",
      "\n",
      "Episode 9: Starting computation.\n",
      "Random Seed Set to 51\n",
      "Episode 9: Finished running.\n",
      "Agent 0, Average Reward: -121.66\n",
      "256/256 - 0s - loss: 226.5734\n",
      "256/256 - 0s - loss: 191.5421\n",
      "256/256 - 0s - loss: 204.3935\n",
      "256/256 - 0s - loss: 227.9233\n",
      "256/256 - 0s - loss: 217.3956\n",
      "256/256 - 0s - loss: 225.5443\n",
      "256/256 - 0s - loss: 200.7451\n",
      "256/256 - 0s - loss: 234.1488\n",
      "256/256 - 0s - loss: 216.1267\n",
      "256/256 - 0s - loss: 241.1875\n",
      "Reducing exploration for all agents to 0.6579\n",
      "\n",
      "Episode 10: Starting computation.\n",
      "Random Seed Set to 52\n",
      "Episode 10: Finished running.\n",
      "Agent 0, Average Reward: -112.92\n",
      "256/256 - 0s - loss: 219.8830\n",
      "256/256 - 0s - loss: 198.1504\n",
      "256/256 - 0s - loss: 230.3932\n",
      "256/256 - 0s - loss: 201.0967\n",
      "256/256 - 0s - loss: 192.1430\n",
      "256/256 - 0s - loss: 247.3038\n",
      "256/256 - 0s - loss: 194.0670\n",
      "256/256 - 0s - loss: 185.3560\n",
      "256/256 - 0s - loss: 232.3600\n",
      "256/256 - 0s - loss: 249.4751\n",
      "Weights succesfully copied to Target model for Agent 1.\n",
      "Reducing exploration for all agents to 0.628\n",
      "\n",
      "Episode 11: Starting computation.\n",
      "Random Seed Set to 53\n",
      "Episode 11: Finished running.\n",
      "Agent 0, Average Reward: -100.99\n",
      "256/256 - 0s - loss: 3690.4309\n",
      "256/256 - 0s - loss: 3743.3848\n",
      "256/256 - 0s - loss: 3367.1482\n",
      "256/256 - 0s - loss: 2746.0891\n",
      "256/256 - 0s - loss: 2363.3623\n",
      "256/256 - 0s - loss: 1921.1951\n",
      "256/256 - 0s - loss: 1369.2947\n",
      "256/256 - 0s - loss: 1041.7637\n",
      "256/256 - 0s - loss: 656.9161\n",
      "256/256 - 0s - loss: 393.6400\n",
      "Reducing exploration for all agents to 0.5995\n",
      "\n",
      "Episode 12: Starting computation.\n",
      "Random Seed Set to 54\n",
      "Episode 12: Finished running.\n",
      "Agent 0, Average Reward: -229.46\n",
      "256/256 - 0s - loss: 365.7031\n",
      "256/256 - 0s - loss: 359.0406\n",
      "256/256 - 0s - loss: 600.1568\n",
      "256/256 - 0s - loss: 721.6829\n",
      "256/256 - 0s - loss: 743.7750\n",
      "256/256 - 0s - loss: 912.6317\n",
      "256/256 - 0s - loss: 1021.5366\n",
      "256/256 - 0s - loss: 720.6674\n",
      "256/256 - 0s - loss: 656.7379\n",
      "256/256 - 0s - loss: 464.2729\n",
      "Reducing exploration for all agents to 0.5722\n",
      "\n",
      "Episode 13: Starting computation.\n",
      "Random Seed Set to 55\n",
      "Episode 13: Finished running.\n",
      "Agent 0, Average Reward: -253.02\n",
      "256/256 - 0s - loss: 423.7950\n",
      "256/256 - 0s - loss: 439.8850\n",
      "256/256 - 0s - loss: 289.6832\n",
      "256/256 - 0s - loss: 308.8005\n",
      "256/256 - 0s - loss: 370.6711\n",
      "256/256 - 0s - loss: 357.6908\n",
      "256/256 - 0s - loss: 353.9066\n",
      "256/256 - 0s - loss: 401.5148\n",
      "256/256 - 0s - loss: 423.5320\n",
      "256/256 - 0s - loss: 406.5637\n",
      "Reducing exploration for all agents to 0.5462\n",
      "\n",
      "Episode 14: Starting computation.\n",
      "Random Seed Set to 56\n",
      "Episode 14: Finished running.\n",
      "Agent 0, Average Reward: -84.45\n",
      "Saving architecture, weights, optimizer state for best agent-1\n",
      "256/256 - 0s - loss: 335.4138\n",
      "256/256 - 0s - loss: 320.9422\n",
      "256/256 - 0s - loss: 293.3294\n",
      "256/256 - 0s - loss: 302.7728\n",
      "256/256 - 0s - loss: 297.4098\n",
      "256/256 - 0s - loss: 266.0065\n",
      "256/256 - 0s - loss: 258.3305\n",
      "256/256 - 0s - loss: 227.9888\n",
      "256/256 - 0s - loss: 297.0739\n",
      "256/256 - 0s - loss: 270.0034\n",
      "Reducing exploration for all agents to 0.5214\n",
      "\n",
      "Episode 15: Starting computation.\n",
      "Random Seed Set to 57\n",
      "Episode 15: Finished running.\n",
      "Agent 0, Average Reward: -60.25\n",
      "Saving architecture, weights, optimizer state for best agent-1\n",
      "256/256 - 0s - loss: 276.8673\n",
      "256/256 - 0s - loss: 260.4668\n",
      "256/256 - 0s - loss: 227.6662\n",
      "256/256 - 0s - loss: 256.7600\n",
      "256/256 - 0s - loss: 230.0449\n",
      "256/256 - 0s - loss: 165.8709\n",
      "256/256 - 0s - loss: 214.6652\n",
      "256/256 - 0s - loss: 212.7955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/256 - 0s - loss: 256.6702\n",
      "256/256 - 0s - loss: 226.1898\n",
      "Reducing exploration for all agents to 0.4977\n",
      "\n",
      "Episode 16: Starting computation.\n",
      "Random Seed Set to 58\n",
      "Episode 16: Finished running.\n",
      "Agent 0, Average Reward: -196.77\n",
      "256/256 - 0s - loss: 261.1318\n",
      "256/256 - 0s - loss: 282.2085\n",
      "256/256 - 0s - loss: 216.3782\n",
      "256/256 - 0s - loss: 201.9275\n",
      "256/256 - 0s - loss: 239.5613\n",
      "256/256 - 0s - loss: 243.8661\n",
      "256/256 - 0s - loss: 187.2098\n",
      "256/256 - 0s - loss: 259.1548\n",
      "256/256 - 0s - loss: 211.7810\n",
      "256/256 - 0s - loss: 226.3301\n",
      "Reducing exploration for all agents to 0.4751\n",
      "\n",
      "Episode 17: Starting computation.\n",
      "Random Seed Set to 59\n",
      "Episode 17: Finished running.\n",
      "Agent 0, Average Reward: -47.08\n",
      "Saving architecture, weights, optimizer state for best agent-1\n",
      "256/256 - 0s - loss: 234.7867\n",
      "256/256 - 0s - loss: 186.4053\n",
      "256/256 - 0s - loss: 173.2523\n",
      "256/256 - 0s - loss: 210.2810\n",
      "256/256 - 0s - loss: 200.5476\n",
      "256/256 - 0s - loss: 206.6118\n",
      "256/256 - 0s - loss: 202.7536\n",
      "256/256 - 0s - loss: 256.8416\n",
      "256/256 - 0s - loss: 196.0421\n",
      "256/256 - 0s - loss: 244.7222\n",
      "Reducing exploration for all agents to 0.4535\n",
      "\n",
      "Episode 18: Starting computation.\n",
      "Random Seed Set to 60\n",
      "Episode 18: Finished running.\n",
      "Agent 0, Average Reward: -70.15\n",
      "256/256 - 0s - loss: 177.2350\n",
      "256/256 - 0s - loss: 187.9577\n",
      "256/256 - 0s - loss: 249.1073\n",
      "256/256 - 0s - loss: 175.1960\n",
      "256/256 - 0s - loss: 180.8958\n",
      "256/256 - 0s - loss: 151.9923\n",
      "256/256 - 0s - loss: 209.1060\n",
      "256/256 - 0s - loss: 166.3057\n",
      "256/256 - 0s - loss: 229.3520\n",
      "256/256 - 0s - loss: 162.7091\n",
      "Reducing exploration for all agents to 0.4329\n",
      "\n",
      "Episode 19: Starting computation.\n",
      "Random Seed Set to 61\n",
      "Episode 19: Finished running.\n",
      "Agent 0, Average Reward: -50.02\n",
      "256/256 - 0s - loss: 180.0599\n",
      "256/256 - 0s - loss: 206.8256\n",
      "256/256 - 0s - loss: 193.2710\n",
      "256/256 - 0s - loss: 193.0531\n",
      "256/256 - 0s - loss: 162.3242\n",
      "256/256 - 0s - loss: 212.4869\n",
      "256/256 - 0s - loss: 188.4443\n",
      "256/256 - 0s - loss: 216.4603\n",
      "256/256 - 0s - loss: 222.2996\n",
      "256/256 - 0s - loss: 189.8426\n",
      "Reducing exploration for all agents to 0.4132\n",
      "\n",
      "Episode 20: Starting computation.\n",
      "Random Seed Set to 62\n",
      "Episode 20: Finished running.\n",
      "Agent 0, Average Reward: -48.72\n",
      "256/256 - 0s - loss: 195.2646\n",
      "256/256 - 0s - loss: 163.5254\n",
      "256/256 - 0s - loss: 145.5843\n",
      "256/256 - 0s - loss: 165.9097\n",
      "256/256 - 0s - loss: 181.1916\n",
      "256/256 - 0s - loss: 149.2667\n",
      "256/256 - 0s - loss: 197.3613\n",
      "256/256 - 0s - loss: 177.8036\n",
      "256/256 - 0s - loss: 130.0854\n",
      "256/256 - 0s - loss: 149.9036\n",
      "Weights succesfully copied to Target model for Agent 1.\n",
      "Saving architecture, weights and optimizer state for agent-1\n",
      "Dumping agent-1 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Dumping Loss Results into pickle file.\n",
      "Reducing exploration for all agents to 0.3944\n",
      "\n",
      "Episode 21: Starting computation.\n",
      "Random Seed Set to 63\n",
      "Episode 21: Finished running.\n",
      "Agent 0, Average Reward: -59.58\n",
      "256/256 - 0s - loss: 2783.3926\n",
      "256/256 - 0s - loss: 2666.2249\n",
      "256/256 - 0s - loss: 2012.3066\n",
      "256/256 - 0s - loss: 1504.7646\n",
      "256/256 - 0s - loss: 1209.4603\n",
      "256/256 - 0s - loss: 818.9130\n",
      "256/256 - 0s - loss: 760.0528\n",
      "256/256 - 0s - loss: 435.7900\n",
      "256/256 - 0s - loss: 336.0560\n",
      "256/256 - 0s - loss: 479.8005\n",
      "Reducing exploration for all agents to 0.3765\n",
      "\n",
      "Episode 22: Starting computation.\n",
      "Random Seed Set to 64\n",
      "Episode 22: Finished running.\n",
      "Agent 0, Average Reward: -224.24\n",
      "256/256 - 0s - loss: 705.3530\n",
      "256/256 - 0s - loss: 541.7851\n",
      "256/256 - 0s - loss: 640.6772\n",
      "256/256 - 0s - loss: 814.2652\n",
      "256/256 - 0s - loss: 895.2957\n",
      "256/256 - 0s - loss: 762.3417\n",
      "256/256 - 0s - loss: 693.3330\n",
      "256/256 - 0s - loss: 451.1139\n",
      "256/256 - 0s - loss: 426.8758\n",
      "256/256 - 0s - loss: 373.8356\n",
      "Reducing exploration for all agents to 0.3594\n",
      "\n",
      "Episode 23: Starting computation.\n",
      "Random Seed Set to 65\n",
      "Episode 23: Finished running.\n",
      "Agent 0, Average Reward: -123.39\n",
      "256/256 - 0s - loss: 284.7122\n",
      "256/256 - 0s - loss: 301.1379\n",
      "256/256 - 0s - loss: 245.4640\n",
      "256/256 - 0s - loss: 320.0060\n",
      "256/256 - 0s - loss: 281.5604\n",
      "256/256 - 0s - loss: 395.3700\n",
      "256/256 - 0s - loss: 333.2778\n",
      "256/256 - 0s - loss: 423.4096\n",
      "256/256 - 0s - loss: 364.7715\n",
      "256/256 - 0s - loss: 393.2769\n",
      "Reducing exploration for all agents to 0.343\n",
      "\n",
      "Episode 24: Starting computation.\n",
      "Random Seed Set to 66\n",
      "Episode 24: Finished running.\n",
      "Agent 0, Average Reward: -335.09\n",
      "256/256 - 0s - loss: 942.2365\n",
      "256/256 - 0s - loss: 440.8010\n",
      "256/256 - 0s - loss: 376.7421\n",
      "256/256 - 0s - loss: 254.9200\n",
      "256/256 - 0s - loss: 324.7253\n",
      "256/256 - 0s - loss: 391.6360\n",
      "256/256 - 0s - loss: 335.6577\n",
      "256/256 - 0s - loss: 305.7115\n",
      "256/256 - 0s - loss: 411.3049\n",
      "256/256 - 0s - loss: 265.6477\n",
      "Reducing exploration for all agents to 0.3275\n",
      "\n",
      "Episode 25: Starting computation.\n",
      "Random Seed Set to 67\n",
      "Episode 25: Finished running.\n",
      "Agent 0, Average Reward: -154.82\n",
      "256/256 - 0s - loss: 233.0509\n",
      "256/256 - 0s - loss: 285.4557\n",
      "256/256 - 0s - loss: 252.5321\n",
      "256/256 - 0s - loss: 260.7314\n",
      "256/256 - 0s - loss: 305.3699\n",
      "256/256 - 0s - loss: 296.7042\n",
      "256/256 - 0s - loss: 283.0056\n",
      "256/256 - 0s - loss: 267.7975\n",
      "256/256 - 0s - loss: 228.1941\n",
      "256/256 - 0s - loss: 268.4979\n",
      "Reducing exploration for all agents to 0.3126\n",
      "\n",
      "Episode 26: Starting computation.\n",
      "Random Seed Set to 68\n",
      "Episode 26: Finished running.\n",
      "Agent 0, Average Reward: -232.19\n",
      "256/256 - 0s - loss: 366.3629\n",
      "256/256 - 0s - loss: 268.0216\n",
      "256/256 - 0s - loss: 248.8988\n",
      "256/256 - 0s - loss: 256.0317\n",
      "256/256 - 0s - loss: 258.0814\n",
      "256/256 - 0s - loss: 179.4888\n",
      "256/256 - 0s - loss: 370.2786\n",
      "256/256 - 0s - loss: 269.2767\n",
      "256/256 - 0s - loss: 316.6911\n",
      "256/256 - 0s - loss: 210.8441\n",
      "Reducing exploration for all agents to 0.2984\n",
      "\n",
      "Episode 27: Starting computation.\n",
      "Random Seed Set to 69\n",
      "Episode 27: Finished running.\n",
      "Agent 0, Average Reward: -131.77\n",
      "256/256 - 0s - loss: 258.3586\n",
      "256/256 - 0s - loss: 358.8279\n",
      "256/256 - 0s - loss: 225.3771\n",
      "256/256 - 0s - loss: 315.9443\n",
      "256/256 - 0s - loss: 206.1237\n",
      "256/256 - 0s - loss: 207.9885\n",
      "256/256 - 0s - loss: 274.3910\n",
      "256/256 - 0s - loss: 209.5461\n",
      "256/256 - 0s - loss: 202.3472\n",
      "256/256 - 0s - loss: 231.9873\n",
      "Reducing exploration for all agents to 0.2848\n",
      "\n",
      "Episode 28: Starting computation.\n",
      "Random Seed Set to 70\n",
      "Episode 28: Finished running.\n",
      "Agent 0, Average Reward: -120.81\n",
      "256/256 - 0s - loss: 219.9565\n",
      "256/256 - 0s - loss: 350.0018\n",
      "256/256 - 0s - loss: 270.4271\n",
      "256/256 - 0s - loss: 189.5223\n",
      "256/256 - 0s - loss: 158.7686\n",
      "256/256 - 0s - loss: 205.2195\n",
      "256/256 - 0s - loss: 198.4345\n",
      "256/256 - 0s - loss: 194.9380\n",
      "256/256 - 0s - loss: 240.0221\n",
      "256/256 - 0s - loss: 304.5576\n",
      "Reducing exploration for all agents to 0.2719\n",
      "\n",
      "Episode 29: Starting computation.\n",
      "Random Seed Set to 71\n",
      "Episode 29: Finished running.\n",
      "Agent 0, Average Reward: -124.55\n",
      "256/256 - 0s - loss: 207.6420\n",
      "256/256 - 0s - loss: 208.9906\n",
      "256/256 - 0s - loss: 213.1165\n",
      "256/256 - 0s - loss: 273.0324\n",
      "256/256 - 0s - loss: 197.2967\n",
      "256/256 - 0s - loss: 292.0559\n",
      "256/256 - 0s - loss: 236.2972\n",
      "256/256 - 0s - loss: 251.4146\n",
      "256/256 - 0s - loss: 229.7287\n",
      "256/256 - 0s - loss: 189.3059\n",
      "Reducing exploration for all agents to 0.2595\n",
      "\n",
      "Episode 30: Starting computation.\n",
      "Random Seed Set to 72\n",
      "Episode 30: Finished running.\n",
      "Agent 0, Average Reward: -134.59\n",
      "256/256 - 0s - loss: 159.9369\n",
      "256/256 - 0s - loss: 180.5939\n",
      "256/256 - 0s - loss: 269.8850\n",
      "256/256 - 0s - loss: 154.1837\n",
      "256/256 - 0s - loss: 205.8851\n",
      "256/256 - 0s - loss: 203.0106\n",
      "256/256 - 0s - loss: 205.4235\n",
      "256/256 - 0s - loss: 231.2864\n",
      "256/256 - 0s - loss: 238.6805\n",
      "256/256 - 0s - loss: 196.3630\n",
      "Weights succesfully copied to Target model for Agent 1.\n",
      "Reducing exploration for all agents to 0.2477\n",
      "\n",
      "Episode 31: Starting computation.\n",
      "Random Seed Set to 73\n",
      "Episode 31: Finished running.\n",
      "Agent 0, Average Reward: -96.05\n",
      "256/256 - 0s - loss: 5460.2158\n",
      "256/256 - 0s - loss: 4588.6885\n",
      "256/256 - 0s - loss: 3388.2485\n",
      "256/256 - 0s - loss: 1708.3916\n",
      "256/256 - 0s - loss: 665.7354\n",
      "256/256 - 0s - loss: 447.9793\n",
      "256/256 - 0s - loss: 814.0234\n",
      "256/256 - 0s - loss: 1636.4078\n",
      "256/256 - 0s - loss: 2164.6143\n",
      "256/256 - 0s - loss: 2345.4619\n",
      "Reducing exploration for all agents to 0.2364\n",
      "\n",
      "Episode 32: Starting computation.\n",
      "Random Seed Set to 74\n",
      "Episode 32: Finished running.\n",
      "Agent 0, Average Reward: -47.72\n",
      "256/256 - 0s - loss: 1315.1716\n",
      "256/256 - 0s - loss: 903.0527\n",
      "256/256 - 0s - loss: 663.4145\n",
      "256/256 - 0s - loss: 414.4292\n",
      "256/256 - 0s - loss: 339.5331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/256 - 0s - loss: 329.1082\n",
      "256/256 - 0s - loss: 354.2909\n",
      "256/256 - 0s - loss: 413.9577\n",
      "256/256 - 0s - loss: 480.4845\n",
      "256/256 - 0s - loss: 646.2151\n",
      "Reducing exploration for all agents to 0.2257\n",
      "\n",
      "Episode 33: Starting computation.\n",
      "Random Seed Set to 75\n",
      "Episode 33: Finished running.\n",
      "Agent 0, Average Reward: -231.33\n",
      "256/256 - 0s - loss: 807.0773\n",
      "256/256 - 0s - loss: 807.9836\n",
      "256/256 - 0s - loss: 652.2130\n",
      "256/256 - 0s - loss: 542.9619\n",
      "256/256 - 0s - loss: 470.5807\n",
      "256/256 - 0s - loss: 328.5451\n",
      "256/256 - 0s - loss: 479.2200\n",
      "256/256 - 0s - loss: 304.9062\n",
      "256/256 - 0s - loss: 279.5075\n",
      "256/256 - 0s - loss: 228.3276\n",
      "Reducing exploration for all agents to 0.2154\n",
      "\n",
      "Episode 34: Starting computation.\n",
      "Random Seed Set to 76\n",
      "Episode 34: Finished running.\n",
      "Agent 0, Average Reward: -165.73\n",
      "256/256 - 0s - loss: 307.7211\n",
      "256/256 - 0s - loss: 524.4134\n",
      "256/256 - 0s - loss: 369.5220\n",
      "256/256 - 0s - loss: 274.3025\n",
      "256/256 - 0s - loss: 422.8403\n",
      "256/256 - 0s - loss: 394.6232\n",
      "256/256 - 0s - loss: 436.3322\n",
      "256/256 - 0s - loss: 211.6356\n",
      "256/256 - 0s - loss: 264.5603\n",
      "256/256 - 0s - loss: 338.9690\n",
      "Reducing exploration for all agents to 0.2057\n",
      "\n",
      "Episode 35: Starting computation.\n",
      "Random Seed Set to 77\n",
      "Episode 35: Finished running.\n",
      "Agent 0, Average Reward: -175.44\n",
      "256/256 - 0s - loss: 294.6113\n",
      "256/256 - 0s - loss: 327.6809\n",
      "256/256 - 0s - loss: 405.0386\n",
      "256/256 - 0s - loss: 266.9152\n",
      "256/256 - 0s - loss: 344.8715\n",
      "256/256 - 0s - loss: 253.6002\n",
      "256/256 - 0s - loss: 434.1183\n",
      "256/256 - 0s - loss: 430.0934\n",
      "256/256 - 0s - loss: 426.9552\n",
      "256/256 - 0s - loss: 298.0934\n",
      "Reducing exploration for all agents to 0.1963\n",
      "\n",
      "Episode 36: Starting computation.\n",
      "Random Seed Set to 78\n",
      "Episode 36: Finished running.\n",
      "Agent 0, Average Reward: -94.01\n",
      "256/256 - 0s - loss: 191.5266\n",
      "256/256 - 0s - loss: 260.5906\n",
      "256/256 - 0s - loss: 409.4706\n",
      "256/256 - 0s - loss: 237.1655\n",
      "256/256 - 0s - loss: 214.7573\n",
      "256/256 - 0s - loss: 396.5469\n",
      "256/256 - 0s - loss: 283.8377\n",
      "256/256 - 0s - loss: 250.4657\n",
      "256/256 - 0s - loss: 375.4517\n",
      "256/256 - 0s - loss: 245.6668\n",
      "Reducing exploration for all agents to 0.1874\n",
      "\n",
      "Episode 37: Starting computation.\n",
      "Random Seed Set to 79\n",
      "Episode 37: Finished running.\n",
      "Agent 0, Average Reward: -69.93\n",
      "256/256 - 0s - loss: 300.1475\n",
      "256/256 - 0s - loss: 302.5607\n",
      "256/256 - 0s - loss: 264.7452\n",
      "256/256 - 0s - loss: 227.8321\n",
      "256/256 - 0s - loss: 210.2713\n",
      "256/256 - 0s - loss: 258.9525\n",
      "256/256 - 0s - loss: 245.3712\n",
      "256/256 - 0s - loss: 399.4244\n",
      "256/256 - 0s - loss: 265.9519\n",
      "256/256 - 0s - loss: 346.6590\n",
      "Reducing exploration for all agents to 0.1789\n",
      "\n",
      "Episode 38: Starting computation.\n",
      "Random Seed Set to 80\n",
      "Episode 38: Finished running.\n",
      "Agent 0, Average Reward: -66.67\n",
      "256/256 - 0s - loss: 388.5927\n",
      "256/256 - 0s - loss: 371.3886\n",
      "256/256 - 0s - loss: 262.5548\n",
      "256/256 - 0s - loss: 244.5780\n",
      "256/256 - 0s - loss: 280.1967\n",
      "256/256 - 0s - loss: 355.8520\n",
      "256/256 - 0s - loss: 250.4780\n",
      "256/256 - 0s - loss: 276.1626\n",
      "256/256 - 0s - loss: 284.7959\n",
      "256/256 - 0s - loss: 338.1755\n",
      "Reducing exploration for all agents to 0.1707\n",
      "\n",
      "Episode 39: Starting computation.\n",
      "Random Seed Set to 81\n",
      "Episode 39: Finished running.\n",
      "Agent 0, Average Reward: -127.59\n",
      "256/256 - 0s - loss: 239.4945\n",
      "256/256 - 0s - loss: 358.6215\n",
      "256/256 - 0s - loss: 258.7418\n",
      "256/256 - 0s - loss: 162.0287\n",
      "256/256 - 0s - loss: 275.5245\n",
      "256/256 - 0s - loss: 223.7511\n",
      "256/256 - 0s - loss: 354.6131\n",
      "256/256 - 0s - loss: 238.0038\n",
      "256/256 - 0s - loss: 228.0590\n",
      "256/256 - 0s - loss: 214.3788\n",
      "Reducing exploration for all agents to 0.163\n",
      "\n",
      "Episode 40: Starting computation.\n",
      "Random Seed Set to 82\n",
      "Episode 40: Finished running.\n",
      "Agent 0, Average Reward: -131.14\n",
      "256/256 - 0s - loss: 231.6927\n",
      "256/256 - 0s - loss: 231.6375\n",
      "256/256 - 0s - loss: 263.2552\n",
      "256/256 - 0s - loss: 265.2983\n",
      "256/256 - 0s - loss: 299.7519\n",
      "256/256 - 0s - loss: 261.9541\n",
      "256/256 - 0s - loss: 257.1469\n",
      "256/256 - 0s - loss: 220.3696\n",
      "256/256 - 0s - loss: 196.5067\n",
      "256/256 - 0s - loss: 317.2272\n",
      "Weights succesfully copied to Target model for Agent 1.\n",
      "Saving architecture, weights and optimizer state for agent-1\n",
      "Dumping agent-1 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Dumping Loss Results into pickle file.\n",
      "Reducing exploration for all agents to 0.1556\n",
      "\n",
      "Episode 41: Starting computation.\n",
      "Random Seed Set to 83\n",
      "Episode 41: Finished running.\n",
      "Agent 0, Average Reward: -73.42\n",
      "256/256 - 0s - loss: 2561.8542\n",
      "256/256 - 0s - loss: 2198.9377\n",
      "256/256 - 0s - loss: 1634.0713\n",
      "256/256 - 0s - loss: 1311.1962\n",
      "256/256 - 0s - loss: 1002.5814\n",
      "256/256 - 0s - loss: 548.1007\n",
      "256/256 - 0s - loss: 438.0355\n",
      "256/256 - 0s - loss: 482.5520\n",
      "256/256 - 0s - loss: 593.1252\n",
      "256/256 - 0s - loss: 955.1178\n",
      "Reducing exploration for all agents to 0.1485\n",
      "\n",
      "Episode 42: Starting computation.\n",
      "Random Seed Set to 84\n",
      "Episode 42: Finished running.\n",
      "Agent 0, Average Reward: -280.96\n",
      "256/256 - 0s - loss: 1214.0345\n",
      "256/256 - 0s - loss: 930.8882\n",
      "256/256 - 0s - loss: 924.0250\n",
      "256/256 - 0s - loss: 803.4521\n",
      "256/256 - 0s - loss: 765.8510\n",
      "256/256 - 0s - loss: 651.2284\n",
      "256/256 - 0s - loss: 510.6588\n",
      "256/256 - 0s - loss: 447.6701\n",
      "256/256 - 0s - loss: 312.0814\n",
      "256/256 - 0s - loss: 361.0108\n",
      "Reducing exploration for all agents to 0.1417\n",
      "\n",
      "Episode 43: Starting computation.\n",
      "Random Seed Set to 85\n",
      "Episode 43: Finished running.\n",
      "Agent 0, Average Reward: -256.75\n",
      "256/256 - 0s - loss: 480.4236\n",
      "256/256 - 0s - loss: 546.2797\n",
      "256/256 - 0s - loss: 625.3046\n",
      "256/256 - 0s - loss: 498.5045\n",
      "256/256 - 0s - loss: 430.0455\n",
      "256/256 - 0s - loss: 426.0458\n",
      "256/256 - 0s - loss: 510.9520\n",
      "256/256 - 0s - loss: 424.8241\n",
      "256/256 - 0s - loss: 427.4112\n",
      "256/256 - 0s - loss: 426.5222\n",
      "Reducing exploration for all agents to 0.1353\n",
      "\n",
      "Episode 44: Starting computation.\n",
      "Random Seed Set to 86\n",
      "Episode 44: Finished running.\n",
      "Agent 0, Average Reward: -128.6\n",
      "256/256 - 0s - loss: 332.1992\n",
      "256/256 - 0s - loss: 472.9830\n",
      "256/256 - 0s - loss: 349.4847\n",
      "256/256 - 0s - loss: 304.8604\n",
      "256/256 - 0s - loss: 378.2637\n",
      "256/256 - 0s - loss: 323.8292\n",
      "256/256 - 0s - loss: 326.0025\n",
      "256/256 - 0s - loss: 316.4711\n",
      "256/256 - 0s - loss: 394.0012\n",
      "256/256 - 0s - loss: 471.3593\n",
      "Reducing exploration for all agents to 0.1292\n",
      "\n",
      "Episode 45: Starting computation.\n",
      "Random Seed Set to 87\n",
      "Episode 45: Finished running.\n",
      "Agent 0, Average Reward: -142.22\n",
      "256/256 - 0s - loss: 328.1380\n",
      "256/256 - 0s - loss: 292.6000\n",
      "256/256 - 0s - loss: 317.4888\n",
      "256/256 - 0s - loss: 534.3434\n",
      "256/256 - 0s - loss: 355.2924\n",
      "256/256 - 0s - loss: 307.0981\n",
      "256/256 - 0s - loss: 263.1140\n",
      "256/256 - 0s - loss: 412.2198\n",
      "256/256 - 0s - loss: 355.9044\n",
      "256/256 - 0s - loss: 265.7119\n",
      "Reducing exploration for all agents to 0.1233\n",
      "\n",
      "Episode 46: Starting computation.\n",
      "Random Seed Set to 88\n",
      "Episode 46: Finished running.\n",
      "Agent 0, Average Reward: -137.53\n",
      "256/256 - 0s - loss: 308.8572\n",
      "256/256 - 0s - loss: 347.7698\n",
      "256/256 - 0s - loss: 321.0051\n",
      "256/256 - 0s - loss: 193.6065\n",
      "256/256 - 0s - loss: 348.9124\n",
      "256/256 - 0s - loss: 297.1236\n",
      "256/256 - 0s - loss: 285.2074\n",
      "256/256 - 0s - loss: 271.1711\n",
      "256/256 - 0s - loss: 390.9951\n",
      "256/256 - 0s - loss: 255.8653\n",
      "Reducing exploration for all agents to 0.1177\n",
      "\n",
      "Episode 47: Starting computation.\n",
      "Random Seed Set to 89\n",
      "Episode 47: Finished running.\n",
      "Agent 0, Average Reward: -53.71\n",
      "256/256 - 0s - loss: 341.2725\n",
      "256/256 - 0s - loss: 289.8277\n",
      "256/256 - 0s - loss: 320.2054\n",
      "256/256 - 0s - loss: 360.4962\n",
      "256/256 - 0s - loss: 405.6022\n",
      "256/256 - 0s - loss: 400.8447\n",
      "256/256 - 0s - loss: 268.8185\n",
      "256/256 - 0s - loss: 272.5630\n",
      "256/256 - 0s - loss: 242.6752\n",
      "256/256 - 0s - loss: 335.4553\n",
      "Reducing exploration for all agents to 0.1123\n",
      "\n",
      "Episode 48: Starting computation.\n",
      "Random Seed Set to 90\n",
      "Episode 48: Finished running.\n",
      "Agent 0, Average Reward: -76.58\n",
      "256/256 - 0s - loss: 329.9644\n",
      "256/256 - 0s - loss: 280.5573\n",
      "256/256 - 0s - loss: 312.2814\n",
      "256/256 - 0s - loss: 317.1626\n",
      "256/256 - 0s - loss: 423.5560\n",
      "256/256 - 0s - loss: 334.0356\n",
      "256/256 - 0s - loss: 409.8768\n",
      "256/256 - 0s - loss: 390.5648\n",
      "256/256 - 0s - loss: 327.3290\n",
      "256/256 - 0s - loss: 343.1149\n",
      "Reducing exploration for all agents to 0.1072\n",
      "\n",
      "Episode 49: Starting computation.\n",
      "Random Seed Set to 91\n",
      "Episode 49: Finished running.\n",
      "Agent 0, Average Reward: -133.69\n",
      "256/256 - 0s - loss: 290.9583\n",
      "256/256 - 0s - loss: 282.2831\n",
      "256/256 - 0s - loss: 285.3976\n",
      "256/256 - 0s - loss: 408.9438\n",
      "256/256 - 0s - loss: 334.0733\n",
      "256/256 - 0s - loss: 236.9398\n",
      "256/256 - 0s - loss: 462.5200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/256 - 0s - loss: 274.2609\n",
      "256/256 - 0s - loss: 245.6207\n",
      "256/256 - 0s - loss: 257.8730\n",
      "Reducing exploration for all agents to 0.1024\n",
      "\n",
      "Episode 50: Starting computation.\n",
      "Random Seed Set to 92\n",
      "Episode 50: Finished running.\n",
      "Agent 0, Average Reward: -123.8\n",
      "256/256 - 0s - loss: 310.0203\n",
      "256/256 - 0s - loss: 237.1094\n",
      "256/256 - 0s - loss: 356.9078\n",
      "256/256 - 0s - loss: 410.2444\n",
      "256/256 - 0s - loss: 226.0204\n",
      "256/256 - 0s - loss: 260.8405\n",
      "256/256 - 0s - loss: 281.3237\n",
      "256/256 - 0s - loss: 289.8905\n",
      "256/256 - 0s - loss: 204.7693\n",
      "256/256 - 0s - loss: 289.0635\n",
      "Weights succesfully copied to Target model for Agent 1.\n",
      "Reducing exploration for all agents to 0.0977\n",
      "\n",
      "Episode 51: Starting computation.\n",
      "Random Seed Set to 93\n",
      "Episode 51: Finished running.\n",
      "Agent 0, Average Reward: -66.44\n",
      "256/256 - 0s - loss: 1929.5159\n",
      "256/256 - 0s - loss: 1580.3577\n",
      "256/256 - 0s - loss: 1233.2509\n",
      "256/256 - 0s - loss: 827.3524\n",
      "256/256 - 0s - loss: 522.0208\n",
      "256/256 - 0s - loss: 413.0522\n",
      "256/256 - 0s - loss: 413.4042\n",
      "256/256 - 0s - loss: 453.6614\n",
      "256/256 - 0s - loss: 734.1168\n",
      "256/256 - 0s - loss: 748.6626\n",
      "Reducing exploration for all agents to 0.0933\n",
      "\n",
      "Episode 52: Starting computation.\n",
      "Random Seed Set to 94\n",
      "Episode 52: Finished running.\n",
      "Agent 0, Average Reward: -202.8\n",
      "256/256 - 0s - loss: 913.9673\n",
      "256/256 - 0s - loss: 864.8823\n",
      "256/256 - 0s - loss: 737.8470\n",
      "256/256 - 0s - loss: 576.0933\n",
      "256/256 - 0s - loss: 524.4877\n",
      "256/256 - 0s - loss: 470.1945\n",
      "256/256 - 0s - loss: 537.7473\n",
      "256/256 - 0s - loss: 497.3283\n",
      "256/256 - 0s - loss: 580.4922\n",
      "256/256 - 0s - loss: 487.1921\n",
      "Reducing exploration for all agents to 0.089\n",
      "\n",
      "Episode 53: Starting computation.\n",
      "Random Seed Set to 95\n",
      "Episode 53: Finished running.\n",
      "Agent 0, Average Reward: -189.54\n",
      "256/256 - 0s - loss: 587.9350\n",
      "256/256 - 0s - loss: 445.6503\n",
      "256/256 - 0s - loss: 675.3423\n",
      "256/256 - 0s - loss: 645.8574\n",
      "256/256 - 0s - loss: 390.8150\n",
      "256/256 - 0s - loss: 497.2881\n",
      "256/256 - 0s - loss: 477.4828\n",
      "256/256 - 0s - loss: 443.4065\n",
      "256/256 - 0s - loss: 525.9896\n",
      "256/256 - 0s - loss: 582.4269\n",
      "Reducing exploration for all agents to 0.085\n",
      "\n",
      "Episode 54: Starting computation.\n",
      "Random Seed Set to 96\n",
      "Episode 54: Finished running.\n",
      "Agent 0, Average Reward: -131.1\n",
      "256/256 - 0s - loss: 495.5482\n",
      "256/256 - 0s - loss: 512.9073\n",
      "256/256 - 0s - loss: 465.5733\n",
      "256/256 - 0s - loss: 416.8835\n",
      "256/256 - 0s - loss: 638.2492\n",
      "256/256 - 0s - loss: 452.8659\n",
      "256/256 - 0s - loss: 500.1451\n",
      "256/256 - 0s - loss: 500.9458\n",
      "256/256 - 0s - loss: 487.0724\n",
      "256/256 - 0s - loss: 452.3579\n",
      "Reducing exploration for all agents to 0.0811\n",
      "\n",
      "Episode 55: Starting computation.\n",
      "Random Seed Set to 97\n",
      "Episode 55: Finished running.\n",
      "Agent 0, Average Reward: -277.0\n",
      "256/256 - 0s - loss: 1003.4893\n",
      "256/256 - 0s - loss: 725.5891\n",
      "256/256 - 0s - loss: 520.7632\n",
      "256/256 - 0s - loss: 529.6458\n",
      "256/256 - 0s - loss: 539.3251\n",
      "256/256 - 0s - loss: 524.8654\n",
      "256/256 - 0s - loss: 850.0451\n",
      "256/256 - 0s - loss: 625.2494\n",
      "256/256 - 0s - loss: 627.1591\n",
      "256/256 - 0s - loss: 477.7309\n",
      "Reducing exploration for all agents to 0.0774\n",
      "\n",
      "Episode 56: Starting computation.\n",
      "Random Seed Set to 98\n",
      "Episode 56: Finished running.\n",
      "Agent 0, Average Reward: -158.63\n",
      "256/256 - 0s - loss: 413.8893\n",
      "256/256 - 0s - loss: 556.2883\n",
      "256/256 - 0s - loss: 625.8203\n",
      "256/256 - 0s - loss: 541.1971\n",
      "256/256 - 0s - loss: 599.5254\n",
      "256/256 - 0s - loss: 586.4448\n",
      "256/256 - 0s - loss: 553.1042\n",
      "256/256 - 0s - loss: 697.2194\n",
      "256/256 - 0s - loss: 501.8892\n",
      "256/256 - 0s - loss: 534.8083\n",
      "Reducing exploration for all agents to 0.0739\n",
      "\n",
      "Episode 57: Starting computation.\n",
      "Random Seed Set to 99\n",
      "Episode 57: Finished running.\n",
      "Agent 0, Average Reward: -78.58\n",
      "256/256 - 0s - loss: 598.7038\n",
      "256/256 - 0s - loss: 667.3560\n",
      "256/256 - 0s - loss: 458.6702\n",
      "256/256 - 0s - loss: 638.7563\n",
      "256/256 - 0s - loss: 428.5730\n",
      "256/256 - 0s - loss: 653.7595\n",
      "256/256 - 0s - loss: 613.4730\n",
      "256/256 - 0s - loss: 631.0331\n",
      "256/256 - 0s - loss: 667.7185\n",
      "256/256 - 0s - loss: 600.7025\n",
      "Reducing exploration for all agents to 0.0705\n",
      "\n",
      "Episode 58: Starting computation.\n",
      "Random Seed Set to 100\n",
      "Episode 58: Finished running.\n",
      "Agent 0, Average Reward: -68.91\n",
      "256/256 - 0s - loss: 757.7474\n",
      "256/256 - 0s - loss: 785.6129\n",
      "256/256 - 0s - loss: 731.7499\n",
      "256/256 - 0s - loss: 580.1823\n",
      "256/256 - 0s - loss: 746.6420\n",
      "256/256 - 0s - loss: 482.9984\n",
      "256/256 - 0s - loss: 693.8002\n",
      "256/256 - 0s - loss: 677.2276\n",
      "256/256 - 0s - loss: 691.6331\n",
      "256/256 - 0s - loss: 561.1045\n",
      "Reducing exploration for all agents to 0.0673\n",
      "\n",
      "Episode 59: Starting computation.\n",
      "Random Seed Set to 101\n",
      "Episode 59: Finished running.\n",
      "Agent 0, Average Reward: -132.22\n",
      "256/256 - 0s - loss: 593.1784\n",
      "256/256 - 0s - loss: 845.1465\n",
      "256/256 - 0s - loss: 924.6491\n",
      "256/256 - 0s - loss: 398.7607\n",
      "256/256 - 0s - loss: 471.0638\n",
      "256/256 - 0s - loss: 500.4299\n",
      "256/256 - 0s - loss: 612.2869\n",
      "256/256 - 0s - loss: 570.7831\n",
      "256/256 - 0s - loss: 589.5298\n",
      "256/256 - 0s - loss: 590.5099\n",
      "Reducing exploration for all agents to 0.0643\n",
      "\n",
      "Episode 60: Starting computation.\n",
      "Random Seed Set to 102\n",
      "Episode 60: Finished running.\n",
      "Agent 0, Average Reward: -53.72\n",
      "256/256 - 0s - loss: 457.4471\n",
      "256/256 - 0s - loss: 349.8166\n",
      "256/256 - 0s - loss: 418.8366\n",
      "256/256 - 0s - loss: 448.9749\n",
      "256/256 - 0s - loss: 465.9324\n",
      "256/256 - 0s - loss: 463.7380\n",
      "256/256 - 0s - loss: 524.7088\n",
      "256/256 - 0s - loss: 660.1131\n",
      "256/256 - 0s - loss: 338.3102\n",
      "256/256 - 0s - loss: 646.0175\n",
      "Weights succesfully copied to Target model for Agent 1.\n",
      "Saving architecture, weights and optimizer state for agent-1\n",
      "Dumping agent-1 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Dumping Loss Results into pickle file.\n",
      "Reducing exploration for all agents to 0.0614\n",
      "\n",
      "Episode 61: Starting computation.\n",
      "Random Seed Set to 103\n",
      "Episode 61: Finished running.\n",
      "Agent 0, Average Reward: -60.64\n",
      "256/256 - 0s - loss: 2653.2961\n",
      "256/256 - 0s - loss: 2110.6077\n",
      "256/256 - 0s - loss: 1701.7269\n",
      "256/256 - 0s - loss: 841.1981\n",
      "256/256 - 0s - loss: 810.9466\n",
      "256/256 - 0s - loss: 452.0994\n",
      "256/256 - 0s - loss: 1041.9083\n",
      "256/256 - 0s - loss: 903.2738\n",
      "256/256 - 0s - loss: 1173.4340\n",
      "256/256 - 0s - loss: 1285.1057\n",
      "Reducing exploration for all agents to 0.0586\n",
      "\n",
      "Episode 62: Starting computation.\n",
      "Random Seed Set to 104\n",
      "Episode 62: Finished running.\n",
      "Agent 0, Average Reward: -58.92\n",
      "256/256 - 0s - loss: 1155.2982\n",
      "256/256 - 0s - loss: 778.0057\n",
      "256/256 - 0s - loss: 454.2676\n",
      "256/256 - 0s - loss: 635.0878\n",
      "256/256 - 0s - loss: 624.2227\n",
      "256/256 - 0s - loss: 677.4769\n",
      "256/256 - 0s - loss: 666.2434\n",
      "256/256 - 0s - loss: 712.3882\n",
      "256/256 - 0s - loss: 771.3530\n",
      "256/256 - 0s - loss: 696.1418\n",
      "Reducing exploration for all agents to 0.0559\n",
      "\n",
      "Episode 63: Starting computation.\n",
      "Random Seed Set to 105\n",
      "Episode 63: Finished running.\n",
      "Agent 0, Average Reward: -121.27\n",
      "256/256 - 0s - loss: 399.8287\n",
      "256/256 - 0s - loss: 545.5469\n",
      "256/256 - 0s - loss: 475.2073\n",
      "256/256 - 0s - loss: 487.9652\n",
      "256/256 - 0s - loss: 428.0210\n",
      "256/256 - 0s - loss: 355.1774\n",
      "256/256 - 0s - loss: 395.9813\n",
      "256/256 - 0s - loss: 326.6402\n",
      "256/256 - 0s - loss: 460.1771\n",
      "256/256 - 0s - loss: 420.6840\n",
      "Reducing exploration for all agents to 0.0534\n",
      "\n",
      "Episode 64: Starting computation.\n",
      "Random Seed Set to 106\n",
      "Episode 64: Finished running.\n",
      "Agent 0, Average Reward: -92.54\n",
      "256/256 - 0s - loss: 402.6452\n",
      "256/256 - 0s - loss: 428.1904\n",
      "256/256 - 0s - loss: 327.5088\n",
      "256/256 - 0s - loss: 265.1004\n",
      "256/256 - 0s - loss: 459.0461\n",
      "256/256 - 0s - loss: 304.3380\n",
      "256/256 - 0s - loss: 374.8477\n",
      "256/256 - 0s - loss: 346.3032\n",
      "256/256 - 0s - loss: 463.9127\n",
      "256/256 - 0s - loss: 289.2615\n",
      "Reducing exploration for all agents to 0.0509\n",
      "\n",
      "Episode 65: Starting computation.\n",
      "Random Seed Set to 107\n",
      "Episode 65: Finished running.\n",
      "Agent 0, Average Reward: -78.26\n",
      "256/256 - 0s - loss: 340.1789\n",
      "256/256 - 0s - loss: 350.9106\n",
      "256/256 - 0s - loss: 386.6866\n",
      "256/256 - 0s - loss: 377.1174\n",
      "256/256 - 0s - loss: 381.5699\n",
      "256/256 - 0s - loss: 467.3763\n",
      "256/256 - 0s - loss: 299.5893\n",
      "256/256 - 0s - loss: 503.3171\n",
      "256/256 - 0s - loss: 337.3129\n",
      "256/256 - 0s - loss: 356.4896\n",
      "Reducing exploration for all agents to 0.0486\n",
      "\n",
      "Episode 66: Starting computation.\n",
      "Random Seed Set to 108\n",
      "Episode 66: Finished running.\n",
      "Agent 0, Average Reward: -76.56\n",
      "256/256 - 0s - loss: 388.9991\n",
      "256/256 - 0s - loss: 329.0419\n",
      "256/256 - 0s - loss: 318.9309\n",
      "256/256 - 0s - loss: 355.9983\n",
      "256/256 - 0s - loss: 294.6170\n",
      "256/256 - 0s - loss: 288.7118\n",
      "256/256 - 0s - loss: 324.5470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/256 - 0s - loss: 391.8803\n",
      "256/256 - 0s - loss: 293.8109\n",
      "256/256 - 0s - loss: 367.7583\n",
      "Reducing exploration for all agents to 0.0464\n",
      "\n",
      "Episode 67: Starting computation.\n",
      "Random Seed Set to 109\n",
      "Episode 67: Finished running.\n",
      "Agent 0, Average Reward: -119.67\n",
      "256/256 - 0s - loss: 333.2270\n",
      "256/256 - 0s - loss: 400.9157\n",
      "256/256 - 0s - loss: 368.1825\n",
      "256/256 - 0s - loss: 430.6003\n",
      "256/256 - 0s - loss: 532.4207\n",
      "256/256 - 0s - loss: 299.3199\n",
      "256/256 - 0s - loss: 416.7524\n",
      "256/256 - 0s - loss: 365.2997\n",
      "256/256 - 0s - loss: 309.6823\n",
      "256/256 - 0s - loss: 319.2670\n",
      "Reducing exploration for all agents to 0.0443\n",
      "\n",
      "Episode 68: Starting computation.\n",
      "Random Seed Set to 110\n",
      "Episode 68: Finished running.\n",
      "Agent 0, Average Reward: -63.64\n",
      "256/256 - 0s - loss: 424.8929\n",
      "256/256 - 0s - loss: 414.4536\n",
      "256/256 - 0s - loss: 342.4209\n",
      "256/256 - 0s - loss: 310.9164\n",
      "256/256 - 0s - loss: 344.9904\n",
      "256/256 - 0s - loss: 326.8927\n",
      "256/256 - 0s - loss: 370.8466\n",
      "256/256 - 0s - loss: 347.6020\n",
      "256/256 - 0s - loss: 347.7363\n",
      "256/256 - 0s - loss: 285.4937\n",
      "Reducing exploration for all agents to 0.0423\n",
      "\n",
      "Episode 69: Starting computation.\n",
      "Random Seed Set to 111\n",
      "Episode 69: Finished running.\n",
      "Agent 0, Average Reward: -66.71\n",
      "256/256 - 0s - loss: 301.2282\n",
      "256/256 - 0s - loss: 397.8759\n",
      "256/256 - 0s - loss: 302.2804\n",
      "256/256 - 0s - loss: 435.2281\n",
      "256/256 - 0s - loss: 362.6007\n",
      "256/256 - 0s - loss: 287.6897\n",
      "256/256 - 0s - loss: 328.0428\n",
      "256/256 - 0s - loss: 346.5077\n",
      "256/256 - 0s - loss: 417.2622\n",
      "256/256 - 0s - loss: 357.1759\n",
      "Reducing exploration for all agents to 0.0404\n",
      "\n",
      "Episode 70: Starting computation.\n",
      "Random Seed Set to 112\n",
      "Episode 70: Finished running.\n",
      "Agent 0, Average Reward: -64.15\n",
      "256/256 - 0s - loss: 316.5104\n",
      "256/256 - 0s - loss: 323.4577\n",
      "256/256 - 0s - loss: 324.7341\n",
      "256/256 - 0s - loss: 294.6599\n",
      "256/256 - 0s - loss: 435.4836\n",
      "256/256 - 0s - loss: 288.3078\n",
      "256/256 - 0s - loss: 328.0243\n",
      "256/256 - 0s - loss: 351.6043\n",
      "256/256 - 0s - loss: 308.9719\n",
      "256/256 - 0s - loss: 367.9539\n",
      "Weights succesfully copied to Target model for Agent 1.\n",
      "Reducing exploration for all agents to 0.0385\n",
      "\n",
      "Episode 71: Starting computation.\n",
      "Random Seed Set to 113\n",
      "Episode 71: Finished running.\n",
      "Agent 0, Average Reward: -67.42\n",
      "256/256 - 0s - loss: 1343.3427\n",
      "256/256 - 0s - loss: 1012.2789\n",
      "256/256 - 0s - loss: 1015.7117\n",
      "256/256 - 0s - loss: 600.6406\n",
      "256/256 - 0s - loss: 867.7478\n",
      "256/256 - 0s - loss: 447.4171\n",
      "256/256 - 0s - loss: 335.7483\n",
      "256/256 - 0s - loss: 614.8688\n",
      "256/256 - 0s - loss: 729.3877\n",
      "256/256 - 0s - loss: 638.1135\n",
      "Reducing exploration for all agents to 0.0368\n",
      "\n",
      "Episode 72: Starting computation.\n",
      "Random Seed Set to 114\n",
      "Episode 72: Finished running.\n",
      "Agent 0, Average Reward: -121.74\n",
      "256/256 - 0s - loss: 576.0985\n",
      "256/256 - 0s - loss: 482.6912\n",
      "256/256 - 0s - loss: 535.7025\n",
      "256/256 - 0s - loss: 472.3887\n",
      "256/256 - 0s - loss: 417.7687\n",
      "256/256 - 0s - loss: 520.6688\n",
      "256/256 - 0s - loss: 517.3011\n",
      "256/256 - 0s - loss: 390.6851\n",
      "256/256 - 0s - loss: 432.8766\n",
      "256/256 - 0s - loss: 432.0741\n",
      "Reducing exploration for all agents to 0.0351\n",
      "\n",
      "Episode 73: Starting computation.\n",
      "Random Seed Set to 115\n",
      "Episode 73: Finished running.\n",
      "Agent 0, Average Reward: -151.96\n",
      "256/256 - 0s - loss: 647.9053\n",
      "256/256 - 0s - loss: 430.9468\n",
      "256/256 - 0s - loss: 434.7511\n",
      "256/256 - 0s - loss: 388.3761\n",
      "256/256 - 0s - loss: 470.2836\n",
      "256/256 - 0s - loss: 442.8398\n",
      "256/256 - 0s - loss: 440.7793\n",
      "256/256 - 0s - loss: 443.3670\n",
      "256/256 - 0s - loss: 537.8987\n",
      "256/256 - 0s - loss: 355.5327\n",
      "Reducing exploration for all agents to 0.0335\n",
      "\n",
      "Episode 74: Starting computation.\n",
      "Random Seed Set to 116\n",
      "Episode 74: Finished running.\n",
      "Agent 0, Average Reward: -55.13\n",
      "256/256 - 0s - loss: 447.2142\n",
      "256/256 - 0s - loss: 408.5666\n",
      "256/256 - 0s - loss: 435.6473\n",
      "256/256 - 0s - loss: 358.7624\n",
      "256/256 - 0s - loss: 413.6851\n",
      "256/256 - 0s - loss: 438.3240\n",
      "256/256 - 0s - loss: 411.5646\n",
      "256/256 - 0s - loss: 381.6672\n",
      "256/256 - 0s - loss: 687.2822\n",
      "256/256 - 0s - loss: 395.9821\n",
      "Reducing exploration for all agents to 0.032\n",
      "\n",
      "Episode 75: Starting computation.\n",
      "Random Seed Set to 117\n",
      "Episode 75: Finished running.\n",
      "Agent 0, Average Reward: -49.29\n",
      "256/256 - 0s - loss: 331.5992\n",
      "256/256 - 0s - loss: 400.7620\n",
      "256/256 - 0s - loss: 447.7042\n",
      "256/256 - 0s - loss: 437.0057\n",
      "256/256 - 0s - loss: 437.2574\n",
      "256/256 - 0s - loss: 432.8602\n",
      "256/256 - 0s - loss: 390.5211\n",
      "256/256 - 0s - loss: 469.8030\n",
      "256/256 - 0s - loss: 332.3622\n",
      "256/256 - 0s - loss: 429.9058\n",
      "Reducing exploration for all agents to 0.0305\n",
      "\n",
      "Episode 76: Starting computation.\n",
      "Random Seed Set to 118\n",
      "Episode 76: Finished running.\n",
      "Agent 0, Average Reward: -50.97\n",
      "256/256 - 0s - loss: 508.8130\n",
      "256/256 - 0s - loss: 481.7143\n",
      "256/256 - 0s - loss: 389.8962\n",
      "256/256 - 0s - loss: 324.7687\n",
      "256/256 - 0s - loss: 367.0534\n",
      "256/256 - 0s - loss: 513.4425\n",
      "256/256 - 0s - loss: 393.4132\n",
      "256/256 - 0s - loss: 337.6966\n",
      "256/256 - 0s - loss: 351.6493\n",
      "256/256 - 0s - loss: 415.1183\n",
      "Reducing exploration for all agents to 0.0292\n",
      "\n",
      "Episode 77: Starting computation.\n",
      "Random Seed Set to 119\n",
      "Episode 77: Finished running.\n",
      "Agent 0, Average Reward: -113.54\n",
      "256/256 - 0s - loss: 344.6430\n",
      "256/256 - 0s - loss: 354.1354\n",
      "256/256 - 0s - loss: 424.6849\n",
      "256/256 - 0s - loss: 403.0755\n",
      "256/256 - 0s - loss: 337.7636\n",
      "256/256 - 0s - loss: 389.0485\n",
      "256/256 - 0s - loss: 314.8739\n",
      "256/256 - 0s - loss: 356.9979\n",
      "256/256 - 0s - loss: 414.8898\n",
      "256/256 - 0s - loss: 442.1295\n",
      "Reducing exploration for all agents to 0.0278\n",
      "\n",
      "Episode 78: Starting computation.\n",
      "Random Seed Set to 120\n",
      "Episode 78: Finished running.\n",
      "Agent 0, Average Reward: -93.72\n",
      "256/256 - 0s - loss: 437.1712\n",
      "256/256 - 0s - loss: 446.7704\n",
      "256/256 - 0s - loss: 441.8680\n",
      "256/256 - 0s - loss: 453.1919\n",
      "256/256 - 0s - loss: 398.4917\n",
      "256/256 - 0s - loss: 415.2503\n",
      "256/256 - 0s - loss: 384.6966\n",
      "256/256 - 0s - loss: 447.3731\n",
      "256/256 - 0s - loss: 441.8368\n",
      "256/256 - 0s - loss: 417.8685\n",
      "Reducing exploration for all agents to 0.0266\n",
      "\n",
      "Episode 79: Starting computation.\n",
      "Random Seed Set to 121\n",
      "Episode 79: Finished running.\n",
      "Agent 0, Average Reward: -73.2\n",
      "256/256 - 0s - loss: 471.5365\n",
      "256/256 - 0s - loss: 388.0310\n",
      "256/256 - 0s - loss: 773.6986\n",
      "256/256 - 0s - loss: 409.4811\n",
      "256/256 - 0s - loss: 385.8974\n",
      "256/256 - 0s - loss: 430.8755\n",
      "256/256 - 0s - loss: 300.1177\n",
      "256/256 - 0s - loss: 345.9079\n",
      "256/256 - 0s - loss: 431.4811\n",
      "256/256 - 0s - loss: 392.8287\n",
      "Reducing exploration for all agents to 0.0254\n",
      "\n",
      "Episode 80: Starting computation.\n",
      "Random Seed Set to 122\n",
      "Episode 80: Finished running.\n",
      "Agent 0, Average Reward: -57.73\n",
      "256/256 - 0s - loss: 694.3635\n",
      "256/256 - 0s - loss: 417.3460\n",
      "256/256 - 0s - loss: 319.9711\n",
      "256/256 - 0s - loss: 396.6860\n",
      "256/256 - 0s - loss: 648.9300\n",
      "256/256 - 0s - loss: 340.1472\n",
      "256/256 - 0s - loss: 392.7597\n",
      "256/256 - 0s - loss: 412.4902\n",
      "256/256 - 0s - loss: 480.3917\n",
      "256/256 - 0s - loss: 458.3705\n",
      "Weights succesfully copied to Target model for Agent 1.\n",
      "Saving architecture, weights and optimizer state for agent-1\n",
      "Dumping agent-1 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Dumping Loss Results into pickle file.\n",
      "Reducing exploration for all agents to 0.0242\n",
      "\n",
      "Episode 81: Starting computation.\n",
      "Random Seed Set to 123\n",
      "Episode 81: Finished running.\n",
      "Agent 0, Average Reward: -62.92\n",
      "256/256 - 0s - loss: 1103.5232\n",
      "256/256 - 0s - loss: 1015.4177\n",
      "256/256 - 0s - loss: 740.4677\n",
      "256/256 - 0s - loss: 676.3585\n",
      "256/256 - 0s - loss: 638.1874\n",
      "256/256 - 0s - loss: 351.6549\n",
      "256/256 - 0s - loss: 407.6845\n",
      "256/256 - 0s - loss: 611.8814\n",
      "256/256 - 0s - loss: 555.3959\n",
      "256/256 - 0s - loss: 643.0750\n",
      "Reducing exploration for all agents to 0.0231\n",
      "\n",
      "Episode 82: Starting computation.\n",
      "Random Seed Set to 124\n",
      "Episode 82: Finished running.\n",
      "Agent 0, Average Reward: -57.55\n",
      "256/256 - 0s - loss: 713.5069\n",
      "256/256 - 0s - loss: 633.8773\n",
      "256/256 - 0s - loss: 545.1898\n",
      "256/256 - 0s - loss: 566.8631\n",
      "256/256 - 0s - loss: 520.1614\n",
      "256/256 - 0s - loss: 454.5337\n",
      "256/256 - 0s - loss: 496.2634\n",
      "256/256 - 0s - loss: 485.7154\n",
      "256/256 - 0s - loss: 428.0016\n",
      "256/256 - 0s - loss: 496.0145\n",
      "Reducing exploration for all agents to 0.0221\n",
      "\n",
      "Episode 83: Starting computation.\n",
      "Random Seed Set to 125\n",
      "Episode 83: Finished running.\n",
      "Agent 0, Average Reward: -137.18\n",
      "256/256 - 0s - loss: 575.6707\n",
      "256/256 - 0s - loss: 575.6711\n",
      "256/256 - 0s - loss: 555.4420\n",
      "256/256 - 0s - loss: 549.1866\n",
      "256/256 - 0s - loss: 416.8808\n",
      "256/256 - 0s - loss: 559.2800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/256 - 0s - loss: 422.9615\n",
      "256/256 - 0s - loss: 476.0173\n",
      "256/256 - 0s - loss: 541.1189\n",
      "256/256 - 0s - loss: 433.0581\n",
      "Reducing exploration for all agents to 0.021\n",
      "\n",
      "Episode 84: Starting computation.\n",
      "Random Seed Set to 126\n",
      "Episode 84: Finished running.\n",
      "Agent 0, Average Reward: -78.44\n",
      "256/256 - 0s - loss: 563.9308\n",
      "256/256 - 0s - loss: 549.7685\n",
      "256/256 - 0s - loss: 507.9559\n",
      "256/256 - 0s - loss: 455.2488\n",
      "256/256 - 0s - loss: 539.6456\n",
      "256/256 - 0s - loss: 448.2403\n",
      "256/256 - 0s - loss: 547.0074\n",
      "256/256 - 0s - loss: 523.4884\n",
      "256/256 - 0s - loss: 447.3079\n",
      "256/256 - 0s - loss: 406.8441\n",
      "Reducing exploration for all agents to 0.0201\n",
      "\n",
      "Episode 85: Starting computation.\n",
      "Random Seed Set to 127\n",
      "Episode 85: Finished running.\n",
      "Agent 0, Average Reward: -77.01\n",
      "256/256 - 0s - loss: 458.9970\n",
      "256/256 - 0s - loss: 510.3940\n",
      "256/256 - 0s - loss: 493.2813\n",
      "256/256 - 0s - loss: 581.5930\n",
      "256/256 - 0s - loss: 412.6208\n",
      "256/256 - 0s - loss: 475.9543\n",
      "256/256 - 0s - loss: 437.2645\n",
      "256/256 - 0s - loss: 404.6541\n",
      "256/256 - 0s - loss: 520.7953\n",
      "256/256 - 0s - loss: 459.4056\n",
      "Reducing exploration for all agents to 0.0192\n",
      "\n",
      "Episode 86: Starting computation.\n",
      "Random Seed Set to 128\n",
      "Episode 86: Finished running.\n",
      "Agent 0, Average Reward: -68.3\n",
      "256/256 - 0s - loss: 383.7148\n",
      "256/256 - 0s - loss: 515.2194\n",
      "256/256 - 0s - loss: 439.3630\n",
      "256/256 - 0s - loss: 541.5305\n",
      "256/256 - 0s - loss: 431.1241\n",
      "256/256 - 0s - loss: 455.6059\n",
      "256/256 - 0s - loss: 418.3109\n",
      "256/256 - 0s - loss: 458.3873\n",
      "256/256 - 0s - loss: 503.2000\n",
      "256/256 - 0s - loss: 552.8489\n",
      "Reducing exploration for all agents to 0.0183\n",
      "\n",
      "Episode 87: Starting computation.\n",
      "Random Seed Set to 129\n",
      "Episode 87: Finished running.\n",
      "Agent 0, Average Reward: -57.92\n",
      "256/256 - 0s - loss: 443.1115\n",
      "256/256 - 0s - loss: 389.3326\n",
      "256/256 - 0s - loss: 445.9494\n",
      "256/256 - 0s - loss: 349.0946\n",
      "256/256 - 0s - loss: 462.6669\n",
      "256/256 - 0s - loss: 612.5469\n",
      "256/256 - 0s - loss: 487.4331\n",
      "256/256 - 0s - loss: 413.7072\n",
      "256/256 - 0s - loss: 534.1995\n",
      "256/256 - 0s - loss: 475.0856\n",
      "Reducing exploration for all agents to 0.0175\n",
      "\n",
      "Episode 88: Starting computation.\n",
      "Random Seed Set to 130\n",
      "Episode 88: Finished running.\n",
      "Agent 0, Average Reward: -58.14\n",
      "256/256 - 0s - loss: 386.0370\n",
      "256/256 - 0s - loss: 473.6627\n",
      "256/256 - 0s - loss: 534.0970\n",
      "256/256 - 0s - loss: 530.6085\n",
      "256/256 - 0s - loss: 505.6837\n",
      "256/256 - 0s - loss: 415.9575\n",
      "256/256 - 0s - loss: 363.0622\n",
      "256/256 - 0s - loss: 503.4879\n",
      "256/256 - 0s - loss: 517.9204\n",
      "256/256 - 0s - loss: 424.1059\n",
      "Reducing exploration for all agents to 0.0167\n",
      "\n",
      "Episode 89: Starting computation.\n",
      "Random Seed Set to 131\n",
      "Episode 89: Finished running.\n",
      "Agent 0, Average Reward: -49.6\n",
      "256/256 - 0s - loss: 395.3339\n",
      "256/256 - 0s - loss: 475.7888\n",
      "256/256 - 0s - loss: 341.7449\n",
      "256/256 - 0s - loss: 398.8938\n",
      "256/256 - 0s - loss: 583.2452\n",
      "256/256 - 0s - loss: 500.0843\n",
      "256/256 - 0s - loss: 359.3764\n",
      "256/256 - 0s - loss: 479.2610\n",
      "256/256 - 0s - loss: 342.6781\n",
      "256/256 - 0s - loss: 425.9773\n",
      "Reducing exploration for all agents to 0.0159\n",
      "\n",
      "Episode 90: Starting computation.\n",
      "Random Seed Set to 132\n",
      "Episode 90: Finished running.\n",
      "Agent 0, Average Reward: -44.57\n",
      "Saving architecture, weights, optimizer state for best agent-1\n",
      "256/256 - 0s - loss: 476.4111\n",
      "256/256 - 0s - loss: 532.6220\n",
      "256/256 - 0s - loss: 475.5111\n",
      "256/256 - 0s - loss: 456.1264\n",
      "256/256 - 0s - loss: 597.0394\n",
      "256/256 - 0s - loss: 375.1102\n",
      "256/256 - 0s - loss: 375.1289\n",
      "256/256 - 0s - loss: 369.8109\n",
      "256/256 - 0s - loss: 564.0104\n",
      "256/256 - 0s - loss: 495.2000\n",
      "Weights succesfully copied to Target model for Agent 1.\n",
      "Reducing exploration for all agents to 0.0152\n",
      "\n",
      "Episode 91: Starting computation.\n",
      "Random Seed Set to 133\n",
      "Episode 91: Finished running.\n",
      "Agent 0, Average Reward: -39.56\n",
      "Saving architecture, weights, optimizer state for best agent-1\n",
      "256/256 - 0s - loss: 960.2539\n",
      "256/256 - 0s - loss: 729.9805\n",
      "256/256 - 0s - loss: 830.0627\n",
      "256/256 - 0s - loss: 556.3194\n",
      "256/256 - 0s - loss: 377.5142\n",
      "256/256 - 0s - loss: 544.6858\n",
      "256/256 - 0s - loss: 514.7059\n",
      "256/256 - 0s - loss: 635.7238\n",
      "256/256 - 0s - loss: 545.5682\n",
      "256/256 - 0s - loss: 682.0273\n",
      "Reducing exploration for all agents to 0.0145\n",
      "\n",
      "Episode 92: Starting computation.\n",
      "Random Seed Set to 134\n",
      "Episode 92: Finished running.\n",
      "Agent 0, Average Reward: -41.21\n",
      "256/256 - 0s - loss: 533.2073\n",
      "256/256 - 0s - loss: 669.8608\n",
      "256/256 - 0s - loss: 539.4285\n",
      "256/256 - 0s - loss: 485.7400\n",
      "256/256 - 0s - loss: 609.5743\n",
      "256/256 - 0s - loss: 376.9883\n",
      "256/256 - 0s - loss: 575.1104\n",
      "256/256 - 0s - loss: 376.4368\n",
      "256/256 - 0s - loss: 534.0986\n",
      "256/256 - 0s - loss: 418.0840\n",
      "Reducing exploration for all agents to 0.0138\n",
      "\n",
      "Episode 93: Starting computation.\n",
      "Random Seed Set to 135\n",
      "Episode 93: Finished running.\n",
      "Agent 0, Average Reward: -62.6\n",
      "256/256 - 0s - loss: 535.0917\n",
      "256/256 - 0s - loss: 544.1891\n",
      "256/256 - 0s - loss: 445.0131\n",
      "256/256 - 0s - loss: 444.7498\n",
      "256/256 - 0s - loss: 373.3431\n",
      "256/256 - 0s - loss: 439.4199\n",
      "256/256 - 0s - loss: 391.9499\n",
      "256/256 - 0s - loss: 484.6281\n",
      "256/256 - 0s - loss: 404.6478\n",
      "256/256 - 0s - loss: 502.3836\n",
      "Reducing exploration for all agents to 0.0132\n",
      "\n",
      "Episode 94: Starting computation.\n",
      "Random Seed Set to 136\n",
      "Episode 94: Finished running.\n",
      "Agent 0, Average Reward: -68.3\n",
      "256/256 - 0s - loss: 546.6914\n",
      "256/256 - 0s - loss: 558.7381\n",
      "256/256 - 0s - loss: 445.7797\n",
      "256/256 - 0s - loss: 540.4615\n",
      "256/256 - 0s - loss: 427.9394\n",
      "256/256 - 0s - loss: 580.8525\n",
      "256/256 - 0s - loss: 584.2534\n",
      "256/256 - 0s - loss: 499.1049\n",
      "256/256 - 0s - loss: 409.7543\n",
      "256/256 - 0s - loss: 486.4620\n",
      "Reducing exploration for all agents to 0.0126\n",
      "\n",
      "Episode 95: Starting computation.\n",
      "Random Seed Set to 137\n",
      "Episode 95: Finished running.\n",
      "Agent 0, Average Reward: -128.64\n",
      "256/256 - 0s - loss: 497.5653\n",
      "256/256 - 0s - loss: 447.2801\n",
      "256/256 - 0s - loss: 527.2007\n",
      "256/256 - 0s - loss: 533.6213\n",
      "256/256 - 0s - loss: 493.5131\n",
      "256/256 - 0s - loss: 571.4114\n",
      "256/256 - 0s - loss: 473.9054\n",
      "256/256 - 0s - loss: 415.4103\n",
      "256/256 - 0s - loss: 492.4646\n",
      "256/256 - 0s - loss: 432.2358\n",
      "Reducing exploration for all agents to 0.012\n",
      "\n",
      "Episode 96: Starting computation.\n",
      "Random Seed Set to 138\n",
      "Episode 96: Finished running.\n",
      "Agent 0, Average Reward: -71.7\n",
      "256/256 - 0s - loss: 408.3424\n",
      "256/256 - 0s - loss: 471.7376\n",
      "256/256 - 0s - loss: 428.9638\n",
      "256/256 - 0s - loss: 501.7596\n",
      "256/256 - 0s - loss: 516.0077\n",
      "256/256 - 0s - loss: 642.6318\n",
      "256/256 - 0s - loss: 475.7086\n",
      "256/256 - 0s - loss: 396.8241\n",
      "256/256 - 0s - loss: 457.0311\n",
      "256/256 - 0s - loss: 594.8695\n",
      "Reducing exploration for all agents to 0.0115\n",
      "\n",
      "Episode 97: Starting computation.\n",
      "Random Seed Set to 139\n",
      "Episode 97: Finished running.\n",
      "Agent 0, Average Reward: -52.15\n",
      "256/256 - 0s - loss: 519.3908\n",
      "256/256 - 0s - loss: 409.4878\n",
      "256/256 - 0s - loss: 534.4001\n",
      "256/256 - 0s - loss: 301.4977\n",
      "256/256 - 0s - loss: 468.2200\n",
      "256/256 - 0s - loss: 391.4576\n",
      "256/256 - 0s - loss: 431.6894\n",
      "256/256 - 0s - loss: 504.1358\n",
      "256/256 - 0s - loss: 448.7965\n",
      "256/256 - 0s - loss: 527.8008\n",
      "Reducing exploration for all agents to 0.011\n",
      "\n",
      "Episode 98: Starting computation.\n",
      "Random Seed Set to 140\n",
      "Episode 98: Finished running.\n",
      "Agent 0, Average Reward: -68.58\n",
      "256/256 - 0s - loss: 514.7277\n",
      "256/256 - 0s - loss: 581.9658\n",
      "256/256 - 0s - loss: 493.7576\n",
      "256/256 - 0s - loss: 438.2128\n",
      "256/256 - 0s - loss: 529.8441\n",
      "256/256 - 0s - loss: 587.0307\n",
      "256/256 - 0s - loss: 386.1781\n",
      "256/256 - 0s - loss: 386.0654\n",
      "256/256 - 0s - loss: 564.6014\n",
      "256/256 - 0s - loss: 435.5506\n",
      "Reducing exploration for all agents to 0.0105\n",
      "\n",
      "Episode 99: Starting computation.\n",
      "Random Seed Set to 141\n",
      "Episode 99: Finished running.\n",
      "Agent 0, Average Reward: -59.02\n",
      "256/256 - 0s - loss: 408.4556\n",
      "256/256 - 0s - loss: 659.8778\n",
      "256/256 - 0s - loss: 583.4094\n",
      "256/256 - 0s - loss: 699.1584\n",
      "256/256 - 0s - loss: 623.3872\n",
      "256/256 - 0s - loss: 473.4574\n",
      "256/256 - 0s - loss: 458.7030\n",
      "256/256 - 0s - loss: 460.6919\n",
      "256/256 - 0s - loss: 628.3797\n",
      "256/256 - 0s - loss: 498.0627\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 100: Starting computation.\n",
      "Random Seed Set to 142\n",
      "Episode 100: Finished running.\n",
      "Agent 0, Average Reward: -79.99\n",
      "256/256 - 0s - loss: 542.7775\n",
      "256/256 - 0s - loss: 473.4433\n",
      "256/256 - 0s - loss: 556.0236\n",
      "256/256 - 0s - loss: 538.3156\n",
      "256/256 - 0s - loss: 493.6057\n",
      "256/256 - 0s - loss: 461.2771\n",
      "256/256 - 0s - loss: 477.9412\n",
      "256/256 - 0s - loss: 509.0321\n",
      "256/256 - 0s - loss: 597.4716\n",
      "256/256 - 0s - loss: 593.8158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights succesfully copied to Target model for Agent 1.\n",
      "Saving architecture, weights and optimizer state for agent-1\n",
      "Dumping agent-1 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Dumping Loss Results into pickle file.\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 101: Starting computation.\n"
     ]
    }
   ],
   "source": [
    "Balance_int_MultiDQN_Agents.train(episodes - Balance_int_MultiDQN_Agents.number_of_episode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving architecture, weights and optimizer state for agent-1\n",
      "Dumping agent-1 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Dumping Loss Results into pickle file.\n"
     ]
    }
   ],
   "source": [
    "Balance_int_MultiDQN_Agents.save(episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working Directory set to: E:\\OneDrive - University of Warwick\\Desktop\\ATI\\0_TMF\\MLforFlowOptimisation\\Vissim\n",
      "Generating Cache...\n",
      "Cache generated.\n",
      "\n",
      "****************************\n",
      "*   COM Server dispatched  *\n",
      "****************************\n",
      "\n",
      "Attempting to load Model File: Balance_int2_4.inpx ...\n",
      "Model File load process successful.\n",
      "Simulation length set to 10801 seconds.\n",
      "Results from Previous Simulations: Deleted. Fresh Start Available.\n",
      "Fetched and containerized Network Object \n",
      "\n",
      "*******************************************************\n",
      "*                                                     *\n",
      "*                COM SETUP COMPLETE                   *\n",
      "*                                                     *\n",
      "*******************************************************\n",
      "\n",
      "Random seed set in simulator. Random Seed = 142\n",
      "Deploying Network Parser...\n",
      "Successful Network Crawl: Identified SignalControllers, Links, Lanes and Vehicle Inputs.\n",
      "\n",
      "Setting Simulation mode to: demo\n",
      "Starting Deployments of Signal Control Units...\n",
      "SCUs successfully deployed. Elapsed time 0.6 seconds.\n",
      "\n"
     ]
    },
    {
     "ename": "com_error",
     "evalue": "(-2147352567, 'Exception occurred.', (0, None, None, None, 0, -2147467259), None)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mcom_error\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-2a992ec70e68>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mBalance_int_MultiDQN_Agents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdemo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\OneDrive - University of Warwick\\Desktop\\ATI\\0_TMF\\MLforFlowOptimisation\\Vissim\\MasterDQN_Agent.py\u001b[0m in \u001b[0;36mdemo\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    250\u001b[0m                 \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdone\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m                         \u001b[0mSARSDs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_required\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\OneDrive - University of Warwick\\Desktop\\ATI\\0_TMF\\MLforFlowOptimisation\\Vissim\\Vissim_env_class.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, actions, green_time)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimesteps_per_second\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVissim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSimulation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRunSingleStep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m                 \u001b[1;31m# increase the update counter by one each step (until reach simulation length)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_counter\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\vissim\\lib\\site-packages\\win32com\\client\\dynamic.py\u001b[0m in \u001b[0;36mRunSingleStep\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[1;31mcom_error\u001b[0m: (-2147352567, 'Exception occurred.', (0, None, None, None, 0, -2147467259), None)"
     ]
    }
   ],
   "source": [
    "Balance_int_MultiDQN_Agents.demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intersection 2\n",
      "Agent 2: Training Loss and Average Reward during training successfuly saved to file:\n",
      "E:\\OneDrive - University of Warwick\\Desktop\\ATI\\0_TMF\\MLforFlowOptimisation\\Vissim\\Balance_int2_4\\Agents_Results\\DuelingDDQN\\Balance_int2_4_all_actions_100_10800_DuelingDDQN_delay/Agent2_Loss_average_reward.json\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## AGENT TRAINING RESULTS\n",
    "# Path to results folder\n",
    "results_path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", agent_type, Session_ID)\n",
    "\n",
    "# Loop over each agent\n",
    "for idx , agent in Balance_int_MultiDQN_Agents.Agents.items():\n",
    "    intersection_number_in_vissim = Balance_int_MultiDQN_Agents.Agents[0].signal_id + 1\n",
    "    print(\"Intersection \"+str(intersection_number_in_vissim))\n",
    "    \n",
    "    ## SAVE TRAINING DATA TO JSON.\n",
    "    json_filename = \"Agent{}_Loss_average_reward.json\".format(intersection_number_in_vissim)\n",
    "    Loss_reward = dict()   \n",
    "    # Loss dictionary\n",
    "    for epoch, loss in enumerate(agent.loss):\n",
    "        loss_dict = { epoch : loss }\n",
    "    Loss_reward['Agent{} loss'.format(intersection_number_in_vissim)] = loss_dict\n",
    "    # Reward dictionary            \n",
    "    episode = [i for i in range(len(agent.reward_storage))]\n",
    "    Loss_reward['Agent{} Average_Reward'.format(intersection_number_in_vissim)] = agent.reward_storage\n",
    "    # Store as JSON\n",
    "    with open(results_path + \"/\" + json_filename, 'w') as f:\n",
    "        json.dump(Loss_reward, f)\n",
    "    print(\"Agent {}: Training Loss and Average Reward during training successfuly saved to file:\".format(intersection_number_in_vissim))\n",
    "    print(results_path + \"/\" + json_filename)\n",
    "    \n",
    "    ## LOADING DATA FROM JSON\n",
    "    #results_path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", agent_type, Session_ID)\n",
    "    #dictionary_filename = \"Agent{}_Loss_average_reward.json\".format(intersection_number_in_vissim)\n",
    "    #with open(results_path + \"/\" + json_filename, 'r') as fp:\n",
    "    #    data = json.load(fp)\n",
    "    #print(data)\n",
    "    \n",
    "    ## TRAINING PLOTS\n",
    "    loss_plot_filename  = \"Agent{}_Loss.png\".format(intersection_number_in_vissim)\n",
    "    reward_plot_filename  = \"Agent{}_average_reward.png\".format(intersection_number_in_vissim) \n",
    "    \n",
    "    ## Loss Plot\n",
    "    plt.figure('LossAgent'+str(idx),figsize=(16,9))\n",
    "    plt.plot(agent.loss)\n",
    "    #plt.yscale('log')\n",
    "\n",
    "    plt.xlabel('Training Epoch',fontsize=18)\n",
    "    plt.ylabel('Loss',fontsize=18)\n",
    "    plt.title('Agent {} Loss over training'.format(intersection_number_in_vissim),fontsize=18)\n",
    "    plt.savefig(results_path + \"/\" + loss_plot_filename)\n",
    "\n",
    "    ## Average Reward Plot\n",
    "    plt.figure('RewardAgent'+str(idx),figsize=(16,9))\n",
    "    plt.plot(agent.reward_storage)\n",
    "    plt.xlabel('Training Episode',fontsize=18)\n",
    "    plt.ylabel('Average reward',fontsize=18)\n",
    "    plt.title('Agent {} average reward over training'.format(intersection_number_in_vissim),fontsize=18)\n",
    "    plt.savefig(results_path + \"/\" + reward_plot_filename)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Pre-Trained Agent 1, Architecture, Optimizer and Memory.\n",
      "E:\\OneDrive - University of Warwick\\Desktop\\ATI\\0_TMF\\MLforFlowOptimisation\\Vissim\\Balance_int2_4\\Agents_Results\\DuelingDDQN\\Balance_int2_4_all_actions_100_10800_DuelingDDQN_delay\\BestAgent1.h5\n",
      "WARNING:tensorflow:From C:\\Users\\ACE\\Anaconda3\\envs\\vissim\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\ACE\\Anaconda3\\envs\\vissim\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Items successfully loaded.\n"
     ]
    }
   ],
   "source": [
    "Balance_int_MultiDQN_Agents.load(100, best = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of tensorflow.python.keras.layers.core failed: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ACE\\Anaconda3\\envs\\vissim\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"C:\\Users\\ACE\\Anaconda3\\envs\\vissim\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 434, in superreload\n",
      "    module = reload(module)\n",
      "  File \"C:\\Users\\ACE\\Anaconda3\\envs\\vissim\\lib\\imp.py\", line 314, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"C:\\Users\\ACE\\Anaconda3\\envs\\vissim\\lib\\importlib\\__init__.py\", line 148, in reload\n",
      "    raise ImportError(msg.format(name), name=name)\n",
      "ImportError: module DQNAgents not in sys.modules\n",
      "]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working Directory set to: E:\\OneDrive - University of Warwick\\Desktop\\ATI\\0_TMF\\MLforFlowOptimisation\\Vissim\n",
      "Generating Cache...\n",
      "Cache generated.\n",
      "\n",
      "****************************\n",
      "*   COM Server dispatched  *\n",
      "****************************\n",
      "\n",
      "Attempting to load Model File: Balance_int2_4.inpx ...\n",
      "Model File load process successful.\n",
      "Simulation length set to 10801 seconds.\n",
      "Results from Previous Simulations: Deleted. Fresh Start Available.\n",
      "Fetched and containerized Network Object \n",
      "\n",
      "*******************************************************\n",
      "*                                                     *\n",
      "*                COM SETUP COMPLETE                   *\n",
      "*                                                     *\n",
      "*******************************************************\n",
      "\n",
      "Random seed set in simulator. Random Seed = 142\n",
      "Deploying Network Parser...\n",
      "Successful Network Crawl: Identified SignalControllers, Links, Lanes and Vehicle Inputs.\n",
      "\n",
      "Setting Simulation mode to: demo\n",
      "Starting Deployments of Signal Control Units...\n",
      "SCUs successfully deployed. Elapsed time 0.49 seconds.\n",
      "\n"
     ]
    },
    {
     "ename": "com_error",
     "evalue": "(-2147352567, 'Exception occurred.', (0, None, None, None, 0, -2147467259), None)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mcom_error\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-2a992ec70e68>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mBalance_int_MultiDQN_Agents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdemo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\OneDrive - University of Warwick\\Desktop\\ATI\\0_TMF\\MLforFlowOptimisation\\Vissim\\MasterDQN_Agent.py\u001b[0m in \u001b[0;36mdemo\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    250\u001b[0m                 \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdone\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m                         \u001b[0mSARSDs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_required\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\OneDrive - University of Warwick\\Desktop\\ATI\\0_TMF\\MLforFlowOptimisation\\Vissim\\Vissim_env_class.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, actions, green_time)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimesteps_per_second\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVissim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSimulation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRunSingleStep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m                 \u001b[1;31m# increase the update counter by one each step (until reach simulation length)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_counter\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\vissim\\lib\\site-packages\\win32com\\client\\dynamic.py\u001b[0m in \u001b[0;36mRunSingleStep\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[1;31mcom_error\u001b[0m: (-2147352567, 'Exception occurred.', (0, None, None, None, 0, -2147467259), None)"
     ]
    }
   ],
   "source": [
    "Balance_int_MultiDQN_Agents.demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Balance_int_MultiDQN_Agents.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results_path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", agent_type, Session_ID)\n",
    "time = [t for t in range(len(Cumulative_Totale_network_stop_delay))]\n",
    "\n",
    "########################################\n",
    "## Queues over time for each junction ##\n",
    "########################################\n",
    "for idx, queues in Balance_int_MultiDQN_Agents.Episode_Queues.items():\n",
    "    # Identify Junction ID in map\n",
    "    intersection_number_in_vissim = Balance_int_MultiDQN_Agents.Agents[0].signal_id + 1\n",
    "    \n",
    "    queues = np.array(queues)\n",
    "    queues = queues.T\n",
    "    number_queues = np.size(queues,0)\n",
    "    \n",
    "    plt.figure('1'+str(idx),figsize=(16, 9))\n",
    "    \n",
    "    Queues = dict()\n",
    "    Queues['Time'] = time\n",
    "    Queues_legend = []\n",
    "    \n",
    "    for i, queue in enumerate(queues):\n",
    "        plt.plot(queue, label = \"Queue\"+str(i))\n",
    "        Queues[str(i)] = queue.tolist()\n",
    "        Queues_legend.append(\"Queue\"+str(i))\n",
    "    \n",
    "    ## Plot the queues\n",
    "    plt.xlabel('Time [s]',fontsize=18)\n",
    "    plt.ylabel('Queue Length',fontsize=18)\n",
    "    plt.title('Junction {} Queue length'.format(intersection_number_in_vissim),fontsize=18)\n",
    "    plt.gca().legend(Queues_legend)\n",
    "    \n",
    "    filename = \"Junction{}_Queues.png\".format(intersection_number_in_vissim)           \n",
    "    plt.savefig(results_path + \"/\" + filename)\n",
    "    \n",
    "    # Store as JSON\n",
    "    json_filename = \"Junction{}_Queues.json\".format(intersection_number_in_vissim)        \n",
    "    with open(results_path + \"/\" + json_filename, 'w') as f:\n",
    "        json.dump(Queues, f)\n",
    "        \n",
    "    ### LOADING DATA FROM JSON\n",
    "    #results_path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", agent_type, Session_ID)\n",
    "    #json_filename = \"Junction{}_Queues.json\".format(intersection_number_in_vissim)\n",
    "    #with open(results_path + \"/\" + json_filename, 'r') as fp:\n",
    "    #    data = json.load(fp)\n",
    "    #print(data)\n",
    "        \n",
    "    # Success Message\n",
    "    print(\"Agent {}: Queues during Test successfuly saved to file:\".format(intersection_number_in_vissim))\n",
    "    print(results_path + \"/\" + json_filename)\n",
    "       \n",
    "        \n",
    "###################################################        \n",
    "## Accumulated delay over time for each junction ##\n",
    "###################################################\n",
    "for idx, delay in Balance_int_MultiDQN_Agents.Cumulative_Episode_Delays.items():\n",
    "    # Identify Junction ID in map\n",
    "    intersection_number_in_vissim = Balance_int_MultiDQN_Agents.Agents[idx].signal_id + 1\n",
    "\n",
    "    # Extract and process delay data\n",
    "    Delay = dict()   \n",
    "    Delay['Time'] = time\n",
    "    Delay['Junction {} delay'.format(intersection_number_in_vissim)] = delay\n",
    "    \n",
    "    # Store as JSON\n",
    "    json_filename = \"Junction{}_Cumulative_Delay.json\".format(intersection_number_in_vissim)        \n",
    "    with open(results_path + \"/\" + json_filename, 'w') as f:\n",
    "        json.dump(Delay, f)\n",
    "        \n",
    "    # Success Message\n",
    "    print(\"Agent {}: Test Cumulative Delay successfuly saved to file:\".format(intersection_number_in_vissim))\n",
    "    print(results_path + \"/\" + json_filename)\n",
    "    \n",
    "    ### Loading data from JSON\n",
    "    #results_path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", agent_type, Session_ID)\n",
    "    #dictionary_filename = \"Junction{}_Cumulative_Delay.json\".format(intersection_number_in_vissim)\n",
    "    #with open(results_path + \"/\" + json_filename, 'r') as fp:\n",
    "    #    data = json.load(fp)\n",
    "    #print(data)\n",
    "\n",
    "    # Plot the cumulative delay\n",
    "    plt.figure('2'+str(idx),figsize=(16, 9))\n",
    "    plt.plot(delay)\n",
    "    plt.xlabel('Time [s]',fontsize=18)\n",
    "    plt.ylabel('Accumulated Delay',fontsize=18)\n",
    "    plt.title('Junction {} Delay'.format(intersection_number_in_vissim),fontsize=18)\n",
    "    plt.gca().legend('Junction accumulated delay')\n",
    "    \n",
    "    filename = \"Junction{}_Cumulative_Delay.png\".format(intersection_number_in_vissim)\n",
    "    plt.savefig(results_path + \"/\" + filename)\n",
    "    \n",
    "    \n",
    "    \n",
    "########################################################    \n",
    "## Accumulated stop delay over time for each junction ##\n",
    "########################################################\n",
    "for idx, stop_delay in Balance_int_MultiDQN_Agents.Cumulative_Episode_stop_Delays.items():\n",
    "    # Identify Junction ID in map\n",
    "    intersection_number_in_vissim = Balance_int_MultiDQN_Agents.Agents[idx].signal_id + 1    \n",
    "    \n",
    "    # Extract and process stop delay data\n",
    "    Stop_delay = dict()   \n",
    "    Stop_delay['Time'] = time\n",
    "    Stop_delay['Junction {} stop delay'.format(intersection_number_in_vissim)] = stop_delay\n",
    "    \n",
    "    # Store as JSON\n",
    "    json_filename = \"Junction{}_Cumulative_Stop_Delay.json\".format(intersection_number_in_vissim)        \n",
    "    with open(results_path + \"/\" + json_filename, 'w') as f:\n",
    "        json.dump(Stop_delay, f)\n",
    "    \n",
    "    # Success Message\n",
    "    print(\"Agent {}: Test Cumulative Stop Delay successfuly saved to file:\".format(intersection_number_in_vissim))\n",
    "    print(results_path + \"/\" + json_filename)\n",
    "        \n",
    "    ### Loading data from JSON\n",
    "    #results_path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", agent_type, Session_ID)\n",
    "    #dictionary_filename = \"Junction{}_Cumulative_Stop_Delay.json\".format(intersection_number_in_vissim)\n",
    "    #with open(results_path + \"/\" + json_filename, 'r') as fp:\n",
    "    #    data = json.load(fp)\n",
    "    #print(data)\n",
    "    \n",
    "    # Plot the cumulative stop delay\n",
    "    plt.figure('3'+str(idx),figsize=(16, 9))\n",
    "    plt.plot(stop_delay)\n",
    "    plt.xlabel('Time [s]',fontsize=18)\n",
    "    plt.ylabel('Accumulated Stop Delay',fontsize=18)\n",
    "    plt.title('Junction {} Stop Delay'.format(intersection_number_in_vissim),fontsize=18)\n",
    "    plt.gca().legend('Junction accumulated Stop delay')\n",
    "    \n",
    "    filename = \"Junction{}_Cumulative_Stop_Delay.png\".format(intersection_number_in_vissim)\n",
    "    plt.savefig(results_path + \"/\" + filename)\n",
    "\n",
    "    \n",
    "    \n",
    "###############################################\n",
    "## ONLY IF THERE IS MORE THAN ONE CONTROLLER ##\n",
    "##    These are the global network plots     ##\n",
    "###############################################\n",
    "\n",
    "if len(Balance_int_MultiDQN_Agents.Agents) > 1:\n",
    "    ########################################    \n",
    "    ## Global Accumulated delay over time ##\n",
    "    ########################################\n",
    "    \n",
    "    # Process global delay data\n",
    "    Global_delay = dict()   \n",
    "    Global_delay['Time'] = time\n",
    "    Global_delay['Global accumulated Delay'] = Balance_int_MultiDQN_Agents.Cumulative_Totale_network_delay\n",
    "    \n",
    "    # Store as JSON\n",
    "    json_filename = \"Global_Cumulative_Delay.json\"\n",
    "    with open(results_path + \"/\" + json_filename, 'w') as f:\n",
    "        json.dump(Global_delay, f)\n",
    "    \n",
    "    # Success Message\n",
    "    print(\"Agent {}: Test Cumulative Global Delay successfuly saved to file:\")\n",
    "    print(results_path + \"/\" + json_filename)\n",
    "        \n",
    "    ### Loading data from JSON\n",
    "    #results_path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", agent_type, Session_ID)\n",
    "    #dictionary_filename = \"Global_Cumulative_Delay.json\"\n",
    "    #with open(results_path + \"/\" + json_filename, 'r') as fp:\n",
    "    #    data = json.load(fp)\n",
    "    #print(data)\n",
    "\n",
    "    \n",
    "    # Plot the global delay\n",
    "    plt.figure('4',figsize=(16,9))\n",
    "    plt.plot(Cumulative_Totale_network_delay)\n",
    "    plt.xlabel('Time [s]',fontsize=18)\n",
    "    plt.ylabel('Global accumulated Delay',fontsize=18)\n",
    "    plt.title('Global accumulated Delay',fontsize=18)\n",
    "    plt.gca().legend('Global accumulated delay')\n",
    "\n",
    "    filename = \"Global_Cumulative_Delay.png\".format(intersection_number_in_vissim)\n",
    "    plt.savefig(results_path + \"/\" + filename)\n",
    "\n",
    "\n",
    "    #############################################\n",
    "    ## Global Accumulated stop delay over time ##\n",
    "    #############################################\n",
    "    \n",
    "    # Process global stop delay data\n",
    "    Global_stop_delay = dict()   \n",
    "    Global_stop_delay['Time'] = time\n",
    "    Global_stop_delay['Global accumulated stop Delay'] = Balance_int_MultiDQN_Agents.Cumulative_Totale_network_stop_delay\n",
    "    \n",
    "    # Store as JSON\n",
    "    json_filename = \"Global_Cumulative_Stop_Delay.json\"\n",
    "    with open(results_path + \"/\" + json_filename, 'w') as f:\n",
    "        json.dump(Global_stop_delay, f)\n",
    "    \n",
    "    # Success Message\n",
    "    print(\"Agent {}: Test Cumulative Global Stop Delay successfuly saved to file:\")\n",
    "    print(results_path + \"/\" + json_filename)\n",
    "        \n",
    "    ### Loading data from JSON\n",
    "    #results_path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", agent_type, Session_ID)\n",
    "    #dictionary_filename = \"Global_Cumulative_Stop_Delay.json\"\n",
    "    #with open(results_path + \"/\" + json_filename, 'r') as fp:\n",
    "    #    data = json.load(fp)\n",
    "    #print(data)\n",
    "\n",
    "    # Plot the global stop delay\n",
    "    plt.figure('5'+str(idx),figsize=(16, 9))\n",
    "    plt.plot(Cumulative_Totale_network_stop_delay)\n",
    "    plt.xlabel('Time [s]',fontsize=18)\n",
    "    plt.ylabel('Global accumulated stop Delay',fontsize=18)\n",
    "    plt.title('Global accumulated stop Delay',fontsize=18)\n",
    "    plt.gca().legend('Global accumulated stop Delay')\n",
    "    \n",
    "    filename = \"Global_Cumulative_Delay.png\".format(intersection_number_in_vissim)\n",
    "    plt.savefig(results_path + \"/\" + filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Balance RL DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "map_name  = 'Balance'\n",
    "model_name = map_name\n",
    "\n",
    "vissim_working_directory = 'C:\\\\Users\\\\acabrejasegea\\\\OneDrive - The Alan Turing Institute\\\\Desktop\\\\ATI\\\\0_TMF\\\\MLforFlowOptimisation\\\\Vissim\\\\'\n",
    "#vissim_working_directory = \"E:\\\\OneDrive - University of Warwick\\\\Desktop\\\\ATI\\\\0_TMF\\\\MLforFlowOptimisation\\\\Vissim\"\n",
    "\n",
    "## Simulation Parameters\n",
    "Random_Seed = 44\n",
    "sim_length = 3601\n",
    "timesteps_per_second = 1\n",
    "agent_type = \"DQN\"\n",
    "actions = 'default_actions'     # 'default_actions' or 'all_actions'\n",
    "\n",
    "## DQN Hyperaramenters\n",
    "episodes = 500\n",
    "copy_weights_frequency = 10\n",
    "\n",
    "PER_activated = True\n",
    "memory_size = 5000\n",
    "batch_size = 128\n",
    "batches_per_episode = 10\n",
    "\n",
    "alpha = 0.00005\n",
    "gamma = 0.95\n",
    "\n",
    "# Load and partition balance dictionary\n",
    "Balance_dictionary = balance_dictionary(agent_type)\n",
    "\n",
    "Session_ID = map_name + \"_\" + actions + \"_\" + str(episodes) + \"_\" + str(sim_length-1) + \"_\" + agent_type\n",
    "print(\"Current simulation: {}\".format(Session_ID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Exploration Schedule (\"linear\" or \"geometric\")\n",
    "exploration_schedule = \"geometric\"\n",
    "epsilon_start = 1\n",
    "epsilon_end   = 0.001\n",
    "\n",
    "Random_Seed = 100\n",
    "\n",
    "def choose_schedule(exploration_schedule, espilon_start, epsilon_end, episodes):\n",
    "    if exploration_schedule == \"linear\":\n",
    "        epsilon_decay = 1.2*(epsilon_end - epsilon_start)/(episodes-1)\n",
    "        epsilon_sequence = [1 + epsilon_decay * entry for entry in range(episodes+1)]\n",
    "        epsilon_sequence = [0 if entry < 0 else entry for entry in epsilon_sequence]\n",
    "    elif exploration_schedule == \"geometric\":\n",
    "        epsilon_decay = np.power(epsilon_end/epsilon_start, 1./(episodes-1)) # Geometric decay\n",
    "        epsilon_sequence = [epsilon_start * epsilon_decay ** entry for entry in range(episodes+1)]\n",
    "    elif exploration_schedule == \"entropy\":\n",
    "        pass\n",
    "    else:\n",
    "        print(\"ERROR: Unrecognized choice of exploration schedule.\")\n",
    "        \n",
    "    # Plotting exploration schedule\n",
    "    plt.figure(figsize=(8,4.5))\n",
    "    x_series = np.array(range(1,episodes+1))\n",
    "    y_series = epsilon_sequence[0:episodes]\n",
    "    plt.plot(x_series, y_series, '-b')\n",
    "    plt.xlabel('Episodes')\n",
    "    plt.ylabel('Ratio of random exploration')\n",
    "    plt.title('Exploration schedule')\n",
    "    plt.show()\n",
    "    return(epsilon_sequence)\n",
    "\n",
    "epsilon_sequence = choose_schedule(exploration_schedule, epsilon_start, epsilon_end, episodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Balance_MultiDQN_Agents = MasterDQN_Agent(model_name, vissim_working_directory, sim_length, Balance_dictionary, actions,\\\n",
    "                gamma, alpha, agent_type, memory_size, PER_activated, batch_size, batches_per_episode, copy_weights_frequency, epsilon_sequence,\\\n",
    "                Random_Seed, timesteps_per_second, Session_ID, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Balance_MultiDQN_Agents.prepopulate_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Balance_MultiDQN_Agents.train(episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Balance_MultiDQN_Agents.save(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Balance_MultiDQN_Agents.demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# For the agent training\n",
    "ploty = 1\n",
    "for idx , agent in Balance_MultiDQN_Agents.Agents.items():\n",
    "    print(\"Agent \"+str(idx))\n",
    "    #print(ploty)\n",
    "    #plt.subplot(14, 2, ploty)\n",
    "\n",
    "    plt.figure('6'+str(idx),figsize=(4.5, 3))\n",
    "    \n",
    "    Loss_rewarddf = pd.DataFrame()   \n",
    "    \n",
    "    plt.plot(agent.loss)\n",
    "    plt.xlabel('Episode',fontsize=18)\n",
    "    plt.ylabel('Loss',fontsize=18)\n",
    "    plt.title('Agent{} Loss over training'.format(idx),fontsize=18)\n",
    "    plt.gca().legend('Agent Loss over training')\n",
    "    \n",
    "    Path  = os.path.join(vissim_working_directory, model_name, \"DQN\", \\\n",
    "                        \"Agent{}_Loss.png\".format(idx)) \n",
    "    #plt.savefig(Path)\n",
    "    \n",
    "    csv_Path = os.path.join(vissim_working_directory, model_name, \"DQN\", \\\n",
    "                           \"Agent{}_Loss_average_reward.csv\".format(idx)) \n",
    "    ploty+=1\n",
    "    #print(ploty)\n",
    "\n",
    "    \n",
    "    #plt.subplot(14, 2, ploty)\n",
    "    plt.figure('7'+str(idx),figsize=(4.5, 3))\n",
    "    plt.plot(agent.reward_storage)\n",
    "    plt.xlabel('Episode',fontsize=18)\n",
    "    plt.ylabel('Average reward',fontsize=18)\n",
    "    plt.title('Agent{} average reward over training'.format(idx),fontsize=18)\n",
    "    plt.gca().legend('Agent reward over training')\n",
    "    \n",
    "    Path  = os.path.join(vissim_working_directory, model_name, \"DQN\", Session_ID,\\\n",
    "                        \"Agent{}_average_reward.png\".format(idx)) \n",
    "    #plt.savefig(Path)\n",
    "    \n",
    "    \n",
    "    episode = [i for i in range(len(agent.reward_storage))]\n",
    "    \n",
    "    Loss_rewarddf['episode'] = episode \n",
    "    Loss_rewarddf['Agent{} loss'.format(idx)] = agent.loss\n",
    "    Loss_rewarddf['Agent{} Average_Reward'.format(idx)] = agent.reward_storage\n",
    "    \n",
    "    #Loss_rewarddf.to_csv(csv_Path,index=False)\n",
    "    ploty+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Balance_MultiDQN_Agents.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "time = [t for t in range(len(Cumulative_Totale_network_stop_delay))]\n",
    "\n",
    "# Queues ovzer time for each junction\n",
    "for idx, queues in Balance_MultiDQN_Agents.Episode_Queues.items():\n",
    "    queues = np.array(queues)\n",
    "    queues = queues.T\n",
    "    \n",
    "    plt.figure('1'+str(idx),figsize=(16, 9))\n",
    "    \n",
    "    Queuesdf = pd.DataFrame()\n",
    "    \n",
    "    Queuesdf['Time'] = time\n",
    "    Queues_legend = []\n",
    "    \n",
    "    for i, queue in enumerate(queues):\n",
    "        plt.plot(queue, label = \"Queue\"+str(i))\n",
    "        Queuesdf[str(i)] = queue\n",
    "        Queues_legend.append(\"Queue\"+str(i))\n",
    "        \n",
    "    plt.xlabel('Time [s]',fontsize=18)\n",
    "    plt.ylabel('Queue Length',fontsize=18)\n",
    "    plt.title('Junction {} Queue length'.format(idx),fontsize=18)\n",
    "    #plt.gca().legend(Queues_legend)\n",
    "    \n",
    "    Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Junction{}_Queues.png\".format(idx))               \n",
    "    plt.savefig(Path)\n",
    "    \n",
    "    csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Junction{}_Queues.csv\".format(idx))        \n",
    "   \n",
    "    Queuesdf.to_csv(csv_Path,index=False)\n",
    "    plt.legend()\n",
    "        \n",
    "        \n",
    "# Accumulated delay over time for each junction\n",
    "for idx, delay in Balance_MultiDQN_Agents.Cumulative_Episode_Delays.items():\n",
    "    \n",
    "    plt.figure('2'+str(idx),figsize=(16, 9))\n",
    "    \n",
    "    delaydf = pd.DataFrame()   \n",
    "    delaydf['Time'] = time\n",
    "    delaydf['Junction {} delay'.format(idx)] = delay\n",
    "    \n",
    "    plt.plot(delay)\n",
    "    plt.xlabel('Time [s]',fontsize=18)\n",
    "    plt.ylabel('Accumulated Delay',fontsize=18)\n",
    "    plt.title('Junction {} Delay'.format(idx),fontsize=18)\n",
    "    plt.gca().legend('Junction accumulated delay')\n",
    "    \n",
    "    Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                            \"Junction{}_Cumulative_Delay.png\".format(idx))\n",
    "    csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Junction{}_Cumulative_Delay.csv\".format(idx))   \n",
    "    plt.savefig(Path)\n",
    "\n",
    "    delaydf.to_csv(csv_Path,index=False)\n",
    "    \n",
    "    \n",
    "# Accumulated stop delay over time for each junction\n",
    "for idx, stop_delay in Balance_MultiDQN_Agents.Cumulative_Episode_stop_Delays.items():\n",
    "    \n",
    "    plt.figure('3'+str(idx),figsize=(16, 9))\n",
    "    \n",
    "    stop_delaydf = pd.DataFrame()   \n",
    "    stop_delaydf['Time'] = time\n",
    "    stop_delaydf['Junction {} stop delay'.format(idx)] = stop_delay\n",
    "\n",
    "    plt.plot(stop_delay)\n",
    "    plt.xlabel('Time [s]',fontsize=18)\n",
    "    plt.ylabel('Accumulated Stop Delay',fontsize=18)\n",
    "    plt.title('Junction {} Stop Delay'.format(idx),fontsize=18)\n",
    "    plt.gca().legend('Junction accumulated Stop delay')\n",
    "    \n",
    "    Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                            \"Junction{}_Cumulative_stop_Delay.png\".format(idx))\n",
    "    csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Junction{}_Cumulative_stop_Delay.csv\".format(idx))\n",
    "    plt.savefig(Path)\n",
    "    stop_delaydf.to_csv(csv_Path,index=False)\n",
    "    \n",
    "# Global Accumulated delay over time\n",
    "plt.figure('4',figsize=(16,9))\n",
    "\n",
    "\n",
    "Global_delaydf = pd.DataFrame()   \n",
    "Global_delaydf['Time'] = time\n",
    "Global_delaydf['Global accumulated Delay'] = Balance_MultiDQN_Agents.Cumulative_Totale_network_delay\n",
    "\n",
    "plt.plot(Cumulative_Totale_network_delay)\n",
    "plt.xlabel('Time [s]',fontsize=18)\n",
    "plt.ylabel('Global accumulated Delay',fontsize=18)\n",
    "plt.title('Global accumulated Delay',fontsize=18)\n",
    "plt.gca().legend('Global accumulated delay')\n",
    "\n",
    "Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Total_Cumulative_Delay.png\")\n",
    "csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Total_Cumulative_Delay.csv\")\n",
    "plt.savefig(Path)\n",
    "Global_delaydf.to_csv(csv_Path,index=False)\n",
    "\n",
    "# Global Accumulated stop delay over time\n",
    "plt.figure('5'+str(idx),figsize=(16, 9))\n",
    "\n",
    "Global_stop_delaydf = pd.DataFrame()   \n",
    "Global_stop_delaydf['Time'] = time\n",
    "Global_stop_delaydf['Global accumulated stop Delay'] = Balance_MultiDQN_Agents.Cumulative_Totale_network_stop_delay\n",
    "\n",
    "plt.plot(Cumulative_Totale_network_stop_delay)\n",
    "plt.xlabel('Time [s]',fontsize=18)\n",
    "plt.ylabel('Global accumulated stop Delay',fontsize=18)\n",
    "plt.title('Global accumulated stop Delay',fontsize=18)\n",
    "plt.gca().legend('Global accumulated stop Delay')\n",
    "\n",
    "Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Total_Cumulative_stop_Delay.png\")\n",
    "csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Total_Cumulative_stop_Delay.csv\")\n",
    "plt.savefig(Path)\n",
    "Global_stop_delaydf.to_csv(csv_Path,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Balance_MultiDQN_Agents.load(498, best = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Balance_MultiDQN_Agents.demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Single_Cross_Straight AC\n",
    "\n",
    "---> The lack of speed comes from the size of the model (particularly the change of color of the heads). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_name  = 'Single_Cross_Straight'\n",
    "vissim_working_directory =  'C:\\\\Users\\\\Rzhang\\\\Desktop\\\\MLforFlowOptimisationOrigine\\\\Vissim\\\\'\n",
    "sim_length = 3601\n",
    "\n",
    "agent_type = \"AC\"\n",
    "Session_ID = \"Single_Cross_Straigth_AC\"\n",
    "\n",
    "\n",
    "\n",
    "# all controller actions\n",
    "Single_Cross_Straight_dictionary =\\\n",
    "{'junctions' : {\n",
    "    # Controller Number 0 \n",
    "    0 : {'default_actions' : {     0 : [1, 0, 1, 0],\n",
    "                                     1 : [0, 1, 0, 1]\n",
    "        },\n",
    "         \n",
    "         'all_actions' : {     0 : [1, 0, 1, 0],\n",
    "                                     1 : [0, 1, 0, 1]\n",
    "        },\n",
    " \n",
    "         'link' : [1, 3, 5, 7],\n",
    "         'lane' : ['1-1', '3-1', '5-1', '7-1'],\n",
    "         'agent_type' : agent_type,\n",
    "         'controled_by_com' : True,\n",
    "         'green_time' : 6,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [5],\n",
    "         'state_type' : 'QueuesSig',\n",
    "         'reward_type' : 'Queues' }\n",
    "        },\n",
    " 'demand' : { 'default' : [400, 400, 400, 400],\n",
    "             \n",
    "             0 : [200,200,200,200],\n",
    "             1 : [400,400,400,400],\n",
    "             2 : [900,500,900,500],\n",
    "             3 : [1000,500,1000,500],\n",
    "             4 : [700,500,700,500],\n",
    "             5 : [500,700,500,700],\n",
    "             6 : [500,1000,500,1000],\n",
    "             7 : [500,900,500,900],\n",
    "             8 : [400,400,400,400],\n",
    "             9 : [200,200,200,200]\n",
    "            }\n",
    " \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gamma = 0.95\n",
    "alpha = 0.00001\n",
    "\n",
    "\n",
    "value = 0.5\n",
    "entropy = 0.5\n",
    "n_step_size = 16\n",
    "state_size = [5]\n",
    "reduce_entropy_every = 100\n",
    "Random_Seed = 100\n",
    "\n",
    "\n",
    "\n",
    "# for the monitoring\n",
    "horizon = 50\n",
    "n_sample = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Straight_MultiAC_Agents = MasterAC_Agent(model_name, vissim_working_directory, sim_length, Single_Cross_Straight_dictionary,\\\n",
    "                n_step_size, gamma, alpha, entropy, value, \\\n",
    "                Random_Seed = Random_Seed, timesteps_per_second = 1, Session_ID = Session_ID, verbose = True, \\\n",
    "                 horizon = horizon, n_sample = n_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Straight_MultiAC_Agents.train(200) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Straight_MultiAC_Agents.save(401)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Straight_MultiAC_Agents.load(200, best = True)\n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Episode_Queues, Cumulative_Episode_Delays,Cumulative_Episode_stop_Delays, Cumulative_Totale_network_delay,Cumulative_Totale_network_stop_delay = Single_Cross_Straight_MultiAC_Agents.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "time = [t for t in range(len(Cumulative_Totale_network_stop_delay))]\n",
    "\n",
    "# Queues ovzer time for each junction\n",
    "for idx, queues in Episode_Queues.items():\n",
    "    queues = np.array(Episode_Queues[0])\n",
    "    queues = queues.T\n",
    "    \n",
    "    plt.figure('1'+str(idx),figsize=(16, 9))\n",
    "    \n",
    "    Queuesdf = pd.DataFrame()\n",
    "    \n",
    "    Queuesdf['Time'] = time\n",
    "    Queues_legend = []\n",
    "    \n",
    "    for i, queue in enumerate(queues):\n",
    "        plt.plot(queue)\n",
    "        Queuesdf[str(i)] = queue\n",
    "        Queues_legend.append(\"Queue\"+str(i))\n",
    "        \n",
    "    plt.xlabel('Time [s]',fontsize=18)\n",
    "    plt.ylabel('Queue Length',fontsize=18)\n",
    "    plt.title('Junction {} Queue length'.format(idx),fontsize=18)\n",
    "    plt.gca().legend(Queues_legend)\n",
    "    \n",
    "    Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Junction{}_Queues.png\".format(idx))               \n",
    "    plt.savefig(Path)\n",
    "    \n",
    "    csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Junction{}_Queues.csv\".format(idx))        \n",
    "   \n",
    "    Queuesdf.to_csv(csv_Path,index=False)\n",
    "        \n",
    "        \n",
    "# Accumulated delay over time for each junction\n",
    "for idx, delay in Cumulative_Episode_Delays.items():\n",
    "    \n",
    "    plt.figure('2'+str(idx),figsize=(16, 9))\n",
    "    \n",
    "    delaydf = pd.DataFrame()   \n",
    "    delaydf['Time'] = time\n",
    "    delaydf['Junction {} delay'.format(idx)] = delay\n",
    "    \n",
    "    plt.plot(delay)\n",
    "    plt.xlabel('Time [s]',fontsize=18)\n",
    "    plt.ylabel('Accumulated Delay',fontsize=18)\n",
    "    plt.title('Junction {} Delay'.format(idx),fontsize=18)\n",
    "    plt.gca().legend('Junction accumulated delay')\n",
    "    \n",
    "    Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                            \"Junction{}_Cumulative_Delay.png\".format(idx))\n",
    "    csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Junction{}_Cumulative_Delay.csv\".format(idx))   \n",
    "    plt.savefig(Path)\n",
    "\n",
    "    delaydf.to_csv(csv_Path,index=False)\n",
    "    \n",
    "    \n",
    "# Accumulated stop delay over time for each junction\n",
    "for idx, stop_delay in Cumulative_Episode_stop_Delays.items():\n",
    "    \n",
    "    plt.figure('3'+str(idx),figsize=(16, 9))\n",
    "    \n",
    "    stop_delaydf = pd.DataFrame()   \n",
    "    stop_delaydf['Time'] = time\n",
    "    stop_delaydf['Junction {} stop delay'.format(idx)] = stop_delay\n",
    "\n",
    "    plt.plot(stop_delay)\n",
    "    plt.xlabel('Time [s]',fontsize=18)\n",
    "    plt.ylabel('Accumulated Stop Delay',fontsize=18)\n",
    "    plt.title('Junction {} Stop Delay'.format(idx),fontsize=18)\n",
    "    plt.gca().legend('Junction accumulated Stop delay')\n",
    "    \n",
    "    Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                            \"Junction{}_Cumulative_stop_Delay.png\".format(idx))\n",
    "    csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Junction{}_Cumulative_stop_Delay.csv\".format(idx))\n",
    "    plt.savefig(Path)\n",
    "    stop_delaydf.to_csv(csv_Path,index=False)\n",
    "    \n",
    "# Global Accumulated delay over time\n",
    "plt.figure('4',figsize=(16,9))\n",
    "\n",
    "\n",
    "Global_delaydf = pd.DataFrame()   \n",
    "Global_delaydf['Time'] = time\n",
    "Global_delaydf['Global accumulated Delay'] = Cumulative_Totale_network_delay\n",
    "\n",
    "plt.plot(Cumulative_Totale_network_delay)\n",
    "plt.xlabel('Time [s]',fontsize=18)\n",
    "plt.ylabel('Global accumulated Delay',fontsize=18)\n",
    "plt.title('Global accumulated Delay',fontsize=18)\n",
    "plt.gca().legend('Global accumulated delay')\n",
    "\n",
    "Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Total_Cumulative_Delay.png\")\n",
    "csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Total_Cumulative_Delay.csv\")\n",
    "plt.savefig(Path)\n",
    "Global_delaydf.to_csv(csv_Path,index=False)\n",
    "\n",
    "# Global Accumulated stop delay over time\n",
    "plt.figure('5'+str(idx),figsize=(16, 9))\n",
    "\n",
    "Global_stop_delaydf = pd.DataFrame()   \n",
    "Global_stop_delaydf['Time'] = time\n",
    "Global_stop_delaydf['Global accumulated stop Delay'] = Cumulative_Totale_network_stop_delay\n",
    "\n",
    "plt.plot(Cumulative_Totale_network_stop_delay)\n",
    "plt.xlabel('Time [s]',fontsize=18)\n",
    "plt.ylabel('Global accumulated stop Delay',fontsize=18)\n",
    "plt.title('Global accumulated stop Delay',fontsize=18)\n",
    "plt.gca().legend('Global accumulated stop Delay')\n",
    "\n",
    "Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Total_Cumulative_stop_Delay.png\")\n",
    "csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Total_Cumulative_stop_Delay.csv\")\n",
    "plt.savefig(Path)\n",
    "Global_stop_delaydf.to_csv(csv_Path,index=False)\n",
    "\n",
    "\n",
    "# For the agent training\n",
    "\n",
    "for idx , agent in  Single_Cross_Straight_MultiAC_Agents.Agents.items():  \n",
    "    plt.figure('6'+str(idx),figsize=(16, 9))\n",
    "    \n",
    "    Loss_rewarddf = pd.DataFrame()   \n",
    "    \n",
    "    plt.plot(agent.loss)\n",
    "    plt.xlabel('Episode',fontsize=18)\n",
    "    plt.ylabel('Loss',fontsize=18)\n",
    "    plt.title('Agent{} Loss over training'.format(idx),fontsize=18)\n",
    "    plt.gca().legend('Agent Loss over training')\n",
    "    \n",
    "    Path  = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Agent{}_Loss.png\".format(idx)) \n",
    "    plt.savefig(Path)\n",
    "    \n",
    "    csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                           \"Agent{}_Loss_average_reward.csv\".format(idx)) \n",
    "    \n",
    "    \n",
    "    plt.figure('7'+str(idx),figsize=(16, 9))\n",
    "    plt.plot(agent.reward_storage)\n",
    "    plt.xlabel('Episode',fontsize=18)\n",
    "    plt.ylabel('Average reward',fontsize=18)\n",
    "    plt.title('Agent{} average reward over training'.format(idx),fontsize=18)\n",
    "    plt.gca().legend('Agent reward over training')\n",
    "    \n",
    "    Path  = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Agent{}_average_reward.png\".format(idx)) \n",
    "    plt.savefig(Path)\n",
    "    \n",
    "    \n",
    "    episode = [i for i in range(len(agent.reward_storage))]\n",
    "    \n",
    "    Loss_rewarddf['episode'] = episode \n",
    "    Loss_rewarddf['Agent{} loss'.format(idx)] = agent.loss\n",
    "    Loss_rewarddf['Agent{} Average_Reward'.format(idx)] = agent.reward_storage\n",
    "    \n",
    "    Loss_rewarddf.to_csv(csv_Path,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Straight_MultiAC_Agents.Agents[0].Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Straight_MultiAC_Agents.demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Single_Cross_Straight DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_name  = 'Single_Cross_Straight'\n",
    "vissim_working_directory =  'C:\\\\Users\\\\Rzhang\\\\Desktop\\\\MLforFlowOptimisationOrigine\\\\Vissim\\\\'\n",
    "sim_length = 3601\n",
    "\n",
    "agent_type = \"DuelingDQN\"\n",
    "Session_ID = \"Single_Cross_Straigth_DuelingDQN20c0\"\n",
    "\n",
    "# all controller actions\n",
    "# all controller actions\n",
    "Single_Cross_Straight_dictionary =\\\n",
    "{'junctions' : {\n",
    "    # Controller Number 0 \n",
    "    0 : {'default_actions' : {     0 : [1, 0, 1, 0],\n",
    "                                     1 : [0, 1, 0, 1]\n",
    "        },\n",
    "         \n",
    "         'all_actions' : {     0 : [1, 0, 1, 0],\n",
    "                                     1 : [0, 1, 0, 1]\n",
    "        },\n",
    " \n",
    "         'link' : [1, 3, 5, 7],\n",
    "         'lane' : ['1-1', '3-1', '5-1', '7-1'],\n",
    "         'agent_type' : agent_type,\n",
    "         'controled_by_com' : True,\n",
    "         'green_time' : 6,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [5],\n",
    "         'state_type' : 'QueuesSig',\n",
    "         'reward_type' : 'Queues',\n",
    "         'queues_counter_ID' : [1,2,3,4]  }\n",
    "        },\n",
    " 'demand' : { 'default' : [400, 400, 400, 400],\n",
    "             \n",
    "             0 : [200,200,200,200],\n",
    "             1 : [400,400,400,400],\n",
    "             2 : [900,500,900,500],\n",
    "             3 : [1000,500,1000,500],\n",
    "             4 : [700,500,700,500],\n",
    "             5 : [500,700,500,700],\n",
    "             6 : [500,1000,500,1000],\n",
    "             7 : [500,900,500,900],\n",
    "             8 : [400,400,400,400],\n",
    "             9 : [200,200,200,200]\n",
    "            }\n",
    " \n",
    "}\n",
    "\n",
    "## DQN Hyperaramenters\n",
    "episodes = 300\n",
    "copy_weights_frequency = 10\n",
    "\n",
    "PER_activated = True\n",
    "memory_size = 1000\n",
    "batch_size = 128\n",
    "\n",
    "gamma = 0.95\n",
    "alpha = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Exploration Schedule (\"linear\" or \"geometric\")\n",
    "exploration_schedule = \"geometric\"\n",
    "epsilon_start = 1\n",
    "epsilon_end   = 0.001\n",
    "\n",
    "Random_Seed = 100\n",
    "\n",
    "def choose_schedule(exploration_schedule, espilon_start, epsilon_end, episodes):\n",
    "    if exploration_schedule == \"linear\":\n",
    "        epsilon_decay = 1.2*(epsilon_end - epsilon_start)/(episodes-1)\n",
    "        epsilon_sequence = [1 + epsilon_decay * entry for entry in range(episodes+1)]\n",
    "        epsilon_sequence = [0 if entry < 0 else entry for entry in epsilon_sequence]\n",
    "    elif exploration_schedule == \"geometric\":\n",
    "        epsilon_decay = np.power(epsilon_end/epsilon_start, 1./(episodes-1)) # Geometric decay\n",
    "        epsilon_sequence = [epsilon_start * epsilon_decay ** entry for entry in range(episodes+1)]\n",
    "    elif exploration_schedule == \"entropy\":\n",
    "        pass\n",
    "    else:\n",
    "        print(\"ERROR: Unrecognized choice of exploration schedule.\")\n",
    "        \n",
    "    # Plotting exploration schedule\n",
    "    plt.figure(figsize=(8,4.5))\n",
    "    x_series = np.array(range(1,episodes+1))\n",
    "    y_series = epsilon_sequence[0:episodes]\n",
    "    plt.plot(x_series, y_series, '-b')\n",
    "    plt.xlabel('Episodes')\n",
    "    plt.ylabel('Ratio of random exploration')\n",
    "    plt.title('Exploration schedule')\n",
    "    plt.show()\n",
    "    return(epsilon_sequence)\n",
    "\n",
    "epsilon_sequence = choose_schedule(exploration_schedule, epsilon_start, epsilon_end, episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Straight_MultiDQN_Agents = MasterDQN_Agent(model_name, vissim_working_directory, sim_length, Single_Cross_Straight_dictionary,\\\n",
    "                gamma, alpha, agent_type, memory_size, PER_activated, batch_size, copy_weights_frequency, epsilon_sequence,\\\n",
    "                Random_Seed = Random_Seed, timesteps_per_second = 1, Session_ID = Session_ID, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Straight_MultiDQN_Agents.prepopulate_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Straight_MultiDQN_Agents.train(episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Straight_MultiDQN_Agents.save(401)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Straight_MultiDQN_Agents.load(300 , best = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Episode_Queues, Cumulative_Episode_Delays,Cumulative_Episode_stop_Delays, Cumulative_Totale_network_delay,Cumulative_Totale_network_stop_delay  = Single_Cross_Straight_MultiDQN_Agents.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "time = [t for t in range(len(Cumulative_Totale_network_stop_delay))]\n",
    "\n",
    "# Queues ovzer time for each junction\n",
    "for idx, queues in Episode_Queues.items():\n",
    "    queues = np.array(Episode_Queues[0])\n",
    "    queues = queues.T\n",
    "    \n",
    "    plt.figure('1'+str(idx),figsize=(16, 9))\n",
    "    \n",
    "    Queuesdf = pd.DataFrame()\n",
    "    \n",
    "    Queuesdf['Time'] = time\n",
    "    Queues_legend = []\n",
    "    \n",
    "    for i, queue in enumerate(queues):\n",
    "        plt.plot(queue)\n",
    "        Queuesdf[str(i)] = queue\n",
    "        Queues_legend.append(\"Queue\"+str(i))\n",
    "        \n",
    "    plt.xlabel('Time [s]',fontsize=18)\n",
    "    plt.ylabel('Queue Length',fontsize=18)\n",
    "    plt.title('Junction {} Queue length'.format(idx),fontsize=18)\n",
    "    plt.gca().legend(Queues_legend)\n",
    "    \n",
    "    Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Junction{}_Queues.png\".format(idx))               \n",
    "    plt.savefig(Path)\n",
    "    \n",
    "    csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Junction{}_Queues.csv\".format(idx))        \n",
    "   \n",
    "    Queuesdf.to_csv(csv_Path,index=False)\n",
    "        \n",
    "        \n",
    "# Accumulated delay over time for each junction\n",
    "for idx, delay in Cumulative_Episode_Delays.items():\n",
    "    \n",
    "    plt.figure('2'+str(idx),figsize=(16, 9))\n",
    "    \n",
    "    delaydf = pd.DataFrame()   \n",
    "    delaydf['Time'] = time\n",
    "    delaydf['Junction {} delay'.format(idx)] = delay\n",
    "    \n",
    "    plt.plot(delay)\n",
    "    plt.xlabel('Time [s]',fontsize=18)\n",
    "    plt.ylabel('Accumulated Delay',fontsize=18)\n",
    "    plt.title('Junction {} Delay'.format(idx),fontsize=18)\n",
    "    plt.gca().legend('Junction accumulated delay')\n",
    "    \n",
    "    Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                            \"Junction{}_Cumulative_Delay.png\".format(idx))\n",
    "    csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Junction{}_Cumulative_Delay.csv\".format(idx))   \n",
    "    plt.savefig(Path)\n",
    "\n",
    "    delaydf.to_csv(csv_Path,index=False)\n",
    "    \n",
    "    \n",
    "# Accumulated stop delay over time for each junction\n",
    "for idx, stop_delay in Cumulative_Episode_stop_Delays.items():\n",
    "    \n",
    "    plt.figure('3'+str(idx),figsize=(16, 9))\n",
    "    \n",
    "    stop_delaydf = pd.DataFrame()   \n",
    "    stop_delaydf['Time'] = time\n",
    "    stop_delaydf['Junction {} stop delay'.format(idx)] = stop_delay\n",
    "\n",
    "    plt.plot(stop_delay)\n",
    "    plt.xlabel('Time [s]',fontsize=18)\n",
    "    plt.ylabel('Accumulated Stop Delay',fontsize=18)\n",
    "    plt.title('Junction {} Stop Delay'.format(idx),fontsize=18)\n",
    "    plt.gca().legend('Junction accumulated Stop delay')\n",
    "    \n",
    "    Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                            \"Junction{}_Cumulative_stop_Delay.png\".format(idx))\n",
    "    csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Junction{}_Cumulative_stop_Delay.csv\".format(idx))\n",
    "    plt.savefig(Path)\n",
    "    stop_delaydf.to_csv(csv_Path,index=False)\n",
    "    \n",
    "# Global Accumulated delay over time\n",
    "plt.figure('4',figsize=(16,9))\n",
    "\n",
    "\n",
    "Global_delaydf = pd.DataFrame()   \n",
    "Global_delaydf['Time'] = time\n",
    "Global_delaydf['Global accumulated Delay'] = Cumulative_Totale_network_delay\n",
    "\n",
    "plt.plot(Cumulative_Totale_network_delay)\n",
    "plt.xlabel('Time [s]',fontsize=18)\n",
    "plt.ylabel('Global accumulated Delay',fontsize=18)\n",
    "plt.title('Global accumulated Delay',fontsize=18)\n",
    "plt.gca().legend('Global accumulated delay')\n",
    "\n",
    "Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Total_Cumulative_Delay.png\")\n",
    "csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Total_Cumulative_Delay.csv\")\n",
    "plt.savefig(Path)\n",
    "Global_delaydf.to_csv(csv_Path,index=False)\n",
    "\n",
    "# Global Accumulated stop delay over time\n",
    "plt.figure('5'+str(idx),figsize=(16, 9))\n",
    "\n",
    "Global_stop_delaydf = pd.DataFrame()   \n",
    "Global_stop_delaydf['Time'] = time\n",
    "Global_stop_delaydf['Global accumulated stop Delay'] = Cumulative_Totale_network_stop_delay\n",
    "\n",
    "plt.plot(Cumulative_Totale_network_stop_delay)\n",
    "plt.xlabel('Time [s]',fontsize=18)\n",
    "plt.ylabel('Global accumulated stop Delay',fontsize=18)\n",
    "plt.title('Global accumulated stop Delay',fontsize=18)\n",
    "plt.gca().legend('Global accumulated stop Delay')\n",
    "\n",
    "Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Total_Cumulative_stop_Delay.png\")\n",
    "csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Total_Cumulative_stop_Delay.csv\")\n",
    "plt.savefig(Path)\n",
    "Global_stop_delaydf.to_csv(csv_Path,index=False)\n",
    "\n",
    "\n",
    "# For the agent training\n",
    "\n",
    "for idx , agent in  Single_Cross_Straight_MultiDQN_Agents.Agents.items():  \n",
    "    plt.figure('6'+str(idx),figsize=(16, 9))\n",
    "    \n",
    "    Loss_rewarddf = pd.DataFrame()   \n",
    "    \n",
    "    plt.plot(agent.loss)\n",
    "    plt.xlabel('Episode',fontsize=18)\n",
    "    plt.ylabel('Loss',fontsize=18)\n",
    "    plt.title('Agent{} Loss over training'.format(idx),fontsize=18)\n",
    "    plt.gca().legend('Agent Loss over training')\n",
    "    \n",
    "    Path  = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Agent{}_Loss.png\".format(idx)) \n",
    "    plt.savefig(Path)\n",
    "    \n",
    "    csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                           \"Agent{}_Loss_average_reward.csv\".format(idx)) \n",
    "    \n",
    "    \n",
    "    plt.figure('7'+str(idx),figsize=(16, 9))\n",
    "    plt.plot(agent.reward_storage)\n",
    "    plt.xlabel('Episode',fontsize=18)\n",
    "    plt.ylabel('Average reward',fontsize=18)\n",
    "    plt.title('Agent{} average reward over training'.format(idx),fontsize=18)\n",
    "    plt.gca().legend('Agent reward over training')\n",
    "    \n",
    "    Path  = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Agent{}_average_reward.png\".format(idx)) \n",
    "    plt.savefig(Path)\n",
    "    \n",
    "    \n",
    "    episode = [i for i in range(len(agent.reward_storage))]\n",
    "    \n",
    "    Loss_rewarddf['episode'] = episode \n",
    "    Loss_rewarddf['Agent{} loss'.format(idx)] = agent.loss\n",
    "    Loss_rewarddf['Agent{} Average_Reward'.format(idx)] = agent.reward_storage\n",
    "    \n",
    "    Loss_rewarddf.to_csv(csv_Path,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Straight_MultiDQN_Agents.demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Single_Cross_Triple 4 actions AC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_name  = 'Single_Cross_Triple'\n",
    "vissim_working_directory =  'C:\\\\Users\\\\Rzhang\\\\Desktop\\\\MLforFlowOptimisationOrigine\\\\Vissim\\\\'\n",
    "sim_length = 3600\n",
    "\n",
    "agent_type = \"AC\"\n",
    "Session_ID = \"Single_Cross_TripleAC4test1\"\n",
    "\n",
    "# all controller actions\n",
    "Single_Cross_Triple_dictionary4 =\\\n",
    "{\\\n",
    "    # Controller Number 0 \n",
    "   'junctions' : {0 : {'default_actions' :  {    0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             },\n",
    "         \n",
    "         'all_actions' :        {            0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             },\n",
    " \n",
    "         'link' : [1, 3, 5, 7],\n",
    "         'lane' : ['1-1', '1-2', '1-3', '3-1', '3-2', '3-3', '5-1', '5-2', '5-3', '7-1', '7-2', '7-3'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'agent_type' : agent_type,\n",
    "         'green_time' : 6,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [13],\n",
    "         'state_type' : 'QueuesSig',\n",
    "         'reward_type' : 'Queues' \n",
    "         }\n",
    "    },\n",
    "   'demand' : {\"default\" : [400,400,400,400] }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gamma = 0.85\n",
    "alpha = 0.00005\n",
    "\n",
    "\n",
    "value = 0.5\n",
    "entropy = 5000\n",
    "n_step_size = 4\n",
    "state_size = [13]\n",
    "reduce_entropy_every = 100\n",
    "Random_Seed = 100\n",
    "\n",
    "\n",
    "\n",
    "# for the monitoring\n",
    "horizon = 50\n",
    "n_sample = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Triple4_MultiAC_Agents = MasterAC_Agent(model_name, vissim_working_directory, sim_length, Single_Cross_Triple_dictionary4,\\\n",
    "                n_step_size, gamma, alpha, entropy, value, \\\n",
    "                Random_Seed = Random_Seed, timesteps_per_second = 1, Session_ID = Session_ID, verbose = True, \\\n",
    "                 horizon = horizon, n_sample = n_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Triple4_MultiAC_Agents.train(400) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Triple4_MultiAC_Agents.save(401)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Triple4_MultiAC_Agents.load(50, best = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Episode_Queues, Cumulative_Episode_Delays, Cumulative_Totale_network_delay = Single_Cross_Triple4_MultiAC_Agents.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Triple4_MultiAC_Agents.demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Single_Cross_Triple 4 action DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_name  = 'Single_Cross_Triple'\n",
    "vissim_working_directory =  'C:\\\\Users\\\\Rzhang\\\\Desktop\\\\MLforFlowOptimisationOrigine\\\\Vissim\\\\'\n",
    "sim_length = 3601\n",
    "\n",
    "Session_ID = \"Single_Cross_Triple4_actions\"\n",
    "#Session_ID = \"DQN\"\n",
    "\n",
    "agent_type = \"DuelingDDQN\"\n",
    "\n",
    "# all controller actions\n",
    "Single_Cross_Triple_dictionary4 =\\\n",
    "{ 'junctions' : {\n",
    "    # Controller Number 0 \n",
    "    0 : {'default_actions' :    {    0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                     1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                     2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                     3 : [0,0,0,0,0,0,0,0,0,1,1,1]},\n",
    "         \n",
    "         \n",
    "         'all_actions' :       {    0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                     1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                     2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                     3 : [0,0,0,0,0,0,0,0,0,1,1,1]},\n",
    "         \n",
    " \n",
    "         'link' : [1, 3, 5, 7],\n",
    "         'lane' : ['1-1', '1-2', '1-3', '3-1', '3-2', '3-3', '5-1', '5-2', '5-3', '7-1', '7-2', '7-3'],\n",
    "         'controled_by_com' : True,\n",
    "         'agent_type' : agent_type,\n",
    "         'green_time' : 6,\n",
    "         'redamber_time' : 1,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [13],\n",
    "         'state_type' : 'QueuesSig',\n",
    "         'reward_type' : 'Queues' \n",
    "         },\n",
    "        },\n",
    "     'demand' : { 'default' : [400, 400, 400, 400]}\n",
    "                  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## DQN Hyperaramenters\n",
    "episodes = 400\n",
    "copy_weights_frequency = 5\n",
    "\n",
    "PER_activated = True\n",
    "memory_size = 1000\n",
    "batch_size = 128\n",
    "\n",
    "gamma = 0.95\n",
    "alpha = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Exploration Schedule (\"linear\" or \"geometric\")\n",
    "exploration_schedule = \"geometric\"\n",
    "epsilon_start = 1\n",
    "epsilon_end   = 0.001\n",
    "\n",
    "Random_Seed = 100\n",
    "\n",
    "def choose_schedule(exploration_schedule, espilon_start, epsilon_end, episodes):\n",
    "    if exploration_schedule == \"linear\":\n",
    "        epsilon_decay = 1.2*(epsilon_end - epsilon_start)/(episodes-1)\n",
    "        epsilon_sequence = [1 + epsilon_decay * entry for entry in range(episodes+1)]\n",
    "        epsilon_sequence = [0 if entry < 0 else entry for entry in epsilon_sequence]\n",
    "    elif exploration_schedule == \"geometric\":\n",
    "        epsilon_decay = np.power(epsilon_end/epsilon_start, 1./(episodes-1)) # Geometric decay\n",
    "        epsilon_sequence = [epsilon_start * epsilon_decay ** entry for entry in range(episodes+1)]\n",
    "    elif exploration_schedule == \"entropy\":\n",
    "        pass\n",
    "    else:\n",
    "        print(\"ERROR: Unrecognized choice of exploration schedule.\")\n",
    "        \n",
    "    # Plotting exploration schedule\n",
    "    plt.figure(figsize=(8,4.5))\n",
    "    x_series = np.array(range(1,episodes+1))\n",
    "    y_series = epsilon_sequence[0:episodes]\n",
    "    plt.plot(x_series, y_series, '-b')\n",
    "    plt.xlabel('Episodes')\n",
    "    plt.ylabel('Ratio of random exploration')\n",
    "    plt.title('Exploration schedule')\n",
    "    plt.show()\n",
    "    return(epsilon_sequence)\n",
    "\n",
    "epsilon_sequence = choose_schedule(exploration_schedule, epsilon_start, epsilon_end, episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Triple4_MultiDQN_Agents = MasterDQN_Agent(model_name, vissim_working_directory, sim_length, Single_Cross_Triple_dictionary4,\\\n",
    "                gamma, alpha, agent_type, memory_size, PER_activated, batch_size, copy_weights_frequency, epsilon_sequence,\\\n",
    "                Random_Seed = Random_Seed, timesteps_per_second = 1, Session_ID = Session_ID, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Triple4_MultiDQN_Agents.prepopulate_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Triple4_MultiDQN_Agents.train(120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Triple4_MultiDQN_Agents.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Triple4_MultiDQN_Agents.load(best = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Episode_Queues, Cumulative_Episode_Delays, Cumulative_Totale_network_delay = Single_Cross_Triple4_MultiDQN_Agents.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# To be arranged for multy agents\n",
    "\n",
    "queues = np.array(Episode_Queues[0])\n",
    "queues = queues.T\n",
    "\n",
    "delay = Cumulative_Episode_Delays[0]\n",
    "\n",
    "# Plot the queues\n",
    "plt.figure(1)\n",
    "for queue in queues:\n",
    "    plt.plot(queue)\n",
    "\n",
    "# plot the junctions delays\n",
    "plt.figure(2)\n",
    "plt.plot(delay)\n",
    "\n",
    "#plot the total delays \n",
    "plt.figure(3)\n",
    "plt.plot(Cumulative_Totale_network_delay)\n",
    "\n",
    "# Dont freak out the 2 delays are not the same because the node is not covering all the junction\n",
    "\n",
    "\"\"\"\n",
    "Because the cars never leave the nodes the delay is not computed correctly (when the agent doesn't work) \n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(4)\n",
    "plt.plot(Single_Cross_Triple4_MultiDQN_Agents.Agents[0].loss)\n",
    "\n",
    "plt.figure(5)\n",
    "plt.plot(Single_Cross_Triple4_MultiDQN_Agents.Agents[0].reward_storage)\n",
    "print(Single_Cross_Triple4_MultiDQN_Agents.Agents[0].reward_storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Triple4_MultiDQN_Agents.demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Single_Cross_Triple 8 actions AC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_name  = 'Single_Cross_Triple'\n",
    "vissim_working_directory =  'C:\\\\Users\\\\Rzhang\\\\Desktop\\\\MLforFlowOptimisationOrigine\\\\Vissim\\\\'\n",
    "sim_length = 3601\n",
    "\n",
    "agent_type = \"AC\"\n",
    "Session_ID = \"Single_Cross_Triple8_actions_AC10\"\n",
    "\n",
    "# all controller actions\n",
    "Single_Cross_Triple_dictionary8 =\\\n",
    "{\\\n",
    "    # Controller Number 0 \n",
    "   'junctions' : {0 : {'default_actions' :  {    0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    "         \n",
    "         'all_actions' :        {            0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    " \n",
    "         'link' : [1, 3, 5, 7],\n",
    "         'lane' : ['1-1', '1-2', '1-3', '3-1', '3-2', '3-3', '5-1', '5-2', '5-3', '7-1', '7-2', '7-3'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'agent_type' : agent_type,\n",
    "         'green_time' : 6,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [13],\n",
    "         'state_type' : 'QueuesSig',\n",
    "         'reward_type' : 'Queues' ,\n",
    "         'queues_counter_ID' : [1,2,3,4,5,6,7,8,9,10,11,12]             \n",
    "         }\n",
    "    },\n",
    "   'demand' : { 'default' : [400, 400, 400, 400],\n",
    "             \n",
    "             0 : [300,300,300,300],\n",
    "             1 : [600,600,600,600],\n",
    "             2 : [1350,750,1350,750],\n",
    "             3 : [1500,750,1500,750],\n",
    "             4 : [1050,750,1050,750],\n",
    "             5 : [750,1050,750,1050],\n",
    "             6 : [750,1500,750,1500],\n",
    "             7 : [750,1350,750,1350],\n",
    "             8 : [600,600,600,600],\n",
    "             9 : [300,300,300,300]\n",
    "            }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gamma = 0.95\n",
    "alpha = 0.000001\n",
    "\n",
    "\n",
    "value = 5\n",
    "entropy = 500\n",
    "n_step_size = 4\n",
    "state_size = [13]\n",
    "reduce_entropy_every = 100\n",
    "Random_Seed = 100\n",
    "\n",
    "\n",
    "\n",
    "# for the monitoring\n",
    "horizon = 50\n",
    "n_sample = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Triple8_MultiAC_Agents = MasterAC_Agent(model_name, vissim_working_directory, sim_length, Single_Cross_Triple_dictionary8,\\\n",
    "                n_step_size, gamma, alpha, entropy, value, \\\n",
    "                Random_Seed = Random_Seed, timesteps_per_second = 1, Session_ID = Session_ID, verbose = True, \\\n",
    "                 horizon = horizon, n_sample = n_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Triple8_MultiAC_Agents.train(400) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Triple8_MultiAC_Agents.save(401)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Triple8_MultiAC_Agents.load(50, best = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Episode_Queues, Cumulative_Episode_Delays, Cumulative_Totale_network_delay = Single_Cross_Triple8_MultiAC_Agents.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Triple8_MultiAC_Agents.demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Single_Cross_Triple 8 actions DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_name  = 'Single_Cross_Triple'\n",
    "#vissim_working_directory =  'C:\\\\Users\\\\Rzhang\\\\Desktop\\\\MLforFlowOptimisationOrigine\\\\Vissim\\\\'\n",
    "vissim_working_directory = 'C:\\\\Users\\\\acabrejasegea\\\\OneDrive - The Alan Turing Institute\\\\Desktop\\\\ATI\\\\0_TMF\\\\MLforFlowOptimisation\\\\Vissim\\\\'\n",
    "\n",
    "sim_length = 3601\n",
    "\n",
    "agent_type = \"DuelingDDQN\"\n",
    "Session_ID = \"Single_Cross_Triple8_actions_DuelingDDQN20c10\"\n",
    "\n",
    "# all controller actions\n",
    "Single_Cross_Triple_dictionary8 =\\\n",
    "{\\\n",
    "    # Controller Number 0 \n",
    "   'junctions' : {0 : {'default_actions' :  {    0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    "         \n",
    "         'all_actions' :        {            0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    " \n",
    "         'link' : [1, 3, 5, 7],\n",
    "         'lane' : ['1-1', '1-2', '1-3', '3-1', '3-2', '3-3', '5-1', '5-2', '5-3', '7-1', '7-2', '7-3'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'agent_type' : agent_type,\n",
    "         'green_time' : 6,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [13],\n",
    "         'state_type' : 'QueuesSig',\n",
    "         'reward_type' : 'Queues' ,\n",
    "         'queues_counter_ID' : [1,2,3,4,5,6,7,8,9,10,11,12]             \n",
    "         }\n",
    "    },\n",
    "   'demand' : { 'default' : [400, 400, 400, 400],\n",
    "             \n",
    "             0 : [300,300,300,300],\n",
    "             1 : [600,600,600,600],\n",
    "             2 : [1350,750,1350,750],\n",
    "             3 : [1500,750,1500,750],\n",
    "             4 : [1050,750,1050,750],\n",
    "             5 : [750,1050,750,1050],\n",
    "             6 : [750,1500,750,1500],\n",
    "             7 : [750,1350,750,1350],\n",
    "             8 : [600,600,600,600],\n",
    "             9 : [300,300,300,300]\n",
    "            }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## DQN Hyperaramenters\n",
    "episodes = 400 \n",
    "copy_weights_frequency = 20 # On a successfull run I copied the weight every 50\n",
    "\n",
    "PER_activated = True\n",
    "memory_size = 1000\n",
    "batch_size = 128\n",
    "\n",
    "gamma = 0.95\n",
    "alpha = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Exploration Schedule (\"linear\" or \"geometric\")\n",
    "exploration_schedule = \"geometric\"\n",
    "epsilon_start = 1\n",
    "epsilon_end   = 0.001\n",
    "\n",
    "Random_Seed = 100\n",
    "\n",
    "def choose_schedule(exploration_schedule, espilon_start, epsilon_end, episodes):\n",
    "    if exploration_schedule == \"linear\":\n",
    "        epsilon_decay = 1.2*(epsilon_end - epsilon_start)/(episodes-1)\n",
    "        epsilon_sequence = [1 + epsilon_decay * entry for entry in range(episodes+1)]\n",
    "        epsilon_sequence = [0 if entry < 0 else entry for entry in epsilon_sequence]\n",
    "    elif exploration_schedule == \"geometric\":\n",
    "        epsilon_decay = np.power(epsilon_end/epsilon_start, 1./(episodes-1)) # Geometric decay\n",
    "        epsilon_sequence = [epsilon_start * epsilon_decay ** entry for entry in range(episodes+1)]\n",
    "    elif exploration_schedule == \"entropy\":\n",
    "        pass\n",
    "    else:\n",
    "        print(\"ERROR: Unrecognized choice of exploration schedule.\")\n",
    "        \n",
    "    # Plotting exploration schedule\n",
    "    plt.figure(figsize=(8,4.5))\n",
    "    x_series = np.array(range(1,episodes+1))\n",
    "    y_series = epsilon_sequence[0:episodes]\n",
    "    plt.plot(x_series, y_series, '-b')\n",
    "    plt.xlabel('Episodes')\n",
    "    plt.ylabel('Ratio of random exploration')\n",
    "    plt.title('Exploration schedule')\n",
    "    plt.show()\n",
    "    return(epsilon_sequence)\n",
    "\n",
    "epsilon_sequence = choose_schedule(exploration_schedule, epsilon_start, epsilon_end, episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Triple8_MultiDQN_Agents = MasterDQN_Agent(model_name, vissim_working_directory, sim_length, Single_Cross_Triple_dictionary8,\\\n",
    "                gamma, alpha, agent_type, memory_size, PER_activated, batch_size, copy_weights_frequency, epsilon_sequence,\\\n",
    "                Random_Seed = Random_Seed, timesteps_per_second = 1, Session_ID = Session_ID, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Triple8_MultiDQN_Agents.prepopulate_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Triple8_MultiDQN_Agents.train(episodes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Triple8_MultiDQN_Agents.save(401)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Triple8_MultiDQN_Agents.load(400,best = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Episode_Queues, Cumulative_Episode_Delays,Cumulative_Episode_stop_Delays, Cumulative_Totale_network_delay,Cumulative_Totale_network_stop_delay  = Single_Cross_Triple8_MultiDQN_Agents.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "time = [t for t in range(len(Cumulative_Totale_network_stop_delay))]\n",
    "\n",
    "# Queues ovzer time for each junction\n",
    "for idx, queues in Episode_Queues.items():\n",
    "    queues = np.array(queues)\n",
    "    queues = queues.T\n",
    "    \n",
    "    plt.figure('1'+str(idx),figsize=(16, 9))\n",
    "    \n",
    "    Queuesdf = pd.DataFrame()\n",
    "    \n",
    "    Queuesdf['Time'] = time\n",
    "    Queues_legend = []\n",
    "    \n",
    "    for i, queue in enumerate(queues):\n",
    "        plt.plot(queue, label = \"Queue\"+str(i))\n",
    "        Queuesdf[str(i)] = queue\n",
    "        Queues_legend.append(\"Queue\"+str(i))\n",
    "        \n",
    "    plt.xlabel('Time [s]',fontsize=18)\n",
    "    plt.ylabel('Queue Length',fontsize=18)\n",
    "    plt.title('Junction {} Queue length'.format(idx),fontsize=18)\n",
    "    #plt.gca().legend(Queues_legend)\n",
    "    \n",
    "    Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Junction{}_Queues.png\".format(idx))               \n",
    "    plt.savefig(Path)\n",
    "    \n",
    "    csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Junction{}_Queues.csv\".format(idx))        \n",
    "   \n",
    "    Queuesdf.to_csv(csv_Path,index=False)\n",
    "    plt.legend()\n",
    "        \n",
    "        \n",
    "# Accumulated delay over time for each junction\n",
    "for idx, delay in Cumulative_Episode_Delays.items():\n",
    "    \n",
    "    plt.figure('2'+str(idx),figsize=(16, 9))\n",
    "    \n",
    "    delaydf = pd.DataFrame()   \n",
    "    delaydf['Time'] = time\n",
    "    delaydf['Junction {} delay'.format(idx)] = delay\n",
    "    \n",
    "    plt.plot(delay)\n",
    "    plt.xlabel('Time [s]',fontsize=18)\n",
    "    plt.ylabel('Accumulated Delay',fontsize=18)\n",
    "    plt.title('Junction {} Delay'.format(idx),fontsize=18)\n",
    "    plt.gca().legend('Junction accumulated delay')\n",
    "    \n",
    "    Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                            \"Junction{}_Cumulative_Delay.png\".format(idx))\n",
    "    csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Junction{}_Cumulative_Delay.csv\".format(idx))   \n",
    "    plt.savefig(Path)\n",
    "\n",
    "    delaydf.to_csv(csv_Path,index=False)\n",
    "    \n",
    "    \n",
    "# Accumulated stop delay over time for each junction\n",
    "for idx, stop_delay in Cumulative_Episode_stop_Delays.items():\n",
    "    \n",
    "    plt.figure('3'+str(idx),figsize=(16, 9))\n",
    "    \n",
    "    stop_delaydf = pd.DataFrame()   \n",
    "    stop_delaydf['Time'] = time\n",
    "    stop_delaydf['Junction {} stop delay'.format(idx)] = stop_delay\n",
    "\n",
    "    plt.plot(stop_delay)\n",
    "    plt.xlabel('Time [s]',fontsize=18)\n",
    "    plt.ylabel('Accumulated Stop Delay',fontsize=18)\n",
    "    plt.title('Junction {} Stop Delay'.format(idx),fontsize=18)\n",
    "    plt.gca().legend('Junction accumulated Stop delay')\n",
    "    \n",
    "    Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                            \"Junction{}_Cumulative_stop_Delay.png\".format(idx))\n",
    "    csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Junction{}_Cumulative_stop_Delay.csv\".format(idx))\n",
    "    plt.savefig(Path)\n",
    "    stop_delaydf.to_csv(csv_Path,index=False)\n",
    "    \n",
    "# Global Accumulated delay over time\n",
    "plt.figure('4',figsize=(16,9))\n",
    "\n",
    "\n",
    "Global_delaydf = pd.DataFrame()   \n",
    "Global_delaydf['Time'] = time\n",
    "Global_delaydf['Global accumulated Delay'] = Cumulative_Totale_network_delay\n",
    "\n",
    "plt.plot(Cumulative_Totale_network_delay)\n",
    "plt.xlabel('Time [s]',fontsize=18)\n",
    "plt.ylabel('Global accumulated Delay',fontsize=18)\n",
    "plt.title('Global accumulated Delay',fontsize=18)\n",
    "plt.gca().legend('Global accumulated delay')\n",
    "\n",
    "Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Total_Cumulative_Delay.png\")\n",
    "csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Total_Cumulative_Delay.csv\")\n",
    "plt.savefig(Path)\n",
    "Global_delaydf.to_csv(csv_Path,index=False)\n",
    "\n",
    "# Global Accumulated stop delay over time\n",
    "plt.figure('5'+str(idx),figsize=(16, 9))\n",
    "\n",
    "Global_stop_delaydf = pd.DataFrame()   \n",
    "Global_stop_delaydf['Time'] = time\n",
    "Global_stop_delaydf['Global accumulated stop Delay'] = Cumulative_Totale_network_stop_delay\n",
    "\n",
    "plt.plot(Cumulative_Totale_network_stop_delay)\n",
    "plt.xlabel('Time [s]',fontsize=18)\n",
    "plt.ylabel('Global accumulated stop Delay',fontsize=18)\n",
    "plt.title('Global accumulated stop Delay',fontsize=18)\n",
    "plt.gca().legend('Global accumulated stop Delay')\n",
    "\n",
    "Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Total_Cumulative_stop_Delay.png\")\n",
    "csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Total_Cumulative_stop_Delay.csv\")\n",
    "plt.savefig(Path)\n",
    "Global_stop_delaydf.to_csv(csv_Path,index=False)\n",
    "\n",
    "\n",
    "# For the agent training\n",
    "\n",
    "for idx , agent in Single_Cross_Triple8_MultiDQN_Agents.Agents.items():  \n",
    "    plt.figure('6'+str(idx),figsize=(16, 9))\n",
    "    \n",
    "    Loss_rewarddf = pd.DataFrame()   \n",
    "    \n",
    "    plt.plot(agent.loss)\n",
    "    plt.xlabel('Episode',fontsize=18)\n",
    "    plt.ylabel('Loss',fontsize=18)\n",
    "    plt.title('Agent{} Loss over training'.format(idx),fontsize=18)\n",
    "    plt.gca().legend('Agent Loss over training')\n",
    "    \n",
    "    Path  = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Agent{}_Loss.png\".format(idx)) \n",
    "    plt.savefig(Path)\n",
    "    \n",
    "    csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                           \"Agent{}_Loss_average_reward.csv\".format(idx)) \n",
    "    \n",
    "    \n",
    "    plt.figure('7'+str(idx),figsize=(16, 9))\n",
    "    plt.plot(agent.reward_storage)\n",
    "    plt.xlabel('Episode',fontsize=18)\n",
    "    plt.ylabel('Average reward',fontsize=18)\n",
    "    plt.title('Agent{} average reward over training'.format(idx),fontsize=18)\n",
    "    plt.gca().legend('Agent reward over training')\n",
    "    \n",
    "    Path  = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Agent{}_average_reward.png\".format(idx)) \n",
    "    plt.savefig(Path)\n",
    "    \n",
    "    \n",
    "    episode = [i for i in range(len(agent.reward_storage))]\n",
    "    \n",
    "    Loss_rewarddf['episode'] = episode \n",
    "    Loss_rewarddf['Agent{} loss'.format(idx)] = agent.loss\n",
    "    Loss_rewarddf['Agent{} Average_Reward'.format(idx)] = agent.reward_storage\n",
    "    \n",
    "    Loss_rewarddf.to_csv(csv_Path,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Single_Cross_Triple8_MultiDQN_Agents.demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Five intersection DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_name  = 'Five_intersection'\n",
    "#vissim_working_directory =  'C:\\\\Users\\\\Rzhang\\\\Desktop\\\\MLforFlowOptimisationOrigine\\\\Vissim\\\\'\n",
    "vissim_working_directory = 'C:\\\\Users\\\\acabrejasegea\\\\OneDrive - The Alan Turing Institute\\\\Desktop\\\\ATI\\\\0_TMF\\\\MLforFlowOptimisation\\\\Vissim\\\\'\n",
    "\n",
    "sim_length = 3601\n",
    "\n",
    "agent_type = \"DuelingDDQN\"\n",
    "Session_ID = \"Five5transfert\"\n",
    "\n",
    "# all controller actions\n",
    "Five_intersection_dictionary =\\\n",
    "{\\\n",
    "    # Controller Number 0 \n",
    "   'junctions' : {0 : {'default_actions' :  {    0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    "         \n",
    "         'all_actions' :        {            0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    " \n",
    "         'link' : [],\n",
    "         'lane' : ['11-1', '11-2', '11-3', '12-1', '12-2', '12-3', '13-1', '13-2', '13-3', '14-1', '14-2', '14-3'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'agent_type' : agent_type,\n",
    "         'green_time' : 6,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [13],\n",
    "         'state_type' : 'QueuesSig',\n",
    "         'reward_type' : 'Queues',\n",
    "         'queues_counter_ID' : [1,2,3,4,5,6,7,8,9,10,11,12]\n",
    "         },\n",
    "                  1 : {'default_actions' :  {    0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    "         \n",
    "         'all_actions' :        {            0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    " \n",
    "         'link' : [],\n",
    "         'lane' : ['21-1', '21-2', '21-3', '22-1', '22-2', '22-3', '23-1', '23-2', '23-3', '24-1', '24-2', '24-3'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'agent_type' : agent_type,\n",
    "         'green_time' : 6,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [13],\n",
    "         'state_type' : 'QueuesSig',\n",
    "         'reward_type' : 'Queues' ,\n",
    "        'queues_counter_ID' : [13,14,15,16,17,18,19,20,21,22,23,24]\n",
    "         },\n",
    "                  2 : {'default_actions' :  {    0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    "         \n",
    "         'all_actions' :        {            0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    " \n",
    "         'link' : [],\n",
    "         'lane' : ['31-1', '31-2', '31-3', '32-1', '32-2', '32-3', '33-1', '33-2', '33-3', '34-1', '34-2', '34-3'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'agent_type' : agent_type,\n",
    "         'green_time' : 6,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [13],\n",
    "         'state_type' : 'QueuesSig',\n",
    "         'reward_type' : 'Queues' ,\n",
    "         'queues_counter_ID' : [25,26,27,28,29,30,31,32,33,34,35,36]\n",
    "         },\n",
    "                  3 : {'default_actions' :  {    0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    "         \n",
    "         'all_actions' :        {            0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    " \n",
    "         'link' : [],\n",
    "         'lane' : ['41-1', '41-2', '41-3', '42-1', '42-2', '42-3', '43-1', '43-2', '43-3', '44-1', '44-2', '44-3'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'agent_type' : agent_type,\n",
    "         'green_time' : 6,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [13],\n",
    "         'state_type' : 'QueuesSig',\n",
    "         'reward_type' : 'Queues' ,\n",
    "          'queues_counter_ID' : [37,38,39,40,41,42,43,44,45,46,47,48]\n",
    "         },\n",
    "                  4 : {'default_actions' :  {    0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    "         \n",
    "         'all_actions' :        {            0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    " \n",
    "         'link' : [],\n",
    "         'lane' : ['51-1', '51-2', '51-3', '52-1', '52-2', '52-3', '53-1', '53-2', '53-3', '54-1', '54-2', '54-3'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'agent_type' : agent_type,\n",
    "         'green_time' : 6,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [13],\n",
    "         'state_type' : 'QueuesSig',\n",
    "         'reward_type' : 'Queues' ,\n",
    "         'queues_counter_ID' : [49,50,51,52,53,54,55,56,57,58,59,60]\n",
    "         }\n",
    "    },\n",
    "   'demand' : { 'default' : [400,400,400,400,400,400,400,400,400,400,400,400],\n",
    "             \n",
    "             0 : [200,200,200,200,200,200,200,200,200,200,200,200],\n",
    "             1 : [400,400,400,400,400,400,400,400,400,400,400,400],\n",
    "             2 : [500,900,500,500,900,500,500,900,500,500,900,500],\n",
    "             3 : [500,1000,500,500,1000,500,500,1000,500,500,1000,500],\n",
    "             4 : [500,700,500,500,700,500,500,700,500,500,700,500],\n",
    "             5 : [500,700,500,500,700,500,500,700,500,500,700,500],\n",
    "             6 : [500,1000,500,500,1000,500,500,1000,500,500,1000,500],\n",
    "             7 : [500,900,500,500,900,500,500,900,500,500,900,500],\n",
    "             8 : [400,400,400,400,400,400,400,400,400,400,400,400],\n",
    "             9 : [200,200,200,200,200,200,200,200,200,200,200,200]\n",
    "            }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## DQN Hyperaramenters\n",
    "episodes = 400\n",
    "copy_weights_frequency = 20 # On a successfull run I copied the weight every 50\n",
    "\n",
    "PER_activated = True\n",
    "memory_size = 1000\n",
    "batch_size = 128\n",
    "\n",
    "gamma = 0.95\n",
    "alpha = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Exploration Schedule (\"linear\" or \"geometric\")\n",
    "exploration_schedule = \"geometric\"\n",
    "epsilon_start = 1\n",
    "epsilon_end   = 0.001\n",
    "\n",
    "Random_Seed = 100\n",
    "\n",
    "def choose_schedule(exploration_schedule, espilon_start, epsilon_end, episodes):\n",
    "    if exploration_schedule == \"linear\":\n",
    "        epsilon_decay = 1.2*(epsilon_end - epsilon_start)/(episodes-1)\n",
    "        epsilon_sequence = [1 + epsilon_decay * entry for entry in range(episodes+1)]\n",
    "        epsilon_sequence = [0 if entry < 0 else entry for entry in epsilon_sequence]\n",
    "    elif exploration_schedule == \"geometric\":\n",
    "        epsilon_decay = np.power(epsilon_end/epsilon_start, 1./(episodes-1)) # Geometric decay\n",
    "        epsilon_sequence = [epsilon_start * epsilon_decay ** entry for entry in range(episodes+1)]\n",
    "    elif exploration_schedule == \"entropy\":\n",
    "        pass\n",
    "    else:\n",
    "        print(\"ERROR: Unrecognized choice of exploration schedule.\")\n",
    "        \n",
    "    # Plotting exploration schedule\n",
    "    plt.figure(figsize=(8,4.5))\n",
    "    x_series = np.array(range(1,episodes+1))\n",
    "    y_series = epsilon_sequence[0:episodes]\n",
    "    plt.plot(x_series, y_series, '-b')\n",
    "    plt.xlabel('Episodes')\n",
    "    plt.ylabel('Ratio of random exploration')\n",
    "    plt.title('Exploration schedule')\n",
    "    plt.show()\n",
    "    return(epsilon_sequence)\n",
    "\n",
    "epsilon_sequence = choose_schedule(exploration_schedule, epsilon_start, epsilon_end, episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Five_intersection_MultiDQN_Agents = MasterDQN_Agent(model_name, vissim_working_directory, sim_length, Five_intersection_dictionary,\\\n",
    "                gamma, alpha, agent_type, memory_size, PER_activated, batch_size, copy_weights_frequency, epsilon_sequence,\\\n",
    "                Random_Seed = Random_Seed, timesteps_per_second = 1, Session_ID = Session_ID, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Five_intersection_MultiDQN_Agents.prepopulate_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Five_intersection_MultiDQN_Agents.train(episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Five_intersection_MultiDQN_Agents.save(401)\n",
    "Five_intersection_MultiDQN_Agents.load(400,best = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Five_intersection_MultiDQN_Agents.Agents[0].load_agent(vissim_working_directory, 'Single_Cross_Triple', 'Single_Cross_Triple8_actions',400 , best = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Episode_Queues, Cumulative_Episode_Delays,Cumulative_Episode_stop_Delays, Cumulative_Totale_network_delay,Cumulative_Totale_network_stop_delay = Five_intersection_MultiDQN_Agents.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "time = [t for t in range(len(Cumulative_Totale_network_stop_delay))]\n",
    "\n",
    "\n",
    "# Queues ovzer time for each junction\n",
    "for idx, queues in Episode_Queues.items():\n",
    "    queues = np.array(queues)\n",
    "    queues = queues.T\n",
    "    \n",
    "    plt.figure('1'+str(idx),figsize=(16, 9))\n",
    "    \n",
    "    Queuesdf = pd.DataFrame()\n",
    "    \n",
    "    Queuesdf['Time'] = time\n",
    "    \n",
    "    for i, queue in enumerate(queues):\n",
    "        plt.plot(queue)\n",
    "        Queuesdf[str(i)] = queue\n",
    "        \n",
    "    plt.xlabel('Time [s]')\n",
    "    plt.ylabel('Queue Length')\n",
    "    plt.title('Junction {} Queue length'.format(idx))\n",
    "    plt.gca().legend(('West Queue','South Queue', 'East Queue', 'North Queue'))\n",
    "    \n",
    "    Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Junction{}_Queues.png\".format(idx))               \n",
    "    plt.savefig(Path)\n",
    "    \n",
    "    csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Junction{}_Queues.csv\".format(idx))        \n",
    "   \n",
    "    Queuesdf.to_csv(csv_Path,index=False)\n",
    "        \n",
    "        \n",
    "# Accumulated delay over time for each junction\n",
    "for idx, delay in Cumulative_Episode_Delays.items():\n",
    "    \n",
    "    plt.figure('2'+str(idx),figsize=(16, 9))\n",
    "    \n",
    "    delaydf = pd.DataFrame()   \n",
    "    delaydf['Time'] = time\n",
    "    delaydf['Junction {} delay'.format(idx)] = delay\n",
    "    \n",
    "    plt.plot(delay)\n",
    "    plt.xlabel('Time [s]')\n",
    "    plt.ylabel('Accumulated Delay')\n",
    "    plt.title('Junction {} Delay'.format(idx))\n",
    "    plt.gca().legend('Junction accumulated delay')\n",
    "    \n",
    "    Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                            \"Junction{}_Cumulative_Delay.png\".format(idx))\n",
    "    csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Junction{}_Cumulative_Delay.csv\".format(idx))   \n",
    "    plt.savefig(Path)\n",
    "\n",
    "    delaydf.to_csv(csv_Path,index=False)\n",
    "    \n",
    "    \n",
    "# Accumulated stop delay over time for each junction\n",
    "for idx, stop_delay in Cumulative_Episode_stop_Delays.items():\n",
    "    \n",
    "    plt.figure('3'+str(idx),figsize=(16, 9))\n",
    "    \n",
    "    stop_delaydf = pd.DataFrame()   \n",
    "    stop_delaydf['Time'] = time\n",
    "    stop_delaydf['Junction {} stop delay'.format(idx)] = stop_delay\n",
    "\n",
    "    plt.plot(stop_delay)\n",
    "    plt.xlabel('Time [s]')\n",
    "    plt.ylabel('Accumulated Stop Delay')\n",
    "    plt.title('Junction {} Stop Delay'.format(idx))\n",
    "    plt.gca().legend('Junction accumulated Stop delay')\n",
    "    \n",
    "    Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                            \"Junction{}_Cumulative_stop_Delay.png\".format(idx))\n",
    "    csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Junction{}_Cumulative_stop_Delay.csv\".format(idx))\n",
    "    plt.savefig(Path)\n",
    "    stop_delaydf.to_csv(csv_Path,index=False)\n",
    "    \n",
    "# Global Accumulated delay over time\n",
    "plt.figure('4',figsize=(16,9))\n",
    "\n",
    "\n",
    "Global_delaydf = pd.DataFrame()   \n",
    "Global_delaydf['Time'] = time\n",
    "Global_delaydf['Global accumulated Delay'] = Cumulative_Totale_network_delay\n",
    "\n",
    "plt.plot(Cumulative_Totale_network_delay)\n",
    "plt.xlabel('Time [s]')\n",
    "plt.ylabel('Global accumulated Delay')\n",
    "plt.title('Global accumulated Delay')\n",
    "plt.gca().legend('Global accumulated delay')\n",
    "\n",
    "Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Total_Cumulative_Delay.png\")\n",
    "csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Total_Cumulative_Delay.csv\")\n",
    "plt.savefig(Path)\n",
    "Global_delaydf.to_csv(csv_Path,index=False)\n",
    "\n",
    "# Global Accumulated stop delay over time\n",
    "plt.figure('5'+str(idx),figsize=(16, 9))\n",
    "\n",
    "Global_stop_delaydf = pd.DataFrame()   \n",
    "Global_stop_delaydf['Time'] = time\n",
    "Global_stop_delaydf['Global accumulated stop Delay'] = Cumulative_Totale_network_stop_delay\n",
    "\n",
    "plt.plot(Cumulative_Totale_network_stop_delay)\n",
    "plt.xlabel('Time [s]')\n",
    "plt.ylabel('Global accumulated stop Delay')\n",
    "plt.title('Global accumulated stop Delay')\n",
    "plt.gca().legend('Global accumulated stop Delay')\n",
    "\n",
    "Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Total_Cumulative_stop_Delay.png\")\n",
    "csv_Path = os.path.join(vissim_working_directory, model_name, \"Agents_Results\", Session_ID,\\\n",
    "                        \"Total_Cumulative_stop_Delay.csv\")\n",
    "plt.savefig(Path)\n",
    "Global_stop_delaydf.to_csv(csv_Path,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Five_intersection_MultiDQN_Agents.Agents[2] = Five_intersection_MultiDQN_Agents.Agents[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Five_intersection_MultiDQN_Agents.demo()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
