{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device: /device:GPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "## VISSIM Modules\n",
    "import win32com.client as com\n",
    "import os\n",
    "\n",
    "## RL Modules\n",
    "import tensorflow as tf\n",
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"ERROR: GPU DEVICE NOT FOUND.\")\n",
    "\n",
    "from keras.models import load_model\n",
    "    \n",
    "## Data Management Modules\n",
    "import pickle\n",
    "\n",
    "## User Defined Modules\n",
    "import Simulator_Functions as SF\n",
    "from RLAgents import DQNAgent\n",
    "from NParser import NetworkParser\n",
    "from COMServer import COMServerDispatch, COMServerReload\n",
    "from TupleToList import toList\n",
    "from Utilities import log_progress, pltlive\n",
    "## Other Modules\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RL Hyperparamenters\n",
    "# Number of simulations, save every \"n\" episodes and copy weights with frequency \"f\"\n",
    "episodes = 50\n",
    "partial_save_at = 100\n",
    "copy_weights_frequency = 5\n",
    "\n",
    "# Timesteps per simulation (1 timestep = 0.1 sec), length for random population is a multiple of episode\n",
    "timesteps_per_second = 1\n",
    "seconds_per_green = 6\n",
    "seconds_per_yellow = 3\n",
    "simulation_length = 3600*1 + 1\n",
    "memory_population_length = (simulation_length-1)*200+1\n",
    "\n",
    "## State-Action Parameters\n",
    "action_type = \"phases\"        # options are \"phases\" and \"programs\"\n",
    "state_size = 4\n",
    "action_size = 2\n",
    "\n",
    "# Hyperparameters\n",
    "PER_activated = True\n",
    "batch_size = 256\n",
    "memory_size = 10000\n",
    "alpha   = 0.01\n",
    "gamma   = 0.95\n",
    "\n",
    "# Exploration Schedule (\"linear\" or \"geometric\")\n",
    "exploration_schedule = \"geometric\"\n",
    "epsilon_start = 1\n",
    "epsilon_end   = 0.001\n",
    "if exploration_schedule == \"linear\":\n",
    "    epsilon_decay = 1.2*(epsilon_end - epsilon_start)/(episodes-1)\n",
    "    epsilon_sequence = [1 + epsilon_decay * entry for entry in range(episodes+1)]\n",
    "    epsilon_sequence = [0 if entry < 0 else entry for entry in epsilon_sequence]\n",
    "elif exploration_schedule == \"geometric\":\n",
    "    epsilon_decay = np.power(epsilon_end/epsilon_start, 1./(episodes-1)) # Geometric decay\n",
    "    epsilon_sequence = [1 * epsilon_decay ** entry for entry in range(episodes+1)]\n",
    "else:\n",
    "    print(\"ERROR: Unrecognized choice of exploration schedule.\")\n",
    "\n",
    "# Demand Schedule (times in seconds, demand in cars/hour as PPP)\n",
    "demand_change_timesteps = 450\n",
    "demand = {\"h\":800, 'm':400, 'l':200}\n",
    "demand_list = [[demand['l'], demand['l']], [demand['m'], demand['l']],\\\n",
    "              [demand['h'], demand['l']], [demand['h'], demand['m']],\\\n",
    "              [demand['h'], demand['h']], [demand['m'], demand['h']],\n",
    "              [demand['l'], demand['h']], [demand['l'], demand['m']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Operation mode (selects functionalities)\n",
    "mode = \"training\"\n",
    "# \"populate\" = population of memory, generation of initial memory file\n",
    "# \"training\" = training agents, maximum speed, frozen UI, mid amount of messages\n",
    "# \"debug\"    = trains for 1 episode, minimum speed, working UI, all messages\n",
    "# \"demo\"     = loads pretrained agent, minimum speed, working UI\n",
    "# \"test\"     = executes evaluation, maximum speed\n",
    "\n",
    "## Network Model Parameters\n",
    "\n",
    "model_name  = 'Single_Cross_Straight'\n",
    "vissim_working_directory = 'C:\\\\Users\\\\acabrejasegea\\\\OneDrive - The Alan Turing Institute\\\\Desktop\\\\ATI\\\\0_TMF\\\\MLforFlowOptimisation\\\\Vissim\\\\'\n",
    "agent_type = 'DQN' # DQN, DuelingDQN, DDQN, DuelingDDQN\n",
    "reward_type = 'QueuesDifference'  \n",
    "state_type  = 'Queues'    # 'Queues', 'Delays', 'QueueDifference'\n",
    "Random_Seed = 42\n",
    "\n",
    "## Use of additional files?\n",
    "flag_read_additionally  = False\n",
    "SaveResultsAgent = True\n",
    "# Random demand\n",
    "Random_Demand = False\n",
    "\n",
    "# Session ID\n",
    "Session_ID = 'Ep_'+str(episodes)+'_A_'+agent_type+\"_Act_\"+action_type+\"_Rew_\"+reward_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x324 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting exploration schedule\n",
    "plt.figure(figsize=(8,4.5))\n",
    "x_series = np.array(range(1,episodes+1))\n",
    "y_series = epsilon_sequence[0:episodes]\n",
    "plt.plot(x_series, y_series, '-b')\n",
    "plt.xlabel('Episodes')\n",
    "plt.ylabel('Ratio of random exploration')\n",
    "plt.title('Exploration schedule')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Initialize storage\n",
    "    reward_storage = []\n",
    "    best_agent_weights = []\n",
    "    best_agent_memory = []\n",
    "    reward_plot = np.zeros([episodes,])\n",
    "    loss_plot = np.zeros([episodes,])\n",
    "\n",
    "    # Initialize simulation\n",
    "    Vissim, Simulation, Network, cache_flag = COMServerDispatch(model_name, vissim_working_directory,\\\n",
    "                                                                memory_population_length, timesteps_per_second,\\\n",
    "                                                                delete_results = True, verbose = True)\n",
    "        \n",
    "    # Setting Random Seed\n",
    "    Vissim.Simulation.SetAttValue('RandSeed', Random_Seed)\n",
    "    print ('Random seed set in simulator. Random Seed = '+str(Random_Seed))\n",
    "\n",
    "    # Deploy Network Parser (crawl network)\n",
    "    npa = NetworkParser(Vissim)\n",
    "    print('NetworkParser has succesfully crawled the model network.')\n",
    "    \n",
    "    # Initialize agents\n",
    "    if agent_type in ['DQN', 'DuelingDQN', 'DDQN', 'DuelingDDQN'] :\n",
    "        Agents = [DQNAgent(state_size, action_size, ID, state_type, npa, memory_size,\\\n",
    "                           gamma, epsilon_sequence[0], alpha, copy_weights_frequency, Vissim, PER_activated,\\\n",
    "                           DoubleDQN = True if agent_type == \"DDQN\" or \"DuelingDDQN\" else False,\\\n",
    "                           Dueling = False if agent_type == \"DQN\" or \"DDQN\" else True) for ID in npa.signal_controllers_ids] \n",
    "        agents_deployed = True\n",
    "    else:\n",
    "        print(\"Incorrect Agent Class selected. Deployment could not be completed.\")\n",
    "        quit()\n",
    "    if agents_deployed:\n",
    "        print(\"Deployed {} agent(s) of the Class {}.\".format(len(Agents), agent_type))\n",
    "    \n",
    "    ## EXECUTION OF A DEMONSTRATION RUN (slow, choice of best available agent)\n",
    "    if mode == \"demo\":\n",
    "        timesteps_per_second = 10\n",
    "        Vissim.Simulation.SetAttValue('SimRes', timesteps_per_second)\n",
    "        Agents = SF.load_agents(vissim_working_directory, model_name, Agents, Session_ID, best = True)\n",
    "        for agent in Agents:\n",
    "            agent.epsilon = 0\n",
    "        SF.run_simulation_episode(Agents, Vissim, state_type, reward_type, state_size, memory_population_length,\\\n",
    "                                  timesteps_per_second, seconds_per_green, seconds_per_yellow,\\\n",
    "                                  demand_list, demand_change_timesteps, mode, PER_activated)\n",
    "        Vissim = None\n",
    "    \n",
    "    ## EXECUTION IN DEBUGGING MODE (slow, extra messages)\n",
    "    elif mode == \"debug\":\n",
    "        timesteps_per_second = 10\n",
    "        Vissim.Simulation.SetAttValue('SimRes', timesteps_per_second)\n",
    "        SF.run_simulation_episode(Agents, Vissim, state_type, reward_type, state_size, memory_population_length,\\\n",
    "                                  timesteps_per_second, seconds_per_green, seconds_per_yellow,\\\n",
    "                                  demand_list, demand_change_timesteps, mode, PER_activated)\n",
    "        Vissim = None\n",
    "        \n",
    "    ## EXECUTION OF MEMORY POPULATION and creation of memory files\n",
    "    elif mode == \"populate\":\n",
    "        SF.Set_Quickmode(Vissim, timesteps_per_second)\n",
    "        if PER_activated:\n",
    "            memory, Agents, runflag = SF.prepopulate_memory(Agents, Vissim, state_type, reward_type, state_size, memory_size,\\\n",
    "                                                                vissim_working_directory, model_name, Session_ID,\\\n",
    "                                                                seconds_per_green, seconds_per_green, timesteps_per_second,\\\n",
    "                                                                demand_list, demand_change_timesteps, PER_activated)\n",
    "            print(\"PER memory prepopulated with {} entries\".format(memory_size))\n",
    "        Vissim = None\n",
    "        \n",
    "    ## EXECUTION OF TEST MODE (fast, best agents, more metrics out)    \n",
    "    elif mode == \"test\":\n",
    "        pass\n",
    "    \n",
    "    ## EXECUTION OF THE NORMAL TRAINING LOOP\n",
    "    elif mode == \"training\":\n",
    "        # Load previous memory if available, else create it\n",
    "        SF.Set_Quickmode(Vissim, timesteps_per_second)\n",
    "        memory, Agents, runflag = SF.prepopulate_memory(Agents, Vissim, state_type, reward_type, state_size, memory_size,\\\n",
    "                                                        vissim_working_directory, model_name, Session_ID,\\\n",
    "                                                        seconds_per_green, seconds_per_green, timesteps_per_second,\\\n",
    "                                                        demand_list, demand_change_timesteps, PER_activated)\n",
    "        print('Memory pre-populated. Starting Training.\\n')\n",
    "        \n",
    "        # Iterations of the simulation\n",
    "        for episode in log_progress(range(episodes), every=1):\n",
    "        \n",
    "            # Reload map if it has already been run (previous episode or prepopulation)\n",
    "            if episode !=0 or runflag == True:\n",
    "                Simulation, Network = COMServerReload(Vissim, model_name, vissim_working_directory,\\\n",
    "                                                      simulation_length, timesteps_per_second, delete_results = True)\n",
    "\n",
    "                # Run Network Parser and ensure agents are linked to their intersections\n",
    "                #npa.update(Vissim) \n",
    "                npa = NetworkParser(Vissim)\n",
    "                for index, agent in enumerate(Agents):\n",
    "                    #agent.update_IDS(npa.signal_controllers_ids[index], npa)\n",
    "                    agent.update_IDS(agent.signal_id, npa)\n",
    "                    agent.episode_reward = []\n",
    "\n",
    "            # Change the random seed\n",
    "            Random_Seed += 1\n",
    "            Vissim.Simulation.SetAttValue('RandSeed', Random_Seed)\n",
    "                    \n",
    "            # Run Episode at maximum speed\n",
    "            SF.Set_Quickmode(Vissim, timesteps_per_second)\n",
    "            SF.run_simulation_episode(Agents, Vissim, state_type, reward_type, state_size, simulation_length, timesteps_per_second,\\\n",
    "                                      seconds_per_green, seconds_per_yellow, demand_list, demand_change_timesteps, mode,\\\n",
    "                                      PER_activated)\n",
    "        \n",
    "            # Calculate episode average reward\n",
    "            reward_storage, average_reward = SF.average_reward(reward_storage, Agents, episode, episodes)\n",
    "            best_agent_weights, best_agent_memory = SF.best_agent(reward_storage, average_reward,\\\n",
    "                                                                  best_agent_weights, best_agent_memory,\\\n",
    "                                                                  vissim_working_directory, model_name, Agents, Session_ID)\n",
    "        \n",
    "            # Train agent with experience of episode and copy weights when necessary\n",
    "            # Update exploration rate\n",
    "            for agent in Agents:\n",
    "                agent.learn_batch(batch_size, episode)\n",
    "                agent.epsilon = epsilon_sequence[episode+1]\n",
    "            \n",
    "            # Security save for long trainings\n",
    "            if SaveResultsAgent:\n",
    "                if (episode+1)%partial_save_at == 0:\n",
    "                    SF.save_agents(vissim_working_directory, model_name, Agents, Session_ID, reward_storage)\n",
    "                    print('Saved Partial results at the end of episode {}.'.format(episode+1))\n",
    "\n",
    "        #Saving agents memory, weights and optimizer\n",
    "        if SaveResultsAgent:\n",
    "            SF.save_agents(vissim_working_directory, model_name, Agents, Session_ID, reward_storage)\n",
    "            print(\"Model, architecture, weights, optimizer, memory and training results succesfully saved.\\\n",
    "            Succesfully Terminated.\")\n",
    "    \n",
    "    else:\n",
    "        print(\"ERROR: Mode selected not recognized. TERMINATING.\")\n",
    "    # Close Vissim\n",
    "    Vissim = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plotting training progress\n",
    "plt.figure(figsize=(8,4.5))\n",
    "x_series = range(1,len(reward_storage)+1)\n",
    "fit = np.polyfit(x_series,reward_storage,1)\n",
    "fit_fn = np.poly1d(fit) \n",
    "plt.plot(x_series,reward_storage, '-b', x_series, fit_fn(x_series), '--r')\n",
    "plt.xlabel('Episodes')\n",
    "plt.ylabel('Average agent reward in episode')\n",
    "plt.title('Training evolution and trend')\n",
    "plt.gca().legend(('Episode Reward','Linear Trend'))\n",
    "plt.show()\n",
    "\n",
    "# Plotting training loss\n",
    "plt.figure(figsize=(8,4.5))\n",
    "x_series = range(1,len(Agents[0].loss)+1)\n",
    "plt.plot(x_series,Agents[0].loss, '-b')\n",
    "plt.xlabel('Training Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.gca().legend(('Loss'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working Directory set to: C:\\Users\\acabrejasegea\\OneDrive - The Alan Turing Institute\\Desktop\\ATI\\0_TMF\\MLforFlowOptimisation\\Vissim\\\n",
      "Generating Cache...\n",
      "Cache generated.\n",
      "\n",
      "****************************\n",
      "*   COM Server dispatched  *\n",
      "****************************\n",
      "\n",
      "Loading Model File: Single_Cross_Straight.inpx ...\n",
      "Load process successful\n",
      "Simulation length set to 720001 seconds.\n",
      "Results from Previous Simulations: Deleted. Fresh Start Available.\n",
      "Fetched and containerized Simulation Object\n",
      "Fetched and containerized Network Object \n",
      "\n",
      "*******************************************************\n",
      "*                                                     *\n",
      "*                 SETUP COMPLETE                      *\n",
      "*                                                     *\n",
      "*******************************************************\n",
      "\n",
      "Random seed set in simulator. Random Seed = 42\n",
      "NetworkParser has succesfully crawled the model network.\n",
      "WARNING:tensorflow:From C:\\Users\\acabrejasegea\\AppData\\Local\\Continuum\\anaconda3\\envs\\vissimgpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Deploying instance of Double Deep Q Learning Agent(s)\n",
      "Deployed 1 agent(s) of the Class DQN.\n",
      "Previous Experience Found: Loading into agent\n",
      "Memory pre-populated. Starting Training.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### SHORT PRETRAINED FROM MEMORY DEMO\n",
    "# Initialize storage\n",
    "reward_storage = []\n",
    "best_agent_weights = []\n",
    "best_agent_memory = []\n",
    "reward_plot = np.zeros([episodes,])\n",
    "loss_plot = np.zeros([episodes,])\n",
    "\n",
    "# Initialize simulation\n",
    "Vissim, Simulation, Network, cache_flag = COMServerDispatch(model_name, vissim_working_directory,\\\n",
    "                                                            memory_population_length, timesteps_per_second,\\\n",
    "                                                            delete_results = True, verbose = True)\n",
    "\n",
    "# Setting Random Seed\n",
    "Vissim.Simulation.SetAttValue('RandSeed', Random_Seed)\n",
    "print ('Random seed set in simulator. Random Seed = '+str(Random_Seed))\n",
    "\n",
    "# Deploy Network Parser (crawl network)\n",
    "npa = NetworkParser(Vissim)\n",
    "print('NetworkParser has succesfully crawled the model network.')\n",
    "\n",
    "# Initialize agents\n",
    "if agent_type in ['DQN', 'DuelingDQN', 'DDQN', 'DuelingDDQN'] :\n",
    "    Agents = [DQNAgent(state_size, action_size, ID, state_type, npa, memory_size,\\\n",
    "                       gamma, epsilon_sequence[0], alpha, copy_weights_frequency, Vissim, PER_activated,\\\n",
    "                       DoubleDQN = True if agent_type == \"DDQN\" or \"DuelingDDQN\" else False,\\\n",
    "                       Dueling = False if agent_type == \"DQN\" or \"DDQN\" else True) for ID in npa.signal_controllers_ids] \n",
    "    agents_deployed = True\n",
    "else:\n",
    "    print(\"Incorrect Agent Class selected. Deployment could not be completed.\")\n",
    "    quit()\n",
    "if agents_deployed:\n",
    "    print(\"Deployed {} agent(s) of the Class {}.\".format(len(Agents), agent_type))\n",
    "\n",
    "    memory, Agents, runflag = SF.prepopulate_memory(Agents, Vissim, state_type, reward_type, state_size, memory_size,\\\n",
    "                                                        vissim_working_directory, model_name, Session_ID,\\\n",
    "                                                        seconds_per_green, seconds_per_green, timesteps_per_second,\\\n",
    "                                                        demand_list, demand_change_timesteps, PER_activated)\n",
    "print('Memory pre-populated. Starting Training.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Prediction for [50,0,50,0] is: [[14.431094  9.798054]]\n",
      "Epoch: 1. Prediction for [50,0,50,0] is: [[14.471184  9.865913]]\n",
      "Epoch: 2. Prediction for [50,0,50,0] is: [[14.332758  9.798343]]\n",
      "Epoch: 3. Prediction for [50,0,50,0] is: [[14.140976  9.700982]]\n",
      "Epoch: 4. Prediction for [50,0,50,0] is: [[14.041296  9.673279]]\n",
      "Epoch: 5. Prediction for [50,0,50,0] is: [[14.043154  9.726464]]\n",
      "Epoch: 6. Prediction for [50,0,50,0] is: [[14.148184  9.842136]]\n",
      "Epoch: 7. Prediction for [50,0,50,0] is: [[14.155445  9.876852]]\n",
      "Epoch: 8. Prediction for [50,0,50,0] is: [[14.108507  9.814601]]\n",
      "Epoch: 9. Prediction for [50,0,50,0] is: [[13.924747  9.69348 ]]\n",
      "Epoch: 10. Prediction for [50,0,50,0] is: [[13.739946  9.551117]]\n",
      "Epoch: 11. Prediction for [50,0,50,0] is: [[13.362836  9.235298]]\n",
      "Epoch: 12. Prediction for [50,0,50,0] is: [[12.992366  8.931301]]\n",
      "Epoch: 13. Prediction for [50,0,50,0] is: [[12.757621  8.700622]]\n",
      "Epoch: 14. Prediction for [50,0,50,0] is: [[12.596164  8.519325]]\n",
      "Epoch: 15. Prediction for [50,0,50,0] is: [[12.521316   8.4081135]]\n",
      "Epoch: 16. Prediction for [50,0,50,0] is: [[12.434648  8.30567 ]]\n",
      "Epoch: 17. Prediction for [50,0,50,0] is: [[12.359641  8.262053]]\n",
      "Epoch: 18. Prediction for [50,0,50,0] is: [[12.269875  8.213848]]\n",
      "Epoch: 19. Prediction for [50,0,50,0] is: [[12.274202  8.270274]]\n",
      "Epoch: 20. Prediction for [50,0,50,0] is: [[12.264185  8.18384 ]]\n",
      "Epoch: 21. Prediction for [50,0,50,0] is: [[12.439781  8.267761]]\n",
      "Epoch: 22. Prediction for [50,0,50,0] is: [[12.479293  8.253209]]\n",
      "Epoch: 23. Prediction for [50,0,50,0] is: [[12.764646  8.384513]]\n",
      "Epoch: 24. Prediction for [50,0,50,0] is: [[13.045489  8.510122]]\n",
      "Epoch: 25. Prediction for [50,0,50,0] is: [[13.27967  8.60581]]\n",
      "Epoch: 26. Prediction for [50,0,50,0] is: [[13.4978695  8.646469 ]]\n",
      "Epoch: 27. Prediction for [50,0,50,0] is: [[13.7228365  8.681425 ]]\n",
      "Epoch: 28. Prediction for [50,0,50,0] is: [[13.8636055  8.654722 ]]\n",
      "Epoch: 29. Prediction for [50,0,50,0] is: [[13.852687  8.532869]]\n",
      "Epoch: 30. Prediction for [50,0,50,0] is: [[13.799386  8.383862]]\n",
      "Epoch: 31. Prediction for [50,0,50,0] is: [[13.640941  8.163237]]\n",
      "Epoch: 32. Prediction for [50,0,50,0] is: [[13.481959   7.9314003]]\n",
      "Epoch: 33. Prediction for [50,0,50,0] is: [[13.281111  7.68199 ]]\n",
      "Epoch: 34. Prediction for [50,0,50,0] is: [[13.10501   7.475176]]\n",
      "Epoch: 35. Prediction for [50,0,50,0] is: [[12.991126   7.3423653]]\n",
      "Epoch: 36. Prediction for [50,0,50,0] is: [[12.851633   7.1713223]]\n",
      "Epoch: 37. Prediction for [50,0,50,0] is: [[12.894265   7.1217675]]\n",
      "Epoch: 38. Prediction for [50,0,50,0] is: [[12.941147  7.093299]]\n",
      "Epoch: 39. Prediction for [50,0,50,0] is: [[12.962237  7.038208]]\n",
      "Epoch: 40. Prediction for [50,0,50,0] is: [[12.969269  7.006259]]\n",
      "Epoch: 41. Prediction for [50,0,50,0] is: [[12.998881  6.995366]]\n",
      "Epoch: 42. Prediction for [50,0,50,0] is: [[13.021114  6.971033]]\n",
      "Epoch: 43. Prediction for [50,0,50,0] is: [[13.09762    6.9738636]]\n",
      "Epoch: 44. Prediction for [50,0,50,0] is: [[13.225966  7.001678]]\n",
      "Epoch: 45. Prediction for [50,0,50,0] is: [[13.327021  7.012433]]\n",
      "Epoch: 46. Prediction for [50,0,50,0] is: [[13.363272   7.0551257]]\n",
      "Epoch: 47. Prediction for [50,0,50,0] is: [[13.408703  7.11551 ]]\n",
      "Epoch: 48. Prediction for [50,0,50,0] is: [[13.534797  7.217043]]\n",
      "Epoch: 49. Prediction for [50,0,50,0] is: [[14.230396  7.617393]]\n",
      "Epoch: 50. Prediction for [50,0,50,0] is: [[14.920274  8.028109]]\n",
      "Epoch: 51. Prediction for [50,0,50,0] is: [[15.46768   8.380726]]\n",
      "Epoch: 52. Prediction for [50,0,50,0] is: [[15.924678  8.677717]]\n",
      "Epoch: 53. Prediction for [50,0,50,0] is: [[16.615488  9.109266]]\n",
      "Epoch: 54. Prediction for [50,0,50,0] is: [[17.17572   9.483913]]\n",
      "Epoch: 55. Prediction for [50,0,50,0] is: [[17.663319  9.787613]]\n",
      "Epoch: 56. Prediction for [50,0,50,0] is: [[18.561176 10.290624]]\n",
      "Epoch: 57. Prediction for [50,0,50,0] is: [[19.447624 10.787224]]\n",
      "Epoch: 58. Prediction for [50,0,50,0] is: [[20.27225  11.261104]]\n",
      "Epoch: 59. Prediction for [50,0,50,0] is: [[21.096392  11.7218685]]\n",
      "Epoch: 60. Prediction for [50,0,50,0] is: [[22.439953 12.49263 ]]\n",
      "Epoch: 61. Prediction for [50,0,50,0] is: [[23.625082 13.046022]]\n",
      "Epoch: 62. Prediction for [50,0,50,0] is: [[24.61105  13.460795]]\n",
      "Epoch: 63. Prediction for [50,0,50,0] is: [[25.922964 14.143005]]\n",
      "Epoch: 64. Prediction for [50,0,50,0] is: [[27.026999 14.66059 ]]\n",
      "Epoch: 65. Prediction for [50,0,50,0] is: [[27.994572 15.127647]]\n",
      "Epoch: 66. Prediction for [50,0,50,0] is: [[29.183136 15.717012]]\n",
      "Epoch: 67. Prediction for [50,0,50,0] is: [[29.656485 16.012934]]\n",
      "Epoch: 68. Prediction for [50,0,50,0] is: [[29.669785 16.048471]]\n",
      "Epoch: 69. Prediction for [50,0,50,0] is: [[28.94864  15.643792]]\n",
      "Epoch: 70. Prediction for [50,0,50,0] is: [[27.856634 14.931706]]\n",
      "Epoch: 71. Prediction for [50,0,50,0] is: [[25.898733 13.817488]]\n",
      "Epoch: 72. Prediction for [50,0,50,0] is: [[24.370964 13.061116]]\n",
      "Epoch: 73. Prediction for [50,0,50,0] is: [[22.96361   12.3636265]]\n",
      "Epoch: 74. Prediction for [50,0,50,0] is: [[21.513111 11.637136]]\n",
      "Epoch: 75. Prediction for [50,0,50,0] is: [[20.219463 10.964479]]\n",
      "Epoch: 76. Prediction for [50,0,50,0] is: [[19.02911  10.357546]]\n",
      "Epoch: 77. Prediction for [50,0,50,0] is: [[18.007502  9.815039]]\n",
      "Epoch: 78. Prediction for [50,0,50,0] is: [[17.140003  9.279587]]\n",
      "Epoch: 79. Prediction for [50,0,50,0] is: [[16.357615  8.829386]]\n",
      "Epoch: 80. Prediction for [50,0,50,0] is: [[15.656494  8.410666]]\n",
      "Epoch: 81. Prediction for [50,0,50,0] is: [[14.973695  7.991307]]\n",
      "Epoch: 82. Prediction for [50,0,50,0] is: [[14.269979   7.6063547]]\n",
      "Epoch: 83. Prediction for [50,0,50,0] is: [[13.588822  7.250432]]\n",
      "Epoch: 84. Prediction for [50,0,50,0] is: [[13.0381155  6.98607  ]]\n",
      "Epoch: 85. Prediction for [50,0,50,0] is: [[12.559331   6.7616677]]\n",
      "Epoch: 86. Prediction for [50,0,50,0] is: [[12.170042  6.573635]]\n",
      "Epoch: 87. Prediction for [50,0,50,0] is: [[11.970363   6.5001965]]\n",
      "Epoch: 88. Prediction for [50,0,50,0] is: [[11.790122  6.426034]]\n",
      "Epoch: 89. Prediction for [50,0,50,0] is: [[11.724368  6.4172  ]]\n",
      "Epoch: 90. Prediction for [50,0,50,0] is: [[11.754107  6.490898]]\n",
      "Epoch: 91. Prediction for [50,0,50,0] is: [[11.777313   6.5686665]]\n",
      "Epoch: 92. Prediction for [50,0,50,0] is: [[11.796883  6.642318]]\n",
      "Epoch: 93. Prediction for [50,0,50,0] is: [[12.012118  6.854803]]\n",
      "Epoch: 94. Prediction for [50,0,50,0] is: [[12.209898  7.05064 ]]\n",
      "Epoch: 95. Prediction for [50,0,50,0] is: [[12.555883  7.280281]]\n",
      "Epoch: 96. Prediction for [50,0,50,0] is: [[12.844816   7.4687524]]\n",
      "Epoch: 97. Prediction for [50,0,50,0] is: [[13.028998   7.5665617]]\n",
      "Epoch: 98. Prediction for [50,0,50,0] is: [[13.138057  7.616825]]\n",
      "Epoch: 99. Prediction for [50,0,50,0] is: [[13.244936  7.690117]]\n",
      "Epoch: 100. Prediction for [50,0,50,0] is: [[13.2910795  7.743883 ]]\n",
      "Epoch: 101. Prediction for [50,0,50,0] is: [[13.590924  7.957919]]\n",
      "Epoch: 102. Prediction for [50,0,50,0] is: [[13.827218  8.120434]]\n",
      "Epoch: 103. Prediction for [50,0,50,0] is: [[13.945364  8.209834]]\n",
      "Epoch: 104. Prediction for [50,0,50,0] is: [[14.044458  8.275639]]\n",
      "Epoch: 105. Prediction for [50,0,50,0] is: [[14.1409025  8.340753 ]]\n",
      "Epoch: 106. Prediction for [50,0,50,0] is: [[14.176237  8.414933]]\n",
      "Epoch: 107. Prediction for [50,0,50,0] is: [[14.16059   8.443081]]\n",
      "Epoch: 108. Prediction for [50,0,50,0] is: [[14.031997  8.435017]]\n",
      "Epoch: 109. Prediction for [50,0,50,0] is: [[13.93659   8.398543]]\n",
      "Epoch: 110. Prediction for [50,0,50,0] is: [[13.735098  8.352737]]\n",
      "Epoch: 111. Prediction for [50,0,50,0] is: [[13.518199  8.310117]]\n",
      "Epoch: 112. Prediction for [50,0,50,0] is: [[13.2469635  8.216558 ]]\n",
      "Epoch: 113. Prediction for [50,0,50,0] is: [[13.012601  8.171017]]\n",
      "Epoch: 114. Prediction for [50,0,50,0] is: [[12.789992  8.124849]]\n",
      "Epoch: 115. Prediction for [50,0,50,0] is: [[12.5610695  8.007942 ]]\n",
      "Epoch: 116. Prediction for [50,0,50,0] is: [[12.230516   7.8215566]]\n",
      "Epoch: 117. Prediction for [50,0,50,0] is: [[11.891291   7.6130104]]\n",
      "Epoch: 118. Prediction for [50,0,50,0] is: [[11.669534  7.570512]]\n",
      "Epoch: 119. Prediction for [50,0,50,0] is: [[11.482629  7.514802]]\n",
      "Epoch: 120. Prediction for [50,0,50,0] is: [[11.333497   7.4994354]]\n",
      "Epoch: 121. Prediction for [50,0,50,0] is: [[11.175867   7.4636455]]\n",
      "Epoch: 122. Prediction for [50,0,50,0] is: [[11.083658   7.5060525]]\n",
      "Epoch: 123. Prediction for [50,0,50,0] is: [[10.977929  7.544548]]\n",
      "Epoch: 124. Prediction for [50,0,50,0] is: [[10.851097   7.6118565]]\n",
      "Epoch: 125. Prediction for [50,0,50,0] is: [[10.862845  7.737932]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 126. Prediction for [50,0,50,0] is: [[10.845944   7.9281635]]\n",
      "Epoch: 127. Prediction for [50,0,50,0] is: [[10.908813  8.226075]]\n",
      "Epoch: 128. Prediction for [50,0,50,0] is: [[-1.4142715 -3.471178 ]]\n",
      "Epoch: 129. Prediction for [50,0,50,0] is: [[-1.4120319 -3.4640565]]\n",
      "Epoch: 130. Prediction for [50,0,50,0] is: [[-1.4086534 -3.456588 ]]\n",
      "Epoch: 131. Prediction for [50,0,50,0] is: [[-1.402538  -3.4520535]]\n",
      "Epoch: 132. Prediction for [50,0,50,0] is: [[-1.3995937 -3.4477787]]\n",
      "Epoch: 133. Prediction for [50,0,50,0] is: [[-1.3972118 -3.4426205]]\n",
      "Epoch: 134. Prediction for [50,0,50,0] is: [[-1.3971336 -3.4376373]]\n",
      "Epoch: 135. Prediction for [50,0,50,0] is: [[-1.3983467 -3.4311342]]\n",
      "Epoch: 136. Prediction for [50,0,50,0] is: [[-1.3994536 -3.425546 ]]\n",
      "Epoch: 137. Prediction for [50,0,50,0] is: [[-1.3985642 -3.4200478]]\n",
      "Epoch: 138. Prediction for [50,0,50,0] is: [[-1.3994081 -3.416628 ]]\n",
      "Epoch: 139. Prediction for [50,0,50,0] is: [[-1.3993484 -3.4110463]]\n",
      "Epoch: 140. Prediction for [50,0,50,0] is: [[-1.3989347 -3.4041278]]\n",
      "Epoch: 141. Prediction for [50,0,50,0] is: [[-1.3982671 -3.3973238]]\n",
      "Epoch: 142. Prediction for [50,0,50,0] is: [[-1.3993918 -3.3905883]]\n",
      "Epoch: 143. Prediction for [50,0,50,0] is: [[-1.400181  -3.3850768]]\n",
      "Epoch: 144. Prediction for [50,0,50,0] is: [[-1.4003584 -3.379067 ]]\n",
      "Epoch: 145. Prediction for [50,0,50,0] is: [[-1.4015493 -3.3732715]]\n",
      "Epoch: 146. Prediction for [50,0,50,0] is: [[-1.4040015 -3.367948 ]]\n",
      "Epoch: 147. Prediction for [50,0,50,0] is: [[-1.4041041 -3.3663418]]\n",
      "Epoch: 148. Prediction for [50,0,50,0] is: [[-1.4033184 -3.3675196]]\n",
      "Epoch: 149. Prediction for [50,0,50,0] is: [[-1.4027721 -3.368171 ]]\n",
      "Epoch: 150. Prediction for [50,0,50,0] is: [[-1.4017969 -3.3690622]]\n",
      "Epoch: 151. Prediction for [50,0,50,0] is: [[-1.3976659 -3.369821 ]]\n",
      "Epoch: 152. Prediction for [50,0,50,0] is: [[-1.3953676 -3.370192 ]]\n",
      "Epoch: 153. Prediction for [50,0,50,0] is: [[-1.3920602 -3.3708768]]\n",
      "Epoch: 154. Prediction for [50,0,50,0] is: [[-1.3868865 -3.3720064]]\n",
      "Epoch: 155. Prediction for [50,0,50,0] is: [[-1.3820152 -3.372613 ]]\n",
      "Epoch: 156. Prediction for [50,0,50,0] is: [[-1.3760785 -3.3740256]]\n",
      "Epoch: 157. Prediction for [50,0,50,0] is: [[-1.3692406 -3.3743715]]\n",
      "Epoch: 158. Prediction for [50,0,50,0] is: [[-1.3641114 -3.3748462]]\n",
      "Epoch: 159. Prediction for [50,0,50,0] is: [[-1.3560843 -3.3752246]]\n",
      "Epoch: 160. Prediction for [50,0,50,0] is: [[-1.3487483 -3.3752725]]\n",
      "Epoch: 161. Prediction for [50,0,50,0] is: [[-1.3391585 -3.3747115]]\n",
      "Epoch: 162. Prediction for [50,0,50,0] is: [[-1.3306813 -3.3744724]]\n",
      "Epoch: 163. Prediction for [50,0,50,0] is: [[-1.3227851 -3.373576 ]]\n",
      "Epoch: 164. Prediction for [50,0,50,0] is: [[-1.3143893 -3.3720644]]\n",
      "Epoch: 165. Prediction for [50,0,50,0] is: [[-1.307886 -3.370506]]\n",
      "Epoch: 166. Prediction for [50,0,50,0] is: [[-1.3022842 -3.3713984]]\n",
      "Epoch: 167. Prediction for [50,0,50,0] is: [[-1.2983652 -3.3721313]]\n",
      "Epoch: 168. Prediction for [50,0,50,0] is: [[-1.2952958 -3.369985 ]]\n",
      "Epoch: 169. Prediction for [50,0,50,0] is: [[-1.2930343 -3.3675492]]\n",
      "Epoch: 170. Prediction for [50,0,50,0] is: [[-1.2897748 -3.365272 ]]\n",
      "Epoch: 171. Prediction for [50,0,50,0] is: [[-1.2849574 -3.3629923]]\n",
      "Epoch: 172. Prediction for [50,0,50,0] is: [[-1.2796646 -3.3594966]]\n",
      "Epoch: 173. Prediction for [50,0,50,0] is: [[-1.2747351 -3.3571134]]\n",
      "Epoch: 174. Prediction for [50,0,50,0] is: [[-1.2712522 -3.3549116]]\n",
      "Epoch: 175. Prediction for [50,0,50,0] is: [[-1.2682725 -3.3530076]]\n",
      "Epoch: 176. Prediction for [50,0,50,0] is: [[-1.2665029 -3.351749 ]]\n",
      "Epoch: 177. Prediction for [50,0,50,0] is: [[-1.2634356 -3.3509803]]\n",
      "Epoch: 178. Prediction for [50,0,50,0] is: [[-1.2610308 -3.3498611]]\n",
      "Epoch: 179. Prediction for [50,0,50,0] is: [[-1.2568823 -3.3472643]]\n",
      "Epoch: 180. Prediction for [50,0,50,0] is: [[-1.2524731 -3.3467245]]\n",
      "Epoch: 181. Prediction for [50,0,50,0] is: [[-1.247386  -3.3466964]]\n",
      "Epoch: 182. Prediction for [50,0,50,0] is: [[-1.2405516 -3.347432 ]]\n",
      "Epoch: 183. Prediction for [50,0,50,0] is: [[-1.232451 -3.347709]]\n",
      "Epoch: 184. Prediction for [50,0,50,0] is: [[-1.2245829 -3.347814 ]]\n",
      "Epoch: 185. Prediction for [50,0,50,0] is: [[-1.2180643 -3.348499 ]]\n",
      "Epoch: 186. Prediction for [50,0,50,0] is: [[-1.2116225 -3.3486848]]\n",
      "Epoch: 187. Prediction for [50,0,50,0] is: [[-1.2064297 -3.3475473]]\n",
      "Epoch: 188. Prediction for [50,0,50,0] is: [[-1.2010349 -3.346339 ]]\n",
      "Epoch: 189. Prediction for [50,0,50,0] is: [[-1.1940578 -3.3451595]]\n",
      "Epoch: 190. Prediction for [50,0,50,0] is: [[-1.1863079 -3.3442276]]\n",
      "Epoch: 191. Prediction for [50,0,50,0] is: [[-1.1782187 -3.341562 ]]\n",
      "Epoch: 192. Prediction for [50,0,50,0] is: [[-1.1696111 -3.3381917]]\n",
      "Epoch: 193. Prediction for [50,0,50,0] is: [[-1.1649544 -3.3359802]]\n",
      "Epoch: 194. Prediction for [50,0,50,0] is: [[-1.1621764 -3.3331394]]\n",
      "Epoch: 195. Prediction for [50,0,50,0] is: [[-1.1586105 -3.3318522]]\n",
      "Epoch: 196. Prediction for [50,0,50,0] is: [[-1.1555291 -3.3313806]]\n",
      "Epoch: 197. Prediction for [50,0,50,0] is: [[-1.150867  -3.3310173]]\n",
      "Epoch: 198. Prediction for [50,0,50,0] is: [[-1.146375  -3.3288045]]\n",
      "Epoch: 199. Prediction for [50,0,50,0] is: [[-1.1406971 -3.3274121]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(200):\n",
    "    Agents[0].learn_batch(32, 0)\n",
    "    print(\"Epoch: {}. Prediction for [50,0,50,0] is: {}\".format(i, Agents[0].model.predict(np.reshape([50,0,50,0], [1,4]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "com_error",
     "evalue": "(-2147352567, 'Exception occurred.', (0, 'VISSIM.Vissim.1100', 'AttValue failed: The simulation resolution can only be set at full simulation seconds.', None, 0, -2147352567), None)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mcom_error\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-16c5de5459b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## EXECUTION OF A DEMONSTRATION RUN (slow, choice of best available agent)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtimesteps_per_second\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mVissim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSimulation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSetAttValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'SimRes'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimesteps_per_second\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0magent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mAgents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\vissimgpu\\lib\\site-packages\\win32com\\client\\dynamic.py\u001b[0m in \u001b[0;36mSetAttValue\u001b[1;34m(self, Attribut, arg1)\u001b[0m\n",
      "\u001b[1;31mcom_error\u001b[0m: (-2147352567, 'Exception occurred.', (0, 'VISSIM.Vissim.1100', 'AttValue failed: The simulation resolution can only be set at full simulation seconds.', None, 0, -2147352567), None)"
     ]
    }
   ],
   "source": [
    "## EXECUTION OF A DEMONSTRATION RUN (slow, choice of best available agent)\n",
    "timesteps_per_second = 10\n",
    "Vissim.Simulation.SetAttValue('SimRes', timesteps_per_second)\n",
    "for agent in Agents:\n",
    "    agent.epsilon = 0\n",
    "SF.run_simulation_episode(Agents, Vissim, state_type, reward_type, state_size, memory_population_length,\\\n",
    "                          timesteps_per_second, seconds_per_green, seconds_per_yellow,\\\n",
    "                          demand_list, demand_change_timesteps, mode, PER_activated)\n",
    "Vissim = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Agents[0].model.predict(np.reshape([0,50,0,50], [1,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(Agents[0].reward)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "vissimgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
