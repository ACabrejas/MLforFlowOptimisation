{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modules that we need\n",
    "from Vissim_env_class import environment, Load_Vissim\n",
    "from MasterDQN_Agent import MasterDQN_Agent\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Libraries\n",
    "import numpy as np \n",
    "import pylab as plt\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fail\n",
      "fail\n",
      "success\n"
     ]
    }
   ],
   "source": [
    "vissim \\\n",
    "= \\\n",
    "Load_Vissim(\n",
    "Path_to_network = 'C:\\\\Users\\\\nwalton\\\\OneDrive - The Alan Turing Institute\\\\Documents\\\\MLforFlowOptimisation\\\\NSW_9_Cross_Experiment\\\\Single_Cross_TripleMOVA\\\\',\\\n",
    "inpx_Filename = 'Single_Cross_Triple.inpx',\\\n",
    "layx_Filename = 'Single_Cross_Triple.layx',\\\n",
    "attempts=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name  = 'Single_Cross_Triple'\n",
    "#vissim_working_directory =  'C:\\\\Users\\\\Rzhang\\\\Desktop\\\\MLforFlowOptimisationOrigine\\\\Vissim\\\\'\n",
    "vissim_working_directory='C:\\\\Users\\\\nwalton\\\\OneDrive - The Alan Turing Institute\\\\Documents\\\\MLforFlowOptimisation\\\\Vissim\\\\'\n",
    "\n",
    "sim_length = 3601\n",
    "\n",
    "agent_type = \"DuelingDDQN\"\n",
    "Session_ID = \"Single_Cross_Triple8_actions_DuelingDDQN20c10\"\n",
    "\n",
    "# all controller actions\n",
    "Single_Cross_Triple_dictionary8 =\\\n",
    "{\\\n",
    "    # Controller Number 0 \n",
    "   'junctions' : {0 : {'default_actions' :  {    0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    "         \n",
    "         'all_actions' :        {            0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    " \n",
    "         'link' : [1, 3, 5, 7],\n",
    "         'lane' : ['1-1', '1-2', '1-3', '3-1', '3-2', '3-3', '5-1', '5-2', '5-3', '7-1', '7-2', '7-3'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'agent_type' : agent_type,\n",
    "         'green_time' : 6,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [13],\n",
    "         'state_type' : 'QueuesSig',\n",
    "         'reward_type' : 'Queues' ,\n",
    "         'queues_counter_ID' : [1,2,3,4,5,6,7,8,9,10,11,12]             \n",
    "         }\n",
    "    },\n",
    "   'demand' : { 'default' : [400, 400, 400, 400],\n",
    "             \n",
    "             0 : [300,300,300,300],\n",
    "             1 : [600,600,600,600],\n",
    "             2 : [1350,750,1350,750],\n",
    "             3 : [1500,750,1500,750],\n",
    "             4 : [1050,750,1050,750],\n",
    "             5 : [750,1050,750,1050],\n",
    "             6 : [750,1500,750,1500],\n",
    "             7 : [750,1350,750,1350],\n",
    "             8 : [600,600,600,600],\n",
    "             9 : [300,300,300,300]\n",
    "            }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name  = 'Single_Cross_Triple'\n",
    "#vissim_working_directory =  'C:\\\\Users\\\\Rzhang\\\\Desktop\\\\MLforFlowOptimisationOrigine\\\\Vissim\\\\'\n",
    "vissim_working_directory='C:\\\\Users\\\\nwalton\\\\OneDrive - The Alan Turing Institute\\\\Documents\\\\MLforFlowOptimisation\\\\Vissim\\\\'\n",
    "\n",
    "sim_length = 3601\n",
    "\n",
    "agent_type = \"DuelingDDQN\"\n",
    "Session_ID = \"Single_Cross_Triple8_actions_DuelingDDQN20c10\"\n",
    "\n",
    "# all controller actions\n",
    "Single_Cross_Triple_dictionary8 =\\\n",
    "{\\\n",
    "    # Controller Number 0 \n",
    "   'junctions' : {0 : {'default_actions' :  {    0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    "         \n",
    "         'all_actions' :        {            0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    " \n",
    "         'link' : [1, 3, 5, 7],\n",
    "         'lane' : ['1-1', '1-2', '1-3', '3-1', '3-2', '3-3', '5-1', '5-2', '5-3', '7-1', '7-2', '7-3'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'agent_type' : agent_type,\n",
    "         'green_time' : 6,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [13],\n",
    "         'state_type' : 'QueuesSig',\n",
    "         'reward_type' : 'Queues' ,\n",
    "         'queues_counter_ID' : [1,2,3,4,5,6,7,8,9,10,11,12]             \n",
    "         }\n",
    "    },\n",
    "   'demand' : { 'default' : [400, 400, 400, 400],\n",
    "             \n",
    "             0 : [100,100,100,100],\n",
    "             1 : [200,200,200,200],\n",
    "             2 : [300,300,300,300],\n",
    "             3 : [400,400,400,400],\n",
    "             4 : [500,500,500,500],\n",
    "             5 : [600,600,600,600],\n",
    "             6 : [700,700,700,700],\n",
    "             7 : [800,800,800,800],\n",
    "             8 : [900,900,900,900],\n",
    "             9 : [1000,1000,1000,1000]\n",
    "            }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name  = 'Single_Cross_Triple'\n",
    "#vissim_working_directory =  'C:\\\\Users\\\\Rzhang\\\\Desktop\\\\MLforFlowOptimisationOrigine\\\\Vissim\\\\'\n",
    "vissim_working_directory='C:\\\\Users\\\\nwalton\\\\OneDrive - The Alan Turing Institute\\\\Documents\\\\MLforFlowOptimisation\\\\Vissim\\\\'\n",
    "\n",
    "sim_length = 3601\n",
    "\n",
    "agent_type = \"DuelingDDQN\"\n",
    "Session_ID = \"Single_Cross_Triple8_actions_DuelingDDQN20c10\"\n",
    "\n",
    "# all controller actions\n",
    "Single_Cross_Triple_dictionary8 =\\\n",
    "{\\\n",
    "    # Controller Number 0 \n",
    "   'junctions' : {0 : {'default_actions' :  {    0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    "         \n",
    "         'all_actions' :        {            0 : [1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "                                             1 : [0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "                                             2 : [0,0,0,0,0,0,1,1,1,0,0,0],\n",
    "                                             3 : [0,0,0,0,0,0,0,0,0,1,1,1],\n",
    "                                             4 : [1,0,0,0,0,0,1,0,0,0,0,0],\n",
    "                                             5 : [0,0,0,1,0,0,0,0,0,1,0,0],\n",
    "                                             6 : [0,1,1,0,0,0,0,1,1,0,0,0],\n",
    "                                             7 : [0,0,0,0,1,1,0,0,0,0,1,1]},\n",
    " \n",
    "         'link' : [1, 3, 5, 7],\n",
    "         'lane' : ['1-1', '1-2', '1-3', '3-1', '3-2', '3-3', '5-1', '5-2', '5-3', '7-1', '7-2', '7-3'],\n",
    "         \n",
    "         'controled_by_com' : True,\n",
    "         'agent_type' : agent_type,\n",
    "         'green_time' : 6,\n",
    "         'redamber_time' : 0,\n",
    "         'amber_time' : 3, \n",
    "         'red_time' : 0,\n",
    "         'state_size' : [13],\n",
    "         'state_type' : 'QueuesSig',\n",
    "         'reward_type' : 'Queues' ,\n",
    "         'queues_counter_ID' : [1,2,3,4,5,6,7,8,9,10,11,12]             \n",
    "         }\n",
    "    },\n",
    "   'demand' : { 'default' : [400, 400, 400, 400],\n",
    "             \n",
    "             0 : [400,400,400,400],\n",
    "             1 : [400,400,400,400],\n",
    "             2 : [400,400,400,400],\n",
    "             3 : [400,400,400,400],\n",
    "             4 : [400,400,400,400],\n",
    "             5 : [400,400,400,400],\n",
    "             6 : [400,400,400,400],\n",
    "             7 : [400,400,400,400],\n",
    "             8 : [400,400,400,400],\n",
    "             9 : [400,400,400,400],\n",
    "            }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes = 400 \n",
    "copy_weights_frequency = 20 # On a successfull run I copied the weight every 50\n",
    "\n",
    "PER_activated = False\n",
    "memory_size = 1000\n",
    "batch_size = 128\n",
    "\n",
    "gamma = 0.95\n",
    "alpha = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x324 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Exploration Schedule (\"linear\" or \"geometric\")\n",
    "exploration_schedule = \"geometric\"\n",
    "epsilon_start = 1\n",
    "epsilon_end   = 0.001\n",
    "\n",
    "Random_Seed = 1\n",
    "\n",
    "def choose_schedule(exploration_schedule, espilon_start, epsilon_end, episodes):\n",
    "    if exploration_schedule == \"linear\":\n",
    "        epsilon_decay = 1.2*(epsilon_end - epsilon_start)/(episodes-1)\n",
    "        epsilon_sequence = [1 + epsilon_decay * entry for entry in range(episodes+1)]\n",
    "        epsilon_sequence = [0 if entry < 0 else entry for entry in epsilon_sequence]\n",
    "    elif exploration_schedule == \"geometric\":\n",
    "        epsilon_decay = np.power(epsilon_end/epsilon_start, 1./(episodes-1)) # Geometric decay\n",
    "        epsilon_sequence = [epsilon_start * epsilon_decay ** entry for entry in range(episodes+1)]\n",
    "    elif exploration_schedule == \"entropy\":\n",
    "        pass\n",
    "    else:\n",
    "        print(\"ERROR: Unrecognized choice of exploration schedule.\")\n",
    "        \n",
    "    # Plotting exploration schedule\n",
    "    plt.figure(figsize=(8,4.5))\n",
    "    x_series = np.array(range(1,episodes+1))\n",
    "    y_series = epsilon_sequence[0:episodes]\n",
    "    plt.plot(x_series, y_series, '-b')\n",
    "    plt.xlabel('Episodes')\n",
    "    plt.ylabel('Ratio of random exploration')\n",
    "    plt.title('Exploration schedule')\n",
    "    plt.show()\n",
    "    return(epsilon_sequence)\n",
    "\n",
    "epsilon_sequence = choose_schedule(exploration_schedule, epsilon_start, epsilon_end, episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTERSECTION 0: SETTING UP AGENT\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 13)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 24)           336         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 24)           600         dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 24)           600         dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 24)           600         dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 1)            25          dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 8)            200         dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "policy (Lambda)                 (None, 8)            0           dense_17[0][0]                   \n",
      "                                                                 dense_15[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 2,361\n",
      "Trainable params: 2,361\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Deployed instance of Dueling Double Deep Q Learning Agent(s) at Intersection 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Single_Cross_Triple8_MultiDQN_Agents = MasterDQN_Agent(model_name, \n",
    "                                                       vissim_working_directory, \n",
    "                                                       sim_length, \n",
    "                                                       Single_Cross_Triple_dictionary8,\n",
    "                                                       'default_actions',\n",
    "                                                       gamma, alpha, agent_type, memory_size, PER_activated, batch_size, copy_weights_frequency, epsilon_sequence,\\\n",
    "                Random_Seed = Random_Seed, timesteps_per_second = 1, Session_ID = Session_ID, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Single_Cross_Triple8_MultiDQN_Agents.prepopulate_memory(vissim = vissim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vissim.Simulation.SetAttValue('UseMaxSimSpeed', True)\n",
    "vissim.Graphics.CurrentNetworkWindow.SetAttValue(\"QuickMode\", 1)\n",
    "vissim.Simulation.SetAttValue('SimRes', 1)\n",
    "vissim.SuspendUpdateGUI()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set in simulator. Random Seed = 1\n",
      "Deploying Network Parser...\n",
      "Successful Network Crawl: Identified SignalControllers, Links, Lanes and Vehicle Inputs.\n",
      "\n",
      "Setting Simulation mode to: train\n",
      "Starting Deployments of Signal Control Units...\n",
      "SCUs successfully deployed. Elapsed time 0.08 seconds.\n",
      "\n",
      "start\n",
      "Random Seed Set to 2\n",
      "Episode 1: Finished running.\n",
      "Agent 0, Average Reward: -1402.25\n",
      "Saving architecture, weights, optimizer state for best agent-0\n",
      "Epoch 1/1\n",
      " - 1s - loss: 70819.5859\n",
      "Reducing exploration for all agents to 0.9828\n",
      "\n",
      "Episode 2: Starting computation.\n",
      "Random Seed Set to 3\n",
      "Episode 2: Finished running.\n",
      "Agent 0, Average Reward: -1330.05\n",
      "Saving architecture, weights, optimizer state for best agent-0\n",
      "Epoch 1/1\n",
      " - 0s - loss: 91692.9453\n",
      "Reducing exploration for all agents to 0.966\n",
      "\n",
      "Episode 3: Starting computation.\n",
      "Random Seed Set to 4\n",
      "Episode 3: Finished running.\n",
      "Agent 0, Average Reward: -1576.44\n",
      "Epoch 1/1\n",
      " - 0s - loss: 114007.2891\n",
      "Reducing exploration for all agents to 0.9494\n",
      "\n",
      "Episode 4: Starting computation.\n",
      "Random Seed Set to 5\n",
      "Episode 4: Finished running.\n",
      "Agent 0, Average Reward: -1444.84\n",
      "Epoch 1/1\n",
      " - 0s - loss: 114722.3672\n",
      "Reducing exploration for all agents to 0.9331\n",
      "\n",
      "Episode 5: Starting computation.\n",
      "Random Seed Set to 6\n",
      "Episode 5: Finished running.\n",
      "Agent 0, Average Reward: -227.18\n",
      "Saving architecture, weights, optimizer state for best agent-0\n",
      "Epoch 1/1\n",
      " - 0s - loss: 119857.8047\n",
      "Reducing exploration for all agents to 0.9171\n",
      "\n",
      "Episode 6: Starting computation.\n",
      "Random Seed Set to 7\n",
      "Episode 6: Finished running.\n",
      "Agent 0, Average Reward: -1551.81\n",
      "Epoch 1/1\n",
      " - 0s - loss: 121169.4141\n",
      "Reducing exploration for all agents to 0.9013\n",
      "\n",
      "Episode 7: Starting computation.\n",
      "Random Seed Set to 8\n",
      "Episode 7: Finished running.\n",
      "Agent 0, Average Reward: -1513.27\n",
      "Epoch 1/1\n",
      " - 0s - loss: 102969.4141\n",
      "Reducing exploration for all agents to 0.8859\n",
      "\n",
      "Episode 8: Starting computation.\n",
      "Random Seed Set to 9\n",
      "Episode 8: Finished running.\n",
      "Agent 0, Average Reward: -885.21\n",
      "Epoch 1/1\n",
      " - 0s - loss: 88481.5391\n",
      "Reducing exploration for all agents to 0.8707\n",
      "\n",
      "Episode 9: Starting computation.\n",
      "Random Seed Set to 10\n",
      "Episode 9: Finished running.\n",
      "Agent 0, Average Reward: -1320.98\n",
      "Epoch 1/1\n",
      " - 0s - loss: 95309.6172\n",
      "Reducing exploration for all agents to 0.8557\n",
      "\n",
      "Episode 10: Starting computation.\n",
      "Random Seed Set to 11\n",
      "Episode 10: Finished running.\n",
      "Agent 0, Average Reward: -840.03\n",
      "Epoch 1/1\n",
      " - 0s - loss: 61395.3516\n",
      "Reducing exploration for all agents to 0.841\n",
      "\n",
      "Episode 11: Starting computation.\n",
      "Random Seed Set to 12\n",
      "Episode 11: Finished running.\n",
      "Agent 0, Average Reward: -1213.15\n",
      "Epoch 1/1\n",
      " - 0s - loss: 46284.9922\n",
      "Reducing exploration for all agents to 0.8266\n",
      "\n",
      "Episode 12: Starting computation.\n",
      "Random Seed Set to 13\n",
      "Episode 12: Finished running.\n",
      "Agent 0, Average Reward: -1215.71\n",
      "Epoch 1/1\n",
      " - 0s - loss: 27186.9590\n",
      "Reducing exploration for all agents to 0.8124\n",
      "\n",
      "Episode 13: Starting computation.\n",
      "Random Seed Set to 14\n",
      "Episode 13: Finished running.\n",
      "Agent 0, Average Reward: -1650.45\n",
      "Epoch 1/1\n",
      " - 0s - loss: 15015.0254\n",
      "Reducing exploration for all agents to 0.7985\n",
      "\n",
      "Episode 14: Starting computation.\n",
      "Random Seed Set to 15\n",
      "Episode 14: Finished running.\n",
      "Agent 0, Average Reward: -1619.79\n",
      "Epoch 1/1\n",
      " - 0s - loss: 7408.8931\n",
      "Reducing exploration for all agents to 0.7848\n",
      "\n",
      "Episode 15: Starting computation.\n",
      "Random Seed Set to 16\n",
      "Episode 15: Finished running.\n",
      "Agent 0, Average Reward: -72.08\n",
      "Saving architecture, weights, optimizer state for best agent-0\n",
      "Epoch 1/1\n",
      " - 0s - loss: 6647.9717\n",
      "Reducing exploration for all agents to 0.7713\n",
      "\n",
      "Episode 16: Starting computation.\n",
      "Random Seed Set to 17\n",
      "Episode 16: Finished running.\n",
      "Agent 0, Average Reward: -193.89\n",
      "Epoch 1/1\n",
      " - 0s - loss: 19900.8789\n",
      "Reducing exploration for all agents to 0.7581\n",
      "\n",
      "Episode 17: Starting computation.\n",
      "Random Seed Set to 18\n",
      "Episode 17: Finished running.\n",
      "Agent 0, Average Reward: -1588.89\n",
      "Epoch 1/1\n",
      " - 0s - loss: 24385.6914\n",
      "Reducing exploration for all agents to 0.745\n",
      "\n",
      "Episode 18: Starting computation.\n",
      "Random Seed Set to 19\n",
      "Episode 18: Finished running.\n",
      "Agent 0, Average Reward: -170.36\n",
      "Epoch 1/1\n",
      " - 0s - loss: 23189.1738\n",
      "Reducing exploration for all agents to 0.7323\n",
      "\n",
      "Episode 19: Starting computation.\n",
      "Random Seed Set to 20\n",
      "Episode 19: Finished running.\n",
      "Agent 0, Average Reward: -1060.84\n",
      "Epoch 1/1\n",
      " - 0s - loss: 17296.5977\n",
      "Reducing exploration for all agents to 0.7197\n",
      "\n",
      "Episode 20: Starting computation.\n",
      "Random Seed Set to 21\n",
      "Episode 20: Finished running.\n",
      "Agent 0, Average Reward: -878.11\n",
      "Epoch 1/1\n",
      " - 0s - loss: 15603.4492\n",
      "Weights succesfully copied to Target model for Agent 0.\n",
      "Saving architecture, weights and optimizer state for agent-0\n",
      "Dumping agent-0 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Dumping Loss Results into pickle file.\n",
      "Reducing exploration for all agents to 0.7073\n",
      "\n",
      "Episode 21: Starting computation.\n",
      "Random Seed Set to 22\n",
      "Episode 21: Finished running.\n",
      "Agent 0, Average Reward: -809.8\n",
      "Epoch 1/1\n",
      " - 0s - loss: 157912.3750\n",
      "Reducing exploration for all agents to 0.6952\n",
      "\n",
      "Episode 22: Starting computation.\n",
      "Random Seed Set to 23\n",
      "Episode 22: Finished running.\n",
      "Agent 0, Average Reward: -201.55\n",
      "Epoch 1/1\n",
      " - 0s - loss: 106301.3047\n",
      "Reducing exploration for all agents to 0.6833\n",
      "\n",
      "Episode 23: Starting computation.\n",
      "Random Seed Set to 24\n",
      "Episode 23: Finished running.\n",
      "Agent 0, Average Reward: -1075.42\n",
      "Epoch 1/1\n",
      " - 0s - loss: 90635.8047\n",
      "Reducing exploration for all agents to 0.6715\n",
      "\n",
      "Episode 24: Starting computation.\n",
      "Random Seed Set to 25\n",
      "Episode 24: Finished running.\n",
      "Agent 0, Average Reward: -69.87\n",
      "Saving architecture, weights, optimizer state for best agent-0\n",
      "Epoch 1/1\n",
      " - 0s - loss: 71364.6484\n",
      "Reducing exploration for all agents to 0.66\n",
      "\n",
      "Episode 25: Starting computation.\n",
      "Random Seed Set to 26\n",
      "Episode 25: Finished running.\n",
      "Agent 0, Average Reward: -1411.65\n",
      "Epoch 1/1\n",
      " - 0s - loss: 47876.4180\n",
      "Reducing exploration for all agents to 0.6487\n",
      "\n",
      "Episode 26: Starting computation.\n",
      "Random Seed Set to 27\n",
      "Episode 26: Finished running.\n",
      "Agent 0, Average Reward: -558.86\n",
      "Epoch 1/1\n",
      " - 0s - loss: 28730.5234\n",
      "Reducing exploration for all agents to 0.6375\n",
      "\n",
      "Episode 27: Starting computation.\n",
      "Random Seed Set to 28\n",
      "Episode 27: Finished running.\n",
      "Agent 0, Average Reward: -2196.09\n",
      "Epoch 1/1\n",
      " - 0s - loss: 10296.5928\n",
      "Reducing exploration for all agents to 0.6266\n",
      "\n",
      "Episode 28: Starting computation.\n",
      "Random Seed Set to 29\n",
      "Episode 28: Finished running.\n",
      "Agent 0, Average Reward: -2144.58\n",
      "Epoch 1/1\n",
      " - 0s - loss: 4873.2021\n",
      "Reducing exploration for all agents to 0.6158\n",
      "\n",
      "Episode 29: Starting computation.\n",
      "Random Seed Set to 30\n",
      "Episode 29: Finished running.\n",
      "Agent 0, Average Reward: -557.72\n",
      "Epoch 1/1\n",
      " - 0s - loss: 12523.6426\n",
      "Reducing exploration for all agents to 0.6053\n",
      "\n",
      "Episode 30: Starting computation.\n",
      "Random Seed Set to 31\n",
      "Episode 30: Finished running.\n",
      "Agent 0, Average Reward: -2197.45\n",
      "Epoch 1/1\n",
      " - 0s - loss: 31189.6973\n",
      "Reducing exploration for all agents to 0.5949\n",
      "\n",
      "Episode 31: Starting computation.\n",
      "Random Seed Set to 32\n",
      "Episode 31: Finished running.\n",
      "Agent 0, Average Reward: -1582.82\n",
      "Epoch 1/1\n",
      " - 0s - loss: 46417.3320\n",
      "Reducing exploration for all agents to 0.5847\n",
      "\n",
      "Episode 32: Starting computation.\n",
      "Random Seed Set to 33\n",
      "Episode 32: Finished running.\n",
      "Agent 0, Average Reward: -460.33\n",
      "Epoch 1/1\n",
      " - 0s - loss: 42126.0117\n",
      "Reducing exploration for all agents to 0.5746\n",
      "\n",
      "Episode 33: Starting computation.\n",
      "Random Seed Set to 34\n",
      "Episode 33: Finished running.\n",
      "Agent 0, Average Reward: -2025.45\n",
      "Epoch 1/1\n",
      " - 0s - loss: 40363.8242\n",
      "Reducing exploration for all agents to 0.5648\n",
      "\n",
      "Episode 34: Starting computation.\n",
      "Random Seed Set to 35\n",
      "Episode 34: Finished running.\n",
      "Agent 0, Average Reward: -745.55\n",
      "Epoch 1/1\n",
      " - 0s - loss: 16187.0576\n",
      "Reducing exploration for all agents to 0.5551\n",
      "\n",
      "Episode 35: Starting computation.\n",
      "Random Seed Set to 36\n",
      "Episode 35: Finished running.\n",
      "Agent 0, Average Reward: -1440.52\n",
      "Epoch 1/1\n",
      " - 0s - loss: 4231.6821\n",
      "Reducing exploration for all agents to 0.5456\n",
      "\n",
      "Episode 36: Starting computation.\n",
      "Random Seed Set to 37\n",
      "Episode 36: Finished running.\n",
      "Agent 0, Average Reward: -1979.18\n",
      "Epoch 1/1\n",
      " - 0s - loss: 3978.3669\n",
      "Reducing exploration for all agents to 0.5362\n",
      "\n",
      "Episode 37: Starting computation.\n",
      "Random Seed Set to 38\n",
      "Episode 37: Finished running.\n",
      "Agent 0, Average Reward: -111.69\n",
      "Epoch 1/1\n",
      " - 0s - loss: 8505.9326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reducing exploration for all agents to 0.527\n",
      "\n",
      "Episode 38: Starting computation.\n",
      "Random Seed Set to 39\n",
      "Episode 38: Finished running.\n",
      "Agent 0, Average Reward: -2071.58\n",
      "Epoch 1/1\n",
      " - 0s - loss: 14546.1768\n",
      "Reducing exploration for all agents to 0.5179\n",
      "\n",
      "Episode 39: Starting computation.\n",
      "Random Seed Set to 40\n",
      "Episode 39: Finished running.\n",
      "Agent 0, Average Reward: -816.47\n",
      "Epoch 1/1\n",
      " - 0s - loss: 25083.8750\n",
      "Reducing exploration for all agents to 0.5091\n",
      "\n",
      "Episode 40: Starting computation.\n",
      "Random Seed Set to 41\n",
      "Episode 40: Finished running.\n",
      "Agent 0, Average Reward: -2166.97\n",
      "Epoch 1/1\n",
      " - 0s - loss: 19497.5293\n",
      "Weights succesfully copied to Target model for Agent 0.\n",
      "Saving architecture, weights and optimizer state for agent-0\n",
      "Dumping agent-0 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Dumping Loss Results into pickle file.\n",
      "Reducing exploration for all agents to 0.5003\n",
      "\n",
      "Episode 41: Starting computation.\n",
      "Random Seed Set to 42\n",
      "Episode 41: Finished running.\n",
      "Agent 0, Average Reward: -95.77\n",
      "Epoch 1/1\n",
      " - 0s - loss: 187582.2188\n",
      "Reducing exploration for all agents to 0.4917\n",
      "\n",
      "Episode 42: Starting computation.\n",
      "Random Seed Set to 43\n",
      "Episode 42: Finished running.\n",
      "Agent 0, Average Reward: -1491.32\n",
      "Epoch 1/1\n",
      " - 0s - loss: 153149.8750\n",
      "Reducing exploration for all agents to 0.4833\n",
      "\n",
      "Episode 43: Starting computation.\n",
      "Random Seed Set to 44\n",
      "Episode 43: Finished running.\n",
      "Agent 0, Average Reward: -1554.37\n",
      "Epoch 1/1\n",
      " - 0s - loss: 94686.9297\n",
      "Reducing exploration for all agents to 0.475\n",
      "\n",
      "Episode 44: Starting computation.\n",
      "Random Seed Set to 45\n",
      "Episode 44: Finished running.\n",
      "Agent 0, Average Reward: -1633.53\n",
      "Epoch 1/1\n",
      " - 0s - loss: 47208.5234\n",
      "Reducing exploration for all agents to 0.4668\n",
      "\n",
      "Episode 45: Starting computation.\n",
      "Random Seed Set to 46\n",
      "Episode 45: Finished running.\n",
      "Agent 0, Average Reward: -775.89\n",
      "Epoch 1/1\n",
      " - 0s - loss: 11635.6562\n",
      "Reducing exploration for all agents to 0.4588\n",
      "\n",
      "Episode 46: Starting computation.\n",
      "Random Seed Set to 47\n",
      "Episode 46: Finished running.\n",
      "Agent 0, Average Reward: -2436.16\n",
      "Epoch 1/1\n",
      " - 0s - loss: 5116.1074\n",
      "Reducing exploration for all agents to 0.451\n",
      "\n",
      "Episode 47: Starting computation.\n",
      "Random Seed Set to 48\n",
      "Episode 47: Finished running.\n",
      "Agent 0, Average Reward: -2759.94\n",
      "Epoch 1/1\n",
      " - 0s - loss: 18044.0781\n",
      "Reducing exploration for all agents to 0.4432\n",
      "\n",
      "Episode 48: Starting computation.\n",
      "Random Seed Set to 49\n",
      "Episode 48: Finished running.\n",
      "Agent 0, Average Reward: -2531.07\n",
      "Epoch 1/1\n",
      " - 0s - loss: 55808.9219\n",
      "Reducing exploration for all agents to 0.4356\n",
      "\n",
      "Episode 49: Starting computation.\n",
      "Random Seed Set to 50\n",
      "Episode 49: Finished running.\n",
      "Agent 0, Average Reward: -1605.49\n",
      "Epoch 1/1\n",
      " - 0s - loss: 69602.1875\n",
      "Reducing exploration for all agents to 0.4281\n",
      "\n",
      "Episode 50: Starting computation.\n",
      "Random Seed Set to 51\n",
      "Episode 50: Finished running.\n",
      "Agent 0, Average Reward: -2951.55\n",
      "Epoch 1/1\n",
      " - 0s - loss: 71013.1250\n",
      "Reducing exploration for all agents to 0.4208\n",
      "\n",
      "Episode 51: Starting computation.\n",
      "Random Seed Set to 52\n",
      "Episode 51: Finished running.\n",
      "Agent 0, Average Reward: -1901.68\n",
      "Epoch 1/1\n",
      " - 0s - loss: 43194.3047\n",
      "Reducing exploration for all agents to 0.4136\n",
      "\n",
      "Episode 52: Starting computation.\n",
      "Random Seed Set to 53\n",
      "Episode 52: Finished running.\n",
      "Agent 0, Average Reward: -2908.62\n",
      "Epoch 1/1\n",
      " - 0s - loss: 21557.8301\n",
      "Reducing exploration for all agents to 0.4065\n",
      "\n",
      "Episode 53: Starting computation.\n",
      "Random Seed Set to 54\n",
      "Episode 53: Finished running.\n",
      "Agent 0, Average Reward: -2867.02\n",
      "Epoch 1/1\n",
      " - 0s - loss: 9354.8389\n",
      "Reducing exploration for all agents to 0.3995\n",
      "\n",
      "Episode 54: Starting computation.\n",
      "Random Seed Set to 55\n",
      "Episode 54: Finished running.\n",
      "Agent 0, Average Reward: -2983.8\n",
      "Epoch 1/1\n",
      " - 0s - loss: 16537.4297\n",
      "Reducing exploration for all agents to 0.3926\n",
      "\n",
      "Episode 55: Starting computation.\n",
      "Random Seed Set to 56\n",
      "Episode 55: Finished running.\n",
      "Agent 0, Average Reward: -2513.22\n",
      "Epoch 1/1\n",
      " - 0s - loss: 22476.1465\n",
      "Reducing exploration for all agents to 0.3859\n",
      "\n",
      "Episode 56: Starting computation.\n",
      "Random Seed Set to 57\n",
      "Episode 56: Finished running.\n",
      "Agent 0, Average Reward: -1417.89\n",
      "Epoch 1/1\n",
      " - 0s - loss: 33370.0547\n",
      "Reducing exploration for all agents to 0.3793\n",
      "\n",
      "Episode 57: Starting computation.\n",
      "Random Seed Set to 58\n",
      "Episode 57: Finished running.\n",
      "Agent 0, Average Reward: -1683.7\n",
      "Epoch 1/1\n",
      " - 0s - loss: 16015.5811\n",
      "Reducing exploration for all agents to 0.3728\n",
      "\n",
      "Episode 58: Starting computation.\n",
      "Random Seed Set to 59\n",
      "Episode 58: Finished running.\n",
      "Agent 0, Average Reward: -1724.49\n",
      "Epoch 1/1\n",
      " - 0s - loss: 8846.1523\n",
      "Reducing exploration for all agents to 0.3664\n",
      "\n",
      "Episode 59: Starting computation.\n",
      "Random Seed Set to 60\n",
      "Episode 59: Finished running.\n",
      "Agent 0, Average Reward: -1664.04\n",
      "Epoch 1/1\n",
      " - 0s - loss: 5804.2222\n",
      "Reducing exploration for all agents to 0.3601\n",
      "\n",
      "Episode 60: Starting computation.\n",
      "Random Seed Set to 61\n",
      "Episode 60: Finished running.\n",
      "Agent 0, Average Reward: -2120.23\n",
      "Epoch 1/1\n",
      " - 0s - loss: 5208.7144\n",
      "Weights succesfully copied to Target model for Agent 0.\n",
      "Saving architecture, weights and optimizer state for agent-0\n",
      "Dumping agent-0 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Dumping Loss Results into pickle file.\n",
      "Reducing exploration for all agents to 0.3539\n",
      "\n",
      "Episode 61: Starting computation.\n",
      "Random Seed Set to 62\n",
      "Episode 61: Finished running.\n",
      "Agent 0, Average Reward: -110.23\n",
      "Epoch 1/1\n",
      " - 0s - loss: 203939.4688\n",
      "Reducing exploration for all agents to 0.3478\n",
      "\n",
      "Episode 62: Starting computation.\n",
      "Random Seed Set to 63\n",
      "Episode 62: Finished running.\n",
      "Agent 0, Average Reward: -130.4\n",
      "Epoch 1/1\n",
      " - 0s - loss: 124836.4375\n",
      "Reducing exploration for all agents to 0.3418\n",
      "\n",
      "Episode 63: Starting computation.\n",
      "Random Seed Set to 64\n",
      "Episode 63: Finished running.\n",
      "Agent 0, Average Reward: -1477.29\n",
      "Epoch 1/1\n",
      " - 0s - loss: 51061.0352\n",
      "Reducing exploration for all agents to 0.336\n",
      "\n",
      "Episode 64: Starting computation.\n",
      "Random Seed Set to 65\n",
      "Episode 64: Finished running.\n",
      "Agent 0, Average Reward: -1968.5\n",
      "Epoch 1/1\n",
      " - 0s - loss: 16077.6719\n",
      "Reducing exploration for all agents to 0.3302\n",
      "\n",
      "Episode 65: Starting computation.\n",
      "Random Seed Set to 66\n",
      "Episode 65: Finished running.\n",
      "Agent 0, Average Reward: -144.92\n",
      "Epoch 1/1\n",
      " - 0s - loss: 60682.5430\n",
      "Reducing exploration for all agents to 0.3245\n",
      "\n",
      "Episode 66: Starting computation.\n",
      "Random Seed Set to 67\n",
      "Episode 66: Finished running.\n",
      "Agent 0, Average Reward: -2043.96\n",
      "Epoch 1/1\n",
      " - 0s - loss: 57705.5156\n",
      "Reducing exploration for all agents to 0.319\n",
      "\n",
      "Episode 67: Starting computation.\n",
      "Random Seed Set to 68\n",
      "Episode 67: Finished running.\n",
      "Agent 0, Average Reward: -2062.66\n",
      "Epoch 1/1\n",
      " - 0s - loss: 106296.0859\n",
      "Reducing exploration for all agents to 0.3135\n",
      "\n",
      "Episode 68: Starting computation.\n",
      "Random Seed Set to 69\n",
      "Episode 68: Finished running.\n",
      "Agent 0, Average Reward: -1469.26\n",
      "Epoch 1/1\n",
      " - 0s - loss: 77955.0000\n",
      "Reducing exploration for all agents to 0.3081\n",
      "\n",
      "Episode 69: Starting computation.\n",
      "Random Seed Set to 70\n",
      "Episode 69: Finished running.\n",
      "Agent 0, Average Reward: -2039.06\n",
      "Epoch 1/1\n",
      " - 0s - loss: 49492.2773\n",
      "Reducing exploration for all agents to 0.3028\n",
      "\n",
      "Episode 70: Starting computation.\n",
      "Random Seed Set to 71\n",
      "Episode 70: Finished running.\n",
      "Agent 0, Average Reward: -1860.1\n",
      "Epoch 1/1\n",
      " - 0s - loss: 12097.2842\n",
      "Reducing exploration for all agents to 0.2976\n",
      "\n",
      "Episode 71: Starting computation.\n",
      "Random Seed Set to 72\n",
      "Episode 71: Finished running.\n",
      "Agent 0, Average Reward: -3153.57\n",
      "Epoch 1/1\n",
      " - 0s - loss: 13232.3555\n",
      "Reducing exploration for all agents to 0.2925\n",
      "\n",
      "Episode 72: Starting computation.\n",
      "Random Seed Set to 73\n",
      "Episode 72: Finished running.\n",
      "Agent 0, Average Reward: -2623.24\n",
      "Epoch 1/1\n",
      " - 0s - loss: 35597.9453\n",
      "Reducing exploration for all agents to 0.2875\n",
      "\n",
      "Episode 73: Starting computation.\n",
      "Random Seed Set to 74\n",
      "Episode 73: Finished running.\n",
      "Agent 0, Average Reward: -245.75\n",
      "Epoch 1/1\n",
      " - 0s - loss: 53485.6172\n",
      "Reducing exploration for all agents to 0.2826\n",
      "\n",
      "Episode 74: Starting computation.\n",
      "Random Seed Set to 75\n",
      "Episode 74: Finished running.\n",
      "Agent 0, Average Reward: -325.88\n",
      "Epoch 1/1\n",
      " - 0s - loss: 46236.2422\n",
      "Reducing exploration for all agents to 0.2777\n",
      "\n",
      "Episode 75: Starting computation.\n",
      "Random Seed Set to 76\n",
      "Episode 75: Finished running.\n",
      "Agent 0, Average Reward: -2107.86\n",
      "Epoch 1/1\n",
      " - 0s - loss: 38023.0000\n",
      "Reducing exploration for all agents to 0.273\n",
      "\n",
      "Episode 76: Starting computation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed Set to 77\n",
      "Episode 76: Finished running.\n",
      "Agent 0, Average Reward: -2323.11\n",
      "Epoch 1/1\n",
      " - 0s - loss: 25876.9043\n",
      "Reducing exploration for all agents to 0.2683\n",
      "\n",
      "Episode 77: Starting computation.\n",
      "Random Seed Set to 78\n",
      "Episode 77: Finished running.\n",
      "Agent 0, Average Reward: -2124.37\n",
      "Epoch 1/1\n",
      " - 0s - loss: 6152.6035\n",
      "Reducing exploration for all agents to 0.2637\n",
      "\n",
      "Episode 78: Starting computation.\n",
      "Random Seed Set to 79\n",
      "Episode 78: Finished running.\n",
      "Agent 0, Average Reward: -2013.12\n",
      "Epoch 1/1\n",
      " - 0s - loss: 11162.7998\n",
      "Reducing exploration for all agents to 0.2591\n",
      "\n",
      "Episode 79: Starting computation.\n",
      "Random Seed Set to 80\n",
      "Episode 79: Finished running.\n",
      "Agent 0, Average Reward: -268.61\n",
      "Epoch 1/1\n",
      " - 0s - loss: 31448.2207\n",
      "Reducing exploration for all agents to 0.2547\n",
      "\n",
      "Episode 80: Starting computation.\n",
      "Random Seed Set to 81\n",
      "Episode 80: Finished running.\n",
      "Agent 0, Average Reward: -2042.16\n",
      "Epoch 1/1\n",
      " - 0s - loss: 29833.0605\n",
      "Weights succesfully copied to Target model for Agent 0.\n",
      "Saving architecture, weights and optimizer state for agent-0\n",
      "Dumping agent-0 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Dumping Loss Results into pickle file.\n",
      "Reducing exploration for all agents to 0.2503\n",
      "\n",
      "Episode 81: Starting computation.\n",
      "Random Seed Set to 82\n",
      "Episode 81: Finished running.\n",
      "Agent 0, Average Reward: -2147.15\n",
      "Epoch 1/1\n",
      " - 0s - loss: 200649.2969\n",
      "Reducing exploration for all agents to 0.246\n",
      "\n",
      "Episode 82: Starting computation.\n",
      "Random Seed Set to 83\n",
      "Episode 82: Finished running.\n",
      "Agent 0, Average Reward: -565.25\n",
      "Epoch 1/1\n",
      " - 0s - loss: 109561.8672\n",
      "Reducing exploration for all agents to 0.2418\n",
      "\n",
      "Episode 83: Starting computation.\n",
      "Random Seed Set to 84\n",
      "Episode 83: Finished running.\n",
      "Agent 0, Average Reward: -2217.27\n",
      "Epoch 1/1\n",
      " - 0s - loss: 59056.3047\n",
      "Reducing exploration for all agents to 0.2377\n",
      "\n",
      "Episode 84: Starting computation.\n",
      "Random Seed Set to 85\n",
      "Episode 84: Finished running.\n",
      "Agent 0, Average Reward: -1941.69\n",
      "Epoch 1/1\n",
      " - 0s - loss: 9040.8076\n",
      "Reducing exploration for all agents to 0.2336\n",
      "\n",
      "Episode 85: Starting computation.\n",
      "Random Seed Set to 86\n",
      "Episode 85: Finished running.\n",
      "Agent 0, Average Reward: -1598.4\n",
      "Epoch 1/1\n",
      " - 0s - loss: 18907.1309\n",
      "Reducing exploration for all agents to 0.2296\n",
      "\n",
      "Episode 86: Starting computation.\n",
      "Random Seed Set to 87\n",
      "Episode 86: Finished running.\n",
      "Agent 0, Average Reward: -1889.43\n",
      "Epoch 1/1\n",
      " - 0s - loss: 73722.6094\n",
      "Reducing exploration for all agents to 0.2256\n",
      "\n",
      "Episode 87: Starting computation.\n",
      "Random Seed Set to 88\n",
      "Episode 87: Finished running.\n",
      "Agent 0, Average Reward: -1817.35\n",
      "Epoch 1/1\n",
      " - 0s - loss: 126380.0312\n",
      "Reducing exploration for all agents to 0.2218\n",
      "\n",
      "Episode 88: Starting computation.\n",
      "Random Seed Set to 89\n",
      "Episode 88: Finished running.\n",
      "Agent 0, Average Reward: -1682.54\n",
      "Epoch 1/1\n",
      " - 0s - loss: 85180.1641\n",
      "Reducing exploration for all agents to 0.2179\n",
      "\n",
      "Episode 89: Starting computation.\n",
      "Random Seed Set to 90\n",
      "Episode 89: Finished running.\n",
      "Agent 0, Average Reward: -1754.46\n",
      "Epoch 1/1\n",
      " - 0s - loss: 27510.5996\n",
      "Reducing exploration for all agents to 0.2142\n",
      "\n",
      "Episode 90: Starting computation.\n",
      "Random Seed Set to 91\n",
      "Episode 90: Finished running.\n",
      "Agent 0, Average Reward: -3557.29\n",
      "Epoch 1/1\n",
      " - 0s - loss: 6185.1489\n",
      "Reducing exploration for all agents to 0.2105\n",
      "\n",
      "Episode 91: Starting computation.\n",
      "Random Seed Set to 92\n",
      "Episode 91: Finished running.\n",
      "Agent 0, Average Reward: -1864.98\n",
      "Epoch 1/1\n",
      " - 0s - loss: 25893.9434\n",
      "Reducing exploration for all agents to 0.2069\n",
      "\n",
      "Episode 92: Starting computation.\n",
      "Random Seed Set to 93\n",
      "Episode 92: Finished running.\n",
      "Agent 0, Average Reward: -2524.81\n",
      "Epoch 1/1\n",
      " - 0s - loss: 58722.8867\n",
      "Reducing exploration for all agents to 0.2034\n",
      "\n",
      "Episode 93: Starting computation.\n",
      "Random Seed Set to 94\n",
      "Episode 93: Finished running.\n",
      "Agent 0, Average Reward: -2521.93\n",
      "Epoch 1/1\n",
      " - 0s - loss: 80598.4219\n",
      "Reducing exploration for all agents to 0.1999\n",
      "\n",
      "Episode 94: Starting computation.\n",
      "Random Seed Set to 95\n",
      "Episode 94: Finished running.\n",
      "Agent 0, Average Reward: -2641.0\n",
      "Epoch 1/1\n",
      " - 0s - loss: 73838.5781\n",
      "Reducing exploration for all agents to 0.1964\n",
      "\n",
      "Episode 95: Starting computation.\n",
      "Random Seed Set to 96\n",
      "Episode 95: Finished running.\n",
      "Agent 0, Average Reward: -2893.18\n",
      "Epoch 1/1\n",
      " - 0s - loss: 51408.6133\n",
      "Reducing exploration for all agents to 0.1931\n",
      "\n",
      "Episode 96: Starting computation.\n",
      "Random Seed Set to 97\n",
      "Episode 96: Finished running.\n",
      "Agent 0, Average Reward: -1992.8\n",
      "Epoch 1/1\n",
      " - 0s - loss: 13457.0957\n",
      "Reducing exploration for all agents to 0.1898\n",
      "\n",
      "Episode 97: Starting computation.\n",
      "Random Seed Set to 98\n",
      "Episode 97: Finished running.\n",
      "Agent 0, Average Reward: -1923.8\n",
      "Epoch 1/1\n",
      " - 0s - loss: 9285.1504\n",
      "Reducing exploration for all agents to 0.1865\n",
      "\n",
      "Episode 98: Starting computation.\n",
      "Random Seed Set to 99\n",
      "Episode 98: Finished running.\n",
      "Agent 0, Average Reward: -2061.07\n",
      "Epoch 1/1\n",
      " - 0s - loss: 42126.1211\n",
      "Reducing exploration for all agents to 0.1833\n",
      "\n",
      "Episode 99: Starting computation.\n",
      "Random Seed Set to 100\n",
      "Episode 99: Finished running.\n",
      "Agent 0, Average Reward: -1845.55\n",
      "Epoch 1/1\n",
      " - 0s - loss: 54911.4883\n",
      "Reducing exploration for all agents to 0.1802\n",
      "\n",
      "Episode 100: Starting computation.\n",
      "Random Seed Set to 101\n",
      "Episode 100: Finished running.\n",
      "Agent 0, Average Reward: -1663.7\n",
      "Epoch 1/1\n",
      " - 0s - loss: 56999.6719\n",
      "Weights succesfully copied to Target model for Agent 0.\n",
      "Saving architecture, weights and optimizer state for agent-0\n",
      "Dumping agent-0 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Dumping Loss Results into pickle file.\n",
      "Reducing exploration for all agents to 0.1771\n",
      "\n",
      "Episode 101: Starting computation.\n",
      "Random Seed Set to 102\n",
      "Episode 101: Finished running.\n",
      "Agent 0, Average Reward: -2646.95\n",
      "Epoch 1/1\n",
      " - 0s - loss: 224341.0938\n",
      "Reducing exploration for all agents to 0.174\n",
      "\n",
      "Episode 102: Starting computation.\n",
      "Random Seed Set to 103\n",
      "Episode 102: Finished running.\n",
      "Agent 0, Average Reward: -2626.6\n",
      "Epoch 1/1\n",
      " - 0s - loss: 221774.2969\n",
      "Reducing exploration for all agents to 0.171\n",
      "\n",
      "Episode 103: Starting computation.\n",
      "Random Seed Set to 104\n",
      "Episode 103: Finished running.\n",
      "Agent 0, Average Reward: -2541.37\n",
      "Epoch 1/1\n",
      " - 0s - loss: 77656.6484\n",
      "Reducing exploration for all agents to 0.1681\n",
      "\n",
      "Episode 104: Starting computation.\n",
      "Random Seed Set to 105\n",
      "Episode 104: Finished running.\n",
      "Agent 0, Average Reward: -2128.94\n",
      "Epoch 1/1\n",
      " - 0s - loss: 7760.4785\n",
      "Reducing exploration for all agents to 0.1652\n",
      "\n",
      "Episode 105: Starting computation.\n",
      "Random Seed Set to 106\n",
      "Episode 105: Finished running.\n",
      "Agent 0, Average Reward: -526.84\n",
      "Epoch 1/1\n",
      " - 0s - loss: 29233.9395\n",
      "Reducing exploration for all agents to 0.1624\n",
      "\n",
      "Episode 106: Starting computation.\n",
      "Random Seed Set to 107\n",
      "Episode 106: Finished running.\n",
      "Agent 0, Average Reward: -2422.82\n",
      "Epoch 1/1\n",
      " - 0s - loss: 107364.5234\n",
      "Reducing exploration for all agents to 0.1596\n",
      "\n",
      "Episode 107: Starting computation.\n",
      "Random Seed Set to 108\n",
      "Episode 107: Finished running.\n",
      "Agent 0, Average Reward: -2692.03\n",
      "Epoch 1/1\n",
      " - 0s - loss: 145677.3906\n",
      "Reducing exploration for all agents to 0.1569\n",
      "\n",
      "Episode 108: Starting computation.\n",
      "Random Seed Set to 109\n",
      "Episode 108: Finished running.\n",
      "Agent 0, Average Reward: -2648.67\n",
      "Epoch 1/1\n",
      " - 0s - loss: 78683.2188\n",
      "Reducing exploration for all agents to 0.1542\n",
      "\n",
      "Episode 109: Starting computation.\n",
      "Random Seed Set to 110\n",
      "Episode 109: Finished running.\n",
      "Agent 0, Average Reward: -1137.28\n",
      "Epoch 1/1\n",
      " - 0s - loss: 20227.5801\n",
      "Reducing exploration for all agents to 0.1515\n",
      "\n",
      "Episode 110: Starting computation.\n",
      "Random Seed Set to 111\n",
      "Episode 110: Finished running.\n",
      "Agent 0, Average Reward: -2450.27\n",
      "Epoch 1/1\n",
      " - 0s - loss: 8995.0029\n",
      "Reducing exploration for all agents to 0.1489\n",
      "\n",
      "Episode 111: Starting computation.\n",
      "Random Seed Set to 112\n",
      "Episode 111: Finished running.\n",
      "Agent 0, Average Reward: -2235.44\n",
      "Epoch 1/1\n",
      " - 0s - loss: 42238.2422\n",
      "Reducing exploration for all agents to 0.1464\n",
      "\n",
      "Episode 112: Starting computation.\n",
      "Random Seed Set to 113\n",
      "Episode 112: Finished running.\n",
      "Agent 0, Average Reward: -2248.13\n",
      "Epoch 1/1\n",
      " - 0s - loss: 85155.2422\n",
      "Reducing exploration for all agents to 0.1438\n",
      "\n",
      "Episode 113: Starting computation.\n",
      "Random Seed Set to 114\n",
      "Episode 113: Finished running.\n",
      "Agent 0, Average Reward: -2531.96\n",
      "Epoch 1/1\n",
      " - 0s - loss: 93033.2109\n",
      "Reducing exploration for all agents to 0.1414\n",
      "\n",
      "Episode 114: Starting computation.\n",
      "Random Seed Set to 115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 114: Finished running.\n",
      "Agent 0, Average Reward: -2666.55\n",
      "Epoch 1/1\n",
      " - 0s - loss: 43016.5938\n",
      "Reducing exploration for all agents to 0.1389\n",
      "\n",
      "Episode 115: Starting computation.\n",
      "Random Seed Set to 116\n",
      "Episode 115: Finished running.\n",
      "Agent 0, Average Reward: -1808.07\n",
      "Epoch 1/1\n",
      " - 0s - loss: 8585.5527\n",
      "Reducing exploration for all agents to 0.1366\n",
      "\n",
      "Episode 116: Starting computation.\n",
      "Random Seed Set to 117\n",
      "Episode 116: Finished running.\n",
      "Agent 0, Average Reward: -2114.45\n",
      "Epoch 1/1\n",
      " - 0s - loss: 12903.5234\n",
      "Reducing exploration for all agents to 0.1342\n",
      "\n",
      "Episode 117: Starting computation.\n",
      "Random Seed Set to 118\n",
      "Episode 117: Finished running.\n",
      "Agent 0, Average Reward: -1448.92\n",
      "Epoch 1/1\n",
      " - 0s - loss: 39338.0117\n",
      "Reducing exploration for all agents to 0.1319\n",
      "\n",
      "Episode 118: Starting computation.\n",
      "Random Seed Set to 119\n",
      "Episode 118: Finished running.\n",
      "Agent 0, Average Reward: -2728.7\n",
      "Epoch 1/1\n",
      " - 0s - loss: 57533.0859\n",
      "Reducing exploration for all agents to 0.1297\n",
      "\n",
      "Episode 119: Starting computation.\n",
      "Random Seed Set to 120\n",
      "Episode 119: Finished running.\n",
      "Agent 0, Average Reward: -3054.67\n",
      "Epoch 1/1\n",
      " - 0s - loss: 47195.9180\n",
      "Reducing exploration for all agents to 0.1274\n",
      "\n",
      "Episode 120: Starting computation.\n",
      "Random Seed Set to 121\n",
      "Episode 120: Finished running.\n",
      "Agent 0, Average Reward: -3015.23\n",
      "Epoch 1/1\n",
      " - 0s - loss: 14506.3281\n",
      "Weights succesfully copied to Target model for Agent 0.\n",
      "Saving architecture, weights and optimizer state for agent-0\n",
      "Dumping agent-0 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Dumping Loss Results into pickle file.\n",
      "Reducing exploration for all agents to 0.1252\n",
      "\n",
      "Episode 121: Starting computation.\n",
      "Random Seed Set to 122\n",
      "Episode 121: Finished running.\n",
      "Agent 0, Average Reward: -1491.71\n",
      "Epoch 1/1\n",
      " - 0s - loss: 246943.9688\n",
      "Reducing exploration for all agents to 0.1231\n",
      "\n",
      "Episode 122: Starting computation.\n",
      "Random Seed Set to 123\n",
      "Episode 122: Finished running.\n",
      "Agent 0, Average Reward: -2777.4\n",
      "Epoch 1/1\n",
      " - 0s - loss: 211444.3750\n",
      "Reducing exploration for all agents to 0.121\n",
      "\n",
      "Episode 123: Starting computation.\n",
      "Random Seed Set to 124\n",
      "Episode 123: Finished running.\n",
      "Agent 0, Average Reward: -2557.2\n",
      "Epoch 1/1\n",
      " - 0s - loss: 78371.1094\n",
      "Reducing exploration for all agents to 0.1189\n",
      "\n",
      "Episode 124: Starting computation.\n",
      "Random Seed Set to 125\n",
      "Episode 124: Finished running.\n",
      "Agent 0, Average Reward: -2696.62\n",
      "Epoch 1/1\n",
      " - 0s - loss: 13599.2266\n",
      "Reducing exploration for all agents to 0.1169\n",
      "\n",
      "Episode 125: Starting computation.\n",
      "Random Seed Set to 126\n",
      "Episode 125: Finished running.\n",
      "Agent 0, Average Reward: -1353.62\n",
      "Epoch 1/1\n",
      " - 0s - loss: 41767.7539\n",
      "Reducing exploration for all agents to 0.1149\n",
      "\n",
      "Episode 126: Starting computation.\n",
      "Random Seed Set to 127\n",
      "Episode 126: Finished running.\n",
      "Agent 0, Average Reward: -2271.0\n",
      "Epoch 1/1\n",
      " - 0s - loss: 122391.8047\n",
      "Reducing exploration for all agents to 0.1129\n",
      "\n",
      "Episode 127: Starting computation.\n",
      "Random Seed Set to 128\n",
      "Episode 127: Finished running.\n",
      "Agent 0, Average Reward: -2421.56\n",
      "Epoch 1/1\n",
      " - 0s - loss: 166752.0000\n",
      "Reducing exploration for all agents to 0.1109\n",
      "\n",
      "Episode 128: Starting computation.\n",
      "Random Seed Set to 129\n",
      "Episode 128: Finished running.\n",
      "Agent 0, Average Reward: -2474.14\n",
      "Epoch 1/1\n",
      " - 0s - loss: 77612.6641\n",
      "Reducing exploration for all agents to 0.109\n",
      "\n",
      "Episode 129: Starting computation.\n",
      "Random Seed Set to 130\n",
      "Episode 129: Finished running.\n",
      "Agent 0, Average Reward: -2124.95\n",
      "Epoch 1/1\n",
      " - 0s - loss: 13021.5840\n",
      "Reducing exploration for all agents to 0.1072\n",
      "\n",
      "Episode 130: Starting computation.\n",
      "Random Seed Set to 131\n",
      "Episode 130: Finished running.\n",
      "Agent 0, Average Reward: -2387.05\n",
      "Epoch 1/1\n",
      " - 0s - loss: 30499.5703\n",
      "Reducing exploration for all agents to 0.1053\n",
      "\n",
      "Episode 131: Starting computation.\n",
      "Random Seed Set to 132\n",
      "Episode 131: Finished running.\n",
      "Agent 0, Average Reward: -2240.22\n",
      "Epoch 1/1\n",
      " - 0s - loss: 84788.5000\n",
      "Reducing exploration for all agents to 0.1035\n",
      "\n",
      "Episode 132: Starting computation.\n",
      "Random Seed Set to 133\n",
      "Episode 132: Finished running.\n",
      "Agent 0, Average Reward: -2400.82\n",
      "Epoch 1/1\n",
      " - 0s - loss: 100650.5078\n",
      "Reducing exploration for all agents to 0.1017\n",
      "\n",
      "Episode 133: Starting computation.\n",
      "Random Seed Set to 134\n",
      "Episode 133: Finished running.\n",
      "Agent 0, Average Reward: -1181.28\n",
      "Epoch 1/1\n",
      " - 0s - loss: 57775.3438\n",
      "Reducing exploration for all agents to 0.1\n",
      "\n",
      "Episode 134: Starting computation.\n",
      "Random Seed Set to 135\n",
      "Episode 134: Finished running.\n",
      "Agent 0, Average Reward: -2573.51\n",
      "Epoch 1/1\n",
      " - 0s - loss: 40317.4766\n",
      "Reducing exploration for all agents to 0.0983\n",
      "\n",
      "Episode 135: Starting computation.\n",
      "Random Seed Set to 136\n",
      "Episode 135: Finished running.\n",
      "Agent 0, Average Reward: -500.69\n",
      "Epoch 1/1\n",
      " - 0s - loss: 11981.8154\n",
      "Reducing exploration for all agents to 0.0966\n",
      "\n",
      "Episode 136: Starting computation.\n",
      "Random Seed Set to 137\n",
      "Episode 136: Finished running.\n",
      "Agent 0, Average Reward: -1218.26\n",
      "Epoch 1/1\n",
      " - 0s - loss: 26924.3711\n",
      "Reducing exploration for all agents to 0.0949\n",
      "\n",
      "Episode 137: Starting computation.\n",
      "Random Seed Set to 138\n",
      "Episode 137: Finished running.\n",
      "Agent 0, Average Reward: -958.82\n",
      "Epoch 1/1\n",
      " - 0s - loss: 54054.2227\n",
      "Reducing exploration for all agents to 0.0933\n",
      "\n",
      "Episode 138: Starting computation.\n",
      "Random Seed Set to 139\n",
      "Episode 138: Finished running.\n",
      "Agent 0, Average Reward: -2224.27\n",
      "Epoch 1/1\n",
      " - 0s - loss: 61299.9766\n",
      "Reducing exploration for all agents to 0.0917\n",
      "\n",
      "Episode 139: Starting computation.\n",
      "Random Seed Set to 140\n",
      "Episode 139: Finished running.\n",
      "Agent 0, Average Reward: -2156.55\n",
      "Epoch 1/1\n",
      " - 0s - loss: 32722.5625\n",
      "Reducing exploration for all agents to 0.0901\n",
      "\n",
      "Episode 140: Starting computation.\n",
      "Random Seed Set to 141\n",
      "Episode 140: Finished running.\n",
      "Agent 0, Average Reward: -1604.36\n",
      "Epoch 1/1\n",
      " - 0s - loss: 5598.9702\n",
      "Weights succesfully copied to Target model for Agent 0.\n",
      "Saving architecture, weights and optimizer state for agent-0\n",
      "Dumping agent-0 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Dumping Loss Results into pickle file.\n",
      "Reducing exploration for all agents to 0.0886\n",
      "\n",
      "Episode 141: Starting computation.\n",
      "Random Seed Set to 142\n",
      "Episode 141: Finished running.\n",
      "Agent 0, Average Reward: -2847.73\n",
      "Epoch 1/1\n",
      " - 0s - loss: 265599.8750\n",
      "Reducing exploration for all agents to 0.0871\n",
      "\n",
      "Episode 142: Starting computation.\n",
      "Random Seed Set to 143\n",
      "Episode 142: Finished running.\n",
      "Agent 0, Average Reward: -2262.52\n",
      "Epoch 1/1\n",
      " - 0s - loss: 184706.4844\n",
      "Reducing exploration for all agents to 0.0856\n",
      "\n",
      "Episode 143: Starting computation.\n",
      "Random Seed Set to 144\n",
      "Episode 143: Finished running.\n",
      "Agent 0, Average Reward: -2307.43\n",
      "Epoch 1/1\n",
      " - 0s - loss: 108415.6094\n",
      "Reducing exploration for all agents to 0.0841\n",
      "\n",
      "Episode 144: Starting computation.\n",
      "Random Seed Set to 145\n",
      "Episode 144: Finished running.\n",
      "Agent 0, Average Reward: -2320.02\n",
      "Epoch 1/1\n",
      " - 0s - loss: 12716.3652\n",
      "Reducing exploration for all agents to 0.0827\n",
      "\n",
      "Episode 145: Starting computation.\n",
      "Random Seed Set to 146\n",
      "Episode 145: Finished running.\n",
      "Agent 0, Average Reward: -2690.25\n",
      "Epoch 1/1\n",
      " - 0s - loss: 47854.2305\n",
      "Reducing exploration for all agents to 0.0812\n",
      "\n",
      "Episode 146: Starting computation.\n",
      "Random Seed Set to 147\n",
      "Episode 146: Finished running.\n",
      "Agent 0, Average Reward: -2724.09\n",
      "Epoch 1/1\n",
      " - 0s - loss: 120353.3594\n",
      "Reducing exploration for all agents to 0.0798\n",
      "\n",
      "Episode 147: Starting computation.\n",
      "Random Seed Set to 148\n",
      "Episode 147: Finished running.\n",
      "Agent 0, Average Reward: -2484.64\n",
      "Epoch 1/1\n",
      " - 0s - loss: 152346.5469\n",
      "Reducing exploration for all agents to 0.0785\n",
      "\n",
      "Episode 148: Starting computation.\n",
      "Random Seed Set to 149\n",
      "Episode 148: Finished running.\n",
      "Agent 0, Average Reward: -2709.74\n",
      "Epoch 1/1\n",
      " - 0s - loss: 79166.7031\n",
      "Reducing exploration for all agents to 0.0771\n",
      "\n",
      "Episode 149: Starting computation.\n",
      "Random Seed Set to 150\n",
      "Episode 149: Finished running.\n",
      "Agent 0, Average Reward: -2651.61\n",
      "Epoch 1/1\n",
      " - 0s - loss: 12747.3066\n",
      "Reducing exploration for all agents to 0.0758\n",
      "\n",
      "Episode 150: Starting computation.\n",
      "Random Seed Set to 151\n",
      "Episode 150: Finished running.\n",
      "Agent 0, Average Reward: -2396.33\n",
      "Epoch 1/1\n",
      " - 0s - loss: 32842.2656\n",
      "Reducing exploration for all agents to 0.0745\n",
      "\n",
      "Episode 151: Starting computation.\n",
      "Random Seed Set to 152\n",
      "Episode 151: Finished running.\n",
      "Agent 0, Average Reward: -1997.47\n",
      "Epoch 1/1\n",
      " - 0s - loss: 65709.9141\n",
      "Reducing exploration for all agents to 0.0732\n",
      "\n",
      "Episode 152: Starting computation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed Set to 153\n",
      "Episode 152: Finished running.\n",
      "Agent 0, Average Reward: -2754.62\n",
      "Epoch 1/1\n",
      " - 0s - loss: 69695.5781\n",
      "Reducing exploration for all agents to 0.072\n",
      "\n",
      "Episode 153: Starting computation.\n",
      "Random Seed Set to 154\n",
      "Episode 153: Finished running.\n",
      "Agent 0, Average Reward: -2605.42\n",
      "Epoch 1/1\n",
      " - 0s - loss: 55024.4648\n",
      "Reducing exploration for all agents to 0.0707\n",
      "\n",
      "Episode 154: Starting computation.\n",
      "Random Seed Set to 155\n",
      "Episode 154: Finished running.\n",
      "Agent 0, Average Reward: -2433.12\n",
      "Epoch 1/1\n",
      " - 0s - loss: 25943.9961\n",
      "Reducing exploration for all agents to 0.0695\n",
      "\n",
      "Episode 155: Starting computation.\n",
      "Random Seed Set to 156\n",
      "Episode 155: Finished running.\n",
      "Agent 0, Average Reward: -2735.01\n",
      "Epoch 1/1\n",
      " - 0s - loss: 10702.2969\n",
      "Reducing exploration for all agents to 0.0683\n",
      "\n",
      "Episode 156: Starting computation.\n",
      "Random Seed Set to 157\n",
      "Episode 156: Finished running.\n",
      "Agent 0, Average Reward: -2923.57\n",
      "Epoch 1/1\n",
      " - 0s - loss: 24624.5527\n",
      "Reducing exploration for all agents to 0.0672\n",
      "\n",
      "Episode 157: Starting computation.\n",
      "Random Seed Set to 158\n",
      "Episode 157: Finished running.\n",
      "Agent 0, Average Reward: -2783.41\n",
      "Epoch 1/1\n",
      " - 0s - loss: 44428.8906\n",
      "Reducing exploration for all agents to 0.066\n",
      "\n",
      "Episode 158: Starting computation.\n",
      "Random Seed Set to 159\n",
      "Episode 158: Finished running.\n",
      "Agent 0, Average Reward: -2830.77\n",
      "Epoch 1/1\n",
      " - 0s - loss: 45728.0195\n",
      "Reducing exploration for all agents to 0.0649\n",
      "\n",
      "Episode 159: Starting computation.\n",
      "Random Seed Set to 160\n",
      "Episode 159: Finished running.\n",
      "Agent 0, Average Reward: -2894.14\n",
      "Epoch 1/1\n",
      " - 0s - loss: 25172.6934\n",
      "Reducing exploration for all agents to 0.0638\n",
      "\n",
      "Episode 160: Starting computation.\n",
      "Random Seed Set to 161\n",
      "Episode 160: Finished running.\n",
      "Agent 0, Average Reward: -2409.47\n",
      "Epoch 1/1\n",
      " - 0s - loss: 8750.1699\n",
      "Weights succesfully copied to Target model for Agent 0.\n",
      "Saving architecture, weights and optimizer state for agent-0\n",
      "Dumping agent-0 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Dumping Loss Results into pickle file.\n",
      "Reducing exploration for all agents to 0.0627\n",
      "\n",
      "Episode 161: Starting computation.\n",
      "Random Seed Set to 162\n",
      "Episode 161: Finished running.\n",
      "Agent 0, Average Reward: -2788.92\n",
      "Epoch 1/1\n",
      " - 0s - loss: 218125.7344\n",
      "Reducing exploration for all agents to 0.0616\n",
      "\n",
      "Episode 162: Starting computation.\n",
      "Random Seed Set to 163\n",
      "Episode 162: Finished running.\n",
      "Agent 0, Average Reward: -2474.59\n",
      "Epoch 1/1\n",
      " - 0s - loss: 167658.2500\n",
      "Reducing exploration for all agents to 0.0605\n",
      "\n",
      "Episode 163: Starting computation.\n",
      "Random Seed Set to 164\n",
      "Episode 163: Finished running.\n",
      "Agent 0, Average Reward: -2608.06\n",
      "Epoch 1/1\n",
      " - 0s - loss: 73085.9609\n",
      "Reducing exploration for all agents to 0.0595\n",
      "\n",
      "Episode 164: Starting computation.\n",
      "Random Seed Set to 165\n",
      "Episode 164: Finished running.\n",
      "Agent 0, Average Reward: -1788.54\n",
      "Epoch 1/1\n",
      " - 0s - loss: 15004.4131\n",
      "Reducing exploration for all agents to 0.0585\n",
      "\n",
      "Episode 165: Starting computation.\n",
      "Random Seed Set to 166\n",
      "Episode 165: Finished running.\n",
      "Agent 0, Average Reward: -2640.98\n",
      "Epoch 1/1\n",
      " - 0s - loss: 74728.7578\n",
      "Reducing exploration for all agents to 0.0575\n",
      "\n",
      "Episode 166: Starting computation.\n",
      "Random Seed Set to 167\n",
      "Episode 166: Finished running.\n",
      "Agent 0, Average Reward: -2867.9\n",
      "Epoch 1/1\n",
      " - 0s - loss: 121930.1953\n",
      "Reducing exploration for all agents to 0.0565\n",
      "\n",
      "Episode 167: Starting computation.\n",
      "Random Seed Set to 168\n",
      "Episode 167: Finished running.\n",
      "Agent 0, Average Reward: -2863.33\n",
      "Epoch 1/1\n",
      " - 0s - loss: 108670.7109\n",
      "Reducing exploration for all agents to 0.0555\n",
      "\n",
      "Episode 168: Starting computation.\n",
      "Random Seed Set to 169\n",
      "Episode 168: Finished running.\n",
      "Agent 0, Average Reward: -3026.51\n",
      "Epoch 1/1\n",
      " - 0s - loss: 32424.6426\n",
      "Reducing exploration for all agents to 0.0546\n",
      "\n",
      "Episode 169: Starting computation.\n",
      "Random Seed Set to 170\n",
      "Episode 169: Finished running.\n",
      "Agent 0, Average Reward: -3209.85\n",
      "Epoch 1/1\n",
      " - 0s - loss: 11679.7725\n",
      "Reducing exploration for all agents to 0.0536\n",
      "\n",
      "Episode 170: Starting computation.\n",
      "Random Seed Set to 171\n",
      "Episode 170: Finished running.\n",
      "Agent 0, Average Reward: -3499.83\n",
      "Epoch 1/1\n",
      " - 0s - loss: 38372.0938\n",
      "Reducing exploration for all agents to 0.0527\n",
      "\n",
      "Episode 171: Starting computation.\n",
      "Random Seed Set to 172\n",
      "Episode 171: Finished running.\n",
      "Agent 0, Average Reward: -1870.28\n",
      "Epoch 1/1\n",
      " - 0s - loss: 62700.0039\n",
      "Reducing exploration for all agents to 0.0518\n",
      "\n",
      "Episode 172: Starting computation.\n",
      "Random Seed Set to 173\n",
      "Episode 172: Finished running.\n",
      "Agent 0, Average Reward: -2445.06\n",
      "Epoch 1/1\n",
      " - 0s - loss: 65225.3789\n",
      "Reducing exploration for all agents to 0.0509\n",
      "\n",
      "Episode 173: Starting computation.\n",
      "Random Seed Set to 174\n",
      "Episode 173: Finished running.\n",
      "Agent 0, Average Reward: -2561.51\n",
      "Epoch 1/1\n",
      " - 0s - loss: 25957.8320\n",
      "Reducing exploration for all agents to 0.05\n",
      "\n",
      "Episode 174: Starting computation.\n",
      "Random Seed Set to 175\n",
      "Episode 174: Finished running.\n",
      "Agent 0, Average Reward: -2643.45\n",
      "Epoch 1/1\n",
      " - 0s - loss: 5573.0430\n",
      "Reducing exploration for all agents to 0.0492\n",
      "\n",
      "Episode 175: Starting computation.\n",
      "Random Seed Set to 176\n",
      "Episode 175: Finished running.\n",
      "Agent 0, Average Reward: -2136.03\n",
      "Epoch 1/1\n",
      " - 0s - loss: 21379.1289\n",
      "Reducing exploration for all agents to 0.0483\n",
      "\n",
      "Episode 176: Starting computation.\n",
      "Random Seed Set to 177\n",
      "Episode 176: Finished running.\n",
      "Agent 0, Average Reward: -1096.07\n",
      "Epoch 1/1\n",
      " - 0s - loss: 50765.7773\n",
      "Reducing exploration for all agents to 0.0475\n",
      "\n",
      "Episode 177: Starting computation.\n",
      "Random Seed Set to 178\n",
      "Episode 177: Finished running.\n",
      "Agent 0, Average Reward: -2023.01\n",
      "Epoch 1/1\n",
      " - 0s - loss: 92630.7969\n",
      "Reducing exploration for all agents to 0.0467\n",
      "\n",
      "Episode 178: Starting computation.\n",
      "Random Seed Set to 179\n",
      "Episode 178: Finished running.\n",
      "Agent 0, Average Reward: -1526.64\n",
      "Epoch 1/1\n",
      " - 0s - loss: 12806.4102\n",
      "Reducing exploration for all agents to 0.0459\n",
      "\n",
      "Episode 179: Starting computation.\n",
      "Random Seed Set to 180\n",
      "Episode 179: Finished running.\n",
      "Agent 0, Average Reward: -1439.26\n",
      "Epoch 1/1\n",
      " - 0s - loss: 7004.4106\n",
      "Reducing exploration for all agents to 0.0451\n",
      "\n",
      "Episode 180: Starting computation.\n",
      "Random Seed Set to 181\n",
      "Episode 180: Finished running.\n",
      "Agent 0, Average Reward: -2842.59\n",
      "Epoch 1/1\n",
      " - 0s - loss: 25158.9922\n",
      "Weights succesfully copied to Target model for Agent 0.\n",
      "Saving architecture, weights and optimizer state for agent-0\n",
      "Dumping agent-0 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Dumping Loss Results into pickle file.\n",
      "Reducing exploration for all agents to 0.0443\n",
      "\n",
      "Episode 181: Starting computation.\n",
      "Random Seed Set to 182\n",
      "Episode 181: Finished running.\n",
      "Agent 0, Average Reward: -1024.81\n",
      "Epoch 1/1\n",
      " - 0s - loss: 232706.1875\n",
      "Reducing exploration for all agents to 0.0436\n",
      "\n",
      "Episode 182: Starting computation.\n",
      "Random Seed Set to 183\n",
      "Episode 182: Finished running.\n",
      "Agent 0, Average Reward: -2724.15\n",
      "Epoch 1/1\n",
      " - 0s - loss: 122193.8750\n",
      "Reducing exploration for all agents to 0.0428\n",
      "\n",
      "Episode 183: Starting computation.\n",
      "Random Seed Set to 184\n",
      "Episode 183: Finished running.\n",
      "Agent 0, Average Reward: -2721.05\n",
      "Epoch 1/1\n",
      " - 0s - loss: 21502.3438\n",
      "Reducing exploration for all agents to 0.0421\n",
      "\n",
      "Episode 184: Starting computation.\n",
      "Random Seed Set to 185\n",
      "Episode 184: Finished running.\n",
      "Agent 0, Average Reward: -3145.4\n",
      "Epoch 1/1\n",
      " - 0s - loss: 30450.6719\n",
      "Reducing exploration for all agents to 0.0414\n",
      "\n",
      "Episode 185: Starting computation.\n",
      "Random Seed Set to 186\n",
      "Episode 185: Finished running.\n",
      "Agent 0, Average Reward: -3057.62\n",
      "Epoch 1/1\n",
      " - 0s - loss: 97794.5391\n",
      "Reducing exploration for all agents to 0.0406\n",
      "\n",
      "Episode 186: Starting computation.\n",
      "Random Seed Set to 187\n",
      "Episode 186: Finished running.\n",
      "Agent 0, Average Reward: -3175.8\n",
      "Epoch 1/1\n",
      " - 0s - loss: 98890.8047\n",
      "Reducing exploration for all agents to 0.0399\n",
      "\n",
      "Episode 187: Starting computation.\n",
      "Random Seed Set to 188\n",
      "Episode 187: Finished running.\n",
      "Agent 0, Average Reward: -2423.81\n",
      "Epoch 1/1\n",
      " - 0s - loss: 64956.6445\n",
      "Reducing exploration for all agents to 0.0393\n",
      "\n",
      "Episode 188: Starting computation.\n",
      "Random Seed Set to 189\n",
      "Episode 188: Finished running.\n",
      "Agent 0, Average Reward: -3276.42\n",
      "Epoch 1/1\n",
      " - 0s - loss: 9842.3008\n",
      "Reducing exploration for all agents to 0.0386\n",
      "\n",
      "Episode 189: Starting computation.\n",
      "Random Seed Set to 190\n",
      "Episode 189: Finished running.\n",
      "Agent 0, Average Reward: -3276.45\n",
      "Epoch 1/1\n",
      " - 0s - loss: 25771.9336\n",
      "Reducing exploration for all agents to 0.0379\n",
      "\n",
      "Episode 190: Starting computation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed Set to 191\n",
      "Episode 190: Finished running.\n",
      "Agent 0, Average Reward: -3480.85\n",
      "Epoch 1/1\n",
      " - 0s - loss: 62106.0000\n",
      "Reducing exploration for all agents to 0.0373\n",
      "\n",
      "Episode 191: Starting computation.\n",
      "Random Seed Set to 192\n",
      "Episode 191: Finished running.\n",
      "Agent 0, Average Reward: -3171.3\n",
      "Epoch 1/1\n",
      " - 0s - loss: 63623.6445\n",
      "Reducing exploration for all agents to 0.0366\n",
      "\n",
      "Episode 192: Starting computation.\n",
      "Random Seed Set to 193\n",
      "Episode 192: Finished running.\n",
      "Agent 0, Average Reward: -2422.84\n",
      "Epoch 1/1\n",
      " - 0s - loss: 28984.9863\n",
      "Reducing exploration for all agents to 0.036\n",
      "\n",
      "Episode 193: Starting computation.\n",
      "Random Seed Set to 194\n",
      "Episode 193: Finished running.\n",
      "Agent 0, Average Reward: -2483.28\n",
      "Epoch 1/1\n",
      " - 0s - loss: 10893.7285\n",
      "Reducing exploration for all agents to 0.0354\n",
      "\n",
      "Episode 194: Starting computation.\n",
      "Random Seed Set to 195\n",
      "Episode 194: Finished running.\n",
      "Agent 0, Average Reward: -2875.49\n",
      "Epoch 1/1\n",
      " - 0s - loss: 25270.8359\n",
      "Reducing exploration for all agents to 0.0348\n",
      "\n",
      "Episode 195: Starting computation.\n",
      "Random Seed Set to 196\n",
      "Episode 195: Finished running.\n",
      "Agent 0, Average Reward: -2386.14\n",
      "Epoch 1/1\n",
      " - 0s - loss: 51098.9805\n",
      "Reducing exploration for all agents to 0.0342\n",
      "\n",
      "Episode 196: Starting computation.\n",
      "Random Seed Set to 197\n",
      "Episode 196: Finished running.\n",
      "Agent 0, Average Reward: -1731.98\n",
      "Epoch 1/1\n",
      " - 0s - loss: 32125.8867\n",
      "Reducing exploration for all agents to 0.0336\n",
      "\n",
      "Episode 197: Starting computation.\n",
      "Random Seed Set to 198\n",
      "Episode 197: Finished running.\n",
      "Agent 0, Average Reward: -2856.98\n",
      "Epoch 1/1\n",
      " - 0s - loss: 21691.5273\n",
      "Reducing exploration for all agents to 0.033\n",
      "\n",
      "Episode 198: Starting computation.\n",
      "Random Seed Set to 199\n",
      "Episode 198: Finished running.\n",
      "Agent 0, Average Reward: -2468.29\n",
      "Epoch 1/1\n",
      " - 0s - loss: 10022.1973\n",
      "Reducing exploration for all agents to 0.0325\n",
      "\n",
      "Episode 199: Starting computation.\n",
      "Random Seed Set to 200\n",
      "Episode 199: Finished running.\n",
      "Agent 0, Average Reward: -2922.92\n",
      "Epoch 1/1\n",
      " - 0s - loss: 23449.6680\n",
      "Reducing exploration for all agents to 0.0319\n",
      "\n",
      "Episode 200: Starting computation.\n",
      "Random Seed Set to 201\n",
      "Episode 200: Finished running.\n",
      "Agent 0, Average Reward: -2790.3\n",
      "Epoch 1/1\n",
      " - 0s - loss: 34194.7617\n",
      "Weights succesfully copied to Target model for Agent 0.\n",
      "Saving architecture, weights and optimizer state for agent-0\n",
      "Dumping agent-0 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Dumping Loss Results into pickle file.\n",
      "Reducing exploration for all agents to 0.0314\n",
      "\n",
      "Episode 201: Starting computation.\n",
      "Random Seed Set to 202\n",
      "Episode 201: Finished running.\n",
      "Agent 0, Average Reward: -1729.86\n",
      "Epoch 1/1\n",
      " - 0s - loss: 228113.2812\n",
      "Reducing exploration for all agents to 0.0308\n",
      "\n",
      "Episode 202: Starting computation.\n",
      "Random Seed Set to 203\n",
      "Episode 202: Finished running.\n",
      "Agent 0, Average Reward: -1943.83\n",
      "Epoch 1/1\n",
      " - 0s - loss: 90976.7109\n",
      "Reducing exploration for all agents to 0.0303\n",
      "\n",
      "Episode 203: Starting computation.\n",
      "Random Seed Set to 204\n",
      "Episode 203: Finished running.\n",
      "Agent 0, Average Reward: -2459.03\n",
      "Epoch 1/1\n",
      " - 0s - loss: 17570.8496\n",
      "Reducing exploration for all agents to 0.0298\n",
      "\n",
      "Episode 204: Starting computation.\n",
      "Random Seed Set to 205\n",
      "Episode 204: Finished running.\n",
      "Agent 0, Average Reward: -1783.43\n",
      "Epoch 1/1\n",
      " - 0s - loss: 103344.6719\n",
      "Reducing exploration for all agents to 0.0293\n",
      "\n",
      "Episode 205: Starting computation.\n",
      "Random Seed Set to 206\n",
      "Episode 205: Finished running.\n",
      "Agent 0, Average Reward: -2427.59\n",
      "Epoch 1/1\n",
      " - 0s - loss: 152632.3438\n",
      "Reducing exploration for all agents to 0.0288\n",
      "\n",
      "Episode 206: Starting computation.\n",
      "Random Seed Set to 207\n",
      "Episode 206: Finished running.\n",
      "Agent 0, Average Reward: -3369.41\n",
      "Epoch 1/1\n",
      " - 0s - loss: 95126.5547\n",
      "Reducing exploration for all agents to 0.0283\n",
      "\n",
      "Episode 207: Starting computation.\n",
      "Random Seed Set to 208\n",
      "Episode 207: Finished running.\n",
      "Agent 0, Average Reward: -3346.45\n",
      "Epoch 1/1\n",
      " - 0s - loss: 20753.7305\n",
      "Reducing exploration for all agents to 0.0278\n",
      "\n",
      "Episode 208: Starting computation.\n",
      "Random Seed Set to 209\n",
      "Episode 208: Finished running.\n",
      "Agent 0, Average Reward: -3381.97\n",
      "Epoch 1/1\n",
      " - 0s - loss: 23487.2598\n",
      "Reducing exploration for all agents to 0.0273\n",
      "\n",
      "Episode 209: Starting computation.\n",
      "Random Seed Set to 210\n",
      "Episode 209: Finished running.\n",
      "Agent 0, Average Reward: -2553.65\n",
      "Epoch 1/1\n",
      " - 0s - loss: 82951.0625\n",
      "Reducing exploration for all agents to 0.0268\n",
      "\n",
      "Episode 210: Starting computation.\n",
      "Random Seed Set to 211\n",
      "Episode 210: Finished running.\n",
      "Agent 0, Average Reward: -2820.49\n",
      "Epoch 1/1\n",
      " - 0s - loss: 95126.6172\n",
      "Reducing exploration for all agents to 0.0264\n",
      "\n",
      "Episode 211: Starting computation.\n",
      "Random Seed Set to 212\n",
      "Episode 211: Finished running.\n",
      "Agent 0, Average Reward: -3111.89\n",
      "Epoch 1/1\n",
      " - 0s - loss: 67387.9375\n",
      "Reducing exploration for all agents to 0.0259\n",
      "\n",
      "Episode 212: Starting computation.\n",
      "Random Seed Set to 213\n",
      "Episode 212: Finished running.\n",
      "Agent 0, Average Reward: -3176.06\n",
      "Epoch 1/1\n",
      " - 0s - loss: 8447.7686\n",
      "Reducing exploration for all agents to 0.0255\n",
      "\n",
      "Episode 213: Starting computation.\n",
      "Random Seed Set to 214\n",
      "Episode 213: Finished running.\n",
      "Agent 0, Average Reward: -2685.48\n",
      "Epoch 1/1\n",
      " - 0s - loss: 47162.4141\n",
      "Reducing exploration for all agents to 0.025\n",
      "\n",
      "Episode 214: Starting computation.\n",
      "Random Seed Set to 215\n",
      "Episode 214: Finished running.\n",
      "Agent 0, Average Reward: -2614.52\n",
      "Epoch 1/1\n",
      " - 0s - loss: 73393.7891\n",
      "Reducing exploration for all agents to 0.0246\n",
      "\n",
      "Episode 215: Starting computation.\n",
      "Random Seed Set to 216\n",
      "Episode 215: Finished running.\n",
      "Agent 0, Average Reward: -2411.41\n",
      "Epoch 1/1\n",
      " - 0s - loss: 58681.0039\n",
      "Reducing exploration for all agents to 0.0242\n",
      "\n",
      "Episode 216: Starting computation.\n",
      "Random Seed Set to 217\n",
      "Episode 216: Finished running.\n",
      "Agent 0, Average Reward: -2625.09\n",
      "Epoch 1/1\n",
      " - 0s - loss: 15108.0039\n",
      "Reducing exploration for all agents to 0.0238\n",
      "\n",
      "Episode 217: Starting computation.\n",
      "Random Seed Set to 218\n",
      "Episode 217: Finished running.\n",
      "Agent 0, Average Reward: -2750.63\n",
      "Epoch 1/1\n",
      " - 0s - loss: 17054.2012\n",
      "Reducing exploration for all agents to 0.0234\n",
      "\n",
      "Episode 218: Starting computation.\n",
      "Random Seed Set to 219\n",
      "Episode 218: Finished running.\n",
      "Agent 0, Average Reward: -1724.6\n",
      "Epoch 1/1\n",
      " - 0s - loss: 46494.0039\n",
      "Reducing exploration for all agents to 0.023\n",
      "\n",
      "Episode 219: Starting computation.\n",
      "Random Seed Set to 220\n",
      "Episode 219: Finished running.\n",
      "Agent 0, Average Reward: -3220.14\n",
      "Epoch 1/1\n",
      " - 0s - loss: 49022.2305\n",
      "Reducing exploration for all agents to 0.0226\n",
      "\n",
      "Episode 220: Starting computation.\n",
      "Random Seed Set to 221\n",
      "Episode 220: Finished running.\n",
      "Agent 0, Average Reward: -2256.85\n",
      "Epoch 1/1\n",
      " - 0s - loss: 17552.5996\n",
      "Weights succesfully copied to Target model for Agent 0.\n",
      "Saving architecture, weights and optimizer state for agent-0\n",
      "Dumping agent-0 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Dumping Loss Results into pickle file.\n",
      "Reducing exploration for all agents to 0.0222\n",
      "\n",
      "Episode 221: Starting computation.\n",
      "Random Seed Set to 222\n",
      "Episode 221: Finished running.\n",
      "Agent 0, Average Reward: -1842.86\n",
      "Epoch 1/1\n",
      " - 0s - loss: 239115.8281\n",
      "Reducing exploration for all agents to 0.0218\n",
      "\n",
      "Episode 222: Starting computation.\n",
      "Random Seed Set to 223\n",
      "Episode 222: Finished running.\n",
      "Agent 0, Average Reward: -2867.18\n",
      "Epoch 1/1\n",
      " - 0s - loss: 40298.3125\n",
      "Reducing exploration for all agents to 0.0214\n",
      "\n",
      "Episode 223: Starting computation.\n",
      "Random Seed Set to 224\n",
      "Episode 223: Finished running.\n",
      "Agent 0, Average Reward: -2505.18\n",
      "Epoch 1/1\n",
      " - 0s - loss: 78245.0781\n",
      "Reducing exploration for all agents to 0.0211\n",
      "\n",
      "Episode 224: Starting computation.\n",
      "Random Seed Set to 225\n",
      "Episode 224: Finished running.\n",
      "Agent 0, Average Reward: -3003.66\n",
      "Epoch 1/1\n",
      " - 0s - loss: 212068.7969\n",
      "Reducing exploration for all agents to 0.0207\n",
      "\n",
      "Episode 225: Starting computation.\n",
      "Random Seed Set to 226\n",
      "Episode 225: Finished running.\n",
      "Agent 0, Average Reward: -2802.61\n",
      "Epoch 1/1\n",
      " - 0s - loss: 143169.2344\n",
      "Reducing exploration for all agents to 0.0203\n",
      "\n",
      "Episode 226: Starting computation.\n",
      "Random Seed Set to 227\n",
      "Episode 226: Finished running.\n",
      "Agent 0, Average Reward: -3049.58\n",
      "Epoch 1/1\n",
      " - 0s - loss: 52010.6562\n",
      "Reducing exploration for all agents to 0.02\n",
      "\n",
      "Episode 227: Starting computation.\n",
      "Random Seed Set to 228\n",
      "Episode 227: Finished running.\n",
      "Agent 0, Average Reward: -2145.37\n",
      "Epoch 1/1\n",
      " - 0s - loss: 10627.9043\n",
      "Reducing exploration for all agents to 0.0196\n",
      "\n",
      "Episode 228: Starting computation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed Set to 229\n",
      "Episode 228: Finished running.\n",
      "Agent 0, Average Reward: -2332.98\n",
      "Epoch 1/1\n",
      " - 0s - loss: 74575.2891\n",
      "Reducing exploration for all agents to 0.0193\n",
      "\n",
      "Episode 229: Starting computation.\n",
      "Random Seed Set to 230\n",
      "Episode 229: Finished running.\n",
      "Agent 0, Average Reward: -2703.62\n",
      "Epoch 1/1\n",
      " - 0s - loss: 119382.4531\n",
      "Reducing exploration for all agents to 0.019\n",
      "\n",
      "Episode 230: Starting computation.\n",
      "Random Seed Set to 231\n",
      "Episode 230: Finished running.\n",
      "Agent 0, Average Reward: -2741.64\n",
      "Epoch 1/1\n",
      " - 0s - loss: 82251.6953\n",
      "Reducing exploration for all agents to 0.0186\n",
      "\n",
      "Episode 231: Starting computation.\n",
      "Random Seed Set to 232\n",
      "Episode 231: Finished running.\n",
      "Agent 0, Average Reward: -2186.09\n",
      "Epoch 1/1\n",
      " - 0s - loss: 37750.2695\n",
      "Reducing exploration for all agents to 0.0183\n",
      "\n",
      "Episode 232: Starting computation.\n",
      "Random Seed Set to 233\n",
      "Episode 232: Finished running.\n",
      "Agent 0, Average Reward: -2637.46\n",
      "Epoch 1/1\n",
      " - 0s - loss: 17636.9551\n",
      "Reducing exploration for all agents to 0.018\n",
      "\n",
      "Episode 233: Starting computation.\n",
      "Random Seed Set to 234\n",
      "Episode 233: Finished running.\n",
      "Agent 0, Average Reward: -1695.8\n",
      "Epoch 1/1\n",
      " - 0s - loss: 117407.9609\n",
      "Reducing exploration for all agents to 0.0177\n",
      "\n",
      "Episode 234: Starting computation.\n",
      "Random Seed Set to 235\n",
      "Episode 234: Finished running.\n",
      "Agent 0, Average Reward: -2291.86\n",
      "Epoch 1/1\n",
      " - 0s - loss: 65549.6875\n",
      "Reducing exploration for all agents to 0.0174\n",
      "\n",
      "Episode 235: Starting computation.\n",
      "Random Seed Set to 236\n",
      "Episode 235: Finished running.\n",
      "Agent 0, Average Reward: -2862.17\n",
      "Epoch 1/1\n",
      " - 0s - loss: 25475.8926\n",
      "Reducing exploration for all agents to 0.0171\n",
      "\n",
      "Episode 236: Starting computation.\n",
      "Random Seed Set to 237\n",
      "Episode 236: Finished running.\n",
      "Agent 0, Average Reward: -2697.29\n",
      "Epoch 1/1\n",
      " - 0s - loss: 20373.0098\n",
      "Reducing exploration for all agents to 0.0168\n",
      "\n",
      "Episode 237: Starting computation.\n",
      "Random Seed Set to 238\n",
      "Episode 237: Finished running.\n",
      "Agent 0, Average Reward: -2749.73\n",
      "Epoch 1/1\n",
      " - 0s - loss: 32814.8555\n",
      "Reducing exploration for all agents to 0.0165\n",
      "\n",
      "Episode 238: Starting computation.\n",
      "Random Seed Set to 239\n",
      "Episode 238: Finished running.\n",
      "Agent 0, Average Reward: -2788.92\n",
      "Epoch 1/1\n",
      " - 0s - loss: 55673.3164\n",
      "Reducing exploration for all agents to 0.0162\n",
      "\n",
      "Episode 239: Starting computation.\n",
      "Random Seed Set to 240\n",
      "Episode 239: Finished running.\n",
      "Agent 0, Average Reward: -2712.31\n",
      "Epoch 1/1\n",
      " - 0s - loss: 21163.9219\n",
      "Reducing exploration for all agents to 0.016\n",
      "\n",
      "Episode 240: Starting computation.\n",
      "Random Seed Set to 241\n",
      "Episode 240: Finished running.\n",
      "Agent 0, Average Reward: -1628.29\n",
      "Epoch 1/1\n",
      " - 0s - loss: 23809.9805\n",
      "Weights succesfully copied to Target model for Agent 0.\n",
      "Saving architecture, weights and optimizer state for agent-0\n",
      "Dumping agent-0 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Dumping Loss Results into pickle file.\n",
      "Reducing exploration for all agents to 0.0157\n",
      "\n",
      "Episode 241: Starting computation.\n",
      "Random Seed Set to 242\n",
      "Episode 241: Finished running.\n",
      "Agent 0, Average Reward: -2261.97\n",
      "Epoch 1/1\n",
      " - 0s - loss: 218671.7969\n",
      "Reducing exploration for all agents to 0.0154\n",
      "\n",
      "Episode 242: Starting computation.\n",
      "Random Seed Set to 243\n",
      "Episode 242: Finished running.\n",
      "Agent 0, Average Reward: -1844.68\n",
      "Epoch 1/1\n",
      " - 0s - loss: 27976.6582\n",
      "Reducing exploration for all agents to 0.0152\n",
      "\n",
      "Episode 243: Starting computation.\n",
      "Random Seed Set to 244\n",
      "Episode 243: Finished running.\n",
      "Agent 0, Average Reward: -1070.24\n",
      "Epoch 1/1\n",
      " - 0s - loss: 57685.2148\n",
      "Reducing exploration for all agents to 0.0149\n",
      "\n",
      "Episode 244: Starting computation.\n",
      "Random Seed Set to 245\n",
      "Episode 244: Finished running.\n",
      "Agent 0, Average Reward: -920.94\n",
      "Epoch 1/1\n",
      " - 0s - loss: 182078.5469\n",
      "Reducing exploration for all agents to 0.0146\n",
      "\n",
      "Episode 245: Starting computation.\n",
      "Random Seed Set to 246\n",
      "Episode 245: Finished running.\n",
      "Agent 0, Average Reward: -1182.28\n",
      "Epoch 1/1\n",
      " - 0s - loss: 154074.8594\n",
      "Reducing exploration for all agents to 0.0144\n",
      "\n",
      "Episode 246: Starting computation.\n",
      "Random Seed Set to 247\n",
      "Episode 246: Finished running.\n",
      "Agent 0, Average Reward: -1457.89\n",
      "Epoch 1/1\n",
      " - 0s - loss: 34675.2852\n",
      "Reducing exploration for all agents to 0.0141\n",
      "\n",
      "Episode 247: Starting computation.\n",
      "Random Seed Set to 248\n",
      "Episode 247: Finished running.\n",
      "Agent 0, Average Reward: -2932.66\n",
      "Epoch 1/1\n",
      " - 0s - loss: 27122.8145\n",
      "Reducing exploration for all agents to 0.0139\n",
      "\n",
      "Episode 248: Starting computation.\n",
      "Random Seed Set to 249\n",
      "Episode 248: Finished running.\n",
      "Agent 0, Average Reward: -3134.38\n",
      "Epoch 1/1\n",
      " - 0s - loss: 101819.9609\n",
      "Reducing exploration for all agents to 0.0137\n",
      "\n",
      "Episode 249: Starting computation.\n",
      "Random Seed Set to 250\n",
      "Episode 249: Finished running.\n",
      "Agent 0, Average Reward: -2404.82\n",
      "Epoch 1/1\n",
      " - 0s - loss: 120253.2891\n",
      "Reducing exploration for all agents to 0.0134\n",
      "\n",
      "Episode 250: Starting computation.\n",
      "Random Seed Set to 251\n",
      "Episode 250: Finished running.\n",
      "Agent 0, Average Reward: -2499.15\n",
      "Epoch 1/1\n",
      " - 0s - loss: 60339.6289\n",
      "Reducing exploration for all agents to 0.0132\n",
      "\n",
      "Episode 251: Starting computation.\n",
      "Random Seed Set to 252\n",
      "Episode 251: Finished running.\n",
      "Agent 0, Average Reward: -1620.57\n",
      "Epoch 1/1\n",
      " - 0s - loss: 9908.8604\n",
      "Reducing exploration for all agents to 0.013\n",
      "\n",
      "Episode 252: Starting computation.\n",
      "Random Seed Set to 253\n",
      "Episode 252: Finished running.\n",
      "Agent 0, Average Reward: -2400.56\n",
      "Epoch 1/1\n",
      " - 0s - loss: 43987.7305\n",
      "Reducing exploration for all agents to 0.0127\n",
      "\n",
      "Episode 253: Starting computation.\n",
      "Random Seed Set to 254\n",
      "Episode 253: Finished running.\n",
      "Agent 0, Average Reward: -2770.65\n",
      "Epoch 1/1\n",
      " - 0s - loss: 62251.5078\n",
      "Reducing exploration for all agents to 0.0125\n",
      "\n",
      "Episode 254: Starting computation.\n",
      "Random Seed Set to 255\n",
      "Episode 254: Finished running.\n",
      "Agent 0, Average Reward: -2746.0\n",
      "Epoch 1/1\n",
      " - 0s - loss: 65992.3984\n",
      "Reducing exploration for all agents to 0.0123\n",
      "\n",
      "Episode 255: Starting computation.\n",
      "Random Seed Set to 256\n",
      "Episode 255: Finished running.\n",
      "Agent 0, Average Reward: -2005.61\n",
      "Epoch 1/1\n",
      " - 0s - loss: 12566.1680\n",
      "Reducing exploration for all agents to 0.0121\n",
      "\n",
      "Episode 256: Starting computation.\n",
      "Random Seed Set to 257\n",
      "Episode 256: Finished running.\n",
      "Agent 0, Average Reward: -2454.52\n",
      "Epoch 1/1\n",
      " - 0s - loss: 24672.0352\n",
      "Reducing exploration for all agents to 0.0119\n",
      "\n",
      "Episode 257: Starting computation.\n",
      "Random Seed Set to 258\n",
      "Episode 257: Finished running.\n",
      "Agent 0, Average Reward: -1649.94\n",
      "Epoch 1/1\n",
      " - 0s - loss: 51925.0430\n",
      "Reducing exploration for all agents to 0.0117\n",
      "\n",
      "Episode 258: Starting computation.\n",
      "Random Seed Set to 259\n",
      "Episode 258: Finished running.\n",
      "Agent 0, Average Reward: -2233.29\n",
      "Epoch 1/1\n",
      " - 0s - loss: 40870.4844\n",
      "Reducing exploration for all agents to 0.0115\n",
      "\n",
      "Episode 259: Starting computation.\n",
      "Random Seed Set to 260\n",
      "Episode 259: Finished running.\n",
      "Agent 0, Average Reward: -2699.11\n",
      "Epoch 1/1\n",
      " - 0s - loss: 25303.2012\n",
      "Reducing exploration for all agents to 0.0113\n",
      "\n",
      "Episode 260: Starting computation.\n",
      "Random Seed Set to 261\n",
      "Episode 260: Finished running.\n",
      "Agent 0, Average Reward: -2570.44\n",
      "Epoch 1/1\n",
      " - 0s - loss: 13773.1143\n",
      "Weights succesfully copied to Target model for Agent 0.\n",
      "Saving architecture, weights and optimizer state for agent-0\n",
      "Dumping agent-0 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Dumping Loss Results into pickle file.\n",
      "Reducing exploration for all agents to 0.0111\n",
      "\n",
      "Episode 261: Starting computation.\n",
      "Random Seed Set to 262\n",
      "Episode 261: Finished running.\n",
      "Agent 0, Average Reward: -2495.71\n",
      "Epoch 1/1\n",
      " - 0s - loss: 168913.3906\n",
      "Reducing exploration for all agents to 0.0109\n",
      "\n",
      "Episode 262: Starting computation.\n",
      "Random Seed Set to 263\n",
      "Episode 262: Finished running.\n",
      "Agent 0, Average Reward: -2415.42\n",
      "Epoch 1/1\n",
      " - 0s - loss: 24723.8086\n",
      "Reducing exploration for all agents to 0.0107\n",
      "\n",
      "Episode 263: Starting computation.\n",
      "Random Seed Set to 264\n",
      "Episode 263: Finished running.\n",
      "Agent 0, Average Reward: -2444.85\n",
      "Epoch 1/1\n",
      " - 0s - loss: 85252.1250\n",
      "Reducing exploration for all agents to 0.0105\n",
      "\n",
      "Episode 264: Starting computation.\n",
      "Random Seed Set to 265\n",
      "Episode 264: Finished running.\n",
      "Agent 0, Average Reward: -1907.72\n",
      "Epoch 1/1\n",
      " - 0s - loss: 162029.8281\n",
      "Reducing exploration for all agents to 0.0104\n",
      "\n",
      "Episode 265: Starting computation.\n",
      "Random Seed Set to 266\n",
      "Episode 265: Finished running.\n",
      "Agent 0, Average Reward: -2714.28\n",
      "Epoch 1/1\n",
      " - 0s - loss: 165290.8125\n",
      "Reducing exploration for all agents to 0.0102\n",
      "\n",
      "Episode 266: Starting computation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed Set to 267\n",
      "Episode 266: Finished running.\n",
      "Agent 0, Average Reward: -2678.18\n",
      "Epoch 1/1\n",
      " - 0s - loss: 29304.8457\n",
      "Reducing exploration for all agents to 0.01\n",
      "\n",
      "Episode 267: Starting computation.\n",
      "Random Seed Set to 268\n",
      "Episode 267: Finished running.\n",
      "Agent 0, Average Reward: -2488.05\n",
      "Epoch 1/1\n",
      " - 0s - loss: 49187.4258\n",
      "Reducing exploration for all agents to 0.0098\n",
      "\n",
      "Episode 268: Starting computation.\n",
      "Random Seed Set to 269\n",
      "Episode 268: Finished running.\n",
      "Agent 0, Average Reward: -2372.75\n",
      "Epoch 1/1\n",
      " - 0s - loss: 110924.8516\n",
      "Reducing exploration for all agents to 0.0097\n",
      "\n",
      "Episode 269: Starting computation.\n",
      "Random Seed Set to 270\n",
      "Episode 269: Finished running.\n",
      "Agent 0, Average Reward: -2686.23\n",
      "Epoch 1/1\n",
      " - 0s - loss: 154022.5469\n",
      "Reducing exploration for all agents to 0.0095\n",
      "\n",
      "Episode 270: Starting computation.\n",
      "Random Seed Set to 271\n",
      "Episode 270: Finished running.\n",
      "Agent 0, Average Reward: -981.94\n",
      "Epoch 1/1\n",
      " - 0s - loss: 75945.9688\n",
      "Reducing exploration for all agents to 0.0093\n",
      "\n",
      "Episode 271: Starting computation.\n",
      "Random Seed Set to 272\n",
      "Episode 271: Finished running.\n",
      "Agent 0, Average Reward: -2958.27\n",
      "Epoch 1/1\n",
      " - 0s - loss: 5959.6201\n",
      "Reducing exploration for all agents to 0.0092\n",
      "\n",
      "Episode 272: Starting computation.\n",
      "Random Seed Set to 273\n",
      "Episode 272: Finished running.\n",
      "Agent 0, Average Reward: -999.87\n",
      "Epoch 1/1\n",
      " - 0s - loss: 64743.0820\n",
      "Reducing exploration for all agents to 0.009\n",
      "\n",
      "Episode 273: Starting computation.\n",
      "Random Seed Set to 274\n",
      "Episode 273: Finished running.\n",
      "Agent 0, Average Reward: -3187.54\n",
      "Epoch 1/1\n",
      " - 0s - loss: 107810.5156\n",
      "Reducing exploration for all agents to 0.0089\n",
      "\n",
      "Episode 274: Starting computation.\n",
      "Random Seed Set to 275\n",
      "Episode 274: Finished running.\n",
      "Agent 0, Average Reward: -2447.93\n",
      "Epoch 1/1\n",
      " - 0s - loss: 75685.9609\n",
      "Reducing exploration for all agents to 0.0087\n",
      "\n",
      "Episode 275: Starting computation.\n",
      "Random Seed Set to 276\n",
      "Episode 275: Finished running.\n",
      "Agent 0, Average Reward: -3189.21\n",
      "Epoch 1/1\n",
      " - 0s - loss: 16127.5176\n",
      "Reducing exploration for all agents to 0.0086\n",
      "\n",
      "Episode 276: Starting computation.\n",
      "Random Seed Set to 277\n",
      "Episode 276: Finished running.\n",
      "Agent 0, Average Reward: -1491.02\n",
      "Epoch 1/1\n",
      " - 0s - loss: 31510.9922\n",
      "Reducing exploration for all agents to 0.0084\n",
      "\n",
      "Episode 277: Starting computation.\n",
      "Random Seed Set to 278\n",
      "Episode 277: Finished running.\n",
      "Agent 0, Average Reward: -1722.64\n",
      "Epoch 1/1\n",
      " - 0s - loss: 105533.0078\n",
      "Reducing exploration for all agents to 0.0083\n",
      "\n",
      "Episode 278: Starting computation.\n",
      "Random Seed Set to 279\n",
      "Episode 278: Finished running.\n",
      "Agent 0, Average Reward: -2560.41\n",
      "Epoch 1/1\n",
      " - 0s - loss: 110281.7734\n",
      "Reducing exploration for all agents to 0.0081\n",
      "\n",
      "Episode 279: Starting computation.\n",
      "Random Seed Set to 280\n",
      "Episode 279: Finished running.\n",
      "Agent 0, Average Reward: -2577.89\n",
      "Epoch 1/1\n",
      " - 0s - loss: 33609.1719\n",
      "Reducing exploration for all agents to 0.008\n",
      "\n",
      "Episode 280: Starting computation.\n",
      "Random Seed Set to 281\n",
      "Episode 280: Finished running.\n",
      "Agent 0, Average Reward: -2623.08\n",
      "Epoch 1/1\n",
      " - 0s - loss: 8628.9766\n",
      "Weights succesfully copied to Target model for Agent 0.\n",
      "Saving architecture, weights and optimizer state for agent-0\n",
      "Dumping agent-0 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Dumping Loss Results into pickle file.\n",
      "Reducing exploration for all agents to 0.0078\n",
      "\n",
      "Episode 281: Starting computation.\n",
      "Random Seed Set to 282\n",
      "Episode 281: Finished running.\n",
      "Agent 0, Average Reward: -2731.45\n",
      "Epoch 1/1\n",
      " - 0s - loss: 176525.0469\n",
      "Reducing exploration for all agents to 0.0077\n",
      "\n",
      "Episode 282: Starting computation.\n",
      "Random Seed Set to 283\n",
      "Episode 282: Finished running.\n",
      "Agent 0, Average Reward: -2472.02\n",
      "Epoch 1/1\n",
      " - 0s - loss: 14537.6064\n",
      "Reducing exploration for all agents to 0.0076\n",
      "\n",
      "Episode 283: Starting computation.\n",
      "Random Seed Set to 284\n",
      "Episode 283: Finished running.\n",
      "Agent 0, Average Reward: -2943.23\n",
      "Epoch 1/1\n",
      " - 0s - loss: 121916.9766\n",
      "Reducing exploration for all agents to 0.0075\n",
      "\n",
      "Episode 284: Starting computation.\n",
      "Random Seed Set to 285\n",
      "Episode 284: Finished running.\n",
      "Agent 0, Average Reward: -3058.22\n",
      "Epoch 1/1\n",
      " - 0s - loss: 207058.1406\n",
      "Reducing exploration for all agents to 0.0073\n",
      "\n",
      "Episode 285: Starting computation.\n",
      "Random Seed Set to 286\n",
      "Episode 285: Finished running.\n",
      "Agent 0, Average Reward: -1194.88\n",
      "Epoch 1/1\n",
      " - 0s - loss: 99856.7734\n",
      "Reducing exploration for all agents to 0.0072\n",
      "\n",
      "Episode 286: Starting computation.\n",
      "Random Seed Set to 287\n",
      "Episode 286: Finished running.\n",
      "Agent 0, Average Reward: -2652.56\n",
      "Epoch 1/1\n",
      " - 0s - loss: 23442.9277\n",
      "Reducing exploration for all agents to 0.0071\n",
      "\n",
      "Episode 287: Starting computation.\n",
      "Random Seed Set to 288\n",
      "Episode 287: Finished running.\n",
      "Agent 0, Average Reward: -2334.34\n",
      "Epoch 1/1\n",
      " - 0s - loss: 90282.5000\n",
      "Reducing exploration for all agents to 0.007\n",
      "\n",
      "Episode 288: Starting computation.\n",
      "Random Seed Set to 289\n",
      "Episode 288: Finished running.\n",
      "Agent 0, Average Reward: -2434.39\n",
      "Epoch 1/1\n",
      " - 0s - loss: 154990.3438\n",
      "Reducing exploration for all agents to 0.0068\n",
      "\n",
      "Episode 289: Starting computation.\n",
      "Random Seed Set to 290\n",
      "Episode 289: Finished running.\n",
      "Agent 0, Average Reward: -2648.74\n",
      "Epoch 1/1\n",
      " - 0s - loss: 140374.7344\n",
      "Reducing exploration for all agents to 0.0067\n",
      "\n",
      "Episode 290: Starting computation.\n",
      "Random Seed Set to 291\n",
      "Episode 290: Finished running.\n",
      "Agent 0, Average Reward: -2542.54\n",
      "Epoch 1/1\n",
      " - 0s - loss: 21817.3691\n",
      "Reducing exploration for all agents to 0.0066\n",
      "\n",
      "Episode 291: Starting computation.\n",
      "Random Seed Set to 292\n",
      "Episode 291: Finished running.\n",
      "Agent 0, Average Reward: -2816.96\n",
      "Epoch 1/1\n",
      " - 0s - loss: 48613.5508\n",
      "Reducing exploration for all agents to 0.0065\n",
      "\n",
      "Episode 292: Starting computation.\n",
      "Random Seed Set to 293\n",
      "Episode 292: Finished running.\n",
      "Agent 0, Average Reward: -2837.38\n",
      "Epoch 1/1\n",
      " - 0s - loss: 106175.1016\n",
      "Reducing exploration for all agents to 0.0064\n",
      "\n",
      "Episode 293: Starting computation.\n",
      "Random Seed Set to 294\n",
      "Episode 293: Finished running.\n",
      "Agent 0, Average Reward: -2732.6\n",
      "Epoch 1/1\n",
      " - 0s - loss: 117956.5703\n",
      "Reducing exploration for all agents to 0.0063\n",
      "\n",
      "Episode 294: Starting computation.\n",
      "Random Seed Set to 295\n",
      "Episode 294: Finished running.\n",
      "Agent 0, Average Reward: -2669.26\n",
      "Epoch 1/1\n",
      " - 0s - loss: 11961.0410\n",
      "Reducing exploration for all agents to 0.0062\n",
      "\n",
      "Episode 295: Starting computation.\n",
      "Random Seed Set to 296\n",
      "Episode 295: Finished running.\n",
      "Agent 0, Average Reward: -2670.46\n",
      "Epoch 1/1\n",
      " - 0s - loss: 51186.8711\n",
      "Reducing exploration for all agents to 0.0061\n",
      "\n",
      "Episode 296: Starting computation.\n",
      "Random Seed Set to 297\n",
      "Episode 296: Finished running.\n",
      "Agent 0, Average Reward: -2612.17\n",
      "Epoch 1/1\n",
      " - 0s - loss: 68254.8047\n",
      "Reducing exploration for all agents to 0.0059\n",
      "\n",
      "Episode 297: Starting computation.\n",
      "Random Seed Set to 298\n",
      "Episode 297: Finished running.\n",
      "Agent 0, Average Reward: -2546.04\n",
      "Epoch 1/1\n",
      " - 0s - loss: 43062.3906\n",
      "Reducing exploration for all agents to 0.0058\n",
      "\n",
      "Episode 298: Starting computation.\n",
      "Random Seed Set to 299\n",
      "Episode 298: Finished running.\n",
      "Agent 0, Average Reward: -2366.47\n",
      "Epoch 1/1\n",
      " - 0s - loss: 16485.3125\n",
      "Reducing exploration for all agents to 0.0057\n",
      "\n",
      "Episode 299: Starting computation.\n",
      "Random Seed Set to 300\n",
      "Episode 299: Finished running.\n",
      "Agent 0, Average Reward: -3466.71\n",
      "Epoch 1/1\n",
      " - 0s - loss: 23433.4395\n",
      "Reducing exploration for all agents to 0.0056\n",
      "\n",
      "Episode 300: Starting computation.\n",
      "Random Seed Set to 301\n",
      "Episode 300: Finished running.\n",
      "Agent 0, Average Reward: -3362.63\n",
      "Epoch 1/1\n",
      " - 0s - loss: 106898.0703\n",
      "Weights succesfully copied to Target model for Agent 0.\n",
      "Saving architecture, weights and optimizer state for agent-0\n",
      "Dumping agent-0 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Dumping Loss Results into pickle file.\n",
      "Reducing exploration for all agents to 0.0056\n",
      "\n",
      "Episode 301: Starting computation.\n",
      "Random Seed Set to 302\n",
      "Episode 301: Finished running.\n",
      "Agent 0, Average Reward: -3661.91\n",
      "Epoch 1/1\n",
      " - 0s - loss: 136463.6250\n",
      "Reducing exploration for all agents to 0.0055\n",
      "\n",
      "Episode 302: Starting computation.\n",
      "Random Seed Set to 303\n",
      "Episode 302: Finished running.\n",
      "Agent 0, Average Reward: -3571.25\n",
      "Epoch 1/1\n",
      " - 0s - loss: 45162.1250\n",
      "Reducing exploration for all agents to 0.0054\n",
      "\n",
      "Episode 303: Starting computation.\n",
      "Random Seed Set to 304\n",
      "Episode 303: Finished running.\n",
      "Agent 0, Average Reward: -3569.74\n",
      "Epoch 1/1\n",
      " - 0s - loss: 47528.6328\n",
      "Reducing exploration for all agents to 0.0053\n",
      "\n",
      "Episode 304: Starting computation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed Set to 305\n",
      "Episode 304: Finished running.\n",
      "Agent 0, Average Reward: -3380.41\n",
      "Epoch 1/1\n",
      " - 0s - loss: 105355.3203\n",
      "Reducing exploration for all agents to 0.0052\n",
      "\n",
      "Episode 305: Starting computation.\n",
      "Random Seed Set to 306\n",
      "Episode 305: Finished running.\n",
      "Agent 0, Average Reward: -2844.26\n",
      "Epoch 1/1\n",
      " - 0s - loss: 90350.4844\n",
      "Reducing exploration for all agents to 0.0051\n",
      "\n",
      "Episode 306: Starting computation.\n",
      "Random Seed Set to 307\n",
      "Episode 306: Finished running.\n",
      "Agent 0, Average Reward: -2653.93\n",
      "Epoch 1/1\n",
      " - 0s - loss: 20899.4727\n",
      "Reducing exploration for all agents to 0.005\n",
      "\n",
      "Episode 307: Starting computation.\n",
      "Random Seed Set to 308\n",
      "Episode 307: Finished running.\n",
      "Agent 0, Average Reward: -3404.79\n",
      "Epoch 1/1\n",
      " - 0s - loss: 29861.4883\n",
      "Reducing exploration for all agents to 0.0049\n",
      "\n",
      "Episode 308: Starting computation.\n",
      "Random Seed Set to 309\n",
      "Episode 308: Finished running.\n",
      "Agent 0, Average Reward: -3397.76\n",
      "Epoch 1/1\n",
      " - 0s - loss: 74959.3516\n",
      "Reducing exploration for all agents to 0.0048\n",
      "\n",
      "Episode 309: Starting computation.\n",
      "Random Seed Set to 310\n",
      "Episode 309: Finished running.\n",
      "Agent 0, Average Reward: -3416.69\n",
      "Epoch 1/1\n",
      " - 0s - loss: 73297.0469\n",
      "Reducing exploration for all agents to 0.0047\n",
      "\n",
      "Episode 310: Starting computation.\n",
      "Random Seed Set to 311\n",
      "Episode 310: Finished running.\n",
      "Agent 0, Average Reward: -2740.04\n",
      "Epoch 1/1\n",
      " - 0s - loss: 43230.3438\n",
      "Reducing exploration for all agents to 0.0047\n",
      "\n",
      "Episode 311: Starting computation.\n",
      "Random Seed Set to 312\n",
      "Episode 311: Finished running.\n",
      "Agent 0, Average Reward: -2295.63\n",
      "Epoch 1/1\n",
      " - 0s - loss: 20723.4336\n",
      "Reducing exploration for all agents to 0.0046\n",
      "\n",
      "Episode 312: Starting computation.\n",
      "Random Seed Set to 313\n",
      "Episode 312: Finished running.\n",
      "Agent 0, Average Reward: -3089.67\n",
      "Epoch 1/1\n",
      " - 0s - loss: 57313.9531\n",
      "Reducing exploration for all agents to 0.0045\n",
      "\n",
      "Episode 313: Starting computation.\n",
      "Random Seed Set to 314\n",
      "Episode 313: Finished running.\n",
      "Agent 0, Average Reward: -2163.67\n",
      "Epoch 1/1\n",
      " - 0s - loss: 87837.8047\n",
      "Reducing exploration for all agents to 0.0044\n",
      "\n",
      "Episode 314: Starting computation.\n",
      "Random Seed Set to 315\n",
      "Episode 314: Finished running.\n",
      "Agent 0, Average Reward: -2593.23\n",
      "Epoch 1/1\n",
      " - 0s - loss: 93370.4297\n",
      "Reducing exploration for all agents to 0.0044\n",
      "\n",
      "Episode 315: Starting computation.\n",
      "Random Seed Set to 316\n",
      "Episode 315: Finished running.\n",
      "Agent 0, Average Reward: -2998.67\n",
      "Epoch 1/1\n",
      " - 0s - loss: 14246.9287\n",
      "Reducing exploration for all agents to 0.0043\n",
      "\n",
      "Episode 316: Starting computation.\n",
      "Random Seed Set to 317\n",
      "Episode 316: Finished running.\n",
      "Agent 0, Average Reward: -3086.97\n",
      "Epoch 1/1\n",
      " - 0s - loss: 92469.5781\n",
      "Reducing exploration for all agents to 0.0042\n",
      "\n",
      "Episode 317: Starting computation.\n",
      "Random Seed Set to 318\n",
      "Episode 317: Finished running.\n",
      "Agent 0, Average Reward: -2913.19\n",
      "Epoch 1/1\n",
      " - 0s - loss: 70012.1328\n",
      "Reducing exploration for all agents to 0.0041\n",
      "\n",
      "Episode 318: Starting computation.\n",
      "Random Seed Set to 319\n",
      "Episode 318: Finished running.\n",
      "Agent 0, Average Reward: -3212.0\n",
      "Epoch 1/1\n",
      " - 0s - loss: 29082.8047\n",
      "Reducing exploration for all agents to 0.0041\n",
      "\n",
      "Episode 319: Starting computation.\n",
      "Random Seed Set to 320\n",
      "Episode 319: Finished running.\n",
      "Agent 0, Average Reward: -2454.1\n",
      "Epoch 1/1\n",
      " - 0s - loss: 24445.4434\n",
      "Reducing exploration for all agents to 0.004\n",
      "\n",
      "Episode 320: Starting computation.\n",
      "Random Seed Set to 321\n",
      "Episode 320: Finished running.\n",
      "Agent 0, Average Reward: -3214.39\n",
      "Epoch 1/1\n",
      " - 0s - loss: 47092.7734\n",
      "Weights succesfully copied to Target model for Agent 0.\n",
      "Saving architecture, weights and optimizer state for agent-0\n",
      "Dumping agent-0 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Dumping Loss Results into pickle file.\n",
      "Reducing exploration for all agents to 0.0039\n",
      "\n",
      "Episode 321: Starting computation.\n",
      "Random Seed Set to 322\n",
      "Episode 321: Finished running.\n",
      "Agent 0, Average Reward: -3005.01\n",
      "Epoch 1/1\n",
      " - 0s - loss: 118621.8828\n",
      "Reducing exploration for all agents to 0.0039\n",
      "\n",
      "Episode 322: Starting computation.\n",
      "Random Seed Set to 323\n",
      "Episode 322: Finished running.\n",
      "Agent 0, Average Reward: -2381.14\n",
      "Epoch 1/1\n",
      " - 0s - loss: 109229.7266\n",
      "Reducing exploration for all agents to 0.0038\n",
      "\n",
      "Episode 323: Starting computation.\n",
      "Random Seed Set to 324\n",
      "Episode 323: Finished running.\n",
      "Agent 0, Average Reward: -2252.43\n",
      "Epoch 1/1\n",
      " - 0s - loss: 40578.0195\n",
      "Reducing exploration for all agents to 0.0037\n",
      "\n",
      "Episode 324: Starting computation.\n",
      "Random Seed Set to 325\n",
      "Episode 324: Finished running.\n",
      "Agent 0, Average Reward: -2431.0\n",
      "Epoch 1/1\n",
      " - 0s - loss: 88305.1406\n",
      "Reducing exploration for all agents to 0.0037\n",
      "\n",
      "Episode 325: Starting computation.\n",
      "Random Seed Set to 326\n",
      "Episode 325: Finished running.\n",
      "Agent 0, Average Reward: -2838.07\n",
      "Epoch 1/1\n",
      " - 0s - loss: 48801.1602\n",
      "Reducing exploration for all agents to 0.0036\n",
      "\n",
      "Episode 326: Starting computation.\n",
      "Random Seed Set to 327\n",
      "Episode 326: Finished running.\n",
      "Agent 0, Average Reward: -3344.44\n",
      "Epoch 1/1\n",
      " - 0s - loss: 26978.1348\n",
      "Reducing exploration for all agents to 0.0035\n",
      "\n",
      "Episode 327: Starting computation.\n",
      "Random Seed Set to 328\n",
      "Episode 327: Finished running.\n",
      "Agent 0, Average Reward: -2352.63\n",
      "Epoch 1/1\n",
      " - 0s - loss: 37361.8516\n",
      "Reducing exploration for all agents to 0.0035\n",
      "\n",
      "Episode 328: Starting computation.\n",
      "Random Seed Set to 329\n",
      "Episode 328: Finished running.\n",
      "Agent 0, Average Reward: -1607.02\n",
      "Epoch 1/1\n",
      " - 0s - loss: 55687.4805\n",
      "Reducing exploration for all agents to 0.0034\n",
      "\n",
      "Episode 329: Starting computation.\n",
      "Random Seed Set to 330\n",
      "Episode 329: Finished running.\n",
      "Agent 0, Average Reward: -2303.07\n",
      "Epoch 1/1\n",
      " - 0s - loss: 24708.0625\n",
      "Reducing exploration for all agents to 0.0034\n",
      "\n",
      "Episode 330: Starting computation.\n",
      "Random Seed Set to 331\n",
      "Episode 330: Finished running.\n",
      "Agent 0, Average Reward: -3007.91\n",
      "Epoch 1/1\n",
      " - 0s - loss: 35024.5234\n",
      "Reducing exploration for all agents to 0.0033\n",
      "\n",
      "Episode 331: Starting computation.\n",
      "Random Seed Set to 332\n",
      "Episode 331: Finished running.\n",
      "Agent 0, Average Reward: -2889.74\n",
      "Epoch 1/1\n",
      " - 0s - loss: 47426.7344\n",
      "Reducing exploration for all agents to 0.0032\n",
      "\n",
      "Episode 332: Starting computation.\n",
      "Random Seed Set to 333\n",
      "Episode 332: Finished running.\n",
      "Agent 0, Average Reward: -2322.56\n",
      "Epoch 1/1\n",
      " - 0s - loss: 35004.7891\n",
      "Reducing exploration for all agents to 0.0032\n",
      "\n",
      "Episode 333: Starting computation.\n",
      "Random Seed Set to 334\n",
      "Episode 333: Finished running.\n",
      "Agent 0, Average Reward: -2855.21\n",
      "Epoch 1/1\n",
      " - 0s - loss: 19147.9902\n",
      "Reducing exploration for all agents to 0.0031\n",
      "\n",
      "Episode 334: Starting computation.\n",
      "Random Seed Set to 335\n",
      "Episode 334: Finished running.\n",
      "Agent 0, Average Reward: -2935.53\n",
      "Epoch 1/1\n",
      " - 0s - loss: 13362.4316\n",
      "Reducing exploration for all agents to 0.0031\n",
      "\n",
      "Episode 335: Starting computation.\n",
      "Random Seed Set to 336\n",
      "Episode 335: Finished running.\n",
      "Agent 0, Average Reward: -2958.52\n",
      "Epoch 1/1\n",
      " - 0s - loss: 29400.4473\n",
      "Reducing exploration for all agents to 0.003\n",
      "\n",
      "Episode 336: Starting computation.\n",
      "Random Seed Set to 337\n",
      "Episode 336: Finished running.\n",
      "Agent 0, Average Reward: -2524.51\n",
      "Epoch 1/1\n",
      " - 0s - loss: 49953.2031\n",
      "Reducing exploration for all agents to 0.003\n",
      "\n",
      "Episode 337: Starting computation.\n",
      "Random Seed Set to 338\n",
      "Episode 337: Finished running.\n",
      "Agent 0, Average Reward: -2655.91\n",
      "Epoch 1/1\n",
      " - 0s - loss: 15949.0146\n",
      "Reducing exploration for all agents to 0.0029\n",
      "\n",
      "Episode 338: Starting computation.\n",
      "Random Seed Set to 339\n",
      "Episode 338: Finished running.\n",
      "Agent 0, Average Reward: -2986.59\n",
      "Epoch 1/1\n",
      " - 0s - loss: 14612.6729\n",
      "Reducing exploration for all agents to 0.0029\n",
      "\n",
      "Episode 339: Starting computation.\n",
      "Random Seed Set to 340\n",
      "Episode 339: Finished running.\n",
      "Agent 0, Average Reward: -3319.97\n",
      "Epoch 1/1\n",
      " - 0s - loss: 23664.2051\n",
      "Reducing exploration for all agents to 0.0028\n",
      "\n",
      "Episode 340: Starting computation.\n",
      "Random Seed Set to 341\n",
      "Episode 340: Finished running.\n",
      "Agent 0, Average Reward: -1936.25\n",
      "Epoch 1/1\n",
      " - 0s - loss: 40492.8984\n",
      "Weights succesfully copied to Target model for Agent 0.\n",
      "Saving architecture, weights and optimizer state for agent-0\n",
      "Dumping agent-0 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Dumping Loss Results into pickle file.\n",
      "Reducing exploration for all agents to 0.0028\n",
      "\n",
      "Episode 341: Starting computation.\n",
      "Random Seed Set to 342\n",
      "Episode 341: Finished running.\n",
      "Agent 0, Average Reward: -2540.53\n",
      "Epoch 1/1\n",
      " - 0s - loss: 131923.1406\n",
      "Reducing exploration for all agents to 0.0027\n",
      "\n",
      "Episode 342: Starting computation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed Set to 343\n",
      "Episode 342: Finished running.\n",
      "Agent 0, Average Reward: -2881.77\n",
      "Epoch 1/1\n",
      " - 0s - loss: 50987.1250\n",
      "Reducing exploration for all agents to 0.0027\n",
      "\n",
      "Episode 343: Starting computation.\n",
      "Random Seed Set to 344\n",
      "Episode 343: Finished running.\n",
      "Agent 0, Average Reward: -1775.93\n",
      "Epoch 1/1\n",
      " - 0s - loss: 24681.7012\n",
      "Reducing exploration for all agents to 0.0026\n",
      "\n",
      "Episode 344: Starting computation.\n",
      "Random Seed Set to 345\n",
      "Episode 344: Finished running.\n",
      "Agent 0, Average Reward: -1504.87\n",
      "Epoch 1/1\n",
      " - 0s - loss: 90994.2188\n",
      "Reducing exploration for all agents to 0.0026\n",
      "\n",
      "Episode 345: Starting computation.\n",
      "Random Seed Set to 346\n",
      "Episode 345: Finished running.\n",
      "Agent 0, Average Reward: -2041.59\n",
      "Epoch 1/1\n",
      " - 0s - loss: 71449.7578\n",
      "Reducing exploration for all agents to 0.0025\n",
      "\n",
      "Episode 346: Starting computation.\n",
      "Random Seed Set to 347\n",
      "Episode 346: Finished running.\n",
      "Agent 0, Average Reward: -1775.45\n",
      "Epoch 1/1\n",
      " - 0s - loss: 84559.9219\n",
      "Reducing exploration for all agents to 0.0025\n",
      "\n",
      "Episode 347: Starting computation.\n",
      "Random Seed Set to 348\n",
      "Episode 347: Finished running.\n",
      "Agent 0, Average Reward: -2709.63\n",
      "Epoch 1/1\n",
      " - 0s - loss: 30411.3457\n",
      "Reducing exploration for all agents to 0.0025\n",
      "\n",
      "Episode 348: Starting computation.\n",
      "Random Seed Set to 349\n",
      "Episode 348: Finished running.\n",
      "Agent 0, Average Reward: -2607.18\n",
      "Epoch 1/1\n",
      " - 0s - loss: 81271.4375\n",
      "Reducing exploration for all agents to 0.0024\n",
      "\n",
      "Episode 349: Starting computation.\n",
      "Random Seed Set to 350\n",
      "Episode 349: Finished running.\n",
      "Agent 0, Average Reward: -2151.94\n",
      "Epoch 1/1\n",
      " - 0s - loss: 47846.7422\n",
      "Reducing exploration for all agents to 0.0024\n",
      "\n",
      "Episode 350: Starting computation.\n",
      "Random Seed Set to 351\n",
      "Episode 350: Finished running.\n",
      "Agent 0, Average Reward: -1405.25\n",
      "Epoch 1/1\n",
      " - 0s - loss: 15456.2891\n",
      "Reducing exploration for all agents to 0.0023\n",
      "\n",
      "Episode 351: Starting computation.\n",
      "Random Seed Set to 352\n",
      "Episode 351: Finished running.\n",
      "Agent 0, Average Reward: -2815.64\n",
      "Epoch 1/1\n",
      " - 0s - loss: 57341.0000\n",
      "Reducing exploration for all agents to 0.0023\n",
      "\n",
      "Episode 352: Starting computation.\n",
      "Random Seed Set to 353\n",
      "Episode 352: Finished running.\n",
      "Agent 0, Average Reward: -3053.97\n",
      "Epoch 1/1\n",
      " - 0s - loss: 140643.5781\n",
      "Reducing exploration for all agents to 0.0023\n",
      "\n",
      "Episode 353: Starting computation.\n",
      "Random Seed Set to 354\n",
      "Episode 353: Finished running.\n",
      "Agent 0, Average Reward: -3122.15\n",
      "Epoch 1/1\n",
      " - 0s - loss: 24724.2559\n",
      "Reducing exploration for all agents to 0.0022\n",
      "\n",
      "Episode 354: Starting computation.\n",
      "Random Seed Set to 355\n",
      "Episode 354: Finished running.\n",
      "Agent 0, Average Reward: -2261.5\n",
      "Epoch 1/1\n",
      " - 0s - loss: 22353.9941\n",
      "Reducing exploration for all agents to 0.0022\n",
      "\n",
      "Episode 355: Starting computation.\n",
      "Random Seed Set to 356\n",
      "Episode 355: Finished running.\n",
      "Agent 0, Average Reward: -2982.58\n",
      "Epoch 1/1\n",
      " - 0s - loss: 40897.2656\n",
      "Reducing exploration for all agents to 0.0021\n",
      "\n",
      "Episode 356: Starting computation.\n",
      "Random Seed Set to 357\n",
      "Episode 356: Finished running.\n",
      "Agent 0, Average Reward: -2328.19\n",
      "Epoch 1/1\n",
      " - 0s - loss: 42168.2617\n",
      "Reducing exploration for all agents to 0.0021\n",
      "\n",
      "Episode 357: Starting computation.\n",
      "Random Seed Set to 358\n",
      "Episode 357: Finished running.\n",
      "Agent 0, Average Reward: -3126.45\n",
      "Epoch 1/1\n",
      " - 0s - loss: 21415.7930\n",
      "Reducing exploration for all agents to 0.0021\n",
      "\n",
      "Episode 358: Starting computation.\n",
      "Random Seed Set to 359\n",
      "Episode 358: Finished running.\n",
      "Agent 0, Average Reward: -2850.59\n",
      "Epoch 1/1\n",
      " - 0s - loss: 34549.7578\n",
      "Reducing exploration for all agents to 0.002\n",
      "\n",
      "Episode 359: Starting computation.\n",
      "Random Seed Set to 360\n",
      "Episode 359: Finished running.\n",
      "Agent 0, Average Reward: -2245.06\n",
      "Epoch 1/1\n",
      " - 0s - loss: 32232.3164\n",
      "Reducing exploration for all agents to 0.002\n",
      "\n",
      "Episode 360: Starting computation.\n",
      "Random Seed Set to 361\n",
      "Episode 360: Finished running.\n",
      "Agent 0, Average Reward: -2895.88\n",
      "Epoch 1/1\n",
      " - 0s - loss: 126634.1484\n",
      "Weights succesfully copied to Target model for Agent 0.\n",
      "Saving architecture, weights and optimizer state for agent-0\n",
      "Dumping agent-0 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Dumping Loss Results into pickle file.\n",
      "Reducing exploration for all agents to 0.002\n",
      "\n",
      "Episode 361: Starting computation.\n",
      "Random Seed Set to 362\n",
      "Episode 361: Finished running.\n",
      "Agent 0, Average Reward: -3081.66\n",
      "Epoch 1/1\n",
      " - 0s - loss: 104177.0859\n",
      "Reducing exploration for all agents to 0.0019\n",
      "\n",
      "Episode 362: Starting computation.\n",
      "Random Seed Set to 363\n",
      "Episode 362: Finished running.\n",
      "Agent 0, Average Reward: -2619.75\n",
      "Epoch 1/1\n",
      " - 0s - loss: 63579.0156\n",
      "Reducing exploration for all agents to 0.0019\n",
      "\n",
      "Episode 363: Starting computation.\n",
      "Random Seed Set to 364\n",
      "Episode 363: Finished running.\n",
      "Agent 0, Average Reward: -2725.69\n",
      "Epoch 1/1\n",
      " - 0s - loss: 25062.4434\n",
      "Reducing exploration for all agents to 0.0019\n",
      "\n",
      "Episode 364: Starting computation.\n",
      "Random Seed Set to 365\n",
      "Episode 364: Finished running.\n",
      "Agent 0, Average Reward: -2646.03\n",
      "Epoch 1/1\n",
      " - 0s - loss: 104303.8516\n",
      "Reducing exploration for all agents to 0.0018\n",
      "\n",
      "Episode 365: Starting computation.\n",
      "Random Seed Set to 366\n",
      "Episode 365: Finished running.\n",
      "Agent 0, Average Reward: -2767.95\n",
      "Epoch 1/1\n",
      " - 0s - loss: 57247.9297\n",
      "Reducing exploration for all agents to 0.0018\n",
      "\n",
      "Episode 366: Starting computation.\n",
      "Random Seed Set to 367\n",
      "Episode 366: Finished running.\n",
      "Agent 0, Average Reward: -2743.24\n",
      "Epoch 1/1\n",
      " - 0s - loss: 29460.0527\n",
      "Reducing exploration for all agents to 0.0018\n",
      "\n",
      "Episode 367: Starting computation.\n",
      "Random Seed Set to 368\n",
      "Episode 367: Finished running.\n",
      "Agent 0, Average Reward: -2682.63\n",
      "Epoch 1/1\n",
      " - 0s - loss: 33385.2500\n",
      "Reducing exploration for all agents to 0.0017\n",
      "\n",
      "Episode 368: Starting computation.\n",
      "Random Seed Set to 369\n",
      "Episode 368: Finished running.\n",
      "Agent 0, Average Reward: -2813.86\n",
      "Epoch 1/1\n",
      " - 0s - loss: 64935.7734\n",
      "Reducing exploration for all agents to 0.0017\n",
      "\n",
      "Episode 369: Starting computation.\n",
      "Random Seed Set to 370\n",
      "Episode 369: Finished running.\n",
      "Agent 0, Average Reward: -2859.03\n",
      "Epoch 1/1\n",
      " - 0s - loss: 36298.6250\n",
      "Reducing exploration for all agents to 0.0017\n",
      "\n",
      "Episode 370: Starting computation.\n",
      "Random Seed Set to 371\n",
      "Episode 370: Finished running.\n",
      "Agent 0, Average Reward: -2459.46\n",
      "Epoch 1/1\n",
      " - 0s - loss: 38253.4531\n",
      "Reducing exploration for all agents to 0.0017\n",
      "\n",
      "Episode 371: Starting computation.\n",
      "Random Seed Set to 372\n",
      "Episode 371: Finished running.\n",
      "Agent 0, Average Reward: -2239.37\n",
      "Epoch 1/1\n",
      " - 0s - loss: 30970.4863\n",
      "Reducing exploration for all agents to 0.0016\n",
      "\n",
      "Episode 372: Starting computation.\n",
      "Random Seed Set to 373\n",
      "Episode 372: Finished running.\n",
      "Agent 0, Average Reward: -1996.16\n",
      "Epoch 1/1\n",
      " - 0s - loss: 48420.2969\n",
      "Reducing exploration for all agents to 0.0016\n",
      "\n",
      "Episode 373: Starting computation.\n",
      "Random Seed Set to 374\n",
      "Episode 373: Finished running.\n",
      "Agent 0, Average Reward: -2929.05\n",
      "Epoch 1/1\n",
      " - 0s - loss: 18514.0605\n",
      "Reducing exploration for all agents to 0.0016\n",
      "\n",
      "Episode 374: Starting computation.\n",
      "Random Seed Set to 375\n",
      "Episode 374: Finished running.\n",
      "Agent 0, Average Reward: -2175.27\n",
      "Epoch 1/1\n",
      " - 0s - loss: 24198.9590\n",
      "Reducing exploration for all agents to 0.0015\n",
      "\n",
      "Episode 375: Starting computation.\n",
      "Random Seed Set to 376\n",
      "Episode 375: Finished running.\n",
      "Agent 0, Average Reward: -3030.81\n",
      "Epoch 1/1\n",
      " - 0s - loss: 39319.2109\n",
      "Reducing exploration for all agents to 0.0015\n",
      "\n",
      "Episode 376: Starting computation.\n",
      "Random Seed Set to 377\n",
      "Episode 376: Finished running.\n",
      "Agent 0, Average Reward: -2254.14\n",
      "Epoch 1/1\n",
      " - 0s - loss: 34281.1445\n",
      "Reducing exploration for all agents to 0.0015\n",
      "\n",
      "Episode 377: Starting computation.\n",
      "Random Seed Set to 378\n",
      "Episode 377: Finished running.\n",
      "Agent 0, Average Reward: -2041.59\n",
      "Epoch 1/1\n",
      " - 0s - loss: 19291.1270\n",
      "Reducing exploration for all agents to 0.0015\n",
      "\n",
      "Episode 378: Starting computation.\n",
      "Random Seed Set to 379\n",
      "Episode 378: Finished running.\n",
      "Agent 0, Average Reward: -2417.23\n",
      "Epoch 1/1\n",
      " - 0s - loss: 25229.4766\n",
      "Reducing exploration for all agents to 0.0014\n",
      "\n",
      "Episode 379: Starting computation.\n",
      "Random Seed Set to 380\n",
      "Episode 379: Finished running.\n",
      "Agent 0, Average Reward: -2850.9\n",
      "Epoch 1/1\n",
      " - 0s - loss: 32845.3594\n",
      "Reducing exploration for all agents to 0.0014\n",
      "\n",
      "Episode 380: Starting computation.\n",
      "Random Seed Set to 381\n",
      "Episode 380: Finished running.\n",
      "Agent 0, Average Reward: -2914.46\n",
      "Epoch 1/1\n",
      " - 0s - loss: 20171.1230\n",
      "Weights succesfully copied to Target model for Agent 0.\n",
      "Saving architecture, weights and optimizer state for agent-0\n",
      "Dumping agent-0 memory into pickle file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dumping Training Results into pickle file.\n",
      "Dumping Loss Results into pickle file.\n",
      "Reducing exploration for all agents to 0.0014\n",
      "\n",
      "Episode 381: Starting computation.\n",
      "Random Seed Set to 382\n",
      "Episode 381: Finished running.\n",
      "Agent 0, Average Reward: -2494.58\n",
      "Epoch 1/1\n",
      " - 0s - loss: 106880.7266\n",
      "Reducing exploration for all agents to 0.0014\n",
      "\n",
      "Episode 382: Starting computation.\n",
      "Random Seed Set to 383\n",
      "Episode 382: Finished running.\n",
      "Agent 0, Average Reward: -3438.98\n",
      "Epoch 1/1\n",
      " - 0s - loss: 54104.1641\n",
      "Reducing exploration for all agents to 0.0013\n",
      "\n",
      "Episode 383: Starting computation.\n",
      "Random Seed Set to 384\n",
      "Episode 383: Finished running.\n",
      "Agent 0, Average Reward: -2446.67\n",
      "Epoch 1/1\n",
      " - 0s - loss: 33436.5000\n",
      "Reducing exploration for all agents to 0.0013\n",
      "\n",
      "Episode 384: Starting computation.\n",
      "Random Seed Set to 385\n",
      "Episode 384: Finished running.\n",
      "Agent 0, Average Reward: -3702.26\n",
      "Epoch 1/1\n",
      " - 0s - loss: 47004.5312\n",
      "Reducing exploration for all agents to 0.0013\n",
      "\n",
      "Episode 385: Starting computation.\n",
      "Random Seed Set to 386\n",
      "Episode 385: Finished running.\n",
      "Agent 0, Average Reward: -3340.89\n",
      "Epoch 1/1\n",
      " - 0s - loss: 61442.4414\n",
      "Reducing exploration for all agents to 0.0013\n",
      "\n",
      "Episode 386: Starting computation.\n",
      "Random Seed Set to 387\n",
      "Episode 386: Finished running.\n",
      "Agent 0, Average Reward: -2884.04\n",
      "Epoch 1/1\n",
      " - 0s - loss: 16678.8418\n",
      "Reducing exploration for all agents to 0.0013\n",
      "\n",
      "Episode 387: Starting computation.\n",
      "Random Seed Set to 388\n",
      "Episode 387: Finished running.\n",
      "Agent 0, Average Reward: -2863.48\n",
      "Epoch 1/1\n",
      " - 0s - loss: 35295.5234\n",
      "Reducing exploration for all agents to 0.0012\n",
      "\n",
      "Episode 388: Starting computation.\n",
      "Random Seed Set to 389\n",
      "Episode 388: Finished running.\n",
      "Agent 0, Average Reward: -1639.77\n",
      "Epoch 1/1\n",
      " - 0s - loss: 55182.0625\n",
      "Reducing exploration for all agents to 0.0012\n",
      "\n",
      "Episode 389: Starting computation.\n",
      "Random Seed Set to 390\n",
      "Episode 389: Finished running.\n",
      "Agent 0, Average Reward: -2059.97\n",
      "Epoch 1/1\n",
      " - 0s - loss: 40165.7734\n",
      "Reducing exploration for all agents to 0.0012\n",
      "\n",
      "Episode 390: Starting computation.\n",
      "Random Seed Set to 391\n",
      "Episode 390: Finished running.\n",
      "Agent 0, Average Reward: -1676.66\n",
      "Epoch 1/1\n",
      " - 0s - loss: 45424.0586\n",
      "Reducing exploration for all agents to 0.0012\n",
      "\n",
      "Episode 391: Starting computation.\n",
      "Random Seed Set to 392\n",
      "Episode 391: Finished running.\n",
      "Agent 0, Average Reward: -2281.42\n",
      "Epoch 1/1\n",
      " - 0s - loss: 42340.0977\n",
      "Reducing exploration for all agents to 0.0011\n",
      "\n",
      "Episode 392: Starting computation.\n",
      "Random Seed Set to 393\n",
      "Episode 392: Finished running.\n",
      "Agent 0, Average Reward: -2180.56\n",
      "Epoch 1/1\n",
      " - 0s - loss: 37350.7539\n",
      "Reducing exploration for all agents to 0.0011\n",
      "\n",
      "Episode 393: Starting computation.\n",
      "Random Seed Set to 394\n",
      "Episode 393: Finished running.\n",
      "Agent 0, Average Reward: -2412.34\n",
      "Epoch 1/1\n",
      " - 0s - loss: 24944.2480\n",
      "Reducing exploration for all agents to 0.0011\n",
      "\n",
      "Episode 394: Starting computation.\n",
      "Random Seed Set to 395\n",
      "Episode 394: Finished running.\n",
      "Agent 0, Average Reward: -2349.01\n",
      "Epoch 1/1\n",
      " - 0s - loss: 21576.6699\n",
      "Reducing exploration for all agents to 0.0011\n",
      "\n",
      "Episode 395: Starting computation.\n",
      "Random Seed Set to 396\n",
      "Episode 395: Finished running.\n",
      "Agent 0, Average Reward: -2388.61\n",
      "Epoch 1/1\n",
      " - 0s - loss: 37745.2383\n",
      "Reducing exploration for all agents to 0.0011\n",
      "\n",
      "Episode 396: Starting computation.\n",
      "Random Seed Set to 397\n",
      "Episode 396: Finished running.\n",
      "Agent 0, Average Reward: -2676.83\n",
      "Epoch 1/1\n",
      " - 0s - loss: 131132.8906\n",
      "Reducing exploration for all agents to 0.0011\n",
      "\n",
      "Episode 397: Starting computation.\n",
      "Random Seed Set to 398\n",
      "Episode 397: Finished running.\n",
      "Agent 0, Average Reward: -2814.69\n",
      "Epoch 1/1\n",
      " - 0s - loss: 41270.7109\n",
      "Reducing exploration for all agents to 0.001\n",
      "\n",
      "Episode 398: Starting computation.\n",
      "Random Seed Set to 399\n",
      "Episode 398: Finished running.\n",
      "Agent 0, Average Reward: -2628.37\n",
      "Epoch 1/1\n",
      " - 0s - loss: 24663.0547\n",
      "Reducing exploration for all agents to 0.001\n",
      "\n",
      "Episode 399: Starting computation.\n",
      "Random Seed Set to 400\n",
      "Episode 399: Finished running.\n",
      "Agent 0, Average Reward: -2635.06\n",
      "Epoch 1/1\n",
      " - 0s - loss: 21144.7129\n",
      "Reducing exploration for all agents to 0.001\n",
      "\n",
      "Episode 400: Starting computation.\n",
      "Random Seed Set to 401\n",
      "Episode 400: Finished running.\n",
      "Agent 0, Average Reward: -2270.96\n",
      "Epoch 1/1\n",
      " - 0s - loss: 10682.2051\n",
      "Weights succesfully copied to Target model for Agent 0.\n",
      "Saving architecture, weights and optimizer state for agent-0\n",
      "Dumping agent-0 memory into pickle file\n",
      "Dumping Training Results into pickle file.\n",
      "Dumping Loss Results into pickle file.\n",
      "Reducing exploration for all agents to 0.001\n",
      "\n",
      "Episode 401: Starting computation.\n"
     ]
    }
   ],
   "source": [
    "Single_Cross_Triple8_MultiDQN_Agents.train(400, vissim = vissim) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Single_Cross_Triple8_MultiDQN_Agents.load(400,best = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set in simulator. Random Seed = 401\n",
      "Deploying Network Parser...\n",
      "Successful Network Crawl: Identified SignalControllers, Links, Lanes and Vehicle Inputs.\n",
      "\n",
      "Setting Simulation mode to: demo\n",
      "Starting Deployments of Signal Control Units...\n",
      "SCUs successfully deployed. Elapsed time 0.66 seconds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Single_Cross_Triple8_MultiDQN_Agents.demo(vissim=vissim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []    \n",
    "\n",
    "End_of_simulation = 3600\n",
    "no_of_simulations = 1\n",
    "demands = [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200]\n",
    "\n",
    "Vissim = vissim\n",
    "\n",
    "Vissim.Graphics.CurrentNetworkWindow.SetAttValue(\"QuickMode\",1)\n",
    "Vissim.SuspendUpdateGUI()\n",
    "Vissim.Simulation.SetAttValue('SimPeriod', End_of_simulation)\n",
    "Vissim.Simulation.SetAttValue('UseMaxSimSpeed', True)\n",
    "\n",
    "for demand in demands :\n",
    "    for simRun in Vissim.Net.SimulationRuns:\n",
    "        Vissim.Net.SimulationRuns.RemoveSimulationRun(simRun)\n",
    "    \n",
    "    for V_input in list(Vissim.Net.VehicleInputs):\n",
    "        V_input.SetAttValue('Volume(1)', demand)\n",
    "        \n",
    "    Single_Cross_Triple8_MultiDQN_Agents.Model_dictionnary = Single_Cross_Triple_dictionary8\n",
    "    \n",
    "#     Single_Cross_Straight_MultiAC_Agents\\\n",
    "#     = MasterAC_Agent(model_name, \n",
    "#                      vissim_working_directory, \n",
    "#                      sim_length, \n",
    "#                      Single_Cross_Straight_dictionary,\n",
    "#                      n_step_size, gamma, alpha, entropy, value, \n",
    "#                      Random_Seed = Random_Seed, timesteps_per_second = 1, \n",
    "#                      Session_ID = Session_ID, verbose = True, \n",
    "#                      horizon = horizon, n_sample = n_sample,\n",
    "#                      save_location = 'C:\\\\Users\\\\nwalton\\\\OneDrive - The Alan Turing Institute\\\\Desktop')\n",
    "    \n",
    "#     Single_Cross_Straight_MultiAC_Agents.load(episode=100,\n",
    "#                                               best=False, \n",
    "#                                               load_location='C:\\\\Users\\\\nwalton\\\\OneDrive - The Alan Turing Institute\\\\Documents\\\\MLforFlowOptimisation\\\\NSW_Single_Cross_Experiment\\\\Single_Cross_Straight\\\\Agents_Results\\\\Neil_Results\\\\Neils_Good_Agents\\\\Oct24'\n",
    "#                                          )\n",
    "    \n",
    "    Single_Cross_Triple8_MultiDQN_Agents.test(vissim=Vissim)\n",
    "    \n",
    "    data.append([demand, Vissim.Net.DelayMeasurements.GetMultiAttValues('VehDelay(Avg,Avg,All)')])\n",
    "    print(data[-1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f= open(\"DQN_Demands.txt\",\"w+\")\n",
    "\n",
    "f.write('demand, junction_1, junction_2, junction_3, junction_4')\n",
    "\n",
    "for i in range(len(data)):\n",
    "    f.write('\\n')\n",
    "    for j in range(len(data[i])):\n",
    "        if j == 0 :\n",
    "            f.write(str(data[i][j])+', ')\n",
    "        if j == 1:\n",
    "            for k in range(len(data[i][j])):\n",
    "                f.write(str(data[i][j][k][1])+', ')\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vissim.Net.DelayMeasurements.GetMultiAttValues('VehDelay(Avg,Avg,All)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for V_input in list(Vissim.Net.VehicleInputs):\n",
    "    V_input.SetAttValue('Volume(1)', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vissim.Net.VehicleInputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "self = Single_Cross_Triple8_MultiDQN_Agents\n",
    "vissim_working_directory = self.vissim_working_directory \n",
    "model_name = self.model_name  \n",
    "agent_type = self.agent_type\n",
    "Session_ID = self.Session_ID\n",
    "episode = 400\n",
    "self.ID = 0 \n",
    "\n",
    "Filename = os.path.join(vissim_working_directory, \n",
    "                        model_name, \n",
    "                        \"Agents_Results\", \n",
    "                        agent_type, \n",
    "                        Session_ID,\n",
    "                        'Episode'+ str(episode) +'Agent'+str(self.ID)+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model(Filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
