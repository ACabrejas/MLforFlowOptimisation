{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "######################################################################################################\n",
    "#\n",
    "#         SCRIPT DESCRIPTION: Basic Q-Learning in a single intersection\n",
    "#\n",
    "#         Input: Map name, route file\n",
    "#         Output: Tripinfo.xml\n",
    "#\n",
    "#####################################################################################################\n",
    "\n",
    "# Set OPERATING SYSTEM\n",
    "OS = \"windows\"\n",
    "# Set MAP and demand\n",
    "used_map = 'triple_straight_random'\n",
    "demand = \"random\"\n",
    "# Select whether to color code the vehicles\n",
    "color_vehicles = True\n",
    "persistent_color = False\n",
    "round_robin_flag = True\n",
    "queue_tracking = True\n",
    "positional_tracking = True\n",
    "tracking_length = 36000\n",
    "simulation_length = 36000\n",
    "# Select Memory\n",
    "reloadQm = True\n",
    "saveQm = False\n",
    "\n",
    "# Set Path for Sumo Home folder\n",
    "if OS == \"iOS\":\n",
    "    sumo_home_dir = \"/Users/acabrejasegea/sumo-0.32/\"\n",
    "elif OS == \"windows\":\n",
    "    sumo_home_dir = \"C:\\Program Files (x86)\\DLR\\Sumo\"\n",
    "else:\n",
    "    sys.exit(\"Please declare a supported operative system\")\n",
    "    \n",
    "# Create storage if needed\n",
    "if positional_tracking == True:\n",
    "    tracking_data = [[] for _ in range(tracking_length)]\n",
    "if queue_tracking == True:\n",
    "    combined_queue = []\n",
    "\n",
    "# Import basic libraries\n",
    "import os\n",
    "import sys\n",
    "import optparse\n",
    "import subprocess\n",
    "import random\n",
    "import random\n",
    "import pdb\n",
    "import xmltodict\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "import json\n",
    "\n",
    "# Current working directory\n",
    "working_dir = os.getcwd()\n",
    "\n",
    "# Set environment variable SUMO_HOME\n",
    "try:\n",
    "    # Use this line only to manually define SUMO_HOME path\n",
    "    os.environ[\"SUMO_HOME\"] = sumo_home_dir\n",
    "    sys.path.append(os.path.join(os.environ['SUMO_HOME'], 'tools'))\n",
    "except ImportError:\n",
    "    sys.exit(\n",
    "        \"Please declare environment variable 'SUMO_HOME' as the root directory of your sumo installation (it should contain folders 'bin', 'tools' and 'docs')\")\n",
    "\n",
    "# Import API libraries\n",
    "from sumolib import checkBinary\n",
    "import traci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.kernel.execute('notebook_name = \"' + IPython.notebook.notebook_name + '\"')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.notebook.kernel.execute('notebook_name = \"' + IPython.notebook.notebook_name + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set important directories\n",
    "if OS==\"iOS\":\n",
    "    networks_dir = \"/Users/acabrejasegea/sumo-0.32/Data/Networks/\"\n",
    "    scripts_dir = \"/Users/acabrejasegea/sumo-0.32/tools/\"\n",
    "    runners_dir = \"/Users/acabrejasegea/Desktop/ATI_Project/MLforFlowOptimisation/\"\n",
    "elif OS==\"windows\":\n",
    "    networks_dir = \"C:\\\\Users\\\\acabrejasegea\\\\OneDrive - The Alan Turing Institute\\\\Desktop\\\\ATI\\\\0_TMF\\\\MLforFlowOptimisation\\\\Networks\"\n",
    "    scripts_dir = \"C:\\\\Program Files (x86)\\\\DLR\\\\Sumo\\\\tools\\\\\"\n",
    "    runners_dir = \"C:\\\\Users\\\\acabrejasegea\\\\OneDrive - The Alan Turing Institute\\\\Desktop\\\\ATI\\\\0_TMF\\\\MLforFlowOptimisation\\\\Runners\"\n",
    "else:\n",
    "    sys.exit(\"Please declare a supported operative system\")\n",
    "notebook = (os.path.splitext(notebook_name))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a route file for the simulation\n",
    "def generate_routefile(simulation_length):\n",
    "    random.seed(17)  # make tests reproducible\n",
    "    time_counter = 0\n",
    "    # demand per second from different directions\n",
    "    if demand == \"fixed\":\n",
    "        pWE  = 1. / 8\n",
    "        pEW  = 1. / 8\n",
    "        pNS1 = 1. / 20\n",
    "        pNS2 = 1. / 20\n",
    "        pNS3 = 1. / 20\n",
    "        pSN1 = 1. / 20\n",
    "        pSN2 = 1. / 20\n",
    "        pSN3 = 1. / 20\n",
    "    elif demand == \"random\":\n",
    "        thresholds = np.linspace(0,simulation_length,6)\n",
    "        pWE_v  = np.linspace(0.04, 0.16, 5)\n",
    "        pEW_v  = np.linspace(0.04, 0.16, 5)\n",
    "        pNS1_v = np.linspace(0.02, 0.08, 5)\n",
    "        pNS2_v = np.linspace(0.02, 0.08, 5)\n",
    "        pNS3_v = np.linspace(0.02, 0.08, 5)\n",
    "        pSN1_v = np.linspace(0.02, 0.08, 5)\n",
    "        pSN2_v = np.linspace(0.02, 0.08, 5)\n",
    "        pSN3_v = np.linspace(0.02, 0.08, 5)\n",
    "    else:\n",
    "        sys.exit(\"Error in kind of demand, please choose random or fixed\")\n",
    "    \n",
    "    \n",
    "    # Algorithmic access to routefile (names need to be consistent)\n",
    "    with open(os.path.join(networks_dir, used_map, (used_map + '.rou.xml')), \"w\") as routes:\n",
    "        print(\"\"\"<routes>\n",
    "        <vType id=\"typeWE\" accel=\"0.8\" decel=\"4.5\" sigma=\"0.5\" length=\"5\" minGap=\"2\" maxSpeed=\"25\" guiShape=\"passenger\"/>\n",
    "        <vType id=\"typeNS\" accel=\"0.8\" decel=\"4.5\" sigma=\"0.5\" length=\"5\" minGap=\"2\" maxSpeed=\"25\" guiShape=\"passenger\"/>\n",
    "\n",
    "        <route id=\"right\" edges=\"iW iCW oCE oE\" />\n",
    "        <route id=\"left\" edges=\"iE iCE oCW oW\" />\n",
    "        <route id=\"down1\" edges=\"iN1 oS1\" />\n",
    "        <route id=\"down2\" edges=\"iN2 oS2\" />\n",
    "        <route id=\"down3\" edges=\"iN3 oS3\" />\n",
    "        <route id=\"up1\" edges=\"iS1 oN1\" />\n",
    "        <route id=\"up2\" edges=\"iS2 oN2\" />\n",
    "        <route id=\"up3\" edges=\"iS3 oN3\" />\"\"\", file=routes)\n",
    "        lastVeh = 0\n",
    "        vehNr = 0\n",
    "        for i in range(simulation_length):\n",
    "            if demand == \"random\":\n",
    "                if i in thresholds:\n",
    "                    pWE  = random.choice(pWE_v)\n",
    "                    pEW  = random.choice(pEW_v)\n",
    "                    pNS1 = random.choice(pNS1_v)\n",
    "                    pNS2 = random.choice(pNS2_v)\n",
    "                    pNS3 = random.choice(pNS3_v)\n",
    "                    pSN1 = random.choice(pSN1_v)\n",
    "                    pSN2 = random.choice(pSN2_v)\n",
    "                    pSN3 = random.choice(pSN3_v)\n",
    "            \n",
    "            if random.uniform(0, 1) < pWE:\n",
    "                print('    <vehicle id=\"right_%i\" type=\"typeWE\" route=\"right\" depart=\"%i\" color=\"0,1,0\"/>' % (\n",
    "                    vehNr, i), file=routes)\n",
    "                vehNr += 1\n",
    "                lastVeh = i\n",
    "            if random.uniform(0, 1) < pEW:\n",
    "                print('    <vehicle id=\"left_%i\" type=\"typeWE\" route=\"left\" depart=\"%i\" color=\"0,1,0\"/>' % (\n",
    "                    vehNr, i), file=routes)\n",
    "                vehNr += 1\n",
    "                lastVeh = i\n",
    "            if random.uniform(0, 1) < pNS1:\n",
    "                print('    <vehicle id=\"down_%i\" type=\"typeNS\" route=\"down1\" depart=\"%i\" color=\"0,1,0\"/>' % (\n",
    "                    vehNr, i), file=routes)\n",
    "                vehNr += 1\n",
    "                lastVeh = i\n",
    "            if random.uniform(0, 1) < pNS2:\n",
    "                print('    <vehicle id=\"down_%i\" type=\"typeNS\" route=\"down2\" depart=\"%i\" color=\"0,1,0\"/>' % (\n",
    "                    vehNr, i), file=routes)\n",
    "                vehNr += 1\n",
    "                lastVeh = i\n",
    "            if random.uniform(0, 1) < pNS3:\n",
    "                print('    <vehicle id=\"down_%i\" type=\"typeNS\" route=\"down3\" depart=\"%i\" color=\"0,1,0\"/>' % (\n",
    "                    vehNr, i), file=routes)\n",
    "                vehNr += 1\n",
    "                lastVeh = i\n",
    "            if random.uniform(0, 1) < pSN1:\n",
    "                print('    <vehicle id=\"down_%i\" type=\"typeNS\" route=\"up1\" depart=\"%i\" color=\"0,1,0\"/>' % (\n",
    "                    vehNr, i), file=routes)\n",
    "                vehNr += 1\n",
    "                lastVeh = i\n",
    "            if random.uniform(0, 1) < pSN2:\n",
    "                print('    <vehicle id=\"down_%i\" type=\"typeNS\" route=\"up2\" depart=\"%i\" color=\"0,1,0\"/>' % (\n",
    "                    vehNr, i), file=routes)\n",
    "                vehNr += 1\n",
    "                lastVeh = i\n",
    "            if random.uniform(0, 1) < pSN3:\n",
    "                print('    <vehicle id=\"down_%i\" type=\"typeNS\" route=\"up3\" depart=\"%i\" color=\"0,1,0\"/>' % (\n",
    "                    vehNr, i), file=routes)\n",
    "                vehNr += 1\n",
    "                lastVeh = i\n",
    "        print(\"</routes>\", file=routes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkParser:\n",
    "\n",
    "    def __init__(self, file_path):\n",
    "        self.junctions = dict()\n",
    "        self.junction_lights = dict()\n",
    "\n",
    "        with open(file_path) as f:\n",
    "            self.file = xmltodict.parse(f.read())\n",
    "\n",
    "    def get_lane_ids(self):\n",
    "        for junction in self.file['net']['junction']:\n",
    "            if junction['@type'] == 'traffic_light':\n",
    "                self.junctions[junction['@id']] = junction['@incLanes'].split(' ')\n",
    "        return self.junctions\n",
    "\n",
    "    # Given a LaneID it returns the traffic light ID\n",
    "    def get_trafficlights_by_laneID(self, laneID):\n",
    "        for connection in self.file['net']['connection']:\n",
    "            if connection['@from'] == laneID.split('_')[0] and '@tl' in connection:\n",
    "                return connection['@tl']\n",
    "\n",
    "    def get_junction_trafficlights(self):\n",
    "        # If the dictionarty for junctions is empty\n",
    "        if not self.junctions:\n",
    "            self.get_lane_ids()\n",
    "        for junctionID in self.junctions.keys():\n",
    "            for lane in self.junctions[junctionID]:\n",
    "                traffic_light = self.get_trafficlights_by_laneID(lane)\n",
    "                if traffic_light in self.junction_lights and lane not in self.junction_lights[traffic_light]:\n",
    "                    self.junction_lights[traffic_light].append(lane)\n",
    "                else:\n",
    "                    self.junction_lights[traffic_light] = []\n",
    "        return self.junction_lights\n",
    "\n",
    "    def get_traffic_light(self, laneID):\n",
    "        if not self.junction_lights:\n",
    "            self.get_junction_trafficlights()\n",
    "        for traffic_light, lanes in self.junction_lights.iteritems():\n",
    "            if laneID in lanes:\n",
    "                return traffic_light\n",
    "\n",
    "    def get_phases(self, traffic_light):\n",
    "        phases = []\n",
    "        z = 0\n",
    "        for tls in self.file['net']['tlLogic']:\n",
    "            if z < 1:\n",
    "                a=0\n",
    "            z+=1\n",
    "            if tls['@id'] == traffic_light:\n",
    "                for tls_phase in tls['phase']:\n",
    "                    phases.append(tls_phase)\n",
    "        return phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qlearner:\n",
    "    def __init__(self,TLid,lanes,phases):\n",
    "        self.jid     = TLid\n",
    "        self.laneids = lanes\n",
    "        self.Nlanes  = len(self.laneids)                                #len(nodes.junctions[self.jid])\n",
    "        self.phases  = range(0, 23)                            #traci.trafficlights.getallPhases\n",
    "        num_phases   = len(self.phases)\n",
    "        self.Qm      = np.zeros((275, 11))\n",
    "        \n",
    "        self.state   = 0\n",
    "        self.action  = 0\n",
    "        self.neighbor_state = 0\n",
    "                                \n",
    "        self.cycle_time = 90\n",
    "        \n",
    "        self.historic_reward = list()\n",
    "        self.historic_queues = [[] for x in range(self.Nlanes)]\n",
    "  \n",
    "    def set_action(self,action, ):\n",
    "        traci.trafficlights.setProgram(self.jid, str(action))\n",
    "                                                                \n",
    "\n",
    "    def get_reward(self):\n",
    "        # Reward defined as a measure of the amount of waiting in the intersection\n",
    "        return -sum([traci.lane.getLastStepHaltingNumber(lane_id) for lane_id in self.laneids])\n",
    " \n",
    "\n",
    "    def get_state(self,threshold_l=3):\n",
    "        # State is defined as a combination b/w 5 load level for the 2 routes\n",
    "        NS_occupancy = traci.lane.getLastStepHaltingNumber(self.laneids[0]) + traci.lane.getLastStepHaltingNumber(self.laneids[2])\n",
    "        EW_occupancy = traci.lane.getLastStepHaltingNumber(self.laneids[1]) + traci.lane.getLastStepHaltingNumber(self.laneids[3])\n",
    "\n",
    "        NS_state = np.trunc(NS_occupancy/3)\n",
    "        EW_state = np.trunc(EW_occupancy/3)\n",
    "        \n",
    "        if NS_state > 4:\n",
    "            NS_state = 4\n",
    "        if EW_state >4:\n",
    "            EW_state = 4\n",
    "        \n",
    "        if self.jid == learners[0].jid:\n",
    "            self.neighbor_state = 0\n",
    "        elif self.jid == learners[1].jid:\n",
    "            self.neighbor_state = traci.trafficlights.getProgram(\"Centre1\")\n",
    "        elif self.jid == learners[2].jid:\n",
    "            self.neighbor_state = traci.trafficlights.getProgram(\"Centre2\")\n",
    "        else:\n",
    "            sys.exit(\"Error in getProgram or self.jid\")\n",
    "        \n",
    "        state = int(NS_state + 5* EW_state + 25* np.float64(self.neighbor_state))\n",
    "\n",
    "        return(state)\n",
    "\n",
    "    def update(self,gamma=0.8,alpha=0.95,epsilon=0.025):\n",
    "        \n",
    "        # Get current state, action from class\n",
    "        state    = self.state\n",
    "        action   = self.action\n",
    "        # Generate new action and the reward\n",
    "        newstate = self.get_state()\n",
    "        reward   = self.get_reward()\n",
    "        self.historic_reward.append(reward)\n",
    "\n",
    "        # Update the Q matrix\n",
    "        self.Qm[state, action] = self.Qm[state, action]*(1-alpha) + alpha*(reward + gamma*np.max(self.Qm[newstate,:]))\n",
    "\n",
    "        # Explore or exploit\n",
    "        r=np.random.rand(1)\n",
    "        if r > epsilon :\n",
    "            newaction = np.argmax(self.Qm[state,:])\n",
    "        else:\n",
    "            newaction = np.random.randint(0, 10)\n",
    "    \n",
    "        # Set variables for next loop and reset cycle timer\n",
    "        self.state = newstate\n",
    "        self.action = newaction\n",
    "                                \n",
    "        self.set_action(newaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(learners = []):\n",
    "    cycle_timer = 0\n",
    "    timer = 0\n",
    "    while traci.simulation.getMinExpectedNumber() > 0:\n",
    "        traci.simulationStep()\n",
    "        timer = timer + 1\n",
    "        if cycle_timer == 90:\n",
    "            for learner in learners:\n",
    "                learner.update()\n",
    "            cycle_timer = 0\n",
    "        else:\n",
    "            cycle_timer = cycle_timer + 1    \n",
    "        if queue_tracking == True:\n",
    "            combined_queue.append(traci.lane.getLastStepHaltingNumber(learners[0].laneids[0])+\n",
    "                                     traci.lane.getLastStepHaltingNumber(learners[0].laneids[1])+\n",
    "                                     traci.lane.getLastStepHaltingNumber(learners[0].laneids[2])+\n",
    "                                     traci.lane.getLastStepHaltingNumber(learners[0].laneids[3])+\n",
    "                                     traci.lane.getLastStepHaltingNumber(learners[1].laneids[0])+\n",
    "                                     traci.lane.getLastStepHaltingNumber(learners[1].laneids[1])+\n",
    "                                     traci.lane.getLastStepHaltingNumber(learners[1].laneids[2])+\n",
    "                                     traci.lane.getLastStepHaltingNumber(learners[1].laneids[3])+\n",
    "                                     traci.lane.getLastStepHaltingNumber(learners[2].laneids[0])+\n",
    "                                     traci.lane.getLastStepHaltingNumber(learners[2].laneids[1])+\n",
    "                                     traci.lane.getLastStepHaltingNumber(learners[2].laneids[2])+\n",
    "                                     traci.lane.getLastStepHaltingNumber(learners[2].laneids[3]))\n",
    "            for j in range(3):\n",
    "                for k in range(4):\n",
    "                    learners[j].historic_queues[k].append(traci.lane.getLastStepHaltingNumber(learners[j].laneids[k]))\n",
    "            \n",
    "        if positional_tracking == True:\n",
    "            vehicles = traci.vehicle.getIDList()\n",
    "            for vehicle in vehicles:\n",
    "                tracking_data[timer].append(tuple((vehicle, \n",
    "                                                    traci.vehicle.getPosition(vehicle),\n",
    "                                                    traci.vehicle.getCO2Emission(vehicle),\n",
    "                                                    traci.vehicle.getNOxEmission(vehicle))))\n",
    "        \n",
    "        if color_vehicles == True:\n",
    "            vehicleIDs = traci.vehicle.getIDList()\n",
    "            waiting_time = list()\n",
    "            for vehicle in vehicleIDs:\n",
    "                wait = traci.vehicle.getWaitingTime(vehicle)\n",
    "                if wait >= 45:\n",
    "                    traci.vehicle.setColor(vehicle,(255,0,0,255))\n",
    "                elif wait >= 20:\n",
    "                    traci.vehicle.setColor(vehicle,(255,165,0,255)) \n",
    "                elif wait >= 1:\n",
    "                    traci.vehicle.setColor(vehicle,(255,255,0,255))\n",
    "                if persistent_color == False:\n",
    "                    if wait < 1:\n",
    "                        traci.vehicle.setColor(vehicle,(0,255,0,255))\n",
    "\n",
    "    \n",
    "    sys.stdout.flush()\n",
    "\n",
    "### ORIGINAL SIMPLE CONTROLLER BELOW ###\n",
    "# The program looks like this\n",
    "#    <tlLogic id=\"0\" type=\"static\" programID=\"0\" offset=\"0\">\n",
    "# the locations of the tls are      NESW\n",
    "#        <phase duration=\"31\" state=\"GrGr\"/>\n",
    "#        <phase duration=\"6\"  state=\"yryr\"/>\n",
    "#        <phase duration=\"31\" state=\"rGrG\"/>\n",
    "#        <phase duration=\"6\"  state=\"ryry\"/>\n",
    "#    </tlLogic>\n",
    "#\n",
    "#def run():\n",
    "#    \"\"\"execute the TraCI control loop\"\"\"\n",
    "#    step = 0\n",
    "#    # we start with phase 2 where EW has green\n",
    "#    traci.trafficlight.setPhase(\"0\", 2)\n",
    "#    while traci.simulation.getMinExpectedNumber() > 0:\n",
    "#        traci.simulationStep()\n",
    "#        if traci.trafficlight.getPhase(\"0\") == 2:\n",
    "#            # we are not already switching\n",
    "#            if traci.inductionloop.getLastStepVehicleNumber(\"0\") > 0:\n",
    "#                # there is a vehicle from the north, switch\n",
    "#                traci.trafficlight.setPhase(\"0\", 3)\n",
    "#            else:\n",
    "#                # otherwise try to keep green for EW\n",
    "#                traci.trafficlight.setPhase(\"0\", 2)\n",
    "#        step += 1\n",
    "#    traci.close()\n",
    "#    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_options():\n",
    "    optParser = optparse.OptionParser()\n",
    "    optParser.add_option(\"--nogui\", action=\"store_true\",\n",
    "                         default=False, help=\"run the commandline version of sumo\")\n",
    "    options, args = optParser.parse_args()\n",
    "    return options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deployment of Network Parser (input is network file)\n",
    "npa = NetworkParser(os.path.join(networks_dir, used_map, (used_map + '.net.xml')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = npa.junctions\n",
    "phase_list = [len(npa.get_phases(k)) for k in npa.get_junction_trafficlights().keys()]\n",
    "node_list = list(nodes.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Centre1': ['iN1_0', 'oCW_0', 'iS1_0', 'iW_0'], 'Centre2': ['iN2_0', 'iCE_0', 'iS2_0', 'iCW_0'], 'Centre3': ['iN3_0', 'iE_0', 'iS3_0', 'oCE_0']}\n",
      "dict_keys(['Centre1', 'Centre2', 'Centre3'])\n",
      "[44, 44, 44]\n"
     ]
    }
   ],
   "source": [
    "# Checks\n",
    "print(nodes)\n",
    "print(nodes.keys())\n",
    "print(phase_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_routefile(simulation_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumoBinary = checkBinary('sumo-gui')\n",
    "# OR\n",
    "#sumoBinary = checkBinary('sumo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "learners=[Qlearner(ID,lan,p) for ID, lan, p in zip(nodes.keys(),nodes.values(),phase_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pre-trained Q-matrix from file: \n",
      "C:\\Users\\acabrejasegea\\OneDrive - The Alan Turing Institute\\Desktop\\ATI\\0_TMF\\MLforFlowOptimisation\\Networkstriple_straight_random\\Qm_0random.npy\n",
      "Loaded pre-trained Q-matrix from file: \n",
      "C:\\Users\\acabrejasegea\\OneDrive - The Alan Turing Institute\\Desktop\\ATI\\0_TMF\\MLforFlowOptimisation\\Networkstriple_straight_random\\Qm_1random.npy\n",
      "Loaded pre-trained Q-matrix from file: \n",
      "C:\\Users\\acabrejasegea\\OneDrive - The Alan Turing Institute\\Desktop\\ATI\\0_TMF\\MLforFlowOptimisation\\Networkstriple_straight_random\\Qm_2random.npy\n"
     ]
    }
   ],
   "source": [
    "if reloadQm == True:\n",
    "    for i in range(len(nodes.keys())):\n",
    "        if OS == \"iOS\":\n",
    "            learners[i].Qm = np.load(networks_dir+used_map+\"/\"+\"Qm_\" + str(i)+ demand  + \".npy\")\n",
    "            print(\"Loaded pre-trained Q-matrix from file: \"+'\\n'+networks_dir+used_map+\"/\"+\"Qm_\" + str(i)+ demand  + \".npy\")\n",
    "            with open(networks_dir+used_map+\"/\"+\"Reward_\" + str(i) + demand  + \".pickle\", 'rb') as fp:\n",
    "                learners[i].historic_reward = pickle.load(fp)\n",
    "            print(\"Loaded Reward history to file: \"+networks_dir+used_map+\"/\"+\"Reward_\" + str(i) + demand  + \".pickle\")\n",
    "        elif OS == \"windows\":\n",
    "            learners[i].Qm = np.load(networks_dir+\"\\\\\"+used_map+\"\\\\\"+\"Qm_\" + str(i)+ demand  + \".npy\")\n",
    "            print(\"Loaded pre-trained Q-matrix from file: \"+'\\n'+networks_dir+used_map+\"\\\\\"+\"Qm_\" + str(i)+ demand  + \".npy\")\n",
    "            #with open(networks_dir+\"\\\\\"+used_map+\"\\\\\"+\"Reward_\" + str(i) + demand  + \".pickle\", 'rb') as fp:\n",
    "            #    learners[i].historic_reward = pickle.load(fp)\n",
    "            #print(\"Loaded Reward history to file: \"+networks_dir+\"\\\\\"+used_map+\"\\\\\"+\"Reward_\" + str(i) + demand  + \".pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 'SUMO 0.32.0')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traci.start([sumoBinary, \"-c\", os.path.join(networks_dir, used_map, (used_map + '.sumocfg')),\n",
    "                             \"--tripinfo-output\", os.path.join((notebook + '_out'), 'tripinfo.xml')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\DLR\\Sumo\\tools\\traci\\domain.py:112: UserWarning: The domain trafficlights is deprecated, use trafficlight instead.\n",
      "  self._name, self._deprecatedFor))  # , DeprecationWarning)\n"
     ]
    },
    {
     "ename": "FatalTraCIError",
     "evalue": "connection closed by SUMO",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFatalTraCIError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-ae4b1d81d491>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-33-3b2170a2d97f>\u001b[0m in \u001b[0;36mrun\u001b[1;34m(learners)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mtimer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0mtraci\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimulation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetMinExpectedNumber\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mtraci\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimulationStep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mtimer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimer\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcycle_timer\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m90\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\DLR\\Sumo\\tools\\traci\\__init__.py\u001b[0m in \u001b[0;36msimulationStep\u001b[1;34m(step)\u001b[0m\n\u001b[0;32m    107\u001b[0m     \"\"\"\n\u001b[0;32m    108\u001b[0m     \u001b[1;32mglobal\u001b[0m \u001b[0m_stepListeners\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m     \u001b[0mresponses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_connections\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimulationStep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mlistener\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_stepListeners\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[0mlistener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\DLR\\Sumo\\tools\\traci\\connection.py\u001b[0m in \u001b[0;36msimulationStep\u001b[1;34m(self, step)\u001b[0m\n\u001b[0;32m    273\u001b[0m         self._string += struct.pack(\"!BBi\", 1 +\n\u001b[0;32m    274\u001b[0m                                     1 + 4, tc.CMD_SIMSTEP, step)\n\u001b[1;32m--> 275\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sendExact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    276\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0msubscriptionResults\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_subscriptionMapping\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m             \u001b[0msubscriptionResults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\DLR\\Sumo\\tools\\traci\\connection.py\u001b[0m in \u001b[0;36m_sendExact\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     95\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_socket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_socket\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mFatalTraCIError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"connection closed by SUMO\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcommand\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m             \u001b[0mprefix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"!BBB\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFatalTraCIError\u001b[0m: connection closed by SUMO"
     ]
    }
   ],
   "source": [
    "run(learners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if saveQm == True:\n",
    "    for i in range(len(nodes.keys())):\n",
    "        if OS == \"iOS\":\n",
    "            np.save(networks_dir+used_map+\"/\"+\"Qm_\" + str(i) + demand + \".npy\", learners[i].Qm)\n",
    "            print(\"Saved Q-matrix to file: \"+'\\n'+networks_dir+used_map+\"/\"+\"Qm_\" + str(i) + demand + \".npy\")\n",
    "            with open(networks_dir+used_map+\"/\"+\"Reward_\" + str(i) + demand + \".pickle\", 'wb') as fp:\n",
    "                pickle.dump(learners[i].historic_reward, fp)\n",
    "            print(\"Saved Reward history to file: \"+'\\n'+networks_dir+used_map+\"/\"+\"Reward_\" + str(i) + demand + \".pickle\")\n",
    "        elif OS == \"windows\":\n",
    "            np.save(networks_dir+\"\\\\\"+used_map+\"\\\\\"+\"Qm_\" + str(i) + demand + \".npy\", learners[i].Qm)\n",
    "            print(\"Saved Q-matrix to file: \"+'\\n'+networks_dir+\"\\\\\"+used_map+\"\\\\\"+\"Qm_\" + str(i) + demand + \".npy\")\n",
    "            with open(networks_dir+\"\\\\\"+used_map+\"\\\\\"+\"Reward_\" + str(i) + demand + \".pickle\", 'wb') as fp:\n",
    "                pickle.dump(learners[i].historic_reward, fp)\n",
    "            print(\"Saved Reward history to file: \"+'\\n'+networks_dir+\"\\\\\"+used_map+\"\\\\\"+\"Reward_\" + str(i) + demand + \".pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learners[1].Qm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# PLOT GLOBAL TRAINING\n",
    "plt.figure(figsize=(20,10))\n",
    "plot_series = [x+y+z for x,y,z in zip(learners[0].historic_reward,learners[1].historic_reward,learners[2].historic_reward)]\n",
    "plt.plot(plot_series[0:5000])\n",
    "\n",
    "xcoords = [0,1000,2000,3000,4000,5000]\n",
    "for xc in xcoords:\n",
    "    plt.axvline(x=xc, color='red')\n",
    "    \n",
    "texts = ['Demand Regime 1', 'Demand Regime 2', 'Demand Regime 3', 'Demand Regime 4', 'Demand Regime 5' ]\n",
    "for i in range(len(texts)):\n",
    "    plt.text(xcoords[i]+160,-100,texts[i], fontsize = 14, color='red')\n",
    "\n",
    "plt.title(\"Instantaneous reward over time, \"+r'$\\alpha = 0.95, $' + r'$\\epsilon=0.025$', fontsize = 20)\n",
    "plt.xlabel(\"Time [cycles]\"       , fontsize=16)\n",
    "plt.ylabel(\"Instantaneous Reward\", fontsize=16)\n",
    "\n",
    "savedir = 'C:\\\\Users\\\\acabrejasegea\\\\OneDrive - The Alan Turing Institute\\\\Desktop\\\\ATI\\\\07_End_of_Internship_Presentation\\\\'\n",
    "filename = 'trained_global_'+used_map+'_untrained.png'\n",
    "plt.savefig(savedir+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT TRAINING PER LEARNER\n",
    "chosen_learner = 2\n",
    "plt.figure(figsize=(20,10))\n",
    "plot_series = learners[chosen_learner].historic_reward\n",
    "plt.plot(plot_series[0:5000])\n",
    "\n",
    "xcoords = [0,1000,2000,3000,4000,5000]\n",
    "for xc in xcoords:\n",
    "    plt.axvline(x=xc, color='red')\n",
    "    \n",
    "texts = ['Demand Regime 1', 'Demand Regime 2', 'Demand Regime 3', 'Demand Regime 4', 'Demand Regime 5' ]\n",
    "for i in range(len(texts)):\n",
    "    plt.text(xcoords[i]+160,-53,texts[i], fontsize = 14, color='red')\n",
    "\n",
    "plt.title(\"Instantaneous reward over time in Learner \"+str(chosen_learner)+\", \"+r'$\\alpha = 0.95, $' + r'$\\epsilon=0.025$', fontsize = 20)\n",
    "plt.xlabel(\"Time [cycles]\"       , fontsize=16)\n",
    "plt.ylabel(\"Instantaneous Reward\", fontsize=16)\n",
    "plt.ylim(-55,0)\n",
    "\n",
    "savedir = 'C:\\\\Users\\\\acabrejasegea\\\\OneDrive - The Alan Turing Institute\\\\Desktop\\\\ATI\\\\07_End_of_Internship_Presentation\\\\'\n",
    "filename = 'trained_partial_'+used_map+'_untrained_learner_'+str(chosen_learner)+'.png'\n",
    "plt.savefig(savedir+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_cycle = combined_queue[0:90000]\n",
    "#untrained_cycle = combined_queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_cycle = trained_cycle[0:90000]\n",
    "untrained_cycle = untrained_cycle[0:90000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(trained_cycle[0:15000], color = 'blue', label = \"Trained Controller\")\n",
    "\n",
    " \n",
    "plt.plot(untrained_cycle[0:15000], color = 'red', label = \"Untrained Controller\")\n",
    "plt.legend(prop={'size' : 16})\n",
    "\n",
    "plt.title(\"Total stopped vehicles in the model\", fontsize = 20)\n",
    "plt.xlabel(\"Time [seconds]\"       , fontsize=16)\n",
    "plt.ylabel(\"Aggregated queue length [vehicles]\", fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PLOT FOR QUEUES\n",
    "chosen_learner = 2\n",
    "plt.figure(figsize=(20,20))\n",
    "y1 = learners[chosen_learner].historic_queues[0][0:450000]\n",
    "y2 = learners[chosen_learner].historic_queues[1][0:450000]\n",
    "y3 = learners[chosen_learner].historic_queues[2][0:450000]\n",
    "y4 = learners[chosen_learner].historic_queues[3][0:450000]\n",
    "\n",
    "x1 = range(len(y1))\n",
    "x2 = range(len(y1))\n",
    "x3 = range(len(y1))\n",
    "x4 = range(len(y1))\n",
    "\n",
    "plt.subplot(4, 1, 1)\n",
    "plt.plot(x1, y1, '-')\n",
    "plt.ylim(0,25)\n",
    "plt.title('Queues in learner '+str(chosen_learner))\n",
    "plt.ylabel('North Queue Length')\n",
    "xcoords = [0,90000,180000,270000,360000,450000]\n",
    "for xc in xcoords:\n",
    "    plt.axvline(x=xc, color='red')\n",
    "    \n",
    "texts = ['Demand Regime 1', 'Demand Regime 2', 'Demand Regime 3', 'Demand Regime 4', 'Demand Regime 5' ]\n",
    "for i in range(len(texts)):\n",
    "    plt.text(xcoords[i]+16000,23,texts[i], fontsize = 14, color='red')\n",
    "    \n",
    "\n",
    "plt.subplot(4, 1, 2)\n",
    "plt.plot(x2, y2, '-')\n",
    "plt.ylim(0,25)\n",
    "plt.ylabel('West Queue Length')\n",
    "xcoords = [0,90000,180000,270000,360000,450000]\n",
    "for xc in xcoords:\n",
    "    plt.axvline(x=xc, color='red')\n",
    "\n",
    "plt.subplot(4, 1, 3)\n",
    "plt.plot(x1, y1, '-')\n",
    "plt.ylim(0,25)\n",
    "plt.ylabel('South Queue Length')\n",
    "xcoords = [0,90000,180000,270000,360000,450000]\n",
    "for xc in xcoords:\n",
    "    plt.axvline(x=xc, color='red')\n",
    "\n",
    "plt.subplot(4, 1, 4)\n",
    "plt.plot(x2, y2, '-')\n",
    "plt.ylim(0,25)\n",
    "plt.xlabel('Time [s]')\n",
    "plt.ylabel('East Queue Length')\n",
    "xcoords = [0,90000,180000,270000,360000,450000]\n",
    "for xc in xcoords:\n",
    "    plt.axvline(x=xc, color='red')\n",
    "\n",
    "savedir = 'C:\\\\Users\\\\acabrejasegea\\\\OneDrive - The Alan Turing Institute\\\\Desktop\\\\ATI\\\\07_End_of_Internship_Presentation\\\\'\n",
    "filename = 'queues_'+used_map+'_trained_learner_'+str(chosen_learner)+'.png'\n",
    "plt.savefig(savedir+filename)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Exporting Positional data as JSON\n",
    "with open(used_map+'_timesteps_'+str(tracking_length)+'.json', 'w') as outfile:\n",
    "    json.dump(positional_data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = json.loads(output)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
